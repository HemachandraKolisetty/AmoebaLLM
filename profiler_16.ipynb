{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 16, 17, 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.2887797150760889), 2: (1, 0.1443628091365099), 3: (1, 0.15452068857848644), 4: (1, 0.15293646696954966), 5: (1, 0.1912410780787468), 6: (1, 0.14886878617107868), 7: (1, 0.1368118766695261), 8: (1, 0.14045030437409878), 9: (1, 0.1370630133897066), 10: (1, 0.14042172394692898), 11: (1, 0.1391049800440669), 12: (1, 0.14241797011345625), 13: (1, 0.14120514504611492), 14: (1, 0.1445187358185649), 15: (1, 0.14395228307694197), 16: (1, 0.1394538562744856), 17: (1, 0.14089627750217915), 18: (1, 0.14673739951103926), 19: (1, 0.14100003708153963), 20: (1, 0.14461540523916483), 21: (1, 0.14501168113201857), 22: (1, 0.14027496613562107), 23: (1, 0.14065397158265114), 24: (1, 0.14129382371902466), 25: (1, 0.1387761440128088), 26: (1, 0.13964967243373394), 27: (1, 0.13698746357113123), 28: (1, 0.1390821598470211), 29: (1, 0.1440248228609562), 30: (1, 0.13846521638333797), 31: (1, 0.13896409142762423), 32: (1, 0.13954314403235912), 33: (1, 0.13756740745157003), 34: (1, 0.13878365326672792), 35: (1, 0.13920679781585932), 36: (1, 0.1371518513187766), 37: (1, 0.14950102753937244), 38: (1, 0.14156132005155087), 39: (1, 0.1406780704855919), 40: (1, 0.13754224684089422), 41: (1, 0.14230412151664495), 42: (1, 0.13590517546981573), 43: (1, 0.13738898932933807), 44: (1, 0.1366178672760725), 45: (1, 0.1388093726709485), 46: (1, 0.1380697600543499), 47: (1, 0.15366621036082506), 48: (1, 0.13875919301062822), 49: (1, 0.13916000816971064), 50: (1, 0.14089976716786623), 51: (1, 0.13937386590987444), 52: (1, 0.13647930976003408), 53: (1, 0.13541201036423445), 54: (1, 0.1360165635123849), 55: (1, 0.14319472014904022), 56: (1, 0.1372373104095459), 57: (1, 0.14307282026857138), 58: (1, 0.14932687021791935), 59: (1, 0.13870439305901527), 60: (1, 0.14141786098480225), 61: (1, 0.14042760338634253), 62: (1, 0.14034496434032917), 63: (1, 0.1407107301056385), 64: (1, 0.14151700027287006), 65: (1, 0.13937874510884285), 66: (1, 0.13568095862865448), 67: (1, 0.138834360986948), 68: (1, 0.1371600916609168), 69: (1, 0.14784229546785355), 70: (1, 0.13896071910858154), 71: (1, 0.13891830947250128)}\n",
      "{1: (1, 127, 0.08334182318681338), 2: (1, 127, 0.08699231597734249), 3: (1, 127, 0.0887193702982636), 4: (1, 127, 0.08886234663192212), 5: (1, 127, 0.08581879110200198), 6: (1, 127, 0.08428262610457779), 7: (1, 127, 0.0823136140467731), 8: (1, 127, 0.08295522729946872), 9: (1, 127, 0.08391277401847398), 10: (1, 127, 0.0879225741749204), 11: (1, 127, 0.084004670469545), 12: (1, 127, 0.08274222966870219), 13: (1, 127, 0.08549716831074924), 14: (1, 127, 0.0835470624092057), 15: (1, 127, 0.08275429443932894), 16: (1, 127, 0.0856571001638695), 17: (1, 127, 0.08464983842650971), 18: (1, 127, 0.08540344414279216), 19: (1, 127, 0.08463775577742284), 20: (1, 127, 0.08350128569002227), 21: (1, 127, 0.08340852857222707), 22: (1, 127, 0.08277710566047843), 23: (1, 127, 0.08271685327718577), 24: (1, 127, 0.08294168357392699), 25: (1, 127, 0.08222956170775289), 26: (1, 127, 0.08316042280103278), 27: (1, 127, 0.08388130296403029), 28: (1, 127, 0.08540291528356826), 29: (1, 127, 0.08302540720007785), 30: (1, 127, 0.08287917714800656), 31: (1, 127, 0.08285718131077102), 32: (1, 127, 0.08287136049897183), 33: (1, 127, 0.08245346233190044), 34: (1, 127, 0.08274838966354141), 35: (1, 127, 0.08254102669568278), 36: (1, 127, 0.0852693792975207), 37: (1, 127, 0.08410025745131604), 38: (1, 127, 0.08293332393449826), 39: (1, 127, 0.08235376939822839), 40: (1, 127, 0.08235387307569736), 41: (1, 127, 0.08221892367197772), 42: (1, 127, 0.08201479878071255), 43: (1, 127, 0.08208511871703732), 44: (1, 127, 0.08235998612307892), 45: (1, 127, 0.08268429624928733), 46: (1, 127, 0.08507188760829489), 47: (1, 127, 0.08645781480861227), 48: (1, 127, 0.08246395857198031), 49: (1, 127, 0.0826639961451292), 50: (1, 127, 0.08253854466968868), 51: (1, 127, 0.08242927960259473), 52: (1, 127, 0.08265688937656053), 53: (1, 127, 0.08262566042932), 54: (1, 127, 0.08587977576883525), 55: (1, 127, 0.08315773479875148), 56: (1, 127, 0.08332536140031467), 57: (1, 127, 0.08435224490900209), 58: (1, 127, 0.08443929701603538), 59: (1, 127, 0.08385428530347394), 60: (1, 127, 0.0842572744407757), 61: (1, 127, 0.08374048594209388), 62: (1, 127, 0.08287067684953607), 63: (1, 127, 0.08334098306785184), 64: (1, 127, 0.0828667036221018), 65: (1, 127, 0.0830840894761752), 66: (1, 127, 0.08266454970273446), 67: (1, 127, 0.0825949896229651), 68: (1, 127, 0.08303632499928784), 69: (1, 127, 0.08397353791052431), 70: (1, 127, 0.08305721809192905)}\n",
      "{'predict_runtime': 764.9726, 'predict_samples_per_second': 0.093, 'predict_steps_per_second': 0.093}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:12:44.97\n",
      "  predict_samples_per_second =      0.093\n",
      "  predict_steps_per_second   =      0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.18975558690726757), 2: (2, 0.16585505567491055), 3: (2, 0.15928139351308346), 4: (2, 0.14682650845497847), 5: (2, 0.15887849684804678), 6: (2, 0.15410239342600107), 7: (2, 0.14599724765866995), 8: (2, 0.14721471164375544), 9: (2, 0.15993049461394548), 10: (2, 0.15931162051856518), 11: (2, 0.1461735349148512), 12: (2, 0.15653433371335268), 13: (2, 0.1509243594482541), 14: (2, 0.15929878037422895), 15: (2, 0.14565293956547976), 16: (2, 0.1578745674341917), 17: (2, 0.1554602961987257), 18: (2, 0.1439390704035759), 19: (2, 0.14438381511718035), 20: (2, 0.15843624155968428), 21: (2, 0.14391740132123232), 22: (2, 0.15718751586973667), 23: (2, 0.1427615536376834), 24: (2, 0.15728326421231031), 25: (2, 0.1567013105377555), 26: (2, 0.14306152891367674), 27: (2, 0.15540854632854462), 28: (2, 0.1519702458754182), 29: (2, 0.17268869373947382), 30: (2, 0.1584571683779359), 31: (2, 0.16392586566507816), 32: (2, 0.1454097218811512), 33: (2, 0.1469698939472437), 34: (2, 0.1453349320217967), 35: (2, 0.1507272683084011), 36: (2, 0.14939673524349928), 37: (2, 0.15745277144014835), 38: (2, 0.1448194682598114), 39: (2, 0.15084862895309925), 40: (2, 0.14593758527189493), 41: (2, 0.14544250071048737), 42: (2, 0.15411221887916327), 43: (2, 0.15815221332013607), 44: (2, 0.165420257486403), 45: (2, 0.15048589184880257), 46: (2, 0.14422193448990583), 47: (2, 0.1623035641387105), 48: (2, 0.16048997454345226), 49: (2, 0.1616670610383153), 50: (2, 0.15245554875582457), 51: (2, 0.1454374399036169), 52: (2, 0.14712854102253914), 53: (2, 0.14928058441728354), 54: (2, 0.1534469872713089), 55: (2, 0.16277498845010996), 56: (2, 0.1615789821371436), 57: (2, 0.1481678383424878), 58: (2, 0.1428527496755123), 59: (2, 0.16324369236826897), 60: (2, 0.1430099280551076), 61: (2, 0.15104859415441751), 62: (2, 0.15633326210081577), 63: (2, 0.16003840882331133), 64: (2, 0.15592285711318254), 65: (2, 0.14728344790637493), 66: (2, 0.14404117595404387), 67: (2, 0.16389392409473658), 68: (2, 0.14698838163167238), 69: (2, 0.14807036891579628), 70: (2, 0.1587592838332057), 71: (1, 0.13908893428742886)}\n",
      "{1: (2, 127, 0.12983720682884062), 2: (2, 127, 0.1293144852186986), 3: (2, 127, 0.1283961268156532), 4: (2, 127, 0.12831850561100666), 5: (2, 127, 0.1286986324657488), 6: (2, 127, 0.13009368777861746), 7: (2, 127, 0.12991867622169923), 8: (2, 127, 0.12847417034208775), 9: (2, 127, 0.12951519262544284), 10: (2, 127, 0.12860242132918806), 11: (2, 127, 0.12913217729206863), 12: (2, 127, 0.1295033882511413), 13: (2, 127, 0.12981302930614141), 14: (2, 127, 0.12966251558822206), 15: (2, 127, 0.12861663276168306), 16: (2, 127, 0.12916729470172267), 17: (2, 127, 0.1299526953160411), 18: (2, 127, 0.1282755092417044), 19: (2, 127, 0.1283696530548137), 20: (2, 127, 0.12836851229465854), 21: (2, 127, 0.1286678111884655), 22: (2, 127, 0.12837260970332492), 23: (2, 127, 0.1282386849157688), 24: (2, 127, 0.12838850995364387), 25: (2, 127, 0.12806556336435043), 26: (2, 127, 0.1302866367476545), 27: (2, 127, 0.12869254860469675), 28: (2, 127, 0.13012882162208164), 29: (2, 127, 0.1287165072005917), 30: (2, 127, 0.12846568960872456), 31: (2, 127, 0.1293284560033069), 32: (2, 127, 0.12890165888770358), 33: (2, 127, 0.1283673199597658), 34: (2, 127, 0.13147673415621436), 35: (2, 127, 0.13062597377827084), 36: (2, 127, 0.1286489444630822), 37: (2, 127, 0.1283912312782069), 38: (2, 127, 0.12894678670238321), 39: (2, 127, 0.13134365243558574), 40: (2, 127, 0.1295907992326955), 41: (2, 127, 0.13030629540522268), 42: (2, 127, 0.12878981644038376), 43: (2, 127, 0.13025490485689067), 44: (2, 127, 0.12981494003540184), 45: (2, 127, 0.1333779518998514), 46: (2, 127, 0.13234988118221205), 47: (2, 127, 0.1302576979299582), 48: (2, 127, 0.13373788705784975), 49: (2, 127, 0.128347498731409), 50: (2, 127, 0.13178860485612406), 51: (2, 127, 0.12944604523890602), 52: (2, 127, 0.13016993721111084), 53: (2, 127, 0.12973394075511244), 54: (2, 127, 0.13159537816229533), 55: (2, 127, 0.13153486464201936), 56: (2, 127, 0.12831271004929082), 57: (2, 127, 0.13019416487856408), 58: (2, 127, 0.13109266998495642), 59: (2, 127, 0.13104513324210493), 60: (2, 127, 0.12965688249462937), 61: (2, 127, 0.13021859588233506), 62: (2, 127, 0.1284824603009881), 63: (2, 127, 0.12968018310012544), 64: (2, 127, 0.1316473328134441), 65: (2, 127, 0.12872240624911202), 66: (2, 127, 0.12802231501729236), 67: (2, 127, 0.1303954495073069), 68: (2, 127, 0.1305362728505036), 69: (2, 127, 0.128806447991588), 70: (2, 127, 0.13221408849890073)}\n",
      "{'predict_runtime': 1174.1235, 'predict_samples_per_second': 0.12, 'predict_steps_per_second': 0.06}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:34.12\n",
      "  predict_samples_per_second =       0.12\n",
      "  predict_steps_per_second   =       0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.185707769356668), 2: (4, 0.15775413624942303), 3: (4, 0.1650179699063301), 4: (4, 0.15265821479260921), 5: (4, 0.16531131695955992), 6: (4, 0.16430582851171494), 7: (4, 0.1554157231003046), 8: (4, 0.1608815174549818), 9: (4, 0.17001786082983017), 10: (4, 0.1603948837146163), 11: (4, 0.15935712680220604), 12: (4, 0.15787610411643982), 13: (4, 0.15722057223320007), 14: (4, 0.15923427790403366), 15: (4, 0.16552534326910973), 16: (4, 0.1625228589400649), 17: (4, 0.16814079321920872), 18: (4, 0.17136254627257586), 19: (4, 0.1633569486439228), 20: (4, 0.15651818830519915), 21: (4, 0.16138012148439884), 22: (4, 0.16287060361355543), 23: (4, 0.15442941337823868), 24: (4, 0.16000171843916178), 25: (4, 0.15552201494574547), 26: (4, 0.15237732138484716), 27: (4, 0.1555964145809412), 28: (4, 0.15643860399723053), 29: (4, 0.15516546927392483), 30: (4, 0.15989464428275824), 31: (4, 0.159580928273499), 32: (4, 0.16012379061430693), 33: (4, 0.1585800303146243), 34: (4, 0.16519090253859758), 35: (4, 0.15661945194005966), 36: (4, 0.15645655151456594), 37: (4, 0.15448864549398422), 38: (4, 0.15603677835315466), 39: (4, 0.16039942670613527), 40: (4, 0.15930506959557533), 41: (4, 0.15583589859306812), 42: (4, 0.15881778299808502), 43: (4, 0.17207207065075636), 44: (4, 0.1611550860106945), 45: (4, 0.16383543517440557), 46: (4, 0.16640437580645084), 47: (4, 0.16080475971102715), 48: (4, 0.1575661776587367), 49: (4, 0.15938396658748388), 50: (4, 0.15736725833266973), 51: (4, 0.16951389890164137), 52: (4, 0.16927963215857744), 53: (4, 0.15969816222786903), 54: (4, 0.16373920533806086), 55: (4, 0.1683998303487897), 56: (4, 0.16086561791598797), 57: (4, 0.1567448554560542), 58: (4, 0.1622840203344822), 59: (4, 0.16089895833283663), 60: (4, 0.16738547291606665), 61: (4, 0.15640205889940262), 62: (4, 0.15422425419092178), 63: (4, 0.1713321777060628), 64: (4, 0.16126338299363852), 65: (4, 0.15899696853011847), 66: (4, 0.17723425943404436), 67: (4, 0.16049478109925985), 68: (4, 0.1544608399271965), 69: (4, 0.1697265738621354), 70: (4, 0.1570513704791665), 71: (1, 0.13719110935926437)}\n",
      "{1: (4, 127, 0.1301595292120116), 2: (4, 127, 0.128589032093195), 3: (4, 127, 0.12912683293047383), 4: (4, 127, 0.13076674749004089), 5: (4, 127, 0.13114950477372944), 6: (4, 127, 0.1310478217503804), 7: (4, 127, 0.1280304213223143), 8: (4, 127, 0.1288194294622916), 9: (4, 127, 0.1285569787714777), 10: (4, 127, 0.12923595779318744), 11: (4, 127, 0.12829198690468635), 12: (4, 127, 0.12851422495670675), 13: (4, 127, 0.1282920335001481), 14: (4, 127, 0.12831824804531541), 15: (4, 127, 0.1284391088704542), 16: (4, 127, 0.134138546326733), 17: (4, 127, 0.1301761150697437), 18: (4, 127, 0.12970389315022493), 19: (4, 127, 0.12920116805508147), 20: (4, 127, 0.12823496766271084), 21: (4, 127, 0.12812516953444153), 22: (4, 127, 0.12843622577442662), 23: (4, 127, 0.12934945204742546), 24: (4, 127, 0.1281768481474458), 25: (4, 127, 0.12849629911645424), 26: (4, 127, 0.1285444115413221), 27: (4, 127, 0.12852676474584604), 28: (4, 127, 0.12832198103552495), 29: (4, 127, 0.1284606468416457), 30: (4, 127, 0.12837480885658678), 31: (4, 127, 0.12826425533037722), 32: (4, 127, 0.12823904444294887), 33: (4, 127, 0.12920453281354483), 34: (4, 127, 0.1297929279990201), 35: (4, 127, 0.12872292980639718), 36: (4, 127, 0.12872254706215203), 37: (4, 127, 0.12940305351888334), 38: (4, 127, 0.128543968569106), 39: (4, 127, 0.12983185047005105), 40: (4, 127, 0.12959661166821643), 41: (4, 127, 0.12976567303453843), 42: (4, 127, 0.1308417759953052), 43: (4, 127, 0.1292577156078393), 44: (4, 127, 0.1294532488430227), 45: (4, 127, 0.12965991069364735), 46: (4, 127, 0.12849728711770744), 47: (4, 127, 0.12854802265293955), 48: (4, 127, 0.13018045361029115), 49: (4, 127, 0.12893504556268454), 50: (4, 127, 0.12910245795272232), 51: (4, 127, 0.1296191479658752), 52: (4, 127, 0.12888547346201235), 53: (4, 127, 0.12938037949548228), 54: (4, 127, 0.12985115397838862), 55: (4, 127, 0.12878041770162546), 56: (4, 127, 0.1295649120364133), 57: (4, 127, 0.1306551030917665), 58: (4, 127, 0.1291739868924139), 59: (4, 127, 0.12803244733757627), 60: (4, 127, 0.12851328595622083), 61: (4, 127, 0.12929833131864316), 62: (4, 127, 0.1298756804757231), 63: (4, 127, 0.12899501846853909), 64: (4, 127, 0.12921355492398728), 65: (4, 127, 0.12843817438724942), 66: (4, 127, 0.12844153528109076), 67: (4, 127, 0.12866552040626214), 68: (4, 127, 0.12879765273519153), 69: (4, 127, 0.1293788028763622), 70: (4, 127, 0.12855173230875194)}\n",
      "{'predict_runtime': 1170.5266, 'predict_samples_per_second': 0.24, 'predict_steps_per_second': 0.061}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:30.52\n",
      "  predict_samples_per_second =       0.24\n",
      "  predict_steps_per_second   =      0.061\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 16\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.1897322991862893), 2: (1, 0.14813998993486166), 3: (1, 0.14649410918354988), 4: (1, 0.14704889245331287), 5: (1, 0.14728027861565351), 6: (1, 0.14740551635622978), 7: (1, 0.14427790138870478), 8: (1, 0.14389807730913162), 9: (1, 0.14626819919794798), 10: (1, 0.14831313490867615), 11: (1, 0.1462171096354723), 12: (1, 0.1442479006946087), 13: (1, 0.14449437893927097), 14: (1, 0.14325102139264345), 15: (1, 0.1442579198628664), 16: (1, 0.14594561140984297), 17: (1, 0.14407983142882586), 18: (1, 0.14623367600142956), 19: (1, 0.144882682710886), 20: (1, 0.144362086430192), 21: (1, 0.1446632230654359), 22: (1, 0.14551701489835978), 23: (1, 0.14456270541995764), 24: (1, 0.14490855019539595), 25: (1, 0.14498836919665337), 26: (1, 0.1441623978316784), 27: (1, 0.14688763581216335), 28: (1, 0.14377171359956264), 29: (1, 0.14717469364404678), 30: (1, 0.1470534736290574), 31: (1, 0.14727135002613068), 32: (1, 0.14714569225907326), 33: (1, 0.14601599518209696), 34: (1, 0.1484807962551713), 35: (1, 0.14767944440245628), 36: (1, 0.1470053130760789), 37: (1, 0.14660375751554966), 38: (1, 0.147579587996006), 39: (1, 0.1470946753397584), 40: (1, 0.1463940516114235), 41: (1, 0.14877521432936192), 42: (1, 0.14498303551226854), 43: (1, 0.14753638673573732), 44: (1, 0.14596622344106436), 45: (1, 0.14602752216160297), 46: (1, 0.14401119388639927), 47: (1, 0.1468502813950181), 48: (1, 0.14738832507282495), 49: (1, 0.14576134365051985), 50: (1, 0.14721362572163343), 51: (1, 0.1461580079048872), 52: (1, 0.1445060959085822), 53: (1, 0.14703961554914713), 54: (1, 0.14664852991700172), 55: (1, 0.14438738487660885), 56: (1, 0.1457607289776206), 57: (1, 0.1468186154961586), 58: (1, 0.14678598567843437), 59: (1, 0.14428617432713509), 60: (1, 0.14507500547915697), 61: (1, 0.14424213394522667), 62: (1, 0.14403200428932905), 63: (1, 0.14769313391298056), 64: (1, 0.14425176195800304), 65: (1, 0.1451909700408578), 66: (1, 0.14637811668217182), 67: (1, 0.14689470082521439), 68: (1, 0.14423696044832468), 69: (1, 0.14527527801692486), 70: (1, 0.1470451969653368), 71: (1, 0.14329045079648495)}\n",
      "{1: (1, 127, 0.08874902932897327), 2: (1, 127, 0.08763291028247575), 3: (1, 127, 0.08728095540028857), 4: (1, 127, 0.08739140637834945), 5: (1, 127, 0.08740381950028533), 6: (1, 127, 0.08736269664400675), 7: (1, 127, 0.08746670154253329), 8: (1, 127, 0.0873562875753782), 9: (1, 127, 0.08743191195109229), 10: (1, 127, 0.08740082596553357), 11: (1, 127, 0.08741330210207485), 12: (1, 127, 0.0874150992906469), 13: (1, 127, 0.08751919853141693), 14: (1, 127, 0.0874359773427952), 15: (1, 127, 0.08748699600742323), 16: (1, 127, 0.08744067494119481), 17: (1, 127, 0.08750237058114818), 18: (1, 127, 0.08737533887862925), 19: (1, 127, 0.08748108636969187), 20: (1, 127, 0.08735219249135162), 21: (1, 127, 0.08741251522249828), 22: (1, 127, 0.08741389691653684), 23: (1, 127, 0.08754444286579222), 24: (1, 127, 0.08725169521763804), 25: (1, 127, 0.08716873356735143), 26: (1, 127, 0.08714672743423482), 27: (1, 127, 0.08721117909968369), 28: (1, 127, 0.0871718633171963), 29: (1, 127, 0.08721275684812407), 30: (1, 127, 0.08724126557078887), 31: (1, 127, 0.0873019498090927), 32: (1, 127, 0.087320050613324), 33: (1, 127, 0.0872445491941895), 34: (1, 127, 0.08722905668716027), 35: (1, 127, 0.08718600285452181), 36: (1, 127, 0.08720100778118363), 37: (1, 127, 0.08722202082377249), 38: (1, 127, 0.08723250704663475), 39: (1, 127, 0.08738188272503418), 40: (1, 127, 0.08741091386099735), 41: (1, 127, 0.08721522577693612), 42: (1, 127, 0.08714772272473714), 43: (1, 127, 0.08726469995673951), 44: (1, 127, 0.08723015228917044), 45: (1, 127, 0.08724103937673522), 46: (1, 127, 0.0871925257278357), 47: (1, 127, 0.08721980672534996), 48: (1, 127, 0.08719113694254572), 49: (1, 127, 0.08717406310111754), 50: (1, 127, 0.08730297155062279), 51: (1, 127, 0.08724889040403948), 52: (1, 127, 0.08726810663205198), 53: (1, 127, 0.08723157404474621), 54: (1, 127, 0.08719337713266687), 55: (1, 127, 0.08723182967445982), 56: (1, 127, 0.08721720983868274), 57: (1, 127, 0.08724412850771598), 58: (1, 127, 0.08710674948873014), 59: (1, 127, 0.08785025960230451), 60: (1, 127, 0.08813960366244392), 61: (1, 127, 0.08735018200791023), 62: (1, 127, 0.08738668529888777), 63: (1, 127, 0.08732195610664492), 64: (1, 127, 0.0875273274961771), 65: (1, 127, 0.08733547257450153), 66: (1, 127, 0.08735071154912626), 67: (1, 127, 0.08738514187005092), 68: (1, 127, 0.087339467281021), 69: (1, 127, 0.08747896272689104), 70: (1, 127, 0.08744188314523753)}\n",
      "{'predict_runtime': 798.1529, 'predict_samples_per_second': 0.089, 'predict_steps_per_second': 0.089}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:13:18.15\n",
      "  predict_samples_per_second =      0.089\n",
      "  predict_steps_per_second   =      0.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.21285912208259106), 2: (2, 0.1575046069920063), 3: (2, 0.1713616792112589), 4: (2, 0.16639258433133364), 5: (2, 0.15535668935626745), 6: (2, 0.16378427296876907), 7: (2, 0.1663667317479849), 8: (2, 0.1654492523521185), 9: (2, 0.15061939042061567), 10: (2, 0.16421801410615444), 11: (2, 0.15879086591303349), 12: (2, 0.1657898835837841), 13: (2, 0.1561603331938386), 14: (2, 0.16616082843393087), 15: (2, 0.16295066475868225), 16: (2, 0.15957660228013992), 17: (2, 0.15725154988467693), 18: (2, 0.16085109673440456), 19: (2, 0.16516984719783068), 20: (2, 0.16564990114420652), 21: (2, 0.165237694978714), 22: (2, 0.16527641285210848), 23: (2, 0.16591997537761927), 24: (2, 0.1656951867043972), 25: (2, 0.15127483196556568), 26: (2, 0.153957549482584), 27: (2, 0.15764010697603226), 28: (2, 0.165115880779922), 29: (2, 0.165880611166358), 30: (2, 0.16130454372614622), 31: (2, 0.15339542273432016), 32: (2, 0.1537539977580309), 33: (2, 0.15336531307548285), 34: (2, 0.15271300822496414), 35: (2, 0.15202651638537645), 36: (2, 0.15210193488746881), 37: (2, 0.16526001319289207), 38: (2, 0.15939773991703987), 39: (2, 0.16491246595978737), 40: (2, 0.15624908544123173), 41: (2, 0.16319414507597685), 42: (2, 0.15494220796972513), 43: (2, 0.16196048818528652), 44: (2, 0.15459697041660547), 45: (2, 0.16521813720464706), 46: (2, 0.16617920715361834), 47: (2, 0.16660071164369583), 48: (2, 0.1649467395618558), 49: (2, 0.16495577059686184), 50: (2, 0.16641972213983536), 51: (2, 0.16559075098484755), 52: (2, 0.16647773887962103), 53: (2, 0.15849660243839025), 54: (2, 0.16348812263458967), 55: (2, 0.1651922333985567), 56: (2, 0.16531305108219385), 57: (2, 0.16551398765295744), 58: (2, 0.16724276822060347), 59: (2, 0.16501169372349977), 60: (2, 0.1654890775680542), 61: (2, 0.15546971280127764), 62: (2, 0.16526843886822462), 63: (2, 0.1665028128772974), 64: (2, 0.15789391286671162), 65: (2, 0.16454965434968472), 66: (2, 0.16660768166184425), 67: (2, 0.16584351938217878), 68: (2, 0.16594240814447403), 69: (2, 0.16856041736900806), 70: (2, 0.1487688859924674), 71: (1, 0.15831977501511574)}\n",
      "{1: (2, 127, 0.13681725144943618), 2: (2, 127, 0.13630292505231195), 3: (2, 127, 0.13603939907258655), 4: (2, 127, 0.13573349962436307), 5: (2, 127, 0.1356629190203829), 6: (2, 127, 0.13554985655515683), 7: (2, 127, 0.13552800006431154), 8: (2, 127, 0.13587826035740808), 9: (2, 127, 0.13559765587964162), 10: (2, 127, 0.13568009821126076), 11: (2, 127, 0.13559206604488253), 12: (2, 127, 0.13567424949815893), 13: (2, 127, 0.1355888928895391), 14: (2, 127, 0.1356549304726673), 15: (2, 127, 0.1355691856198658), 16: (2, 127, 0.13565404881818557), 17: (2, 127, 0.1357384136049297), 18: (2, 127, 0.13591359673786585), 19: (2, 127, 0.13614951099056427), 20: (2, 127, 0.13581195155407969), 21: (2, 127, 0.13565301362014426), 22: (2, 127, 0.13567934540929052), 23: (2, 127, 0.1356637698752204), 24: (2, 127, 0.13583029375418904), 25: (2, 127, 0.13576363369558506), 26: (2, 127, 0.13569876300097686), 27: (2, 127, 0.1356282803178655), 28: (2, 127, 0.13558480410477308), 29: (2, 127, 0.13558164955388138), 30: (2, 127, 0.13572145353885381), 31: (2, 127, 0.13568860336434185), 32: (2, 127, 0.13574126677396964), 33: (2, 127, 0.13566060345179923), 34: (2, 127, 0.13562085337232888), 35: (2, 127, 0.1357233040914761), 36: (2, 127, 0.1358338097829049), 37: (2, 127, 0.13564353197901033), 38: (2, 127, 0.13555802229615882), 39: (2, 127, 0.13563577654060183), 40: (2, 127, 0.13561266699556526), 41: (2, 127, 0.13566964694599468), 42: (2, 127, 0.13559007168725484), 43: (2, 127, 0.13559775644781316), 44: (2, 127, 0.13553072146220704), 45: (2, 127, 0.13544235922630846), 46: (2, 127, 0.13563188725686448), 47: (2, 127, 0.13559000757266218), 48: (2, 127, 0.13554661719524486), 49: (2, 127, 0.13562470439850816), 50: (2, 127, 0.13554422501621283), 51: (2, 127, 0.1355985957381176), 52: (2, 127, 0.13555416318873956), 53: (2, 127, 0.1355702012821328), 54: (2, 127, 0.13548082642726542), 55: (2, 127, 0.13568765893725193), 56: (2, 127, 0.13559079024295403), 57: (2, 127, 0.13564928659919914), 58: (2, 127, 0.1356132083799778), 59: (2, 127, 0.13554667327993028), 60: (2, 127, 0.13566088231324447), 61: (2, 127, 0.1355151597073111), 62: (2, 127, 0.1356725663709359), 63: (2, 127, 0.13566696310166534), 64: (2, 127, 0.1355214039685102), 65: (2, 127, 0.13556949591161463), 66: (2, 127, 0.13558438933623118), 67: (2, 127, 0.13561998473436343), 68: (2, 127, 0.13558776210993528), 69: (2, 127, 0.1356272059676098), 70: (2, 127, 0.13558712171199988)}\n",
      "{'predict_runtime': 1228.8042, 'predict_samples_per_second': 0.115, 'predict_steps_per_second': 0.058}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:28.80\n",
      "  predict_samples_per_second =      0.115\n",
      "  predict_steps_per_second   =      0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.20760220289230347), 2: (4, 0.1749073825776577), 3: (4, 0.18030220922082663), 4: (4, 0.17414638865739107), 5: (4, 0.18039440643042326), 6: (4, 0.16416581440716982), 7: (4, 0.1765512702986598), 8: (4, 0.16904108691960573), 9: (4, 0.1650386629626155), 10: (4, 0.17652415949851274), 11: (4, 0.1766581665724516), 12: (4, 0.1639205338433385), 13: (4, 0.161605061031878), 14: (4, 0.16962555702775717), 15: (4, 0.16904077399522066), 16: (4, 0.1629204237833619), 17: (4, 0.16958401538431644), 18: (4, 0.16575088258832693), 19: (4, 0.1758532477542758), 20: (4, 0.16590350028127432), 21: (4, 0.17404512781649828), 22: (4, 0.16289339493960142), 23: (4, 0.1789357215166092), 24: (4, 0.16369978617876768), 25: (4, 0.16716617438942194), 26: (4, 0.16564644314348698), 27: (4, 0.16398455202579498), 28: (4, 0.1675144899636507), 29: (4, 0.1654648846015334), 30: (4, 0.1638114731758833), 31: (4, 0.1650556270033121), 32: (4, 0.16275532357394695), 33: (4, 0.16497170738875866), 34: (4, 0.17361237853765488), 35: (4, 0.16605734545737505), 36: (4, 0.1760300798341632), 37: (4, 0.17259258963167667), 38: (4, 0.16219511069357395), 39: (4, 0.17624174524098635), 40: (4, 0.1730695329606533), 41: (4, 0.16178817301988602), 42: (4, 0.1793775800615549), 43: (4, 0.16343075316399336), 44: (4, 0.16100784111768007), 45: (4, 0.17649364192038774), 46: (4, 0.16666516568511724), 47: (4, 0.1804565852507949), 48: (4, 0.17672725953161716), 49: (4, 0.16848953254520893), 50: (4, 0.16649229638278484), 51: (4, 0.16652403585612774), 52: (4, 0.16345896944403648), 53: (4, 0.16881545819342136), 54: (4, 0.173321477137506), 55: (4, 0.1611033771187067), 56: (4, 0.16799696628004313), 57: (4, 0.16730801481753588), 58: (4, 0.16875538788735867), 59: (4, 0.16619798820465803), 60: (4, 0.17382617853581905), 61: (4, 0.16532362718135118), 62: (4, 0.16274580638855696), 63: (4, 0.16710910573601723), 64: (4, 0.16483215428888798), 65: (4, 0.1626458177343011), 66: (4, 0.1766095468774438), 67: (4, 0.16406086087226868), 68: (4, 0.1644827164709568), 69: (4, 0.16615798696875572), 70: (4, 0.17540329042822123), 71: (1, 0.14440576639026403)}\n",
      "{1: (4, 127, 0.13689733324499112), 2: (4, 127, 0.13610228049150835), 3: (4, 127, 0.13595031171773128), 4: (4, 127, 0.1358683218915514), 5: (4, 127, 0.13593290516681325), 6: (4, 127, 0.13616915023702336), 7: (4, 127, 0.13611762738955302), 8: (4, 127, 0.1361998239326782), 9: (4, 127, 0.13587313680726243), 10: (4, 127, 0.13606188370017555), 11: (4, 127, 0.13592206086875416), 12: (4, 127, 0.135948235638381), 13: (4, 127, 0.13595627495417678), 14: (4, 127, 0.13588315260955902), 15: (4, 127, 0.1360941865063441), 16: (4, 127, 0.1373257261634929), 17: (4, 127, 0.13649398688314937), 18: (4, 127, 0.13647988939467143), 19: (4, 127, 0.13647663855822537), 20: (4, 127, 0.13621565532379262), 21: (4, 127, 0.13643106048208054), 22: (4, 127, 0.1357524062426189), 23: (4, 127, 0.13590600564489214), 24: (4, 127, 0.1357253587577404), 25: (4, 127, 0.13577227545975465), 26: (4, 127, 0.13578171581469886), 27: (4, 127, 0.13572582221171986), 28: (4, 127, 0.13579088202347672), 29: (4, 127, 0.13571218709923386), 30: (4, 127, 0.13571439701037144), 31: (4, 127, 0.1357697178719668), 32: (4, 127, 0.13581171031219988), 33: (4, 127, 0.13557212741121533), 34: (4, 127, 0.13578556133360845), 35: (4, 127, 0.135850262879504), 36: (4, 127, 0.13568875845521688), 37: (4, 127, 0.1356900708060565), 38: (4, 127, 0.13591708269292915), 39: (4, 127, 0.13565719405585153), 40: (4, 127, 0.13579288542299994), 41: (4, 127, 0.13570318559522), 42: (4, 127, 0.13586164079606533), 43: (4, 127, 0.1357841939100717), 44: (4, 127, 0.13572733797220968), 45: (4, 127, 0.13593520936886155), 46: (4, 127, 0.13580106818447196), 47: (4, 127, 0.1357509478354665), 48: (4, 127, 0.13582003926931638), 49: (4, 127, 0.13577333691082602), 50: (4, 127, 0.13565104638820324), 51: (4, 127, 0.13598786165395121), 52: (4, 127, 0.13574468354716546), 53: (4, 127, 0.13577500384623611), 54: (4, 127, 0.13587430547776186), 55: (4, 127, 0.13591018848590494), 56: (4, 127, 0.1357465936311), 57: (4, 127, 0.13597232514743027), 58: (4, 127, 0.1358989718494805), 59: (4, 127, 0.1358093654252882), 60: (4, 127, 0.13586274454531472), 61: (4, 127, 0.13587498654589408), 62: (4, 127, 0.1360129056219745), 63: (4, 127, 0.13630795382755242), 64: (4, 127, 0.13595613011518332), 65: (4, 127, 0.1358171495146991), 66: (4, 127, 0.1358707037820356), 67: (4, 127, 0.13581703431669653), 68: (4, 127, 0.13584918284598063), 69: (4, 127, 0.1357925912057321), 70: (4, 127, 0.1359845760139072)}\n",
      "{'predict_runtime': 1231.6036, 'predict_samples_per_second': 0.228, 'predict_steps_per_second': 0.058}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:31.60\n",
      "  predict_samples_per_second =      0.228\n",
      "  predict_steps_per_second   =      0.058\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 17\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.2883700476959348), 2: (1, 0.26047324016690254), 3: (1, 0.2587126297876239), 4: (1, 0.26290444005280733), 5: (1, 0.2586758295074105), 6: (1, 0.2588695166632533), 7: (1, 0.2580789951607585), 8: (1, 0.25424680951982737), 9: (1, 0.2574261808767915), 10: (1, 0.25416560750454664), 11: (1, 0.25809389259666204), 12: (1, 0.2575106490403414), 13: (1, 0.2545321425423026), 14: (1, 0.25714476127177477), 15: (1, 0.25408970657736063), 16: (1, 0.25459885969758034), 17: (1, 0.25392884761095047), 18: (1, 0.25670974515378475), 19: (1, 0.25482648611068726), 20: (1, 0.2588315103203058), 21: (1, 0.25501044373959303), 22: (1, 0.2545546079054475), 23: (1, 0.26101500261574984), 24: (1, 0.2593301525339484), 25: (1, 0.25844743102788925), 26: (1, 0.257045928388834), 27: (1, 0.25556424353271723), 28: (1, 0.2566742114722729), 29: (1, 0.25594926811754704), 30: (1, 0.25836898013949394), 31: (1, 0.2568479673936963), 32: (1, 0.2566597694531083), 33: (1, 0.25689484644681215), 34: (1, 0.25466026179492474), 35: (1, 0.25558422040194273), 36: (1, 0.254271506331861), 37: (1, 0.2549548065289855), 38: (1, 0.25511383451521397), 39: (1, 0.2561741219833493), 40: (1, 0.2558441562578082), 41: (1, 0.2554771192371845), 42: (1, 0.25440347101539373), 43: (1, 0.25718284770846367), 44: (1, 0.2544467793777585), 45: (1, 0.2563353683799505), 46: (1, 0.2571441475301981), 47: (1, 0.25635452661663294), 48: (1, 0.2569380085915327), 49: (1, 0.25690821930766106), 50: (1, 0.2558269016444683), 51: (1, 0.2538004443049431), 52: (1, 0.25549633521586657), 53: (1, 0.2542937081307173), 54: (1, 0.2537280637770891), 55: (1, 0.2574855610728264), 56: (1, 0.25520942732691765), 57: (1, 0.25764577835798264), 58: (1, 0.25610345508903265), 59: (1, 0.2565214205533266), 60: (1, 0.2549886479973793), 61: (1, 0.2602469054982066), 62: (1, 0.25375051982700825), 63: (1, 0.25536070205271244), 64: (1, 0.257350318133831), 65: (1, 0.2555819693952799), 66: (1, 0.2544160317629576), 67: (1, 0.25699908193200827), 68: (1, 0.25554636772722006), 69: (1, 0.2540430845692754), 70: (1, 0.2541511533781886), 71: (1, 0.25512780249118805)}\n",
      "{1: (1, 127, 0.15720693185544155), 2: (1, 127, 0.15640705571634564), 3: (1, 127, 0.1560874467304959), 4: (1, 127, 0.15576558494133744), 5: (1, 127, 0.1556827684307075), 6: (1, 127, 0.1554064637592693), 7: (1, 127, 0.15558331323362243), 8: (1, 127, 0.15544152536290132), 9: (1, 127, 0.15556365146675682), 10: (1, 127, 0.15546942359995186), 11: (1, 127, 0.15539988418527712), 12: (1, 127, 0.15552051305976206), 13: (1, 127, 0.1554593663868003), 14: (1, 127, 0.15557116348531067), 15: (1, 127, 0.15550189068555598), 16: (1, 127, 0.1554957561444227), 17: (1, 127, 0.155511533790158), 18: (1, 127, 0.15593262730298316), 19: (1, 127, 0.15601923799244907), 20: (1, 127, 0.1559051013896315), 21: (1, 127, 0.15567728887334115), 22: (1, 127, 0.15579172845665865), 23: (1, 127, 0.1562124483477999), 24: (1, 127, 0.1560515351373497), 25: (1, 127, 0.15551250361228788), 26: (1, 127, 0.15551433363914724), 27: (1, 127, 0.15565555142312068), 28: (1, 127, 0.15559993006699668), 29: (1, 127, 0.155344949609886), 30: (1, 127, 0.15573604087396634), 31: (1, 127, 0.15556581014048632), 32: (1, 127, 0.15542728525740424), 33: (1, 127, 0.15535971594197073), 34: (1, 127, 0.15532021731959553), 35: (1, 127, 0.15555126501584615), 36: (1, 127, 0.1562850301219957), 37: (1, 127, 0.15571820099405417), 38: (1, 127, 0.15568484041810504), 39: (1, 127, 0.155369201220396), 40: (1, 127, 0.15528886592176955), 41: (1, 127, 0.155259842148388), 42: (1, 127, 0.1551719207140639), 43: (1, 127, 0.155218576785089), 44: (1, 127, 0.155310997585436), 45: (1, 127, 0.1553439383769012), 46: (1, 127, 0.15536258902078068), 47: (1, 127, 0.15525494301764983), 48: (1, 127, 0.15517142170116188), 49: (1, 127, 0.15532409921141827), 50: (1, 127, 0.15518859589809741), 51: (1, 127, 0.15525129288581646), 52: (1, 127, 0.155201333230288), 53: (1, 127, 0.15519779611114912), 54: (1, 127, 0.15572163617370402), 55: (1, 127, 0.15592704724344447), 56: (1, 127, 0.15585095844576208), 57: (1, 127, 0.1555516545286798), 58: (1, 127, 0.1553299300240602), 59: (1, 127, 0.1551821843434976), 60: (1, 127, 0.1551706165397965), 61: (1, 127, 0.1552561597355942), 62: (1, 127, 0.1554677763396478), 63: (1, 127, 0.1551630850074681), 64: (1, 127, 0.15528901827734287), 65: (1, 127, 0.155310632602319), 66: (1, 127, 0.15541596060956087), 67: (1, 127, 0.15534705914351649), 68: (1, 127, 0.15540521550102263), 69: (1, 127, 0.15530324835095585), 70: (1, 127, 0.15532102186496802)}\n",
      "{'predict_runtime': 1420.7259, 'predict_samples_per_second': 0.05, 'predict_steps_per_second': 0.05}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:40.72\n",
      "  predict_samples_per_second =       0.05\n",
      "  predict_steps_per_second   =       0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.29484701063483953), 2: (2, 0.2735160067677498), 3: (2, 0.27171265706419945), 4: (2, 0.2660118527710438), 5: (2, 0.2684419136494398), 6: (2, 0.2684980118647218), 7: (2, 0.2899901019409299), 8: (2, 0.26904124580323696), 9: (2, 0.29080477077513933), 10: (2, 0.2775783147662878), 11: (2, 0.2873190911486745), 12: (2, 0.2705325158312917), 13: (2, 0.29098739847540855), 14: (2, 0.2704502558335662), 15: (2, 0.27798750810325146), 16: (2, 0.2697747331112623), 17: (2, 0.28976564947515726), 18: (2, 0.277624249458313), 19: (2, 0.26784462202340364), 20: (2, 0.2678556824102998), 21: (2, 0.27195210475474596), 22: (2, 0.2681597759947181), 23: (2, 0.26945547107607126), 24: (2, 0.26739653293043375), 25: (2, 0.2902158945798874), 26: (2, 0.2748525682836771), 27: (2, 0.2804597532376647), 28: (2, 0.27403154503554106), 29: (2, 0.27051129285246134), 30: (2, 0.2684723660349846), 31: (2, 0.31273186579346657), 32: (2, 0.28609178494662046), 33: (2, 0.2748491121456027), 34: (2, 0.2707366272807121), 35: (2, 0.30108585208654404), 36: (2, 0.29108806513249874), 37: (2, 0.294891650788486), 38: (2, 0.29420578945428133), 39: (2, 0.2889814367517829), 40: (2, 0.295871046371758), 41: (2, 0.28961064759641886), 42: (2, 0.2916079955175519), 43: (2, 0.3011885453015566), 44: (2, 0.2851003259420395), 45: (2, 0.26814032811671495), 46: (2, 0.2672365177422762), 47: (2, 0.27280400414019823), 48: (2, 0.3005847577005625), 49: (2, 0.26527879759669304), 50: (2, 0.2678111083805561), 51: (2, 0.2909615747630596), 52: (2, 0.2701754802837968), 53: (2, 0.29336772579699755), 54: (2, 0.2668981356546283), 55: (2, 0.29132351744920015), 56: (2, 0.2860527168959379), 57: (2, 0.2707569804042578), 58: (2, 0.2713913032785058), 59: (2, 0.27231735084205866), 60: (2, 0.28674666676670313), 61: (2, 0.29249085020273924), 62: (2, 0.2701391940936446), 63: (2, 0.27065556682646275), 64: (2, 0.2692545922473073), 65: (2, 0.2729414599016309), 66: (2, 0.27079349383711815), 67: (2, 0.26956008095294237), 68: (2, 0.2790225427597761), 69: (2, 0.2937315646559), 70: (2, 0.2712636897340417), 71: (1, 0.2557724751532078)}\n",
      "{1: (2, 127, 0.24416611697818116), 2: (2, 127, 0.24425515801623815), 3: (2, 127, 0.24382295040047075), 4: (2, 127, 0.24354714601791985), 5: (2, 127, 0.24393276046726883), 6: (2, 127, 0.24399451836650296), 7: (2, 127, 0.24368749199596446), 8: (2, 127, 0.2436467051198046), 9: (2, 127, 0.24399935397664158), 10: (2, 127, 0.24393886214078175), 11: (2, 127, 0.2437833426006901), 12: (2, 127, 0.24351948857542097), 13: (2, 127, 0.24379565983306706), 14: (2, 127, 0.2435403617876252), 15: (2, 127, 0.2436924746524044), 16: (2, 127, 0.24358065234218526), 17: (2, 127, 0.2434420044438576), 18: (2, 127, 0.24371228759419025), 19: (2, 127, 0.24357625789295032), 20: (2, 127, 0.24361321684266404), 21: (2, 127, 0.24387305998426723), 22: (2, 127, 0.24384657769485957), 23: (2, 127, 0.24416909863307015), 24: (2, 127, 0.24353251064298895), 25: (2, 127, 0.24373875652241894), 26: (2, 127, 0.24360554253931824), 27: (2, 127, 0.24367825909129043), 28: (2, 127, 0.2437506549309675), 29: (2, 127, 0.2437938456753577), 30: (2, 127, 0.2504998155114219), 31: (2, 127, 0.2485410290894898), 32: (2, 127, 0.24827750825037168), 33: (2, 127, 0.2479857511261082), 34: (2, 127, 0.24807568426119295), 35: (2, 127, 0.24798543722640107), 36: (2, 127, 0.24780222597553975), 37: (2, 127, 0.24790163577981586), 38: (2, 127, 0.2477612337464188), 39: (2, 127, 0.2480450262073574), 40: (2, 127, 0.24792026172531403), 41: (2, 127, 0.2479250223823185), 42: (2, 127, 0.24743651266495778), 43: (2, 127, 0.24415188970586915), 44: (2, 127, 0.24441681124680625), 45: (2, 127, 0.24390578378490577), 46: (2, 127, 0.24358205295600524), 47: (2, 127, 0.24376170381199658), 48: (2, 127, 0.24374344062764108), 49: (2, 127, 0.24395754480895798), 50: (2, 127, 0.2437270852979126), 51: (2, 127, 0.24352706726787127), 52: (2, 127, 0.24360057029609136), 53: (2, 127, 0.2435426567277805), 54: (2, 127, 0.2432822938788477), 55: (2, 127, 0.24344535976443), 56: (2, 127, 0.24385274374696214), 57: (2, 127, 0.24399934289610292), 58: (2, 127, 0.24379538273893472), 59: (2, 127, 0.24446445957236873), 60: (2, 127, 0.24371857054560908), 61: (2, 127, 0.24438761071279996), 62: (2, 127, 0.24389003618349006), 63: (2, 127, 0.24353810128440537), 64: (2, 127, 0.2436937211506714), 65: (2, 127, 0.2439710823159049), 66: (2, 127, 0.2439651047722913), 67: (2, 127, 0.24377195603089538), 68: (2, 127, 0.24353245175700253), 69: (2, 127, 0.2445976877746385), 70: (2, 127, 0.2448175812697434)}\n",
      "{'predict_runtime': 2214.4547, 'predict_samples_per_second': 0.064, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:54.45\n",
      "  predict_samples_per_second =      0.064\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.3227596217766404), 2: (4, 0.29351521376520395), 3: (4, 0.31613945588469505), 4: (4, 0.3150902884081006), 5: (4, 0.3028638968244195), 6: (4, 0.295972834341228), 7: (4, 0.3122323676943779), 8: (4, 0.293271254748106), 9: (4, 0.29771707113832235), 10: (4, 0.3044269150123), 11: (4, 0.2922998918220401), 12: (4, 0.293542536906898), 13: (4, 0.2900266172364354), 14: (4, 0.28693498112261295), 15: (4, 0.3102048747241497), 16: (4, 0.2937872428447008), 17: (4, 0.30106405820697546), 18: (4, 0.29010713193565607), 19: (4, 0.30782030895352364), 20: (4, 0.29155158530920744), 21: (4, 0.28817541245371103), 22: (4, 0.3099891832098365), 23: (4, 0.30968587566167116), 24: (4, 0.3133037043735385), 25: (4, 0.288349567912519), 26: (4, 0.3116832207888365), 27: (4, 0.2894733343273401), 28: (4, 0.3174018654972315), 29: (4, 0.2899214578792453), 30: (4, 0.2874508947134018), 31: (4, 0.30966276209801435), 32: (4, 0.29304980114102364), 33: (4, 0.3099182369187474), 34: (4, 0.2932468568906188), 35: (4, 0.2887788973748684), 36: (4, 0.3105983277782798), 37: (4, 0.2891386626288295), 38: (4, 0.2925798622891307), 39: (4, 0.293298383243382), 40: (4, 0.284037709236145), 41: (4, 0.2896101241931319), 42: (4, 0.29710521921515465), 43: (4, 0.30130975041538477), 44: (4, 0.2971593653783202), 45: (4, 0.2886711033061147), 46: (4, 0.2961733676493168), 47: (4, 0.28814049903303385), 48: (4, 0.2903677523136139), 49: (4, 0.30991370789706707), 50: (4, 0.2879161797463894), 51: (4, 0.2928010420873761), 52: (4, 0.28802774753421545), 53: (4, 0.29009402357041836), 54: (4, 0.3112282305955887), 55: (4, 0.3113686880096793), 56: (4, 0.2874677116051316), 57: (4, 0.28726486675441265), 58: (4, 0.2930793995037675), 59: (4, 0.2863208269700408), 60: (4, 0.29698192328214645), 61: (4, 0.3053442379459739), 62: (4, 0.28925426211208105), 63: (4, 0.28817919362336397), 64: (4, 0.28881407622247934), 65: (4, 0.3061217274516821), 66: (4, 0.31032342836260796), 67: (4, 0.2900174418464303), 68: (4, 0.2895109858363867), 69: (4, 0.2890013325959444), 70: (4, 0.285077266395092), 71: (1, 0.25699400063604116)}\n",
      "{1: (4, 127, 0.24892347950605662), 2: (4, 127, 0.24445520116998923), 3: (4, 127, 0.24426044025055066), 4: (4, 127, 0.24480592674304416), 5: (4, 127, 0.24463620541367945), 6: (4, 127, 0.2447941131801821), 7: (4, 127, 0.24502583365799405), 8: (4, 127, 0.24502224115082832), 9: (4, 127, 0.24462314118726516), 10: (4, 127, 0.24801441908293353), 11: (4, 127, 0.24443297701205793), 12: (4, 127, 0.24417855468849967), 13: (4, 127, 0.24468649851202262), 14: (4, 127, 0.24442772540139165), 15: (4, 127, 0.24446560165250864), 16: (4, 127, 0.24402933844225846), 17: (4, 127, 0.24474504235838576), 18: (4, 127, 0.24465923956558694), 19: (4, 127, 0.24423893783094847), 20: (4, 127, 0.2442515288208296), 21: (4, 127, 0.24437440674400002), 22: (4, 127, 0.24419066822522972), 23: (4, 127, 0.24422615503261644), 24: (4, 127, 0.24442223740345614), 25: (4, 127, 0.24413704259071764), 26: (4, 127, 0.24440378572527818), 27: (4, 127, 0.244353896190273), 28: (4, 127, 0.24431777500554802), 29: (4, 127, 0.24399685039089655), 30: (4, 127, 0.24389035088252128), 31: (4, 127, 0.2443034352705352), 32: (4, 127, 0.2441267465849913), 33: (4, 127, 0.24418958215644276), 34: (4, 127, 0.24425636644027834), 35: (4, 127, 0.2443575733084613), 36: (4, 127, 0.2443223926128717), 37: (4, 127, 0.24421621974938967), 38: (4, 127, 0.2442281959197066), 39: (4, 127, 0.24421028432795616), 40: (4, 127, 0.24402919131529144), 41: (4, 127, 0.24428160733536003), 42: (4, 127, 0.2441482947933979), 43: (4, 127, 0.244203488137133), 44: (4, 127, 0.2444239666714795), 45: (4, 127, 0.24438241181352477), 46: (4, 127, 0.24426064656416732), 47: (4, 127, 0.24436249473227525), 48: (4, 127, 0.244146093161498), 49: (4, 127, 0.24400986478055323), 50: (4, 127, 0.2439537686992466), 51: (4, 127, 0.24417672132501217), 52: (4, 127, 0.2442302658024618), 53: (4, 127, 0.24407938444678942), 54: (4, 127, 0.243965005509438), 55: (4, 127, 0.24453709460794926), 56: (4, 127, 0.24385435555834234), 57: (4, 127, 0.24400895244375928), 58: (4, 127, 0.24389702584007827), 59: (4, 127, 0.24412064694278823), 60: (4, 127, 0.2437565414322995), 61: (4, 127, 0.24413318778791532), 62: (4, 127, 0.2439353700477894), 63: (4, 127, 0.24396422663776893), 64: (4, 127, 0.2440102608273114), 65: (4, 127, 0.2439660978554858), 66: (4, 127, 0.2440121479508445), 67: (4, 127, 0.24404309555066853), 68: (4, 127, 0.24403787451964898), 69: (4, 127, 0.24414166221468467), 70: (4, 127, 0.24413346885666837)}\n",
      "{'predict_runtime': 2213.4336, 'predict_samples_per_second': 0.127, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:53.43\n",
      "  predict_samples_per_second =      0.127\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 31\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 16, 17, 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3360733240842819), 2: (1, 0.1473029712215066), 3: (1, 0.14797697216272354), 4: (1, 0.14446465205401182), 5: (1, 0.14401518739759922), 6: (1, 0.1441052369773388), 7: (1, 0.14542056061327457), 8: (1, 0.1449051769450307), 9: (1, 0.14350104331970215), 10: (1, 0.14320658799260855), 11: (1, 0.14097924251109362), 12: (1, 0.1410330832004547), 13: (1, 0.1424554055556655), 14: (1, 0.14270595461130142), 15: (1, 0.14004030358046293), 16: (1, 0.1404732195660472), 17: (1, 0.14014527387917042), 18: (1, 0.1406751573085785), 19: (1, 0.14300266932696104), 20: (1, 0.15138972271233797), 21: (1, 0.14724675007164478), 22: (1, 0.1444826228544116), 23: (1, 0.1427415730431676), 24: (1, 0.14327924698591232), 25: (1, 0.14260121621191502), 26: (1, 0.14403041824698448), 27: (1, 0.1437675803899765), 28: (1, 0.14124838262796402), 29: (1, 0.14255713485181332), 30: (1, 0.14642760064452887), 31: (1, 0.14555177092552185), 32: (1, 0.14353419467806816), 33: (1, 0.1465085493400693), 34: (1, 0.15305659361183643), 35: (1, 0.14495936874300241), 36: (1, 0.14345102570950985), 37: (1, 0.1436911029741168), 38: (1, 0.14224884007126093), 39: (1, 0.1399787673726678), 40: (1, 0.14149940945208073), 41: (1, 0.14288426283746958), 42: (1, 0.1489558620378375), 43: (1, 0.14563335105776787), 44: (1, 0.15726525522768497), 45: (1, 0.14586202800273895), 46: (1, 0.14536599442362785), 47: (1, 0.1444276049733162), 48: (1, 0.14272684417665005), 49: (1, 0.14306852966547012), 50: (1, 0.14365238323807716), 51: (1, 0.1411865632981062), 52: (1, 0.1436454951763153), 53: (1, 0.14170880615711212), 54: (1, 0.1409269655123353), 55: (1, 0.14663780946284533), 56: (1, 0.14262387715280056), 57: (1, 0.14066307060420513), 58: (1, 0.14353889506310225), 59: (1, 0.14232707116752863), 60: (1, 0.14359868597239256), 61: (1, 0.14395523071289062), 62: (1, 0.14287768490612507), 63: (1, 0.1408225679770112), 64: (1, 0.14123138319700956), 65: (1, 0.14298029243946075), 66: (1, 0.14257938787341118), 67: (1, 0.14134497195482254), 68: (1, 0.1452483655884862), 69: (1, 0.14058745093643665), 70: (1, 0.1411337750032544), 71: (1, 0.15193271823227406)}\n",
      "{1: (1, 127, 0.08367024857081531), 2: (1, 127, 0.08395672209678202), 3: (1, 127, 0.08390306382198033), 4: (1, 127, 0.08255692002341503), 5: (1, 127, 0.08227596634368259), 6: (1, 127, 0.08522849262318039), 7: (1, 127, 0.08329846401970217), 8: (1, 127, 0.0826321218866767), 9: (1, 127, 0.08241920968825657), 10: (1, 127, 0.08247139565939979), 11: (1, 127, 0.08212285687574955), 12: (1, 127, 0.08203057996840693), 13: (1, 127, 0.08216939914942258), 14: (1, 127, 0.08183153804508954), 15: (1, 127, 0.08250916319510598), 16: (1, 127, 0.08227364016388815), 17: (1, 127, 0.0819559296827734), 18: (1, 127, 0.08198858917815478), 19: (1, 127, 0.08374915608593564), 20: (1, 127, 0.08495000863491785), 21: (1, 127, 0.08321474953077909), 22: (1, 127, 0.0830269647600848), 23: (1, 127, 0.08235987744433439), 24: (1, 127, 0.08211732307434316), 25: (1, 127, 0.08201097184425499), 26: (1, 127, 0.08215793802248915), 27: (1, 127, 0.0822624088829662), 28: (1, 127, 0.08280231619591084), 29: (1, 127, 0.08390520761654836), 30: (1, 127, 0.08344240126559349), 31: (1, 127, 0.0823444040404178), 32: (1, 127, 0.08346631665398756), 33: (1, 127, 0.08419658701250872), 34: (1, 127, 0.08448693599170587), 35: (1, 127, 0.08318170703448884), 36: (1, 127, 0.08337191569318217), 37: (1, 127, 0.08252032211153057), 38: (1, 127, 0.08235147467073728), 39: (1, 127, 0.08236591248795039), 40: (1, 127, 0.08243412038267363), 41: (1, 127, 0.08389744088493699), 42: (1, 127, 0.08773645286367635), 43: (1, 127, 0.08395255242628376), 44: (1, 127, 0.08511853058947118), 45: (1, 127, 0.08299601530494886), 46: (1, 127, 0.08333442538360676), 47: (1, 127, 0.08257176657390641), 48: (1, 127, 0.082254309236534), 49: (1, 127, 0.08212307923451417), 50: (1, 127, 0.08192420199396104), 51: (1, 127, 0.08191086776466586), 52: (1, 127, 0.08186773421228166), 53: (1, 127, 0.0824328566732721), 54: (1, 127, 0.08349540825258558), 55: (1, 127, 0.08267464405145701), 56: (1, 127, 0.0826125514334229), 57: (1, 127, 0.08240103024226708), 58: (1, 127, 0.08235999020036515), 59: (1, 127, 0.08800704911439203), 60: (1, 127, 0.08476791399582399), 61: (1, 127, 0.08204585792658133), 62: (1, 127, 0.08209072491227407), 63: (1, 127, 0.0821418625368612), 64: (1, 127, 0.0820430167987356), 65: (1, 127, 0.08181886890477787), 66: (1, 127, 0.08200171577384857), 67: (1, 127, 0.08199882213260949), 68: (1, 127, 0.08232694887739467), 69: (1, 127, 0.08207150433564514), 70: (1, 127, 0.08369557036629577)}\n",
      "{'predict_runtime': 758.9957, 'predict_samples_per_second': 0.094, 'predict_steps_per_second': 0.094}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:12:38.99\n",
      "  predict_samples_per_second =      0.094\n",
      "  predict_steps_per_second   =      0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.20231405831873417), 2: (2, 0.18230770342051983), 3: (2, 0.1592945121228695), 4: (2, 0.15502387285232544), 5: (2, 0.15597933065146208), 6: (2, 0.16840400453656912), 7: (2, 0.16779368184506893), 8: (2, 0.15840121265500784), 9: (2, 0.1737953433766961), 10: (2, 0.16966415103524923), 11: (2, 0.15408456418663263), 12: (2, 0.15618958976119757), 13: (2, 0.15510967187583447), 14: (2, 0.15582220535725355), 15: (2, 0.1557543445378542), 16: (2, 0.15404457598924637), 17: (2, 0.15092308167368174), 18: (2, 0.16665621753782034), 19: (2, 0.1548919351771474), 20: (2, 0.16948345862329006), 21: (2, 0.15201489347964525), 22: (2, 0.1526576764881611), 23: (2, 0.15603872761130333), 24: (2, 0.15385805256664753), 25: (2, 0.15357121638953686), 26: (2, 0.15479888208210468), 27: (2, 0.15527205634862185), 28: (2, 0.15094086714088917), 29: (2, 0.1552683962509036), 30: (2, 0.1505382414907217), 31: (2, 0.15328263025730848), 32: (2, 0.15610437653958797), 33: (2, 0.15373442508280277), 34: (2, 0.1514428723603487), 35: (2, 0.1665248442441225), 36: (2, 0.15785842761397362), 37: (2, 0.15432028751820326), 38: (2, 0.15194660611450672), 39: (2, 0.167188317514956), 40: (2, 0.15457611437886953), 41: (2, 0.16648816596716642), 42: (2, 0.15281607676297426), 43: (2, 0.16541664768010378), 44: (2, 0.15636788494884968), 45: (2, 0.16659988462924957), 46: (2, 0.1536638867110014), 47: (2, 0.16737662628293037), 48: (2, 0.1562377568334341), 49: (2, 0.15441277716308832), 50: (2, 0.1658911034464836), 51: (2, 0.1603890685364604), 52: (2, 0.15691651962697506), 53: (2, 0.16811844799667597), 54: (2, 0.15390594489872456), 55: (2, 0.16562785767018795), 56: (2, 0.15483996365219355), 57: (2, 0.17003090493381023), 58: (2, 0.15578687377274036), 59: (2, 0.15574998315423727), 60: (2, 0.15865718945860863), 61: (2, 0.16993461642414331), 62: (2, 0.1568227019160986), 63: (2, 0.16960963141173124), 64: (2, 0.16655077692121267), 65: (2, 0.15739622339606285), 66: (2, 0.15615634992718697), 67: (2, 0.16681434493511915), 68: (2, 0.15882135834544897), 69: (2, 0.15825531259179115), 70: (2, 0.1512959934771061), 71: (1, 0.14144091121852398)}\n",
      "{1: (2, 127, 0.13007576266435658), 2: (2, 127, 0.12821488023742916), 3: (2, 127, 0.12787619876990639), 4: (2, 127, 0.12808950445578088), 5: (2, 127, 0.13283981837508246), 6: (2, 127, 0.12932786466480475), 7: (2, 127, 0.1280534055054657), 8: (2, 127, 0.12972268773110832), 9: (2, 127, 0.13076689651631934), 10: (2, 127, 0.12925262859193828), 11: (2, 127, 0.1283838169605244), 12: (2, 127, 0.12766011889407955), 13: (2, 127, 0.12749732834998312), 14: (2, 127, 0.1276002113128037), 15: (2, 127, 0.1277836188380643), 16: (2, 127, 0.1275991736727906), 17: (2, 127, 0.12783551309257746), 18: (2, 127, 0.12764511847003238), 19: (2, 127, 0.12764884715562497), 20: (2, 127, 0.12766321150102014), 21: (2, 127, 0.12767619127774332), 22: (2, 127, 0.1276784009468837), 23: (2, 127, 0.12769600939680273), 24: (2, 127, 0.1275390489026904), 25: (2, 127, 0.1275547869855494), 26: (2, 127, 0.12744324262745269), 27: (2, 127, 0.1276985722351966), 28: (2, 127, 0.12767302072570313), 29: (2, 127, 0.1276005710453147), 30: (2, 127, 0.12763328459407167), 31: (2, 127, 0.12757548394312304), 32: (2, 127, 0.1276806514475524), 33: (2, 127, 0.12765042755870135), 34: (2, 127, 0.12745547087085762), 35: (2, 127, 0.12753135651555353), 36: (2, 127, 0.1276364362263304), 37: (2, 127, 0.12761631301479545), 38: (2, 127, 0.12752417621650095), 39: (2, 127, 0.12762973065246044), 40: (2, 127, 0.1276160627016871), 41: (2, 127, 0.12763139843119412), 42: (2, 127, 0.12755656411035324), 43: (2, 127, 0.12757896274826894), 44: (2, 127, 0.12756502700192252), 45: (2, 127, 0.12763209755378446), 46: (2, 127, 0.12747071023414455), 47: (2, 127, 0.12748001855394736), 48: (2, 127, 0.1276176486706992), 49: (2, 127, 0.12749314367565817), 50: (2, 127, 0.12741424167514082), 51: (2, 127, 0.12745818044755639), 52: (2, 127, 0.12751293375237485), 53: (2, 127, 0.12754343203672275), 54: (2, 127, 0.12742582484199774), 55: (2, 127, 0.12760707326086723), 56: (2, 127, 0.1275006062461166), 57: (2, 127, 0.12756451595515952), 58: (2, 127, 0.12749120752202478), 59: (2, 127, 0.12749982710311733), 60: (2, 127, 0.12741442959696994), 61: (2, 127, 0.12762945305966722), 62: (2, 127, 0.12736279294481428), 63: (2, 127, 0.12736391095723223), 64: (2, 127, 0.12746485851441078), 65: (2, 127, 0.12760740542036342), 66: (2, 127, 0.12744097011237163), 67: (2, 127, 0.12748423337525738), 68: (2, 127, 0.12747185038564007), 69: (2, 127, 0.12763224020746983), 70: (2, 127, 0.12751208743681824)}\n",
      "{'predict_runtime': 1158.2898, 'predict_samples_per_second': 0.122, 'predict_steps_per_second': 0.061}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:18.28\n",
      "  predict_samples_per_second =      0.122\n",
      "  predict_steps_per_second   =      0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.2360474020242691), 2: (4, 0.20977313071489334), 3: (4, 0.20237289648503065), 4: (4, 0.2032046364620328), 5: (4, 0.20361589174717665), 6: (4, 0.21478882152587175), 7: (4, 0.21516958624124527), 8: (4, 0.20723605062812567), 9: (4, 0.21269692666828632), 10: (4, 0.20222995802760124), 11: (4, 0.20449910126626492), 12: (4, 0.20181758422404528), 13: (4, 0.2014712980017066), 14: (4, 0.2021847004070878), 15: (4, 0.207410697825253), 16: (4, 0.21238107979297638), 17: (4, 0.21682949922978878), 18: (4, 0.199070006608963), 19: (4, 0.20218228083103895), 20: (4, 0.20334522798657417), 21: (4, 0.2126171886920929), 22: (4, 0.19971559010446072), 23: (4, 0.20129016134887934), 24: (4, 0.20201156195253134), 25: (4, 0.20377980172634125), 26: (4, 0.20069722831249237), 27: (4, 0.20139699149876833), 28: (4, 0.2008741768077016), 29: (4, 0.20205636322498322), 30: (4, 0.21160388085991144), 31: (4, 0.19994243793189526), 32: (4, 0.2011218937113881), 33: (4, 0.2077642073854804), 34: (4, 0.20439309626817703), 35: (4, 0.20573664084076881), 36: (4, 0.20261429715901613), 37: (4, 0.20271251536905766), 38: (4, 0.21165561117231846), 39: (4, 0.20964375510811806), 40: (4, 0.2021922916173935), 41: (4, 0.2019678046926856), 42: (4, 0.20303922332823277), 43: (4, 0.2036768663674593), 44: (4, 0.20173135865479708), 45: (4, 0.20191444642841816), 46: (4, 0.20213023480027914), 47: (4, 0.20013658702373505), 48: (4, 0.20561583247035742), 49: (4, 0.20413101091980934), 50: (4, 0.20220662280917168), 51: (4, 0.20054215285927057), 52: (4, 0.2011653259396553), 53: (4, 0.20357160735875368), 54: (4, 0.21467124857008457), 55: (4, 0.2116866633296013), 56: (4, 0.20260753855109215), 57: (4, 0.20062146335840225), 58: (4, 0.20479802414774895), 59: (4, 0.2070890674367547), 60: (4, 0.2025617202743888), 61: (4, 0.20203625597059727), 62: (4, 0.20515333954244852), 63: (4, 0.20277490839362144), 64: (4, 0.20303996372967958), 65: (4, 0.21471507754176855), 66: (4, 0.19999234098941088), 67: (4, 0.19940999802201986), 68: (4, 0.2144609224051237), 69: (4, 0.20727004576474428), 70: (4, 0.20927713252604008), 71: (1, 0.14133792649954557)}\n",
      "{1: (4, 127, 0.12931009000680577), 2: (4, 127, 0.12817147895547115), 3: (4, 127, 0.12816476470636806), 4: (4, 127, 0.12810674435129082), 5: (4, 127, 0.128182844882171), 6: (4, 127, 0.1281266156070697), 7: (4, 127, 0.12826110001682767), 8: (4, 127, 0.12799027121413176), 9: (4, 127, 0.12806488569151228), 10: (4, 127, 0.12804886059996884), 11: (4, 127, 0.1283491695167746), 12: (4, 127, 0.12827272796050065), 13: (4, 127, 0.1283410365920602), 14: (4, 127, 0.12817040961382425), 15: (4, 127, 0.1280874184692117), 16: (4, 127, 0.128028949289986), 17: (4, 127, 0.12801998718018373), 18: (4, 127, 0.1278923119777652), 19: (4, 127, 0.12791476705969554), 20: (4, 127, 0.12777938808160505), 21: (4, 127, 0.12797120944633494), 22: (4, 127, 0.12787079140837268), 23: (4, 127, 0.1277869908857768), 24: (4, 127, 0.12764875100206907), 25: (4, 127, 0.12774632693686355), 26: (4, 127, 0.12780583165146), 27: (4, 127, 0.12770251686296125), 28: (4, 127, 0.12771343689147882), 29: (4, 127, 0.12782969464379268), 30: (4, 127, 0.1277196148307774), 31: (4, 127, 0.12772635930019804), 32: (4, 127, 0.12775322684182192), 33: (4, 127, 0.1276448122702363), 34: (4, 127, 0.12774615682749532), 35: (4, 127, 0.12779645874040332), 36: (4, 127, 0.1277688258276211), 37: (4, 127, 0.1277225404523137), 38: (4, 127, 0.1276361585308717), 39: (4, 127, 0.1277969641992309), 40: (4, 127, 0.12769934595892513), 41: (4, 127, 0.12773037289716596), 42: (4, 127, 0.12770139195728958), 43: (4, 127, 0.12779926071603467), 44: (4, 127, 0.1277305809560958), 45: (4, 127, 0.12763726769939182), 46: (4, 127, 0.12767924364714875), 47: (4, 127, 0.1276888775485238), 48: (4, 127, 0.12767289589914516), 49: (4, 127, 0.12768332355868395), 50: (4, 127, 0.1277059865088796), 51: (4, 127, 0.12773720800553953), 52: (4, 127, 0.12772926942658003), 53: (4, 127, 0.127718999681217), 54: (4, 127, 0.12774127050060927), 55: (4, 127, 0.12768766985780847), 56: (4, 127, 0.12768945580451038), 57: (4, 127, 0.12771911125659474), 58: (4, 127, 0.12760445966905964), 59: (4, 127, 0.12777272768054657), 60: (4, 127, 0.1277083779472535), 61: (4, 127, 0.1276119927560368), 62: (4, 127, 0.12772860774755712), 63: (4, 127, 0.12749817578019354), 64: (4, 127, 0.12753678751214753), 65: (4, 127, 0.1275260058033654), 66: (4, 127, 0.12739900033921003), 67: (4, 127, 0.12731189833675313), 68: (4, 127, 0.12772252202385992), 69: (4, 127, 0.12758716902013603), 70: (4, 127, 0.12754097575776455)}\n",
      "{'predict_runtime': 1161.3126, 'predict_samples_per_second': 0.242, 'predict_steps_per_second': 0.061}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:21.31\n",
      "  predict_samples_per_second =      0.242\n",
      "  predict_steps_per_second   =      0.061\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 16\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.18986164033412933), 2: (1, 0.16137008275836706), 3: (1, 0.15454840287566185), 4: (1, 0.1535114347934723), 5: (1, 0.15143373049795628), 6: (1, 0.15147087909281254), 7: (1, 0.15136426035314798), 8: (1, 0.14804094843566418), 9: (1, 0.14834765624254942), 10: (1, 0.1490941671654582), 11: (1, 0.15297271125018597), 12: (1, 0.14859020337462425), 13: (1, 0.15055599063634872), 14: (1, 0.14776541199535131), 15: (1, 0.15003539621829987), 16: (1, 0.1497755190357566), 17: (1, 0.14962209109216928), 18: (1, 0.14852833282202482), 19: (1, 0.14963213168084621), 20: (1, 0.15084573719650507), 21: (1, 0.1515732081606984), 22: (1, 0.14985533896833658), 23: (1, 0.15189205575734377), 24: (1, 0.1481613777577877), 25: (1, 0.14922751672565937), 26: (1, 0.15120388194918633), 27: (1, 0.1498878188431263), 28: (1, 0.1516805673018098), 29: (1, 0.1509910747408867), 30: (1, 0.14799849968403578), 31: (1, 0.1509511461481452), 32: (1, 0.14797101076692343), 33: (1, 0.15055767074227333), 34: (1, 0.14868018310517073), 35: (1, 0.14846099447458982), 36: (1, 0.15090877562761307), 37: (1, 0.15477768145501614), 38: (1, 0.15169888734817505), 39: (1, 0.1481695780530572), 40: (1, 0.14995496813207865), 41: (1, 0.1500771064311266), 42: (1, 0.1518523059785366), 43: (1, 0.14887694083154202), 44: (1, 0.14866841305047274), 45: (1, 0.1485351361334324), 46: (1, 0.14874696172773838), 47: (1, 0.14819632843136787), 48: (1, 0.1486170133575797), 49: (1, 0.14877597149461508), 50: (1, 0.14886606112122536), 51: (1, 0.14929125551134348), 52: (1, 0.14953207317739725), 53: (1, 0.14798711147159338), 54: (1, 0.15025545470416546), 55: (1, 0.15078745875507593), 56: (1, 0.149498893879354), 57: (1, 0.15010526683181524), 58: (1, 0.149540264159441), 59: (1, 0.14971215184777975), 60: (1, 0.15107053611427546), 61: (1, 0.15097162686288357), 62: (1, 0.150649880990386), 63: (1, 0.14796436112374067), 64: (1, 0.1488763215020299), 65: (1, 0.14862168487161398), 66: (1, 0.1511592548340559), 67: (1, 0.14974134229123592), 68: (1, 0.15164398029446602), 69: (1, 0.15031531546264887), 70: (1, 0.1533781597390771), 71: (1, 0.14960380271077156)}\n",
      "{1: (1, 127, 0.08850501903046773), 2: (1, 127, 0.08728967483822755), 3: (1, 127, 0.08695929109551541), 4: (1, 127, 0.08681087930664771), 5: (1, 127, 0.08677653446206897), 6: (1, 127, 0.08669981971295096), 7: (1, 127, 0.08675088553036761), 8: (1, 127, 0.08668363538724701), 9: (1, 127, 0.08671919987573633), 10: (1, 127, 0.08661200446406687), 11: (1, 127, 0.08674007457659), 12: (1, 127, 0.08675857783683877), 13: (1, 127, 0.08684962814835114), 14: (1, 127, 0.0866560371240645), 15: (1, 127, 0.08666796441827937), 16: (1, 127, 0.08671433444127558), 17: (1, 127, 0.0866812285637175), 18: (1, 127, 0.08675974231271998), 19: (1, 127, 0.0867043405433926), 20: (1, 127, 0.08670494582973362), 21: (1, 127, 0.08672016190262291), 22: (1, 127, 0.08672348874085765), 23: (1, 127, 0.08670935349348258), 24: (1, 127, 0.08677396615307162), 25: (1, 127, 0.08660944030568825), 26: (1, 127, 0.08670227074130314), 27: (1, 127, 0.08653023119605198), 28: (1, 127, 0.08669599464647179), 29: (1, 127, 0.08662221569743916), 30: (1, 127, 0.08660730737899466), 31: (1, 127, 0.08657124459626168), 32: (1, 127, 0.0866857862803997), 33: (1, 127, 0.08674660731312328), 34: (1, 127, 0.0867499353393443), 35: (1, 127, 0.08674204010721737), 36: (1, 127, 0.08674453553105668), 37: (1, 127, 0.086651361444745), 38: (1, 127, 0.08661898877471685), 39: (1, 127, 0.08663147558113486), 40: (1, 127, 0.08676503010563494), 41: (1, 127, 0.08675347444579357), 42: (1, 127, 0.08667244169655747), 43: (1, 127, 0.08678745267194087), 44: (1, 127, 0.08671903482630966), 45: (1, 127, 0.08677426955889998), 46: (1, 127, 0.08670166484630248), 47: (1, 127, 0.08669878222693608), 48: (1, 127, 0.08676124656000944), 49: (1, 127, 0.08664672185967523), 50: (1, 127, 0.08671890812244003), 51: (1, 127, 0.08668001592305936), 52: (1, 127, 0.08683339336256343), 53: (1, 127, 0.08669107457930882), 54: (1, 127, 0.08671700595108074), 55: (1, 127, 0.0867192542151086), 56: (1, 127, 0.08680313049749595), 57: (1, 127, 0.08671778128079073), 58: (1, 127, 0.08673382238081591), 59: (1, 127, 0.08666370281817641), 60: (1, 127, 0.08666733312090551), 61: (1, 127, 0.08682623230595524), 62: (1, 127, 0.08664488815885829), 63: (1, 127, 0.08681368864486068), 64: (1, 127, 0.08667299613415257), 65: (1, 127, 0.08661110199782557), 66: (1, 127, 0.08650235840537417), 67: (1, 127, 0.08661351358063343), 68: (1, 127, 0.08653137275553126), 69: (1, 127, 0.08661389456489893), 70: (1, 127, 0.08654049529481357)}\n",
      "{'predict_runtime': 792.7854, 'predict_samples_per_second': 0.09, 'predict_steps_per_second': 0.09}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:13:12.78\n",
      "  predict_samples_per_second =       0.09\n",
      "  predict_steps_per_second   =       0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.19155418407171965), 2: (2, 0.16933137364685535), 3: (2, 0.16567816585302353), 4: (2, 0.16810409631580114), 5: (2, 0.16280302964150906), 6: (2, 0.17074539698660374), 7: (2, 0.16886014863848686), 8: (2, 0.17577676847577095), 9: (2, 0.17449090257287025), 10: (2, 0.17054226715117693), 11: (2, 0.174802016466856), 12: (2, 0.16222636494785547), 13: (2, 0.17506952304393053), 14: (2, 0.1614999333396554), 15: (2, 0.17469202727079391), 16: (2, 0.17548143863677979), 17: (2, 0.17498067300766706), 18: (2, 0.17528188973665237), 19: (2, 0.17409901414066553), 20: (2, 0.1629129070788622), 21: (2, 0.1592165706679225), 22: (2, 0.17509354278445244), 23: (2, 0.164726915769279), 24: (2, 0.1786125712096691), 25: (2, 0.1685768598690629), 26: (2, 0.16246334370225668), 27: (2, 0.16554106585681438), 28: (2, 0.17517732363194227), 29: (2, 0.16090654209256172), 30: (2, 0.16282741073518991), 31: (2, 0.17714335024356842), 32: (2, 0.1672499282285571), 33: (2, 0.16093386244028807), 34: (2, 0.17417098488658667), 35: (2, 0.17470604926347733), 36: (2, 0.17466572020202875), 37: (2, 0.17375605087727308), 38: (2, 0.1754414113238454), 39: (2, 0.1758079370483756), 40: (2, 0.16423359420150518), 41: (2, 0.1624314459040761), 42: (2, 0.17506908532232046), 43: (2, 0.17450378369539976), 44: (2, 0.16269982233643532), 45: (2, 0.17657675873488188), 46: (2, 0.17811437975615263), 47: (2, 0.17497219797223806), 48: (2, 0.17543494328856468), 49: (2, 0.1746732210740447), 50: (2, 0.17388157080858946), 51: (2, 0.17604050505906343), 52: (2, 0.17495525814592838), 53: (2, 0.17504761833697557), 54: (2, 0.17593019641935825), 55: (2, 0.17515332717448473), 56: (2, 0.17444227449595928), 57: (2, 0.17077246867120266), 58: (2, 0.17626475263386965), 59: (2, 0.1620099414139986), 60: (2, 0.17480485700070858), 61: (2, 0.17464978899806738), 62: (2, 0.17751012463122606), 63: (2, 0.17491030786186457), 64: (2, 0.17451539356261492), 65: (2, 0.17576053831726313), 66: (2, 0.17500755842775106), 67: (2, 0.1755464021116495), 68: (2, 0.17520489543676376), 69: (2, 0.16379418410360813), 70: (2, 0.1745535535737872), 71: (1, 0.1626406079158187)}\n",
      "{1: (2, 127, 0.1354863713165437), 2: (2, 127, 0.13608239929184435), 3: (2, 127, 0.1356010607216419), 4: (2, 127, 0.13536836506109537), 5: (2, 127, 0.1350677537284498), 6: (2, 127, 0.13505214003948715), 7: (2, 127, 0.1352472688313427), 8: (2, 127, 0.134950238565995), 9: (2, 127, 0.1350830532390419), 10: (2, 127, 0.13493695859540636), 11: (2, 127, 0.13500785424308046), 12: (2, 127, 0.13497919650147044), 13: (2, 127, 0.13491603090449816), 14: (2, 127, 0.13495363686673753), 15: (2, 127, 0.1349375971600296), 16: (2, 127, 0.13501411725539625), 17: (2, 127, 0.13484028253088318), 18: (2, 127, 0.13496274495952007), 19: (2, 127, 0.13505730756712475), 20: (2, 127, 0.1350822502923176), 21: (2, 127, 0.13497375065504802), 22: (2, 127, 0.13504877396103904), 23: (2, 127, 0.13519044381045686), 24: (2, 127, 0.13531535298482875), 25: (2, 127, 0.13520026374168284), 26: (2, 127, 0.13522053990278424), 27: (2, 127, 0.13526814802014453), 28: (2, 127, 0.13520838639251595), 29: (2, 127, 0.13521825841180687), 30: (2, 127, 0.1352086587127034), 31: (2, 127, 0.13514689529153306), 32: (2, 127, 0.13520271929464941), 33: (2, 127, 0.13512452734326283), 34: (2, 127, 0.13524970477520246), 35: (2, 127, 0.13516794953964592), 36: (2, 127, 0.13516856167524113), 37: (2, 127, 0.13518249855090783), 38: (2, 127, 0.13536478805641725), 39: (2, 127, 0.135404940973234), 40: (2, 127, 0.13523365373862542), 41: (2, 127, 0.13520968798547983), 42: (2, 127, 0.13513608823171047), 43: (2, 127, 0.13513562983767255), 44: (2, 127, 0.13516632547440727), 45: (2, 127, 0.135085649355718), 46: (2, 127, 0.13514345042466178), 47: (2, 127, 0.1352923656777134), 48: (2, 127, 0.135218912310253), 49: (2, 127, 0.13512384912776432), 50: (2, 127, 0.1352236733192534), 51: (2, 127, 0.1353538028866522), 52: (2, 127, 0.1351343415545549), 53: (2, 127, 0.13520087149932863), 54: (2, 127, 0.13523578283002996), 55: (2, 127, 0.13523087171676357), 56: (2, 127, 0.13528960898489228), 57: (2, 127, 0.13519705970602947), 58: (2, 127, 0.1352334557849122), 59: (2, 127, 0.1351118765507392), 60: (2, 127, 0.1352781638517741), 61: (2, 127, 0.13521496067190264), 62: (2, 127, 0.1353027717261685), 63: (2, 127, 0.13508872026357593), 64: (2, 127, 0.13521492889693637), 65: (2, 127, 0.13514887675730966), 66: (2, 127, 0.13518826870291722), 67: (2, 127, 0.1352760445575897), 68: (2, 127, 0.13531468154525195), 69: (2, 127, 0.1350475978839585), 70: (2, 127, 0.13518142702395286)}\n",
      "{'predict_runtime': 1224.9796, 'predict_samples_per_second': 0.115, 'predict_steps_per_second': 0.058}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:24.97\n",
      "  predict_samples_per_second =      0.115\n",
      "  predict_steps_per_second   =      0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.24172515980899334), 2: (4, 0.21455817576497793), 3: (4, 0.21380187571048737), 4: (4, 0.2163230963051319), 5: (4, 0.21407352481037378), 6: (4, 0.21186751034110785), 7: (4, 0.2123609147965908), 8: (4, 0.21365120075643063), 9: (4, 0.21238719578832388), 10: (4, 0.21045336965471506), 11: (4, 0.21482031792402267), 12: (4, 0.2108086170628667), 13: (4, 0.21121697314083576), 14: (4, 0.21283943392336369), 15: (4, 0.20975846145302057), 16: (4, 0.21341482736170292), 17: (4, 0.21032551489770412), 18: (4, 0.20983868092298508), 19: (4, 0.2101538684219122), 20: (4, 0.21135779563337564), 21: (4, 0.20936830807477236), 22: (4, 0.21222002524882555), 23: (4, 0.21381076611578465), 24: (4, 0.2114844834432006), 25: (4, 0.21075050346553326), 26: (4, 0.21153499372303486), 27: (4, 0.2095705484971404), 28: (4, 0.21300039812922478), 29: (4, 0.21145487762987614), 30: (4, 0.21056232787668705), 31: (4, 0.215496770106256), 32: (4, 0.2167457453906536), 33: (4, 0.21402221824973822), 34: (4, 0.21272453386336565), 35: (4, 0.21634084079414606), 36: (4, 0.21146338991820812), 37: (4, 0.20983518939465284), 38: (4, 0.21391438134014606), 39: (4, 0.21452880464494228), 40: (4, 0.21282761543989182), 41: (4, 0.21103902626782656), 42: (4, 0.21361008659005165), 43: (4, 0.21187847666442394), 44: (4, 0.21328032203018665), 45: (4, 0.2137366160750389), 46: (4, 0.21234497241675854), 47: (4, 0.2134397504851222), 48: (4, 0.21476962510496378), 49: (4, 0.21335491258651018), 50: (4, 0.21072761248797178), 51: (4, 0.2106293560937047), 52: (4, 0.21992256492376328), 53: (4, 0.2122509367763996), 54: (4, 0.20919456332921982), 55: (4, 0.21042099967598915), 56: (4, 0.21339780371636152), 57: (4, 0.21188479289412498), 58: (4, 0.21173260547220707), 59: (4, 0.21038585156202316), 60: (4, 0.21137958019971848), 61: (4, 0.21196580305695534), 62: (4, 0.21702840365469456), 63: (4, 0.2101268758997321), 64: (4, 0.2106927391141653), 65: (4, 0.2149645583704114), 66: (4, 0.21316699031740427), 67: (4, 0.21356604620814323), 68: (4, 0.21600474696606398), 69: (4, 0.2109300186857581), 70: (4, 0.2087365034967661), 71: (1, 0.14766849018633366)}\n",
      "{1: (4, 127, 0.13646179298305605), 2: (4, 127, 0.13594267350863518), 3: (4, 127, 0.13574199989350058), 4: (4, 127, 0.1356299038624435), 5: (4, 127, 0.1360148169965608), 6: (4, 127, 0.1360280206573643), 7: (4, 127, 0.13584298219561108), 8: (4, 127, 0.1359949342495813), 9: (4, 127, 0.13564269282803762), 10: (4, 127, 0.135632832321947), 11: (4, 127, 0.1357211534109876), 12: (4, 127, 0.1356817018387355), 13: (4, 127, 0.1355610030563915), 14: (4, 127, 0.1356731641626968), 15: (4, 127, 0.1356397374775114), 16: (4, 127, 0.13553455709589748), 17: (4, 127, 0.1357004558887538), 18: (4, 127, 0.13642957574856562), 19: (4, 127, 0.1355006817258953), 20: (4, 127, 0.13558047902807008), 21: (4, 127, 0.13555053732995911), 22: (4, 127, 0.13545521073718006), 23: (4, 127, 0.135350766540395), 24: (4, 127, 0.13517410626385626), 25: (4, 127, 0.13523699926931088), 26: (4, 127, 0.13525217536132872), 27: (4, 127, 0.13526379029581867), 28: (4, 127, 0.1353033793298161), 29: (4, 127, 0.1352651129058731), 30: (4, 127, 0.1352509901176874), 31: (4, 127, 0.1351225861003549), 32: (4, 127, 0.1353331994499982), 33: (4, 127, 0.1352426763183958), 34: (4, 127, 0.13535428675639583), 35: (4, 127, 0.1353007964716535), 36: (4, 127, 0.13523415627882002), 37: (4, 127, 0.13521009052949629), 38: (4, 127, 0.13523079305300562), 39: (4, 127, 0.13523778559156055), 40: (4, 127, 0.13520281745018217), 41: (4, 127, 0.13522023112168463), 42: (4, 127, 0.13524835977674), 43: (4, 127, 0.13516144389213305), 44: (4, 127, 0.13529192376881838), 45: (4, 127, 0.13527948715115393), 46: (4, 127, 0.1353426154732235), 47: (4, 127, 0.13520415404474173), 48: (4, 127, 0.13526433726816667), 49: (4, 127, 0.1352571146049368), 50: (4, 127, 0.13528608276296084), 51: (4, 127, 0.1352921007127743), 52: (4, 127, 0.13527665963381763), 53: (4, 127, 0.1351276637736972), 54: (4, 127, 0.1351562239611008), 55: (4, 127, 0.13517886580620694), 56: (4, 127, 0.13524188197357215), 57: (4, 127, 0.13535678548019703), 58: (4, 127, 0.13531669467599608), 59: (4, 127, 0.1353739087770539), 60: (4, 127, 0.13537516661985652), 61: (4, 127, 0.13522820338225505), 62: (4, 127, 0.13528800469742516), 63: (4, 127, 0.1353517373011807), 64: (4, 127, 0.13539820704169162), 65: (4, 127, 0.13514715266655983), 66: (4, 127, 0.13509816549513048), 67: (4, 127, 0.1351509954721674), 68: (4, 127, 0.13522397247913082), 69: (4, 127, 0.13522897673932116), 70: (4, 127, 0.13532065125695597)}\n",
      "{'predict_runtime': 1229.9191, 'predict_samples_per_second': 0.228, 'predict_steps_per_second': 0.058}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:29.91\n",
      "  predict_samples_per_second =      0.228\n",
      "  predict_steps_per_second   =      0.058\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 17\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.30195895582437515), 2: (1, 0.272229858674109), 3: (1, 0.26851130463182926), 4: (1, 0.2660234235227108), 5: (1, 0.262481477111578), 6: (1, 0.2644328847527504), 7: (1, 0.26358142495155334), 8: (1, 0.2646265532821417), 9: (1, 0.2651177579537034), 10: (1, 0.26457679364830256), 11: (1, 0.26417637057602406), 12: (1, 0.26637514494359493), 13: (1, 0.26643662340939045), 14: (1, 0.26275724917650223), 15: (1, 0.26410985365509987), 16: (1, 0.2627546591684222), 17: (1, 0.26402945443987846), 18: (1, 0.26504540257155895), 19: (1, 0.26416987366974354), 20: (1, 0.26372252963483334), 21: (1, 0.26359021104872227), 22: (1, 0.26383766904473305), 23: (1, 0.2665336485952139), 24: (1, 0.26414391584694386), 25: (1, 0.2628633724525571), 26: (1, 0.26583412662148476), 27: (1, 0.2635901039466262), 28: (1, 0.2675769068300724), 29: (1, 0.2683791881427169), 30: (1, 0.2640834590420127), 31: (1, 0.2684679878875613), 32: (1, 0.26593199744820595), 33: (1, 0.2664439920336008), 34: (1, 0.26498313900083303), 35: (1, 0.2635312154889107), 36: (1, 0.26344124786555767), 37: (1, 0.264026191085577), 38: (1, 0.2628689333796501), 39: (1, 0.2623880011960864), 40: (1, 0.2632727110758424), 41: (1, 0.26236473210155964), 42: (1, 0.2623097114264965), 43: (1, 0.2639130437746644), 44: (1, 0.26320999301970005), 45: (1, 0.2647310448810458), 46: (1, 0.2677276795729995), 47: (1, 0.2632605731487274), 48: (1, 0.266195279546082), 49: (1, 0.26342366077005863), 50: (1, 0.2637877566739917), 51: (1, 0.26266618072986603), 52: (1, 0.26504344306886196), 53: (1, 0.2632655845955014), 54: (1, 0.2634684620425105), 55: (1, 0.26571386586874723), 56: (1, 0.26604307163506746), 57: (1, 0.2647940767928958), 58: (1, 0.2661099536344409), 59: (1, 0.26521521247923374), 60: (1, 0.26558402832597494), 61: (1, 0.2667869655415416), 62: (1, 0.26722707133740187), 63: (1, 0.2671239608898759), 64: (1, 0.2670742515474558), 65: (1, 0.2634136052802205), 66: (1, 0.264100787229836), 67: (1, 0.26334369741380215), 68: (1, 0.26269625406712294), 69: (1, 0.26672296691685915), 70: (1, 0.26765244640409946), 71: (1, 0.26319495867937803)}\n",
      "{1: (1, 127, 0.15619353171965972), 2: (1, 127, 0.15527454627985796), 3: (1, 127, 0.1552600044845127), 4: (1, 127, 0.1553608071366985), 5: (1, 127, 0.15505946731180187), 6: (1, 127, 0.1551797576101981), 7: (1, 127, 0.1550419493835038), 8: (1, 127, 0.15512034520653523), 9: (1, 127, 0.1548824762764174), 10: (1, 127, 0.15522734025918591), 11: (1, 127, 0.15526443207269813), 12: (1, 127, 0.1552402290229605), 13: (1, 127, 0.1551681802439408), 14: (1, 127, 0.15511903029639185), 15: (1, 127, 0.1552365362776194), 16: (1, 127, 0.15528229900496446), 17: (1, 127, 0.15503585558589988), 18: (1, 127, 0.15522403597802392), 19: (1, 127, 0.1550104715384719), 20: (1, 127, 0.1551626640863306), 21: (1, 127, 0.15510572817205914), 22: (1, 127, 0.15532095649638983), 23: (1, 127, 0.1553490361873442), 24: (1, 127, 0.15526311573257126), 25: (1, 127, 0.1549326697379116), 26: (1, 127, 0.15487197614238252), 27: (1, 127, 0.15487092261855293), 28: (1, 127, 0.15489932197314782), 29: (1, 127, 0.1550939381709249), 30: (1, 127, 0.15505292480738145), 31: (1, 127, 0.1549864124330714), 32: (1, 127, 0.15485340117029553), 33: (1, 127, 0.155028720730989), 34: (1, 127, 0.1552132892781707), 35: (1, 127, 0.15500495640018325), 36: (1, 127, 0.1545159146409687), 37: (1, 127, 0.15446185938808626), 38: (1, 127, 0.154566299976913), 39: (1, 127, 0.15453300675685247), 40: (1, 127, 0.15448655613412068), 41: (1, 127, 0.15449280181797), 42: (1, 127, 0.15436292675096452), 43: (1, 127, 0.15496711346401473), 44: (1, 127, 0.1554057677533096), 45: (1, 127, 0.1548181716939361), 46: (1, 127, 0.1550193731709728), 47: (1, 127, 0.15483925978499136), 48: (1, 127, 0.15486067867155853), 49: (1, 127, 0.15476099827774162), 50: (1, 127, 0.1549497640611032), 51: (1, 127, 0.15475673169836285), 52: (1, 127, 0.15499452107739964), 53: (1, 127, 0.1549085630323943), 54: (1, 127, 0.15491021811727465), 55: (1, 127, 0.15504725822284232), 56: (1, 127, 0.15489142115308543), 57: (1, 127, 0.15459110735233608), 58: (1, 127, 0.15484655061810035), 59: (1, 127, 0.15469006883112466), 60: (1, 127, 0.15474350478382795), 61: (1, 127, 0.15481212608310885), 62: (1, 127, 0.15477347376162376), 63: (1, 127, 0.1547587669095186), 64: (1, 127, 0.15487565480055301), 65: (1, 127, 0.15465292723952082), 66: (1, 127, 0.15460922709101532), 67: (1, 127, 0.15456185487692986), 68: (1, 127, 0.15464582243626276), 69: (1, 127, 0.15448569917068708), 70: (1, 127, 0.15457592697770106)}\n",
      "{'predict_runtime': 1415.9652, 'predict_samples_per_second': 0.05, 'predict_steps_per_second': 0.05}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:35.96\n",
      "  predict_samples_per_second =       0.05\n",
      "  predict_steps_per_second   =       0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.329680185765028), 2: (2, 0.31748118065297604), 3: (2, 0.29058586806058884), 4: (2, 0.30805302131921053), 5: (2, 0.3085607374086976), 6: (2, 0.288791929371655), 7: (2, 0.2862203102558851), 8: (2, 0.3001194968819618), 9: (2, 0.2999287899583578), 10: (2, 0.30688553862273693), 11: (2, 0.286979709751904), 12: (2, 0.31040522549301386), 13: (2, 0.2903090100735426), 14: (2, 0.30787136498838663), 15: (2, 0.30133005138486624), 16: (2, 0.2979289414361119), 17: (2, 0.2867299821227789), 18: (2, 0.3095212457701564), 19: (2, 0.28673145174980164), 20: (2, 0.29992469772696495), 21: (2, 0.2983764251694083), 22: (2, 0.29899462778121233), 23: (2, 0.30899479147046804), 24: (2, 0.30805588234215975), 25: (2, 0.3081443114206195), 26: (2, 0.285959399305284), 27: (2, 0.30640525091439486), 28: (2, 0.2991887051612139), 29: (2, 0.31200367491692305), 30: (2, 0.29944639187306166), 31: (2, 0.3000228051096201), 32: (2, 0.3017322653904557), 33: (2, 0.29851965233683586), 34: (2, 0.29997195582836866), 35: (2, 0.28780092764645815), 36: (2, 0.30618785321712494), 37: (2, 0.31281990464776754), 38: (2, 0.30253651551902294), 39: (2, 0.30896019097417593), 40: (2, 0.30899481009691954), 41: (2, 0.30815905053168535), 42: (2, 0.30495461728423834), 43: (2, 0.30670507717877626), 44: (2, 0.31379645224660635), 45: (2, 0.29065814428031445), 46: (2, 0.28333695884793997), 47: (2, 0.3088200008496642), 48: (2, 0.29291656613349915), 49: (2, 0.2988561596721411), 50: (2, 0.2878177771344781), 51: (2, 0.3087565014138818), 52: (2, 0.28822517208755016), 53: (2, 0.28602878749370575), 54: (2, 0.28389568254351616), 55: (2, 0.31084671802818775), 56: (2, 0.2883139895275235), 57: (2, 0.3095643315464258), 58: (2, 0.2881579417735338), 59: (2, 0.29058724362403154), 60: (2, 0.28781709633767605), 61: (2, 0.3088640607893467), 62: (2, 0.29519875068217516), 63: (2, 0.29940502997487783), 64: (2, 0.31427273619920015), 65: (2, 0.3064084891229868), 66: (2, 0.29476796463131905), 67: (2, 0.3130242321640253), 68: (2, 0.30745886638760567), 69: (2, 0.3094735434278846), 70: (2, 0.2962784571573138), 71: (1, 0.27900989912450314)}\n",
      "{1: (2, 127, 0.24577606413660086), 2: (2, 127, 0.24359308109127395), 3: (2, 127, 0.24286104330983688), 4: (2, 127, 0.24266302680200713), 5: (2, 127, 0.24298223032520747), 6: (2, 127, 0.2427381871884146), 7: (2, 127, 0.24262593294985182), 8: (2, 127, 0.24262748320594313), 9: (2, 127, 0.24290925935350768), 10: (2, 127, 0.2426016224826884), 11: (2, 127, 0.2425734775184881), 12: (2, 127, 0.24272530850052365), 13: (2, 127, 0.24273283556690367), 14: (2, 127, 0.24323601732543837), 15: (2, 127, 0.24303177907681606), 16: (2, 127, 0.24266265354698568), 17: (2, 127, 0.2438008515164256), 18: (2, 127, 0.2431585364938369), 19: (2, 127, 0.2426019092273759), 20: (2, 127, 0.24276924719227347), 21: (2, 127, 0.24283991622056547), 22: (2, 127, 0.24327264833960713), 23: (2, 127, 0.2431535091045804), 24: (2, 127, 0.24256698816545366), 25: (2, 127, 0.2430163994651493), 26: (2, 127, 0.24292210980105822), 27: (2, 127, 0.24255711114488718), 28: (2, 127, 0.24739790904357678), 29: (2, 127, 0.24329193629412435), 30: (2, 127, 0.24299050566161007), 31: (2, 127, 0.2426782653879697), 32: (2, 127, 0.2427674643622022), 33: (2, 127, 0.2427477658704275), 34: (2, 127, 0.243234604135097), 35: (2, 127, 0.24336424247750382), 36: (2, 127, 0.24525623048443024), 37: (2, 127, 0.24312472225379522), 38: (2, 127, 0.2427447507245921), 39: (2, 127, 0.24290591067685854), 40: (2, 127, 0.24278914395309104), 41: (2, 127, 0.24291926183129156), 42: (2, 127, 0.24249996005843474), 43: (2, 127, 0.24272200617000578), 44: (2, 127, 0.24274519489212767), 45: (2, 127, 0.24268090244617282), 46: (2, 127, 0.24325632937545852), 47: (2, 127, 0.24274096117303598), 48: (2, 127, 0.24297902943551775), 49: (2, 127, 0.24286093745439305), 50: (2, 127, 0.24312200334187098), 51: (2, 127, 0.24336690831137456), 52: (2, 127, 0.24314291694560858), 53: (2, 127, 0.24318884250040598), 54: (2, 127, 0.242780474007247), 55: (2, 127, 0.2429368579613529), 56: (2, 127, 0.2429017616421219), 57: (2, 127, 0.2439409933074957), 58: (2, 127, 0.24344226319020187), 59: (2, 127, 0.24353758525836655), 60: (2, 127, 0.24381621415895505), 61: (2, 127, 0.24256542984278887), 62: (2, 127, 0.2425187957055104), 63: (2, 127, 0.24242367253704802), 64: (2, 127, 0.2424808063903662), 65: (2, 127, 0.24239312768657142), 66: (2, 127, 0.24247457851164453), 67: (2, 127, 0.24269423015621), 68: (2, 127, 0.24239224672874832), 69: (2, 127, 0.2427093423536326), 70: (2, 127, 0.24272962113270374)}\n",
      "{'predict_runtime': 2201.6573, 'predict_samples_per_second': 0.064, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:41.65\n",
      "  predict_samples_per_second =      0.064\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.4132330100983381), 2: (4, 0.3808830790221691), 3: (4, 0.39323029294610023), 4: (4, 0.3896374348551035), 5: (4, 0.3812220646068454), 6: (4, 0.37776248529553413), 7: (4, 0.3762631742283702), 8: (4, 0.37376447208225727), 9: (4, 0.37177023384720087), 10: (4, 0.376866664737463), 11: (4, 0.40005470626056194), 12: (4, 0.3969041518867016), 13: (4, 0.3761786222457886), 14: (4, 0.37610362097620964), 15: (4, 0.3956777546554804), 16: (4, 0.37448502890765667), 17: (4, 0.38136661890894175), 18: (4, 0.38363548181951046), 19: (4, 0.3743329085409641), 20: (4, 0.373243591748178), 21: (4, 0.39680265821516514), 22: (4, 0.3756591845303774), 23: (4, 0.3759509492665529), 24: (4, 0.3772699609398842), 25: (4, 0.3822800135239959), 26: (4, 0.37567307986319065), 27: (4, 0.3769902242347598), 28: (4, 0.3727601729333401), 29: (4, 0.37341018579900265), 30: (4, 0.39604730159044266), 31: (4, 0.3756689699366689), 32: (4, 0.37280702125281096), 33: (4, 0.3763046218082309), 34: (4, 0.38865718711167574), 35: (4, 0.3801035173237324), 36: (4, 0.38701510708779097), 37: (4, 0.3758770665153861), 38: (4, 0.3746505603194237), 39: (4, 0.3761440636590123), 40: (4, 0.3809913769364357), 41: (4, 0.3796261828392744), 42: (4, 0.3820613147690892), 43: (4, 0.3748494293540716), 44: (4, 0.386320355348289), 45: (4, 0.375602119602263), 46: (4, 0.3726202938705683), 47: (4, 0.3765401095151901), 48: (4, 0.37513949535787106), 49: (4, 0.3744961032643914), 50: (4, 0.3893416803330183), 51: (4, 0.3794342242181301), 52: (4, 0.373957728035748), 53: (4, 0.38145899027585983), 54: (4, 0.398407113738358), 55: (4, 0.38007783703505993), 56: (4, 0.3853125860914588), 57: (4, 0.3782060192897916), 58: (4, 0.3763928096741438), 59: (4, 0.38020158652216196), 60: (4, 0.3974411338567734), 61: (4, 0.376703935675323), 62: (4, 0.38021166529506445), 63: (4, 0.3811355149373412), 64: (4, 0.38577008061110973), 65: (4, 0.38216328248381615), 66: (4, 0.37788223288953304), 67: (4, 0.37537393160164356), 68: (4, 0.3774351980537176), 69: (4, 0.3868377283215523), 70: (4, 0.3718656115233898), 71: (1, 0.268468058668077)}\n",
      "{1: (4, 127, 0.24579556602398006), 2: (4, 127, 0.24385562938029373), 3: (4, 127, 0.243436978968579), 4: (4, 127, 0.24318538856230618), 5: (4, 127, 0.2441046916417719), 6: (4, 127, 0.24335326995759263), 7: (4, 127, 0.24337720028381413), 8: (4, 127, 0.24338979154502546), 9: (4, 127, 0.24315501148922472), 10: (4, 127, 0.2431778847569908), 11: (4, 127, 0.24321234112561452), 12: (4, 127, 0.2432471476495266), 13: (4, 127, 0.24354956463331312), 14: (4, 127, 0.24349384914027658), 15: (4, 127, 0.24360616274148694), 16: (4, 127, 0.243272925125743), 17: (4, 127, 0.24337517074125958), 18: (4, 127, 0.24338717386126518), 19: (4, 127, 0.24338784089355958), 20: (4, 127, 0.24321649212566182), 21: (4, 127, 0.2433419372431758), 22: (4, 127, 0.2433237074177683), 23: (4, 127, 0.2431580316656687), 24: (4, 127, 0.24366973544375634), 25: (4, 127, 0.24328887150219575), 26: (4, 127, 0.2442192795107097), 27: (4, 127, 0.2434967245217266), 28: (4, 127, 0.24333791168567936), 29: (4, 127, 0.24329896486092975), 30: (4, 127, 0.2432684035986427), 31: (4, 127, 0.24333348974409535), 32: (4, 127, 0.24346423346373275), 33: (4, 127, 0.24464072394881428), 34: (4, 127, 0.24664904782181885), 35: (4, 127, 0.24345826357603073), 36: (4, 127, 0.24381161155545805), 37: (4, 127, 0.2439474901697767), 38: (4, 127, 0.2439491289308456), 39: (4, 127, 0.24395932855568533), 40: (4, 127, 0.24399180435318882), 41: (4, 127, 0.24416942210266673), 42: (4, 127, 0.24396041804176616), 43: (4, 127, 0.24389367485345584), 44: (4, 127, 0.2437556217915899), 45: (4, 127, 0.24395733548137616), 46: (4, 127, 0.24381871989334192), 47: (4, 127, 0.2437706392507736), 48: (4, 127, 0.24379137251526117), 49: (4, 127, 0.2439447558946966), 50: (4, 127, 0.2436988624472787), 51: (4, 127, 0.24345091059363969), 52: (4, 127, 0.24327690574509186), 53: (4, 127, 0.24345060833913135), 54: (4, 127, 0.24353071610905289), 55: (4, 127, 0.24420149606014566), 56: (4, 127, 0.24377858222968232), 57: (4, 127, 0.2438250070173792), 58: (4, 127, 0.2436915346912629), 59: (4, 127, 0.24360190846729934), 60: (4, 127, 0.2436307860670362), 61: (4, 127, 0.24371298736943972), 62: (4, 127, 0.24347509184896243), 63: (4, 127, 0.24341116115216196), 64: (4, 127, 0.24342670166263664), 65: (4, 127, 0.24454623913231094), 66: (4, 127, 0.24353214140658772), 67: (4, 127, 0.24346441974291416), 68: (4, 127, 0.24345427188347643), 69: (4, 127, 0.24341449256634384), 70: (4, 127, 0.2433944573537923)}\n",
      "{'predict_runtime': 2212.907, 'predict_samples_per_second': 0.127, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:52.90\n",
      "  predict_samples_per_second =      0.127\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 31\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.31221621483564377), 2: (1, 0.15521261282265186), 3: (1, 0.14476579893380404), 4: (1, 0.14475540909916162), 5: (1, 0.14389574993401766), 6: (1, 0.14233085978776217), 7: (1, 0.14330750610679388), 8: (1, 0.14421710651367903), 9: (1, 0.14225326012820005), 10: (1, 0.14250818639993668), 11: (1, 0.1422156896442175), 12: (1, 0.14432088565081358), 13: (1, 0.14793730340898037), 14: (1, 0.1444513937458396), 15: (1, 0.14343054685741663), 16: (1, 0.14120893273502588), 17: (1, 0.14457865338772535), 18: (1, 0.14864004589617252), 19: (1, 0.14372976403683424), 20: (1, 0.14365740586072206), 21: (1, 0.14614708628505468), 22: (1, 0.1447074543684721), 23: (1, 0.14361262694001198), 24: (1, 0.1429219152778387), 25: (1, 0.1487626051530242), 26: (1, 0.14473680313676596), 27: (1, 0.14488512184470892), 28: (1, 0.14617529697716236), 29: (1, 0.14306757412850857), 30: (1, 0.14447707775980234), 31: (1, 0.1417016014456749), 32: (1, 0.14293838571757078), 33: (1, 0.1448530526831746), 34: (1, 0.1411195769906044), 35: (1, 0.1471120659261942), 36: (1, 0.14394791424274445), 37: (1, 0.1423996826633811), 38: (1, 0.14147889334708452), 39: (1, 0.14806424640119076), 40: (1, 0.14530305843800306), 41: (1, 0.15390110667794943), 42: (1, 0.1487937280908227), 43: (1, 0.1495555192232132), 44: (1, 0.14547182712703943), 45: (1, 0.1452189814299345), 46: (1, 0.14587740413844585), 47: (1, 0.14495544508099556), 48: (1, 0.14270726218819618), 49: (1, 0.1425732532516122), 50: (1, 0.14589598402380943), 51: (1, 0.14367638994008303), 52: (1, 0.14830870646983385), 53: (1, 0.1429365100339055), 54: (1, 0.14259033370763063), 55: (1, 0.14356019161641598), 56: (1, 0.15433789417147636), 57: (1, 0.14373259991407394), 58: (1, 0.14645713940262794), 59: (1, 0.1442776955664158), 60: (1, 0.1442260444164276), 61: (1, 0.14833744708448648), 62: (1, 0.14568529836833477), 63: (1, 0.1420180220156908), 64: (1, 0.1464715600013733), 65: (1, 0.15942154545336962), 66: (1, 0.14342116564512253), 67: (1, 0.14369824435561895), 68: (1, 0.14437109418213367), 69: (1, 0.1408244576305151), 70: (1, 0.14523317478597164), 71: (1, 0.1416462380439043)}\n",
      "{1: (1, 255, 0.08418712522469315), 2: (1, 255, 0.08422356091951039), 3: (1, 255, 0.08318091307346727), 4: (1, 255, 0.08319666654455896), 5: (1, 255, 0.08343429087715991), 6: (1, 255, 0.0830741182882704), 7: (1, 255, 0.08285834969697045), 8: (1, 255, 0.08299232550403651), 9: (1, 255, 0.08291313077012698), 10: (1, 255, 0.0828849165207323), 11: (1, 255, 0.08314189062472067), 12: (1, 255, 0.0833026830545243), 13: (1, 255, 0.08484604112876981), 14: (1, 255, 0.08354719104062693), 15: (1, 255, 0.08317142525213021), 16: (1, 255, 0.0832080787303401), 17: (1, 255, 0.08428389348966234), 18: (1, 255, 0.08449719886058102), 19: (1, 255, 0.08320847060166153), 20: (1, 255, 0.0839722357507722), 21: (1, 255, 0.08351665851751379), 22: (1, 255, 0.08317732354078222), 23: (1, 255, 0.0832032013830601), 24: (1, 255, 0.0844293265146952), 25: (1, 255, 0.08483566653129516), 26: (1, 255, 0.08413892130130061), 27: (1, 255, 0.08340688108594395), 28: (1, 255, 0.08367366648699139), 29: (1, 255, 0.08376174291194069), 30: (1, 255, 0.08350084656301666), 31: (1, 255, 0.08329057690194425), 32: (1, 255, 0.08334228247404099), 33: (1, 255, 0.08315301570018717), 34: (1, 255, 0.08433305382290307), 35: (1, 255, 0.083450757536818), 36: (1, 255, 0.08330435703198115), 37: (1, 255, 0.08284279475463371), 38: (1, 255, 0.0840184313993828), 39: (1, 255, 0.08449409901365346), 40: (1, 255, 0.0843045697273577), 41: (1, 255, 0.08625270761549472), 42: (1, 255, 0.08441939617634989), 43: (1, 255, 0.0841836117536706), 44: (1, 255, 0.08365094709922286), 45: (1, 255, 0.08328087763751255), 46: (1, 255, 0.08308265692024838), 47: (1, 255, 0.08313347939767089), 48: (1, 255, 0.08344328097779961), 49: (1, 255, 0.08337414025456882), 50: (1, 255, 0.08357872019576676), 51: (1, 255, 0.08657878397726546), 52: (1, 255, 0.08297321170422377), 53: (1, 255, 0.08303458260408804), 54: (1, 255, 0.08303148528451429), 55: (1, 255, 0.08350317200244058), 56: (1, 255, 0.08540697844297278), 57: (1, 255, 0.08774087475064923), 58: (1, 255, 0.08374809062875369), 59: (1, 255, 0.08406133465103659), 60: (1, 255, 0.08332675477015038), 61: (1, 255, 0.08292988047880286), 62: (1, 255, 0.08307487245137785), 63: (1, 255, 0.08456424174136391), 64: (1, 255, 0.08514692135082157), 65: (1, 255, 0.0848532884180838), 66: (1, 255, 0.08306951887321239), 67: (1, 255, 0.08281779720941011), 68: (1, 255, 0.08279536881794532), 69: (1, 255, 0.083950681454849), 70: (1, 255, 0.08391675665682437)}\n",
      "{'predict_runtime': 1526.8288, 'predict_samples_per_second': 0.047, 'predict_steps_per_second': 0.047}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:26.82\n",
      "  predict_samples_per_second =      0.047\n",
      "  predict_steps_per_second   =      0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.1945906300097704), 2: (2, 0.15783220622688532), 3: (2, 0.16725793480873108), 4: (2, 0.16095757856965065), 5: (2, 0.15174464881420135), 6: (2, 0.15604025777429342), 7: (2, 0.1625972306355834), 8: (2, 0.15980286337435246), 9: (2, 0.16027839947491884), 10: (2, 0.1575919408351183), 11: (2, 0.15558350458741188), 12: (2, 0.18573410715907812), 13: (2, 0.15648631379008293), 14: (2, 0.1557583138346672), 15: (2, 0.15579275228083134), 16: (2, 0.15784589853137732), 17: (2, 0.15294007677584887), 18: (2, 0.15582349244505167), 19: (2, 0.15579331293702126), 20: (2, 0.1555868461728096), 21: (2, 0.15687059983611107), 22: (2, 0.15704025980085135), 23: (2, 0.15483995620161295), 24: (2, 0.1532586645334959), 25: (2, 0.1881859190762043), 26: (2, 0.16220018826425076), 27: (2, 0.15487436577677727), 28: (2, 0.15385216753929853), 29: (2, 0.15192746091634035), 30: (2, 0.15480476710945368), 31: (2, 0.16724218055605888), 32: (2, 0.15760478470474482), 33: (2, 0.15321684628725052), 34: (2, 0.19260731898248196), 35: (2, 0.15363695193082094), 36: (2, 0.15667670592665672), 37: (2, 0.16156998835504055), 38: (2, 0.1564486688002944), 39: (2, 0.1641933862119913), 40: (2, 0.15598128456622362), 41: (2, 0.16645654011517763), 42: (2, 0.1911162380129099), 43: (2, 0.1622060826048255), 44: (2, 0.1601748364046216), 45: (2, 0.15835906751453876), 46: (2, 0.1967149218544364), 47: (2, 0.15806105267256498), 48: (2, 0.1936976993456483), 49: (2, 0.15359047707170248), 50: (2, 0.1651862384751439), 51: (2, 0.16806823574006557), 52: (2, 0.15744355134665966), 53: (2, 0.16326944157481194), 54: (2, 0.1742578325793147), 55: (2, 0.15840758942067623), 56: (2, 0.18360908143222332), 57: (2, 0.15766408946365118), 58: (2, 0.1614400753751397), 59: (2, 0.1598779745399952), 60: (2, 0.15766536071896553), 61: (2, 0.17560299672186375), 62: (2, 0.16172337252646685), 63: (2, 0.156294715590775), 64: (2, 0.15725914482027292), 65: (2, 0.16357131954282522), 66: (2, 0.15944807045161724), 67: (2, 0.1624266942963004), 68: (2, 0.18287927098572254), 69: (2, 0.1961996629834175), 70: (2, 0.1531501356512308), 71: (1, 0.15592029225081205)}\n",
      "{1: (2, 255, 0.12974352330042452), 2: (2, 255, 0.1285405470788771), 3: (2, 255, 0.12902827765062158), 4: (2, 255, 0.1297908169966118), 5: (2, 255, 0.12882028185196367), 6: (2, 255, 0.12878165113940543), 7: (2, 255, 0.12854876158138115), 8: (2, 255, 0.1309782121768769), 9: (2, 255, 0.12876524998642067), 10: (2, 255, 0.12870238088801794), 11: (2, 255, 0.13029284037868766), 12: (2, 255, 0.1291602699962609), 13: (2, 255, 0.1287676966767393), 14: (2, 255, 0.12866792778174083), 15: (2, 255, 0.1287494866615709), 16: (2, 255, 0.12857020852685558), 17: (2, 255, 0.13005730250083347), 18: (2, 255, 0.12841526875089782), 19: (2, 255, 0.12824738996797333), 20: (2, 255, 0.12856753219430353), 21: (2, 255, 0.12896957368242976), 22: (2, 255, 0.12842285623226096), 23: (2, 255, 0.12849061032939776), 24: (2, 255, 0.1284351356583191), 25: (2, 255, 0.12837864259878795), 26: (2, 255, 0.1285469820832505), 27: (2, 255, 0.1283676617797099), 28: (2, 255, 0.12844851677324257), 29: (2, 255, 0.12844746199746926), 30: (2, 255, 0.12827696804979852), 31: (2, 255, 0.12842426071783491), 32: (2, 255, 0.128477513289773), 33: (2, 255, 0.12839662388478423), 34: (2, 255, 0.1283158554239016), 35: (2, 255, 0.128361587883795), 36: (2, 255, 0.12839819821437784), 37: (2, 255, 0.12851031345552674), 38: (2, 255, 0.12883143114546936), 39: (2, 255, 0.12863418916422947), 40: (2, 255, 0.1288578239287816), 41: (2, 255, 0.12872998868571778), 42: (2, 255, 0.12881199003872917), 43: (2, 255, 0.1285634835195892), 44: (2, 255, 0.1287067421036316), 45: (2, 255, 0.12940827374364816), 46: (2, 255, 0.12884347817550104), 47: (2, 255, 0.12871190879274816), 48: (2, 255, 0.12879515619327625), 49: (2, 255, 0.12881426152718417), 50: (2, 255, 0.12885871726800413), 51: (2, 255, 0.12880903651536096), 52: (2, 255, 0.12867192017900594), 53: (2, 255, 0.12861281070931285), 54: (2, 255, 0.12872822870153422), 55: (2, 255, 0.12911111787692003), 56: (2, 255, 0.12995047354888098), 57: (2, 255, 0.1286239751596369), 58: (2, 255, 0.1286330198211705), 59: (2, 255, 0.1286694577657709), 60: (2, 255, 0.1303236384419542), 61: (2, 255, 0.13210146091878414), 62: (2, 255, 0.12903766743473563), 63: (2, 255, 0.1287171541621872), 64: (2, 255, 0.13026741050622043), 65: (2, 255, 0.12871310138965356), 66: (2, 255, 0.12857553973867028), 67: (2, 255, 0.12874450078051464), 68: (2, 255, 0.12923642285168171), 69: (2, 255, 0.12878355588033502), 70: (2, 255, 0.12896742163335576)}\n",
      "{'predict_runtime': 2333.7514, 'predict_samples_per_second': 0.06, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:53.75\n",
      "  predict_samples_per_second =       0.06\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.23618916049599648), 2: (4, 0.20541807543486357), 3: (4, 0.2030726419761777), 4: (4, 0.20194593630731106), 5: (4, 0.2031832030043006), 6: (4, 0.20200368575751781), 7: (4, 0.2023320123553276), 8: (4, 0.22126713767647743), 9: (4, 0.20689937379211187), 10: (4, 0.20116758160293102), 11: (4, 0.2016600053757429), 12: (4, 0.203023049980402), 13: (4, 0.20109831169247627), 14: (4, 0.20323446579277515), 15: (4, 0.2022274388000369), 16: (4, 0.20364127214998007), 17: (4, 0.2003165315836668), 18: (4, 0.20196749176830053), 19: (4, 0.20483979769051075), 20: (4, 0.203141987323761), 21: (4, 0.20177503302693367), 22: (4, 0.20206187944859266), 23: (4, 0.20714734960347414), 24: (4, 0.20091731380671263), 25: (4, 0.2007064949721098), 26: (4, 0.20535767078399658), 27: (4, 0.20177437365055084), 28: (4, 0.20171486400067806), 29: (4, 0.20071077533066273), 30: (4, 0.20131863001734018), 31: (4, 0.20057377871125937), 32: (4, 0.20336116664111614), 33: (4, 0.20370976068079472), 34: (4, 0.20455683209002018), 35: (4, 0.20215123984962702), 36: (4, 0.20268002338707447), 37: (4, 0.20302161946892738), 38: (4, 0.2051959941163659), 39: (4, 0.2023908868432045), 40: (4, 0.20428479369729757), 41: (4, 0.20358610339462757), 42: (4, 0.19966083765029907), 43: (4, 0.20469302870333195), 44: (4, 0.20538726169615984), 45: (4, 0.20316225662827492), 46: (4, 0.20340421423316002), 47: (4, 0.20054272655397654), 48: (4, 0.20171258319169283), 49: (4, 0.2033637845888734), 50: (4, 0.20217324793338776), 51: (4, 0.200319348834455), 52: (4, 0.2029498592019081), 53: (4, 0.2007174650207162), 54: (4, 0.21774571482092142), 55: (4, 0.20566318556666374), 56: (4, 0.20243255514651537), 57: (4, 0.2009189110249281), 58: (4, 0.20246002450585365), 59: (4, 0.20141275506466627), 60: (4, 0.22525088675320148), 61: (4, 0.20552942715585232), 62: (4, 0.20036922674626112), 63: (4, 0.20128761790692806), 64: (4, 0.20309463515877724), 65: (4, 0.20568234473466873), 66: (4, 0.2044689580798149), 67: (4, 0.20912531483918428), 68: (4, 0.2005879133939743), 69: (4, 0.20555709581822157), 70: (4, 0.20210357569158077), 71: (1, 0.14205093774944544)}\n",
      "{1: (4, 255, 0.1299073911655475), 2: (4, 255, 0.1295388911175085), 3: (4, 255, 0.12954674119896747), 4: (4, 255, 0.1294539247767306), 5: (4, 255, 0.12923089398034648), 6: (4, 255, 0.1299664389707294), 7: (4, 255, 0.12966838686124366), 8: (4, 255, 0.1293817047066256), 9: (4, 255, 0.12954165034142195), 10: (4, 255, 0.12981489929279275), 11: (4, 255, 0.1297441510264488), 12: (4, 255, 0.12963304816946095), 13: (4, 255, 0.12964036797410716), 14: (4, 255, 0.1296373597729732), 15: (4, 255, 0.12957250661052325), 16: (4, 255, 0.1295562454700178), 17: (4, 255, 0.13044783446718664), 18: (4, 255, 0.13104833213283734), 19: (4, 255, 0.12949271458109804), 20: (4, 255, 0.12904212570877052), 21: (4, 255, 0.12903803074184586), 22: (4, 255, 0.1288651576046558), 23: (4, 255, 0.1292091711332985), 24: (4, 255, 0.12921097119722297), 25: (4, 255, 0.12918594432446887), 26: (4, 255, 0.12945677012789483), 27: (4, 255, 0.12951683028801983), 28: (4, 255, 0.12958739123434998), 29: (4, 255, 0.12899761901182286), 30: (4, 255, 0.12905596990649607), 31: (4, 255, 0.12899169805003147), 32: (4, 255, 0.12902838890532067), 33: (4, 255, 0.12906305672345209), 34: (4, 255, 0.12901651796099603), 35: (4, 255, 0.1290500130029578), 36: (4, 255, 0.12899808269724541), 37: (4, 255, 0.12906314118527898), 38: (4, 255, 0.12896356531510167), 39: (4, 255, 0.1290053201145401), 40: (4, 255, 0.12902210132018024), 41: (4, 255, 0.12897127884640996), 42: (4, 255, 0.1289642013974634), 43: (4, 255, 0.12899449864292847), 44: (4, 255, 0.12903402934910035), 45: (4, 255, 0.12897929681063283), 46: (4, 255, 0.12898031522465103), 47: (4, 255, 0.1289617884977191), 48: (4, 255, 0.12891014282244678), 49: (4, 255, 0.12899351148847857), 50: (4, 255, 0.12895057015486208), 51: (4, 255, 0.12894842193699352), 52: (4, 255, 0.12896687854446617), 53: (4, 255, 0.12909506963675513), 54: (4, 255, 0.1292169982202205), 55: (4, 255, 0.1290043217184789), 56: (4, 255, 0.12894414865649215), 57: (4, 255, 0.1289587123757776), 58: (4, 255, 0.1294145341487784), 59: (4, 255, 0.12933690251015564), 60: (4, 255, 0.12927610056073058), 61: (4, 255, 0.1289990844314589), 62: (4, 255, 0.1288611647910347), 63: (4, 255, 0.1288247260064179), 64: (4, 255, 0.12878018603021024), 65: (4, 255, 0.12889563990939482), 66: (4, 255, 0.12887770212529337), 67: (4, 255, 0.12881681801495598), 68: (4, 255, 0.128837268496407), 69: (4, 255, 0.12880527534905603), 70: (4, 255, 0.12895269783250257)}\n",
      "{'predict_runtime': 2342.1427, 'predict_samples_per_second': 0.12, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:39:02.14\n",
      "  predict_samples_per_second =       0.12\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 16\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/71 00:22 < 25:52, 0.04 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.18638758920133114), 2: (1, 0.1547858091071248), 3: (1, 0.15159401763230562), 4: (1, 0.15240871720016003), 5: (1, 0.14855092205107212), 6: (1, 0.15091487392783165), 7: (1, 0.1516077872365713), 8: (1, 0.14968029782176018), 9: (1, 0.14949596114456654), 10: (1, 0.14969526883214712), 11: (1, 0.14939703233540058), 12: (1, 0.1489542368799448), 13: (1, 0.14909941423684359), 14: (1, 0.1492898529395461), 15: (1, 0.15183448232710361), 16: (1, 0.15069384593516588), 17: (1, 0.14930039271712303), 18: (1, 0.15109400171786547), 19: (1, 0.15041206032037735), 20: (1, 0.15005920454859734), 21: (1, 0.1519478913396597), 22: (1, 0.14873815886676311), 23: (1, 0.15034138038754463), 24: (1, 0.1522746980190277), 25: (1, 0.15072835609316826), 26: (1, 0.15064872708171606), 27: (1, 0.15147851593792439), 28: (1, 0.14926034305244684), 29: (1, 0.15128338895738125), 30: (1, 0.1488303979858756), 31: (1, 0.1511839060112834), 32: (1, 0.15197318699210882), 33: (1, 0.1506962003186345), 34: (1, 0.15135389380156994), 35: (1, 0.1525164097547531), 36: (1, 0.15073085948824883), 37: (1, 0.1497833402827382), 38: (1, 0.1514685219153762), 39: (1, 0.15099304541945457), 40: (1, 0.15232261177152395), 41: (1, 0.15340382885187864), 42: (1, 0.14999958779662848), 43: (1, 0.14957762230187654), 44: (1, 0.1500174580141902), 45: (1, 0.1490377690643072), 46: (1, 0.1495867231860757), 47: (1, 0.1519634947180748), 48: (1, 0.15134987235069275), 49: (1, 0.14982382021844387), 50: (1, 0.15263786539435387), 51: (1, 0.1507310476154089), 52: (1, 0.150116054341197), 53: (1, 0.15050866082310677), 54: (1, 0.150154585018754), 55: (1, 0.14950027130544186), 56: (1, 0.15323183871805668), 57: (1, 0.1495577720925212), 58: (1, 0.1497042803093791), 59: (1, 0.15194275323301554), 60: (1, 0.15309670008718967), 61: (1, 0.15097765438258648), 62: (1, 0.1525712152943015), 63: (1, 0.15380709059536457), 64: (1, 0.15035144239664078), 65: (1, 0.14945227187126875), 66: (1, 0.1494308216497302), 67: (1, 0.14968226850032806), 68: (1, 0.15020742267370224), 69: (1, 0.15271064452826977), 70: (1, 0.1516867969185114), 71: (1, 0.15390918962657452)}\n",
      "{1: (1, 255, 0.08783040809280732), 2: (1, 255, 0.08765085957140899), 3: (1, 255, 0.08763143847166907), 4: (1, 255, 0.08766641607325451), 5: (1, 255, 0.08773740768870887), 6: (1, 255, 0.0876802717317261), 7: (1, 255, 0.08767577042693601), 8: (1, 255, 0.0877453825235659), 9: (1, 255, 0.08775994553431576), 10: (1, 255, 0.0876824259794518), 11: (1, 255, 0.08780646936274042), 12: (1, 255, 0.08769438323729178), 13: (1, 255, 0.08777197284952683), 14: (1, 255, 0.08768388451825754), 15: (1, 255, 0.08775526804520803), 16: (1, 255, 0.08780491468953151), 17: (1, 255, 0.08769927773916839), 18: (1, 255, 0.08764071612089289), 19: (1, 255, 0.08773961273551571), 20: (1, 255, 0.08768294635502731), 21: (1, 255, 0.08771705404654437), 22: (1, 255, 0.08768837635642758), 23: (1, 255, 0.08774608851355666), 24: (1, 255, 0.0877634179285344), 25: (1, 255, 0.08770252610465475), 26: (1, 255, 0.08765128107339729), 27: (1, 255, 0.08769236550319429), 28: (1, 255, 0.08748010043420043), 29: (1, 255, 0.08770355826207235), 30: (1, 255, 0.08778426323962563), 31: (1, 255, 0.08779746504025716), 32: (1, 255, 0.08753086503449024), 33: (1, 255, 0.08721957616142782), 34: (1, 255, 0.08715507703668932), 35: (1, 255, 0.08732161492693657), 36: (1, 255, 0.08724734870096047), 37: (1, 255, 0.08727935978814083), 38: (1, 255, 0.08725710653279926), 39: (1, 255, 0.08732872402989397), 40: (1, 255, 0.0872241906931295), 41: (1, 255, 0.08726452142000199), 42: (1, 255, 0.08727693725377321), 43: (1, 255, 0.08734969317036516), 44: (1, 255, 0.0872123234704429), 45: (1, 255, 0.08724499008819168), 46: (1, 255, 0.08721036352582422), 47: (1, 255, 0.08716134543658471), 48: (1, 255, 0.08712046513808709), 49: (1, 255, 0.08715748873119261), 50: (1, 255, 0.08724370159793134), 51: (1, 255, 0.08724397737532855), 52: (1, 255, 0.08720559081172242), 53: (1, 255, 0.08722553675373396), 54: (1, 255, 0.0874721101978246), 55: (1, 255, 0.08780732249804571), 56: (1, 255, 0.08767654802284988), 57: (1, 255, 0.08770359902113092), 58: (1, 255, 0.08780594181780722), 59: (1, 255, 0.08768975439609265), 60: (1, 255, 0.08778883362298502), 61: (1, 255, 0.0876550529152155), 62: (1, 255, 0.0876377380763491), 63: (1, 255, 0.08773175355266122), 64: (1, 255, 0.08781547868149538), 65: (1, 255, 0.08769905695363003), 66: (1, 255, 0.08785933119920539), 67: (1, 255, 0.08768104057320777), 68: (1, 255, 0.08766227426263047), 69: (1, 255, 0.08769370658213602), 70: (1, 255, 0.08770611105011959)}\n",
      "{'predict_runtime': 1596.1894, 'predict_samples_per_second': 0.044, 'predict_steps_per_second': 0.044}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:26:36.18\n",
      "  predict_samples_per_second =      0.044\n",
      "  predict_steps_per_second   =      0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.19106270000338554), 2: (2, 0.203505695797503), 3: (2, 0.16558193508535624), 4: (2, 0.19071461353451014), 5: (2, 0.17752149142324924), 6: (2, 0.19269302766770124), 7: (2, 0.17363327462226152), 8: (2, 0.1662066299468279), 9: (2, 0.169453882612288), 10: (2, 0.16943038161844015), 11: (2, 0.1641014525666833), 12: (2, 0.20075952354818583), 13: (2, 0.17266890406608582), 14: (2, 0.17230173852294683), 15: (2, 0.17169450409710407), 16: (2, 0.1620839238166809), 17: (2, 0.16247797943651676), 18: (2, 0.16338724736124277), 19: (2, 0.17042496800422668), 20: (2, 0.19512764364480972), 21: (2, 0.19658989645540714), 22: (2, 0.1674264194443822), 23: (2, 0.16476253140717745), 24: (2, 0.19960210099816322), 25: (2, 0.16736365109682083), 26: (2, 0.1841620383784175), 27: (2, 0.17539251782000065), 28: (2, 0.18372026085853577), 29: (2, 0.16372377146035433), 30: (2, 0.1719414060935378), 31: (2, 0.1756068943068385), 32: (2, 0.19227932300418615), 33: (2, 0.16393696703016758), 34: (2, 0.1855376185849309), 35: (2, 0.16990853752940893), 36: (2, 0.168438701890409), 37: (2, 0.16832789406180382), 38: (2, 0.16710311826318502), 39: (2, 0.1938009224832058), 40: (2, 0.1640723403543234), 41: (2, 0.16892275493592024), 42: (2, 0.16765866056084633), 43: (2, 0.19928631745278835), 44: (2, 0.1861837161704898), 45: (2, 0.16295163333415985), 46: (2, 0.16651345044374466), 47: (2, 0.16452316474169493), 48: (2, 0.19236876536160707), 49: (2, 0.19935546349734068), 50: (2, 0.16744896955788136), 51: (2, 0.16103511210530996), 52: (2, 0.1631327485665679), 53: (2, 0.16948391497135162), 54: (2, 0.16618962306529284), 55: (2, 0.19868278037756681), 56: (2, 0.16429241374135017), 57: (2, 0.1633671149611473), 58: (2, 0.18637233041226864), 59: (2, 0.16949940379709005), 60: (2, 0.19959769770503044), 61: (2, 0.16500114556401968), 62: (2, 0.1631846046075225), 63: (2, 0.1822549058124423), 64: (2, 0.20000628288835287), 65: (2, 0.16965224035084248), 66: (2, 0.18817806709557772), 67: (2, 0.19828510098159313), 68: (2, 0.17028197273612022), 69: (2, 0.16363079845905304), 70: (2, 0.2025909498333931), 71: (1, 0.15662849880754948)}\n",
      "{1: (2, 255, 0.13672761166943054), 2: (2, 255, 0.13637733809357766), 3: (2, 255, 0.13607985689213462), 4: (2, 255, 0.13583409852330006), 5: (2, 255, 0.13579368526298627), 6: (2, 255, 0.13575316277496954), 7: (2, 255, 0.13580093899486112), 8: (2, 255, 0.13577882818439427), 9: (2, 255, 0.1358654094640823), 10: (2, 255, 0.13593887203537366), 11: (2, 255, 0.13581560430135212), 12: (2, 255, 0.13590676349532954), 13: (2, 255, 0.13582313394575726), 14: (2, 255, 0.13577353789233693), 15: (2, 255, 0.13582479069192036), 16: (2, 255, 0.13580280475172343), 17: (2, 255, 0.13586058155724814), 18: (2, 255, 0.13584005714339367), 19: (2, 255, 0.1356922873971509), 20: (2, 255, 0.13576095486607623), 21: (2, 255, 0.135755814049466), 22: (2, 255, 0.13579736316540078), 23: (2, 255, 0.1357725546859643), 24: (2, 255, 0.13581937731188887), 25: (2, 255, 0.13576091805509494), 26: (2, 255, 0.13577735887876913), 27: (2, 255, 0.1357891338786074), 28: (2, 255, 0.13584525566182884), 29: (2, 255, 0.13574119579485233), 30: (2, 255, 0.13579700092109395), 31: (2, 255, 0.13571063834516442), 32: (2, 255, 0.13595201499102746), 33: (2, 255, 0.13575042723586747), 34: (2, 255, 0.135835298600004), 35: (2, 255, 0.13585902738439687), 36: (2, 255, 0.13585246734540252), 37: (2, 255, 0.1357479869735007), 38: (2, 255, 0.13579169970151841), 39: (2, 255, 0.13583791502842715), 40: (2, 255, 0.13579473867647204), 41: (2, 255, 0.13588324210369118), 42: (2, 255, 0.13582607230865487), 43: (2, 255, 0.13579215397145233), 44: (2, 255, 0.13589204759428314), 45: (2, 255, 0.13590691144779032), 46: (2, 255, 0.13584266378014695), 47: (2, 255, 0.13570001449655084), 48: (2, 255, 0.135776985571811), 49: (2, 255, 0.13582155838535698), 50: (2, 255, 0.13581436454665427), 51: (2, 255, 0.13593734575837266), 52: (2, 255, 0.13591467813387806), 53: (2, 255, 0.13586284202322657), 54: (2, 255, 0.13579380834730817), 55: (2, 255, 0.13583367778097882), 56: (2, 255, 0.13585936050935118), 57: (2, 255, 0.13576315032939115), 58: (2, 255, 0.135903878371213), 59: (2, 255, 0.1357892685661129), 60: (2, 255, 0.13584231545819955), 61: (2, 255, 0.1358168027491546), 62: (2, 255, 0.13592030578018988), 63: (2, 255, 0.13577155091379786), 64: (2, 255, 0.13590279389903243), 65: (2, 255, 0.13579757525494285), 66: (2, 255, 0.13570818736345744), 67: (2, 255, 0.1358744508933787), 68: (2, 255, 0.13591818104625916), 69: (2, 255, 0.13573281411081553), 70: (2, 255, 0.13590760993972129)}\n",
      "{'predict_runtime': 2459.6453, 'predict_samples_per_second': 0.057, 'predict_steps_per_second': 0.029}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:40:59.64\n",
      "  predict_samples_per_second =      0.057\n",
      "  predict_steps_per_second   =      0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.24392789416015148), 2: (4, 0.2154003418982029), 3: (4, 0.2211244348436594), 4: (4, 0.21161405555903912), 5: (4, 0.2116778837516904), 6: (4, 0.21617515105754137), 7: (4, 0.21237234584987164), 8: (4, 0.2148815654218197), 9: (4, 0.21309894602745771), 10: (4, 0.2138876859098673), 11: (4, 0.23573246505111456), 12: (4, 0.21206254698336124), 13: (4, 0.21231015399098396), 14: (4, 0.2146442774683237), 15: (4, 0.211443442851305), 16: (4, 0.211190695874393), 17: (4, 0.21698102913796902), 18: (4, 0.21269438788294792), 19: (4, 0.212738536298275), 20: (4, 0.21462800540030003), 21: (4, 0.2118148785084486), 22: (4, 0.21240056119859219), 23: (4, 0.21368160471320152), 24: (4, 0.21219550352543592), 25: (4, 0.21388879977166653), 26: (4, 0.21459675207734108), 27: (4, 0.21134229749441147), 28: (4, 0.21310977637767792), 29: (4, 0.21766666509211063), 30: (4, 0.21173362247645855), 31: (4, 0.21626208070665598), 32: (4, 0.21363359969109297), 33: (4, 0.22552582621574402), 34: (4, 0.21283630840480328), 35: (4, 0.21338179241865873), 36: (4, 0.21278486773371696), 37: (4, 0.2134769493713975), 38: (4, 0.21337361074984074), 39: (4, 0.21345142927020788), 40: (4, 0.21421106159687042), 41: (4, 0.21063925139606), 42: (4, 0.21516920905560255), 43: (4, 0.2170755472034216), 44: (4, 0.21228241082280874), 45: (4, 0.2133068684488535), 46: (4, 0.2141345888376236), 47: (4, 0.2147729005664587), 48: (4, 0.210687636397779), 49: (4, 0.21246487740427256), 50: (4, 0.21669505909085274), 51: (4, 0.2121058600023389), 52: (4, 0.21091693360358477), 53: (4, 0.22098479885607958), 54: (4, 0.21640102099627256), 55: (4, 0.21192574128508568), 56: (4, 0.21008709259331226), 57: (4, 0.21270822081714869), 58: (4, 0.2133896742016077), 59: (4, 0.21185426134616137), 60: (4, 0.21172351203858852), 61: (4, 0.21140678599476814), 62: (4, 0.21267278026789427), 63: (4, 0.21488606464117765), 64: (4, 0.21621122024953365), 65: (4, 0.21537047903984785), 66: (4, 0.2147189760580659), 67: (4, 0.21848249342292547), 68: (4, 0.21240922156721354), 69: (4, 0.2120559560135007), 70: (4, 0.21272603701800108), 71: (1, 0.1532556749880314)}\n",
      "{1: (4, 255, 0.13770801508616584), 2: (4, 255, 0.13701761663325276), 3: (4, 255, 0.13692535125814817), 4: (4, 255, 0.13686883205949676), 5: (4, 255, 0.1373198948727519), 6: (4, 255, 0.13724973650247443), 7: (4, 255, 0.13699734634993707), 8: (4, 255, 0.13705472703292673), 9: (4, 255, 0.13711639303056633), 10: (4, 255, 0.13693012024330742), 11: (4, 255, 0.1371063314013037), 12: (4, 255, 0.1369650420568445), 13: (4, 255, 0.13706237098896035), 14: (4, 255, 0.13710518258751608), 15: (4, 255, 0.13699179073320886), 16: (4, 255, 0.13721384568249478), 17: (4, 255, 0.13670983688138863), 18: (4, 255, 0.13658120682207392), 19: (4, 255, 0.1366318701821215), 20: (4, 255, 0.13655519743687383), 21: (4, 255, 0.1365964127120142), 22: (4, 255, 0.136688326901811), 23: (4, 255, 0.13660248697680585), 24: (4, 255, 0.1366787799834913), 25: (4, 255, 0.1366396810640307), 26: (4, 255, 0.13660569967811598), 27: (4, 255, 0.13671275454701162), 28: (4, 255, 0.1364115355645909), 29: (4, 255, 0.1364611600251759), 30: (4, 255, 0.1366090412963839), 31: (4, 255, 0.13647533348012789), 32: (4, 255, 0.1364744626022145), 33: (4, 255, 0.13655567812715091), 34: (4, 255, 0.13646216869135114), 35: (4, 255, 0.13645301904602378), 36: (4, 255, 0.13647961222073612), 37: (4, 255, 0.1364295367662813), 38: (4, 255, 0.13643537488419052), 39: (4, 255, 0.13653325304827268), 40: (4, 255, 0.13658296706191464), 41: (4, 255, 0.13651873394116468), 42: (4, 255, 0.1365271221115893), 43: (4, 255, 0.13665378592616204), 44: (4, 255, 0.13707522635585537), 45: (4, 255, 0.13651154287086398), 46: (4, 255, 0.1365094339913305), 47: (4, 255, 0.13645762313595589), 48: (4, 255, 0.13637102059289521), 49: (4, 255, 0.13649648744612933), 50: (4, 255, 0.13646962262470932), 51: (4, 255, 0.13640622504274635), 52: (4, 255, 0.13634095822698344), 53: (4, 255, 0.13637694406743142), 54: (4, 255, 0.13640093981635337), 55: (4, 255, 0.1363930115658863), 56: (4, 255, 0.13635709619551312), 57: (4, 255, 0.13641865447382717), 58: (4, 255, 0.1363581887208948), 59: (4, 255, 0.13636657994824883), 60: (4, 255, 0.13635297205080005), 61: (4, 255, 0.1363769540088434), 62: (4, 255, 0.13637847794475508), 63: (4, 255, 0.13641295769781459), 64: (4, 255, 0.13639183307030037), 65: (4, 255, 0.13645852215807228), 66: (4, 255, 0.13651653706077851), 67: (4, 255, 0.13642753505458435), 68: (4, 255, 0.1365563859469166), 69: (4, 255, 0.1363731868199858), 70: (4, 255, 0.13646969207580767)}\n",
      "{'predict_runtime': 2476.4473, 'predict_samples_per_second': 0.113, 'predict_steps_per_second': 0.029}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:41:16.44\n",
      "  predict_samples_per_second =      0.113\n",
      "  predict_steps_per_second   =      0.029\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 17\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.30464896000921726), 2: (1, 0.2656338242813945), 3: (1, 0.26612279936671257), 4: (1, 0.2655603550374508), 5: (1, 0.2654507262632251), 6: (1, 0.2649861294776201), 7: (1, 0.26634934451431036), 8: (1, 0.26564212143421173), 9: (1, 0.26632312405854464), 10: (1, 0.2672634022310376), 11: (1, 0.26352796517312527), 12: (1, 0.26702419482171535), 13: (1, 0.2670744536444545), 14: (1, 0.26789604406803846), 15: (1, 0.2653981316834688), 16: (1, 0.26536093186587095), 17: (1, 0.26603368390351534), 18: (1, 0.26598197408020496), 19: (1, 0.26446522027254105), 20: (1, 0.26424126233905554), 21: (1, 0.26428130362182856), 22: (1, 0.2650191141292453), 23: (1, 0.26655499543994665), 24: (1, 0.2661151047796011), 25: (1, 0.2656225897371769), 26: (1, 0.26547742169350386), 27: (1, 0.26693609543144703), 28: (1, 0.266989323310554), 29: (1, 0.26702924352139235), 30: (1, 0.26855085510760546), 31: (1, 0.2653059223666787), 32: (1, 0.2630385085940361), 33: (1, 0.2683422463014722), 34: (1, 0.2662267507985234), 35: (1, 0.2649977542459965), 36: (1, 0.2649474050849676), 37: (1, 0.26413186360150576), 38: (1, 0.2648485256358981), 39: (1, 0.26588216330856085), 40: (1, 0.26722545735538006), 41: (1, 0.2634370010346174), 42: (1, 0.26531772036105394), 43: (1, 0.2668348615989089), 44: (1, 0.2640863936394453), 45: (1, 0.2657942632213235), 46: (1, 0.2662842469289899), 47: (1, 0.26761677116155624), 48: (1, 0.2672011675313115), 49: (1, 0.264383708126843), 50: (1, 0.27122240979224443), 51: (1, 0.266538854688406), 52: (1, 0.26437516789883375), 53: (1, 0.26764312013983727), 54: (1, 0.2685592984780669), 55: (1, 0.26832641288638115), 56: (1, 0.2666317019611597), 57: (1, 0.26525324769318104), 58: (1, 0.26703040581196547), 59: (1, 0.26472814194858074), 60: (1, 0.26535767409950495), 61: (1, 0.2682778723537922), 62: (1, 0.26360202487558126), 63: (1, 0.26648355182260275), 64: (1, 0.26943337824195623), 65: (1, 0.2674491498619318), 66: (1, 0.26809952314943075), 67: (1, 0.26651488058269024), 68: (1, 0.26535465382039547), 69: (1, 0.26333670504391193), 70: (1, 0.2669069832190871), 71: (1, 0.26314182579517365)}\n",
      "{1: (1, 255, 0.1568887840846882), 2: (1, 255, 0.1563994698080362), 3: (1, 255, 0.15633046293594674), 4: (1, 255, 0.156489394415243), 5: (1, 255, 0.1563189322786296), 6: (1, 255, 0.1562394507521508), 7: (1, 255, 0.1563856904668843), 8: (1, 255, 0.15658160160642629), 9: (1, 255, 0.1566931279120492), 10: (1, 255, 0.1564610984870324), 11: (1, 255, 0.15634330976023977), 12: (1, 255, 0.15635720546192983), 13: (1, 255, 0.15643585289591083), 14: (1, 255, 0.15650533098435285), 15: (1, 255, 0.15649567632844635), 16: (1, 255, 0.15655600165984795), 17: (1, 255, 0.15625912907588133), 18: (1, 255, 0.15628788026378435), 19: (1, 255, 0.15628275243455872), 20: (1, 255, 0.1563060725838238), 21: (1, 255, 0.1562479203019072), 22: (1, 255, 0.1560592922984677), 23: (1, 255, 0.15621321270717126), 24: (1, 255, 0.15622240726781242), 25: (1, 255, 0.15625899554978984), 26: (1, 255, 0.15630043170177468), 27: (1, 255, 0.15630513012190075), 28: (1, 255, 0.15629018636822117), 29: (1, 255, 0.15618103303964817), 30: (1, 255, 0.1564515787268094), 31: (1, 255, 0.1562982049204555), 32: (1, 255, 0.15632719432606418), 33: (1, 255, 0.15623697807245396), 34: (1, 255, 0.15625012083819098), 35: (1, 255, 0.15641738077735198), 36: (1, 255, 0.15634255815735634), 37: (1, 255, 0.15630447339339584), 38: (1, 255, 0.15636697496634488), 39: (1, 255, 0.1562996243437131), 40: (1, 255, 0.15635471518936694), 41: (1, 255, 0.15632267599815833), 42: (1, 255, 0.15642206480397897), 43: (1, 255, 0.1561939517985664), 44: (1, 255, 0.15585944483093186), 45: (1, 255, 0.15590371247015747), 46: (1, 255, 0.1558645444027349), 47: (1, 255, 0.15594410903970984), 48: (1, 255, 0.156009317813989), 49: (1, 255, 0.15595787369518305), 50: (1, 255, 0.15614451495382717), 51: (1, 255, 0.15605154931180032), 52: (1, 255, 0.15629221944540156), 53: (1, 255, 0.15603400017773988), 54: (1, 255, 0.1562364690626661), 55: (1, 255, 0.15631083710959146), 56: (1, 255, 0.1563115814152886), 57: (1, 255, 0.15632494910455802), 58: (1, 255, 0.1563931876647414), 59: (1, 255, 0.15630755425595186), 60: (1, 255, 0.15644075637865884), 61: (1, 255, 0.15634889104129637), 62: (1, 255, 0.15638000026491342), 63: (1, 255, 0.1562834841582705), 64: (1, 255, 0.15638025419823096), 65: (1, 255, 0.15625302440979902), 66: (1, 255, 0.15628723066081018), 67: (1, 255, 0.15611712662320512), 68: (1, 255, 0.1562041222428282), 69: (1, 255, 0.15626176843310105), 70: (1, 255, 0.15610947570233952)}\n",
      "{'predict_runtime': 2848.5349, 'predict_samples_per_second': 0.025, 'predict_steps_per_second': 0.025}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:47:28.53\n",
      "  predict_samples_per_second =      0.025\n",
      "  predict_steps_per_second   =      0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.31792293675243855), 2: (2, 0.32241983525455), 3: (2, 0.33350146748125553), 4: (2, 0.28521085251122713), 5: (2, 0.28714990988373756), 6: (2, 0.33138730097562075), 7: (2, 0.29471115209162235), 8: (2, 0.3008391913026571), 9: (2, 0.29011831525713205), 10: (2, 0.3249717243015766), 11: (2, 0.34081109147518873), 12: (2, 0.29256107471883297), 13: (2, 0.2960971063002944), 14: (2, 0.29079913161695004), 15: (2, 0.306589069776237), 16: (2, 0.28981440234929323), 17: (2, 0.28504844661802053), 18: (2, 0.3159632608294487), 19: (2, 0.34113378915935755), 20: (2, 0.3100435584783554), 21: (2, 0.28557814098894596), 22: (2, 0.2889547925442457), 23: (2, 0.29796069767326117), 24: (2, 0.34148701559752226), 25: (2, 0.33891133591532707), 26: (2, 0.2922617429867387), 27: (2, 0.2956121936440468), 28: (2, 0.28635821025818586), 29: (2, 0.34196025040000677), 30: (2, 0.3417256725952029), 31: (2, 0.2913272827863693), 32: (2, 0.32241734489798546), 33: (2, 0.34211885649710894), 34: (2, 0.3434871416538954), 35: (2, 0.34214222710579634), 36: (2, 0.34198081865906715), 37: (2, 0.3221341082826257), 38: (2, 0.33648678101599216), 39: (2, 0.3375083710998297), 40: (2, 0.3010101616382599), 41: (2, 0.3386369477957487), 42: (2, 0.34061551466584206), 43: (2, 0.3387293163686991), 44: (2, 0.34831309597939253), 45: (2, 0.3120648832991719), 46: (2, 0.3040486266836524), 47: (2, 0.28828933648765087), 48: (2, 0.3019787101075053), 49: (2, 0.33509359788149595), 50: (2, 0.33981011528521776), 51: (2, 0.3112059663981199), 52: (2, 0.2867234265431762), 53: (2, 0.2932817507535219), 54: (2, 0.28606585320085287), 55: (2, 0.3295691516250372), 56: (2, 0.33389269281178713), 57: (2, 0.28944077529013157), 58: (2, 0.34293044824153185), 59: (2, 0.28822783939540386), 60: (2, 0.3415625439956784), 61: (2, 0.3312864415347576), 62: (2, 0.2885436052456498), 63: (2, 0.3434725133702159), 64: (2, 0.2912243437021971), 65: (2, 0.34186059050261974), 66: (2, 0.3320375233888626), 67: (2, 0.30248712189495564), 68: (2, 0.3383135078474879), 69: (2, 0.3419748963788152), 70: (2, 0.29139243997633457), 71: (1, 0.31396929919719696)}\n",
      "{1: (2, 255, 0.24551624999034638), 2: (2, 255, 0.24460194440302896), 3: (2, 255, 0.24448099363156978), 4: (2, 255, 0.2443733891362653), 5: (2, 255, 0.24456823819189094), 6: (2, 255, 0.24428816235752082), 7: (2, 255, 0.2444800778419948), 8: (2, 255, 0.2442012975211529), 9: (2, 255, 0.24427352807320216), 10: (2, 255, 0.24410172853545814), 11: (2, 255, 0.244238625532564), 12: (2, 255, 0.24361990736980063), 13: (2, 255, 0.244213109711806), 14: (2, 255, 0.24424258484779035), 15: (2, 255, 0.24418175438163328), 16: (2, 255, 0.24402227517509578), 17: (2, 255, 0.24445454848236314), 18: (2, 255, 0.24350841994598216), 19: (2, 255, 0.24358541044753557), 20: (2, 255, 0.24431532111164986), 21: (2, 255, 0.24433001166246102), 22: (2, 255, 0.24413593172588768), 23: (2, 255, 0.2447410173312414), 24: (2, 255, 0.2440185437526773), 25: (2, 255, 0.2444177949435863), 26: (2, 255, 0.24431713122290138), 27: (2, 255, 0.24502234195596448), 28: (2, 255, 0.24418713081920262), 29: (2, 255, 0.24397840357075135), 30: (2, 255, 0.2439327906342406), 31: (2, 255, 0.24397687314114735), 32: (2, 255, 0.24384924245304337), 33: (2, 255, 0.24765581854199079), 34: (2, 255, 0.24435877057486305), 35: (2, 255, 0.24431842310974997), 36: (2, 255, 0.24430786884371555), 37: (2, 255, 0.24418231997565895), 38: (2, 255, 0.24428828427677646), 39: (2, 255, 0.244286388542284), 40: (2, 255, 0.24394014225724867), 41: (2, 255, 0.24373782442919179), 42: (2, 255, 0.24367566255889103), 43: (2, 255, 0.247066080347434), 44: (2, 255, 0.2445491757097782), 45: (2, 255, 0.244584435892894), 46: (2, 255, 0.24437927234114384), 47: (2, 255, 0.24435910485027468), 48: (2, 255, 0.24435457051822954), 49: (2, 255, 0.24439739912894426), 50: (2, 255, 0.24431999559495962), 51: (2, 255, 0.24454650814991954), 52: (2, 255, 0.24434400263297207), 53: (2, 255, 0.24431420504024215), 54: (2, 255, 0.24437027768980638), 55: (2, 255, 0.24434879541251006), 56: (2, 255, 0.24446050070737507), 57: (2, 255, 0.24447845547441757), 58: (2, 255, 0.24449102850448268), 59: (2, 255, 0.2444767503140896), 60: (2, 255, 0.24413158264303325), 61: (2, 255, 0.24452799152144614), 62: (2, 255, 0.24443877478878873), 63: (2, 255, 0.24391561411321164), 64: (2, 255, 0.24512818253726937), 65: (2, 255, 0.24428759285559257), 66: (2, 255, 0.2440811965030198), 67: (2, 255, 0.24389720133268367), 68: (2, 255, 0.24373661648189904), 69: (2, 255, 0.24391223134874712), 70: (2, 255, 0.24387608638727198)}\n",
      "{'predict_runtime': 4423.9269, 'predict_samples_per_second': 0.032, 'predict_steps_per_second': 0.016}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:13:43.92\n",
      "  predict_samples_per_second =      0.032\n",
      "  predict_steps_per_second   =      0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/71 36:48 < 36:48, 0.02 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m data_module \u001b[38;5;241m=\u001b[39m make_data_module(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data_module\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m ttft, tbt \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_latencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m ttfts\u001b[38;5;241m.\u001b[39mappend(ttft)\n\u001b[1;32m     21\u001b[0m tbts\u001b[38;5;241m.\u001b[39mappend(tbt)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/profiler.py:285\u001b[0m, in \u001b[0;36mprofile_latencies\u001b[0;34m(model, tokenizer, args, logger, trainer, data_module)\u001b[0m\n\u001b[1;32m    283\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProfiling model for TTFT and TBT latencies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m timing_stopping_criteria \u001b[38;5;241m=\u001b[39m TokenTimingStoppingCriteria()\n\u001b[0;32m--> 285\u001b[0m prediction_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtiming_stopping_criteria\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mprint\u001b[39m(timing_stopping_criteria\u001b[38;5;241m.\u001b[39mttft)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(timing_stopping_criteria\u001b[38;5;241m.\u001b[39mtbt)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer_seq2seq.py:244\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer.py:3678\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3675\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3677\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3678\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3681\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3788\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3791\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3793\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer_seq2seq.py:310\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    306\u001b[0m ):\n\u001b[1;32m    307\u001b[0m     generation_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    308\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     }\n\u001b[0;32m--> 310\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/peft/src/peft/peft_model.py:1325\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1324\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1325\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:1319\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1316\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1319\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:1116\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1105\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1106\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         layer_index\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_index\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:800\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, index, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    799\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 800\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    803\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:251\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m         down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_width\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x))\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m         down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/peft/src/peft/tuners/lora/bnb.py:611\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinkable_width:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m         result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth_ratio\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m         result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_bias[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_ratio]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 31\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
