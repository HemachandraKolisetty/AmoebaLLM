{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 26, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.37425240967422724), 2: (1, 0.22348991129547358), 3: (1, 0.22393257450312376), 4: (1, 0.21827450208365917), 5: (1, 0.2195634664967656), 6: (1, 0.22213328536599874), 7: (1, 0.2198026431724429), 8: (1, 0.2181745721027255), 9: (1, 0.2161956038326025), 10: (1, 0.21980773098766804), 11: (1, 0.2173703908920288), 12: (1, 0.2186636235564947), 13: (1, 0.21766976546496153), 14: (1, 0.2182830786332488), 15: (1, 0.21814381889998913), 16: (1, 0.21731947921216488), 17: (1, 0.21876843180507421), 18: (1, 0.21720058005303144), 19: (1, 0.21740834787487984), 20: (1, 0.2179154809564352), 21: (1, 0.22017964348196983), 22: (1, 0.21722898911684752), 23: (1, 0.21852057334035635), 24: (1, 0.21836638450622559), 25: (1, 0.22069093771278858), 26: (1, 0.21669530402868986), 27: (1, 0.2171510374173522), 28: (1, 0.21786018833518028), 29: (1, 0.21813300624489784), 30: (1, 0.21727732568979263), 31: (1, 0.220403247512877), 32: (1, 0.2183421328663826), 33: (1, 0.21809555683284998), 34: (1, 0.2171783559024334), 35: (1, 0.2193511500954628), 36: (1, 0.21686917915940285), 37: (1, 0.21803406439721584), 38: (1, 0.21637787483632565), 39: (1, 0.22021454945206642), 40: (1, 0.21728459279984236), 41: (1, 0.216453461907804), 42: (1, 0.21839774958789349), 43: (1, 0.21970520447939634), 44: (1, 0.21787748578935862), 45: (1, 0.2169634159654379), 46: (1, 0.2190291816368699), 47: (1, 0.21697688568383455), 48: (1, 0.21821074094623327), 49: (1, 0.22400800231844187), 50: (1, 0.21921871975064278), 51: (1, 0.214958849363029)}\n",
      "{1: (1, 127, 0.13270973696512736), 2: (1, 127, 0.13274222851444886), 3: (1, 127, 0.1324539219476576), 4: (1, 127, 0.13234580862592524), 5: (1, 127, 0.13238046984884919), 6: (1, 127, 0.13228967182308904), 7: (1, 127, 0.1321301980926765), 8: (1, 127, 0.1321894494142002), 9: (1, 127, 0.1322506355987055), 10: (1, 127, 0.13213604179716956), 11: (1, 127, 0.13217719459510224), 12: (1, 127, 0.13216837169969176), 13: (1, 127, 0.13261452009241412), 14: (1, 127, 0.13272619718231085), 15: (1, 127, 0.13277678301660564), 16: (1, 127, 0.13273621733322388), 17: (1, 127, 0.13208526242377722), 18: (1, 127, 0.1320926218520938), 19: (1, 127, 0.13208131693068922), 20: (1, 127, 0.1329154743717646), 21: (1, 127, 0.1329903256030768), 22: (1, 127, 0.1325347150756618), 23: (1, 127, 0.1324700059911867), 24: (1, 127, 0.13242544297598244), 25: (1, 127, 0.13265456080319374), 26: (1, 127, 0.13259948688874565), 27: (1, 127, 0.13260488368306808), 28: (1, 127, 0.13230650800126276), 29: (1, 127, 0.13236815371645952), 30: (1, 127, 0.13239542065613616), 31: (1, 127, 0.13238441834123585), 32: (1, 127, 0.13240396724207196), 33: (1, 127, 0.1321509055954617), 34: (1, 127, 0.13246091367955518), 35: (1, 127, 0.13264591172044202), 36: (1, 127, 0.13269017199714353), 37: (1, 127, 0.13259926552730283), 38: (1, 127, 0.13215885933957935), 39: (1, 127, 0.1321221537242724), 40: (1, 127, 0.1323393444772663), 41: (1, 127, 0.1321636238245396), 42: (1, 127, 0.1322415869199033), 43: (1, 127, 0.13214643853973215), 44: (1, 127, 0.13231516531191942), 45: (1, 127, 0.1324159505036403), 46: (1, 127, 0.1323714980591587), 47: (1, 127, 0.13285875907827785), 48: (1, 127, 0.13284208905685135), 49: (1, 127, 0.13277236816627302), 50: (1, 127, 0.13220590082415212)}\n",
      "{'predict_runtime': 869.0477, 'predict_samples_per_second': 0.059, 'predict_steps_per_second': 0.059}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:14:29.04\n",
      "  predict_samples_per_second =      0.059\n",
      "  predict_steps_per_second   =      0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.25319147389382124), 2: (2, 0.23170618806034327), 3: (2, 0.22574535012245178), 4: (2, 0.2473006034269929), 5: (2, 0.2435378786176443), 6: (2, 0.22988126054406166), 7: (2, 0.2576550394296646), 8: (2, 0.2435142071917653), 9: (2, 0.24651657044887543), 10: (2, 0.22882508020848036), 11: (2, 0.24492616951465607), 12: (2, 0.23003764636814594), 13: (2, 0.2294417219236493), 14: (2, 0.2427368452772498), 15: (2, 0.2253174614161253), 16: (2, 0.23816049937158823), 17: (2, 0.2263478683307767), 18: (2, 0.24570095725357533), 19: (2, 0.23080749530345201), 20: (2, 0.22524288017302752), 21: (2, 0.2389348354190588), 22: (2, 0.2266263635829091), 23: (2, 0.249720168299973), 24: (2, 0.2266921168193221), 25: (2, 0.22610157169401646), 26: (2, 0.2358825085684657), 27: (2, 0.2293970212340355), 28: (2, 0.2255521034821868), 29: (2, 0.22869516629725695), 30: (2, 0.22610064409673214), 31: (2, 0.22464623861014843), 32: (2, 0.25176644790917635), 33: (2, 0.24224016536027193), 34: (2, 0.23000703379511833), 35: (2, 0.24839932098984718), 36: (2, 0.22792672365903854), 37: (2, 0.24631268251687288), 38: (2, 0.24091435316950083), 39: (2, 0.24310111720114946), 40: (2, 0.24557971581816673), 41: (2, 0.2441579308360815), 42: (2, 0.2451045773923397), 43: (2, 0.24101117346435785), 44: (2, 0.24606439471244812), 45: (2, 0.24709554202854633), 46: (2, 0.22723935823887587), 47: (2, 0.22727013658732176), 48: (2, 0.2281993543729186), 49: (2, 0.22748754173517227), 50: (2, 0.2252454375848174), 51: (1, 0.23594830092042685)}\n",
      "{1: (2, 127, 0.2065369671019982), 2: (2, 127, 0.20658271900546832), 3: (2, 127, 0.2064401048022931), 4: (2, 127, 0.20610618562708924), 5: (2, 127, 0.20591890660855244), 6: (2, 127, 0.2059837922409881), 7: (2, 127, 0.20701123849584127), 8: (2, 127, 0.2060294511295327), 9: (2, 127, 0.2060396643575486), 10: (2, 127, 0.2061395687161116), 11: (2, 127, 0.2067375921930267), 12: (2, 127, 0.20616222687769592), 13: (2, 127, 0.20838276816781345), 14: (2, 127, 0.20631472743666313), 15: (2, 127, 0.2059738673783076), 16: (2, 127, 0.20684085491546025), 17: (2, 127, 0.20590604351114805), 18: (2, 127, 0.20603561116103816), 19: (2, 127, 0.20608098912016143), 20: (2, 127, 0.2059206898419524), 21: (2, 127, 0.20607113615998368), 22: (2, 127, 0.2059743350269053), 23: (2, 127, 0.20593849510159784), 24: (2, 127, 0.20589631687351098), 25: (2, 127, 0.20588375412397028), 26: (2, 127, 0.2058386887445694), 27: (2, 127, 0.20587758561522942), 28: (2, 127, 0.2063599968563736), 29: (2, 127, 0.2064633226007458), 30: (2, 127, 0.20595567276715998), 31: (2, 127, 0.2056862441602889), 32: (2, 127, 0.2056966119731857), 33: (2, 127, 0.20569746441200493), 34: (2, 127, 0.2057881440131331), 35: (2, 127, 0.20583161324497282), 36: (2, 127, 0.2058203127968499), 37: (2, 127, 0.20578047961700618), 38: (2, 127, 0.2057697713947085), 39: (2, 127, 0.20584881106230218), 40: (2, 127, 0.2058461746787579), 41: (2, 127, 0.20609507399545177), 42: (2, 127, 0.20632829240662612), 43: (2, 127, 0.20617009492547023), 44: (2, 127, 0.20572949072536756), 45: (2, 127, 0.20576219432290613), 46: (2, 127, 0.20580724205117762), 47: (2, 127, 0.2059599637442569), 48: (2, 127, 0.20587353095940247), 49: (2, 127, 0.20584155022951328), 50: (2, 127, 0.20580679790564174)}\n",
      "{'predict_runtime': 1337.4945, 'predict_samples_per_second': 0.076, 'predict_steps_per_second': 0.038}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:17.49\n",
      "  predict_samples_per_second =      0.076\n",
      "  predict_steps_per_second   =      0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.2848682552576065), 2: (4, 0.24355594348162413), 3: (4, 0.2542310683056712), 4: (4, 0.26437305845320225), 5: (4, 0.25909214932471514), 6: (4, 0.2482352638617158), 7: (4, 0.24834560975432396), 8: (4, 0.24307712074369192), 9: (4, 0.24429397471249104), 10: (4, 0.2547354334965348), 11: (4, 0.2555257622152567), 12: (4, 0.24342335294932127), 13: (4, 0.24357193429023027), 14: (4, 0.24537561275064945), 15: (4, 0.24572147615253925), 16: (4, 0.24617795832455158), 17: (4, 0.25457830261439085), 18: (4, 0.24669167771935463), 19: (4, 0.24938538577407598), 20: (4, 0.24254362098872662), 21: (4, 0.24655053298920393), 22: (4, 0.25805477146059275), 23: (4, 0.24857430532574654), 24: (4, 0.25404744129627943), 25: (4, 0.24563441518694162), 26: (4, 0.2447385722771287), 27: (4, 0.24196139257401228), 28: (4, 0.24679459631443024), 29: (4, 0.24358686991035938), 30: (4, 0.2447022357955575), 31: (4, 0.2630394659936428), 32: (4, 0.25371792912483215), 33: (4, 0.25173524022102356), 34: (4, 0.2547003049403429), 35: (4, 0.2426032004877925), 36: (4, 0.25085389520972967), 37: (4, 0.2640824830159545), 38: (4, 0.24256978556513786), 39: (4, 0.25685109104961157), 40: (4, 0.24292342737317085), 41: (4, 0.2468315726146102), 42: (4, 0.249903935007751), 43: (4, 0.2449457012116909), 44: (4, 0.24584087915718555), 45: (4, 0.24906824063509703), 46: (4, 0.25897966511547565), 47: (4, 0.24727437645196915), 48: (4, 0.26420969143509865), 49: (4, 0.24317888263612986), 50: (4, 0.24089577607810497), 51: (1, 0.23615838959813118)}\n",
      "{1: (4, 127, 0.2068905213950422), 2: (4, 127, 0.20646416016040356), 3: (4, 127, 0.20635855870365394), 4: (4, 127, 0.20655232040196891), 5: (4, 127, 0.206984517773188), 6: (4, 127, 0.20661892188258293), 7: (4, 127, 0.2065392117507345), 8: (4, 127, 0.20652633699346482), 9: (4, 127, 0.20630087432136215), 10: (4, 127, 0.2060200005813729), 11: (4, 127, 0.20634201945605005), 12: (4, 127, 0.20613473107466312), 13: (4, 127, 0.206425742642206), 14: (4, 127, 0.20635370967367034), 15: (4, 127, 0.20634194503090983), 16: (4, 127, 0.20626577884545477), 17: (4, 127, 0.20647220551146298), 18: (4, 127, 0.20665290467734412), 19: (4, 127, 0.20674924638972977), 20: (4, 127, 0.20678644469667842), 21: (4, 127, 0.2065468449658883), 22: (4, 127, 0.20659512611414035), 23: (4, 127, 0.2061329642970731), 24: (4, 127, 0.20634935839527), 25: (4, 127, 0.2064600654430394), 26: (4, 127, 0.20628253773118801), 27: (4, 127, 0.20621720081796563), 28: (4, 127, 0.20612951206028696), 29: (4, 127, 0.20601761172430252), 30: (4, 127, 0.20603664329378155), 31: (4, 127, 0.20611811781258094), 32: (4, 127, 0.20655807353350825), 33: (4, 127, 0.2064273186746662), 34: (4, 127, 0.20606591489430018), 35: (4, 127, 0.20586789698581995), 36: (4, 127, 0.20593637536008527), 37: (4, 127, 0.2059666012802462), 38: (4, 127, 0.205906908005828), 39: (4, 127, 0.20598479822336688), 40: (4, 127, 0.20607821157158124), 41: (4, 127, 0.20607541251458286), 42: (4, 127, 0.20596226243170226), 43: (4, 127, 0.20604147025802005), 44: (4, 127, 0.20581655567291918), 45: (4, 127, 0.20588247699472378), 46: (4, 127, 0.20600420770448025), 47: (4, 127, 0.2058547821453237), 48: (4, 127, 0.20595493862830747), 49: (4, 127, 0.20608682980335605), 50: (4, 127, 0.20591275978422774)}\n",
      "{'predict_runtime': 1339.2854, 'predict_samples_per_second': 0.15, 'predict_steps_per_second': 0.038}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:19.28\n",
      "  predict_samples_per_second =       0.15\n",
      "  predict_steps_per_second   =      0.038\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 26\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/51 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.2524598501622677), 2: (1, 0.2232570555061102), 3: (1, 0.22363440971821547), 4: (1, 0.2260839818045497), 5: (1, 0.22394854482263327), 6: (1, 0.22562406491488218), 7: (1, 0.22598084062337875), 8: (1, 0.22686141915619373), 9: (1, 0.22632219456136227), 10: (1, 0.22387386206537485), 11: (1, 0.22534590400755405), 12: (1, 0.22628885228186846), 13: (1, 0.22620193287730217), 14: (1, 0.22397928684949875), 15: (1, 0.22705217264592648), 16: (1, 0.2272716574370861), 17: (1, 0.2259208122268319), 18: (1, 0.23862536437809467), 19: (1, 0.2269222605973482), 20: (1, 0.22706343792378902), 21: (1, 0.22615254577249289), 22: (1, 0.22652309201657772), 23: (1, 0.22330782748758793), 24: (1, 0.2243720144033432), 25: (1, 0.22494208812713623), 26: (1, 0.22482818830758333), 27: (1, 0.22520936373621225), 28: (1, 0.22416216507554054), 29: (1, 0.22506065387278795), 30: (1, 0.22342445142567158), 31: (1, 0.22698277048766613), 32: (1, 0.2263466054573655), 33: (1, 0.2271025087684393), 34: (1, 0.2267611501738429), 35: (1, 0.2277718186378479), 36: (1, 0.224333256483078), 37: (1, 0.22609534580260515), 38: (1, 0.2243074169382453), 39: (1, 0.22389461006969213), 40: (1, 0.22443983424454927), 41: (1, 0.22834438737481833), 42: (1, 0.22520349267870188), 43: (1, 0.2244881810620427), 44: (1, 0.2264992780983448), 45: (1, 0.22436894197016954), 46: (1, 0.22676366288214922), 47: (1, 0.2258395329117775), 48: (1, 0.22571295406669378), 49: (1, 0.22794418781995773), 50: (1, 0.2261226186528802), 51: (1, 0.22720670606940985)}\n",
      "{1: (1, 127, 0.13741743995067407), 2: (1, 127, 0.13820096214602548), 3: (1, 127, 0.13701452264987576), 4: (1, 127, 0.13698553544740508), 5: (1, 127, 0.13698535824678545), 6: (1, 127, 0.13702179234856227), 7: (1, 127, 0.13710802250109086), 8: (1, 127, 0.13718706604797304), 9: (1, 127, 0.13755313023983493), 10: (1, 127, 0.1375808806679263), 11: (1, 127, 0.1379202212258352), 12: (1, 127, 0.13746125721116), 13: (1, 127, 0.13763232474897322), 14: (1, 127, 0.137953915361931), 15: (1, 127, 0.13761932677112695), 16: (1, 127, 0.13752209332837598), 17: (1, 127, 0.13766490759724004), 18: (1, 127, 0.13754466440763294), 19: (1, 127, 0.13719947234265448), 20: (1, 127, 0.13722179431878911), 21: (1, 127, 0.1372401802690597), 22: (1, 127, 0.1371432339303254), 23: (1, 127, 0.13709042898899926), 24: (1, 127, 0.13708424995704663), 25: (1, 127, 0.13803554575626306), 26: (1, 127, 0.13723759651624076), 27: (1, 127, 0.13736184110029007), 28: (1, 127, 0.1371173106764597), 29: (1, 127, 0.13693460324911153), 30: (1, 127, 0.1369248890779971), 31: (1, 127, 0.13701756563272297), 32: (1, 127, 0.13703715105313719), 33: (1, 127, 0.1370645185903184), 34: (1, 127, 0.13681492597363362), 35: (1, 127, 0.1369186040586022), 36: (1, 127, 0.13692140111362372), 37: (1, 127, 0.13689712162210246), 38: (1, 127, 0.13694171427096438), 39: (1, 127, 0.1377874609068271), 40: (1, 127, 0.13825186040604442), 41: (1, 127, 0.13874784623104053), 42: (1, 127, 0.13766314538093063), 43: (1, 127, 0.1373732290780685), 44: (1, 127, 0.1369646539999627), 45: (1, 127, 0.1373416137492915), 46: (1, 127, 0.1376004026484067), 47: (1, 127, 0.13740845555512923), 48: (1, 127, 0.13732150345160735), 49: (1, 127, 0.13698224404342765), 50: (1, 127, 0.13698751546119844)}\n",
      "{'predict_runtime': 901.0643, 'predict_samples_per_second': 0.057, 'predict_steps_per_second': 0.057}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:01.06\n",
      "  predict_samples_per_second =      0.057\n",
      "  predict_steps_per_second   =      0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.27177321445196867), 2: (2, 0.2538874391466379), 3: (2, 0.26428940799087286), 4: (2, 0.23860583268105984), 5: (2, 0.2438788916915655), 6: (2, 0.2425448363646865), 7: (2, 0.25887850765138865), 8: (2, 0.23859331011772156), 9: (2, 0.25789555720984936), 10: (2, 0.23677029088139534), 11: (2, 0.23683632910251617), 12: (2, 0.2531608399003744), 13: (2, 0.2381973322480917), 14: (2, 0.24388391617685556), 15: (2, 0.2531219385564327), 16: (2, 0.23798285145312548), 17: (2, 0.25709500070661306), 18: (2, 0.2392780752852559), 19: (2, 0.25482930708676577), 20: (2, 0.2611921513453126), 21: (2, 0.23629709891974926), 22: (2, 0.2543599586933851), 23: (2, 0.2367658130824566), 24: (2, 0.25522603932768106), 25: (2, 0.23625909630209208), 26: (2, 0.2573751835152507), 27: (2, 0.25344495847821236), 28: (2, 0.25589375756680965), 29: (2, 0.2543486151844263), 30: (2, 0.2547221090644598), 31: (2, 0.23959587328135967), 32: (2, 0.23815146833658218), 33: (2, 0.23993756715208292), 34: (2, 0.23711307998746634), 35: (2, 0.2553816381841898), 36: (2, 0.23916968517005444), 37: (2, 0.2532405713573098), 38: (2, 0.23906901385635138), 39: (2, 0.2541571883484721), 40: (2, 0.2367386193946004), 41: (2, 0.2372496733441949), 42: (2, 0.23851334769278765), 43: (2, 0.25549498200416565), 44: (2, 0.23882720433175564), 45: (2, 0.2554553495720029), 46: (2, 0.25493892654776573), 47: (2, 0.25499245524406433), 48: (2, 0.25756354443728924), 49: (2, 0.2551357913762331), 50: (2, 0.2555732959881425), 51: (1, 0.2268161978572607)}\n",
      "{1: (2, 127, 0.21376207033098918), 2: (2, 127, 0.21414163905951217), 3: (2, 127, 0.2165832099776099), 4: (2, 127, 0.21490179085884037), 5: (2, 127, 0.2143109766766429), 6: (2, 127, 0.21435583636575328), 7: (2, 127, 0.2137431559174901), 8: (2, 127, 0.21355371202129547), 9: (2, 127, 0.2137144192774582), 10: (2, 127, 0.2143785614505645), 11: (2, 127, 0.21406132706594982), 12: (2, 127, 0.21360713772945047), 13: (2, 127, 0.21360123299032918), 14: (2, 127, 0.21346941412844528), 15: (2, 127, 0.2135384977450521), 16: (2, 127, 0.21345347527590558), 17: (2, 127, 0.21350050915589952), 18: (2, 127, 0.21392052990978394), 19: (2, 127, 0.21398396399165467), 20: (2, 127, 0.2139446854987365), 21: (2, 127, 0.21368233768606748), 22: (2, 127, 0.21354588693169158), 23: (2, 127, 0.21356698782659891), 24: (2, 127, 0.21353413422012657), 25: (2, 127, 0.21350697647252187), 26: (2, 127, 0.2133958736199915), 27: (2, 127, 0.21346831212450904), 28: (2, 127, 0.2135297210931074), 29: (2, 127, 0.21339089677881773), 30: (2, 127, 0.21353496452720147), 31: (2, 127, 0.213553285702887), 32: (2, 127, 0.21365295114420998), 33: (2, 127, 0.213670778777597), 34: (2, 127, 0.21420635456057985), 35: (2, 127, 0.2140984697942072), 36: (2, 127, 0.2135917866367876), 37: (2, 127, 0.21355802150751194), 38: (2, 127, 0.2137252053275235), 39: (2, 127, 0.21350627005334913), 40: (2, 127, 0.21359815190392217), 41: (2, 127, 0.21364025512020887), 42: (2, 127, 0.21344207962021583), 43: (2, 127, 0.21356070628316384), 44: (2, 127, 0.21347082498681358), 45: (2, 127, 0.21357564788722383), 46: (2, 127, 0.21344707419318476), 47: (2, 127, 0.21364263014677237), 48: (2, 127, 0.21357236438115515), 49: (2, 127, 0.2134800497442484), 50: (2, 127, 0.21366341953261161)}\n",
      "{'predict_runtime': 1387.4563, 'predict_samples_per_second': 0.073, 'predict_steps_per_second': 0.037}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:07.45\n",
      "  predict_samples_per_second =      0.073\n",
      "  predict_steps_per_second   =      0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.2827745210379362), 2: (4, 0.2763301841914654), 3: (4, 0.25239118095487356), 4: (4, 0.2724502785131335), 5: (4, 0.25638293381780386), 6: (4, 0.2557520307600498), 7: (4, 0.2602992467582226), 8: (4, 0.2529518809169531), 9: (4, 0.25480728037655354), 10: (4, 0.2736109411343932), 11: (4, 0.25598945561796427), 12: (4, 0.25687710382044315), 13: (4, 0.2560721021145582), 14: (4, 0.2522764755412936), 15: (4, 0.2514667958021164), 16: (4, 0.25425131153315306), 17: (4, 0.24974195379763842), 18: (4, 0.2556116748601198), 19: (4, 0.27268165722489357), 20: (4, 0.2527899369597435), 21: (4, 0.27162827644497156), 22: (4, 0.2581617124378681), 23: (4, 0.26927537377923727), 24: (4, 0.25390248093754053), 25: (4, 0.25726664159446955), 26: (4, 0.25482671055942774), 27: (4, 0.2564400192350149), 28: (4, 0.2544947415590286), 29: (4, 0.25747984647750854), 30: (4, 0.2527958517894149), 31: (4, 0.25506056379526854), 32: (4, 0.25430224370211363), 33: (4, 0.27176981046795845), 34: (4, 0.2722830316051841), 35: (4, 0.25377404782921076), 36: (4, 0.27477897331118584), 37: (4, 0.2606371361762285), 38: (4, 0.2524401107802987), 39: (4, 0.2719482248649001), 40: (4, 0.2588875750079751), 41: (4, 0.25155410915613174), 42: (4, 0.2721145795658231), 43: (4, 0.25340899731963873), 44: (4, 0.2516773669049144), 45: (4, 0.2713797679170966), 46: (4, 0.2537771621719003), 47: (4, 0.2531930487602949), 48: (4, 0.2729656873270869), 49: (4, 0.2512075314298272), 50: (4, 0.2503353003412485), 51: (1, 0.2241222755983472)}\n",
      "{1: (4, 127, 0.21467004546264964), 2: (4, 127, 0.21449656373139206), 3: (4, 127, 0.21431906684851787), 4: (4, 127, 0.21438997890800238), 5: (4, 127, 0.21440763340338947), 6: (4, 127, 0.2142455413952235), 7: (4, 127, 0.2142792828014399), 8: (4, 127, 0.2142195267764133), 9: (4, 127, 0.21415129503396552), 10: (4, 127, 0.21449962075007714), 11: (4, 127, 0.21412019103794822), 12: (4, 127, 0.21397057112570353), 13: (4, 127, 0.2140833796625297), 14: (4, 127, 0.21417190091992458), 15: (4, 127, 0.21410466729127986), 16: (4, 127, 0.21420745478253664), 17: (4, 127, 0.21397070437816418), 18: (4, 127, 0.21387473456414902), 19: (4, 127, 0.21397789244312704), 20: (4, 127, 0.21394874682048642), 21: (4, 127, 0.2139099492713457), 22: (4, 127, 0.21388121269731306), 23: (4, 127, 0.21405076360197986), 24: (4, 127, 0.2139492363074985), 25: (4, 127, 0.21388798784171267), 26: (4, 127, 0.2140694568740336), 27: (4, 127, 0.2142380535470571), 28: (4, 127, 0.2140592643257788), 29: (4, 127, 0.2145400572949507), 30: (4, 127, 0.21432641903158484), 31: (4, 127, 0.2141636326307739), 32: (4, 127, 0.21384438441875647), 33: (4, 127, 0.21362440350399478), 34: (4, 127, 0.2139589203096281), 35: (4, 127, 0.21406057958058486), 36: (4, 127, 0.2139697977979704), 37: (4, 127, 0.21402232780113933), 38: (4, 127, 0.21386949996661953), 39: (4, 127, 0.21394960903452606), 40: (4, 127, 0.21399018707443176), 41: (4, 127, 0.21376029825879364), 42: (4, 127, 0.21384246345228097), 43: (4, 127, 0.21396538626959943), 44: (4, 127, 0.21389027550728537), 45: (4, 127, 0.21409679499022136), 46: (4, 127, 0.21393975282571917), 47: (4, 127, 0.21384987562132163), 48: (4, 127, 0.2138077948007762), 49: (4, 127, 0.2138545152943904), 50: (4, 127, 0.21370819073874414)}\n",
      "{'predict_runtime': 1389.9563, 'predict_samples_per_second': 0.145, 'predict_steps_per_second': 0.037}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:09.95\n",
      "  predict_samples_per_second =      0.145\n",
      "  predict_steps_per_second   =      0.037\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 27\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 26, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.38340952433645725), 2: (1, 0.23241416458040476), 3: (1, 0.23054997716099024), 4: (1, 0.23658281564712524), 5: (1, 0.23639320954680443), 6: (1, 0.23048040829598904), 7: (1, 0.22932511195540428), 8: (1, 0.22878566943109035), 9: (1, 0.2298876754939556), 10: (1, 0.22953916899859905), 11: (1, 0.2277147714048624), 12: (1, 0.2277315417304635), 13: (1, 0.22626729868352413), 14: (1, 0.2292234543710947), 15: (1, 0.23093054443597794), 16: (1, 0.22867517173290253), 17: (1, 0.22885297890752554), 18: (1, 0.22827131766825914), 19: (1, 0.22919389605522156), 20: (1, 0.2280289502814412), 21: (1, 0.23097559623420238), 22: (1, 0.22712970152497292), 23: (1, 0.22712934110313654), 24: (1, 0.22736470866948366), 25: (1, 0.22895268071442842), 26: (1, 0.22819271869957447), 27: (1, 0.2294433442875743), 28: (1, 0.22833416797220707), 29: (1, 0.22989393025636673), 30: (1, 0.22851263638585806), 31: (1, 0.2273612404242158), 32: (1, 0.22849159594625235), 33: (1, 0.22804440278559923), 34: (1, 0.22910748049616814), 35: (1, 0.22754526790231466), 36: (1, 0.22830420918762684), 37: (1, 0.22925007808953524), 38: (1, 0.2270116452127695), 39: (1, 0.22737743146717548), 40: (1, 0.22726457193493843), 41: (1, 0.22983146272599697), 42: (1, 0.2285336386412382), 43: (1, 0.22780308686196804), 44: (1, 0.22821239102631807), 45: (1, 0.22891296446323395), 46: (1, 0.2266991501674056), 47: (1, 0.226537412032485), 48: (1, 0.23160747159272432), 49: (1, 0.22912576142698526), 50: (1, 0.2269069878384471), 51: (1, 0.22728052455931902), 52: (1, 0.230292827822268), 53: (1, 0.22788584791123867), 54: (1, 0.22671821061521769), 55: (1, 0.22662216238677502), 56: (1, 0.2293703891336918), 57: (1, 0.22701262775808573), 58: (1, 0.22684609983116388), 59: (1, 0.226326416246593), 60: (1, 0.22833597473800182), 61: (1, 0.22641400434076786), 62: (1, 0.22805481683462858), 63: (1, 0.22809034399688244), 64: (1, 0.2290817517787218), 65: (1, 0.22909304220229387), 66: (1, 0.22984566446393728), 67: (1, 0.22782315779477358), 68: (1, 0.22813889291137457), 69: (1, 0.2280186554417014), 70: (1, 0.22852278035134077), 71: (1, 0.22689432930201292)}\n",
      "{1: (1, 127, 0.13728146779343603), 2: (1, 127, 0.1363670740305908), 3: (1, 127, 0.13736016168369083), 4: (1, 127, 0.14538809876360997), 5: (1, 127, 0.1393812561158355), 6: (1, 127, 0.13762995335236777), 7: (1, 127, 0.13605036619522676), 8: (1, 127, 0.13636690555653702), 9: (1, 127, 0.1372793552678401), 10: (1, 127, 0.13619801779754284), 11: (1, 127, 0.13606000641052882), 12: (1, 127, 0.1359621535429335), 13: (1, 127, 0.13586661017932525), 14: (1, 127, 0.13588346793924963), 15: (1, 127, 0.13611484789766196), 16: (1, 127, 0.13612024705329046), 17: (1, 127, 0.13588489509942964), 18: (1, 127, 0.13609749500412405), 19: (1, 127, 0.135778136016053), 20: (1, 127, 0.1364628193298663), 21: (1, 127, 0.13716530904731178), 22: (1, 127, 0.1371652571792443), 23: (1, 127, 0.13580856574185957), 24: (1, 127, 0.13585368458797611), 25: (1, 127, 0.13576225757481544), 26: (1, 127, 0.13577913188588198), 27: (1, 127, 0.13556621590350557), 28: (1, 127, 0.13572772779303977), 29: (1, 127, 0.1356818256679717), 30: (1, 127, 0.1357686196153206), 31: (1, 127, 0.13559004071894593), 32: (1, 127, 0.13566962554024195), 33: (1, 127, 0.13566186580454975), 34: (1, 127, 0.13588277928120507), 35: (1, 127, 0.13575518190655417), 36: (1, 127, 0.13581988202246625), 37: (1, 127, 0.13565936194014128), 38: (1, 127, 0.13578934153527256), 39: (1, 127, 0.13575439282700302), 40: (1, 127, 0.1357863937159927), 41: (1, 127, 0.13571594919510713), 42: (1, 127, 0.13575216634272355), 43: (1, 127, 0.135893742649222), 44: (1, 127, 0.13574170176027797), 45: (1, 127, 0.1356565998573824), 46: (1, 127, 0.13578099203039343), 47: (1, 127, 0.13572386247435891), 48: (1, 127, 0.13568813620707182), 49: (1, 127, 0.13566630725990833), 50: (1, 127, 0.13583107918911563), 51: (1, 127, 0.13578894583317708), 52: (1, 127, 0.13580826639865093), 53: (1, 127, 0.1358591834391196), 54: (1, 127, 0.1358398527317629), 55: (1, 127, 0.13577165094563576), 56: (1, 127, 0.13590027424176848), 57: (1, 127, 0.13571915739604573), 58: (1, 127, 0.13577466808611482), 59: (1, 127, 0.13584829721687816), 60: (1, 127, 0.13578574898410736), 61: (1, 127, 0.13584000458134207), 62: (1, 127, 0.13580777848095404), 63: (1, 127, 0.13571483476131452), 64: (1, 127, 0.1358051867788936), 65: (1, 127, 0.13567531051656861), 66: (1, 127, 0.13566575071033765), 67: (1, 127, 0.13573328630016077), 68: (1, 127, 0.13582579302418185), 69: (1, 127, 0.1356664941037499), 70: (1, 127, 0.13579141721129417)}\n",
      "{'predict_runtime': 1243.9776, 'predict_samples_per_second': 0.057, 'predict_steps_per_second': 0.057}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:43.97\n",
      "  predict_samples_per_second =      0.057\n",
      "  predict_steps_per_second   =      0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2853316040709615), 2: (2, 0.2548189917579293), 3: (2, 0.25470578391104937), 4: (2, 0.26612056884914637), 5: (2, 0.25042793434113264), 6: (2, 0.2678387798368931), 7: (2, 0.26438692957162857), 8: (2, 0.2692579636350274), 9: (2, 0.26342180371284485), 10: (2, 0.26454696990549564), 11: (2, 0.2490090923383832), 12: (2, 0.2558969119563699), 13: (2, 0.2556366352364421), 14: (2, 0.26651316694915295), 15: (2, 0.26632991153746843), 16: (2, 0.2440805910155177), 17: (2, 0.24899306241422892), 18: (2, 0.265573269687593), 19: (2, 0.2482920829206705), 20: (2, 0.24826921243220568), 21: (2, 0.26537742279469967), 22: (2, 0.26524628419429064), 23: (2, 0.26599557511508465), 24: (2, 0.2659064382314682), 25: (2, 0.2543710935860872), 26: (2, 0.24874095804989338), 27: (2, 0.24755427241325378), 28: (2, 0.2568442728370428), 29: (2, 0.2653939435258508), 30: (2, 0.2627240652218461), 31: (2, 0.2656135018914938), 32: (2, 0.2656990811228752), 33: (2, 0.2653189953416586), 34: (2, 0.2524259155616164), 35: (2, 0.265719392336905), 36: (2, 0.25532651226967573), 37: (2, 0.26678184047341347), 38: (2, 0.2546545919030905), 39: (2, 0.26388886384665966), 40: (2, 0.26764457020908594), 41: (2, 0.24730065651237965), 42: (2, 0.2538791410624981), 43: (2, 0.2506659282371402), 44: (2, 0.2664576340466738), 45: (2, 0.245079574175179), 46: (2, 0.26494912151247263), 47: (2, 0.2512476835399866), 48: (2, 0.24630726128816605), 49: (2, 0.26689430978149176), 50: (2, 0.26822339557111263), 51: (2, 0.2688420880585909), 52: (2, 0.266027900390327), 53: (2, 0.2707183761522174), 54: (2, 0.25407654140144587), 55: (2, 0.26631137914955616), 56: (2, 0.2678307304158807), 57: (2, 0.26620882004499435), 58: (2, 0.25518279895186424), 59: (2, 0.2665959456935525), 60: (2, 0.2504635537043214), 61: (2, 0.2680195989087224), 62: (2, 0.254843233153224), 63: (2, 0.26598660461604595), 64: (2, 0.24872300494462252), 65: (2, 0.27118424233049154), 66: (2, 0.26513759419322014), 67: (2, 0.2668285043910146), 68: (2, 0.2678485121577978), 69: (2, 0.26915919687598944), 70: (2, 0.265979983843863), 71: (1, 0.24448399618268013)}\n",
      "{1: (2, 127, 0.2130491424014601), 2: (2, 127, 0.21039637400380035), 3: (2, 127, 0.2095135172359704), 4: (2, 127, 0.2095901714124548), 5: (2, 127, 0.20935801841230608), 6: (2, 127, 0.2093820643985248), 7: (2, 127, 0.20917150153829825), 8: (2, 127, 0.2094214050847245), 9: (2, 127, 0.20944204188765972), 10: (2, 127, 0.20933825194131672), 11: (2, 127, 0.2094678338397089), 12: (2, 127, 0.2093004756717114), 13: (2, 127, 0.2093771777049763), 14: (2, 127, 0.20949793253533952), 15: (2, 127, 0.20954967785890646), 16: (2, 127, 0.20948786537830286), 17: (2, 127, 0.2092962272494562), 18: (2, 127, 0.2094086779164165), 19: (2, 127, 0.20949209167614696), 20: (2, 127, 0.2093140548828432), 21: (2, 127, 0.20958568557627558), 22: (2, 127, 0.20924664035028828), 23: (2, 127, 0.20928797161015938), 24: (2, 127, 0.20925985776826622), 25: (2, 127, 0.20930201075531132), 26: (2, 127, 0.20938803432289305), 27: (2, 127, 0.2093752413386787), 28: (2, 127, 0.20917394567339673), 29: (2, 127, 0.2093519928872468), 30: (2, 127, 0.2091718661767526), 31: (2, 127, 0.20930377746690212), 32: (2, 127, 0.20928335550615168), 33: (2, 127, 0.20928550155202705), 34: (2, 127, 0.20934954237222203), 35: (2, 127, 0.2094773644962766), 36: (2, 127, 0.20937937470226306), 37: (2, 127, 0.20955100087228956), 38: (2, 127, 0.2092793242067216), 39: (2, 127, 0.20932676939396408), 40: (2, 127, 0.20942755782698083), 41: (2, 127, 0.20923742240544144), 42: (2, 127, 0.2093020810078331), 43: (2, 127, 0.20913585696340076), 44: (2, 127, 0.20952775890344943), 45: (2, 127, 0.20933854103264377), 46: (2, 127, 0.20937868842019106), 47: (2, 127, 0.20939041243675421), 48: (2, 127, 0.20919611674594127), 49: (2, 127, 0.20920367373197568), 50: (2, 127, 0.20918891420514565), 51: (2, 127, 0.20918616083428615), 52: (2, 127, 0.20931059345749653), 53: (2, 127, 0.20936132718141623), 54: (2, 127, 0.20934168155503086), 55: (2, 127, 0.20943151907188687), 56: (2, 127, 0.2091696203840295), 57: (2, 127, 0.20947275271888557), 58: (2, 127, 0.2092195115690156), 59: (2, 127, 0.20947808159265932), 60: (2, 127, 0.2094488171933908), 61: (2, 127, 0.20933991922872272), 62: (2, 127, 0.20937524224066828), 63: (2, 127, 0.20930615278679554), 64: (2, 127, 0.20918030596858872), 65: (2, 127, 0.20931595766286212), 66: (2, 127, 0.20957231242942997), 67: (2, 127, 0.2093376111327194), 68: (2, 127, 0.20927165368733208), 69: (2, 127, 0.20917393888280852), 70: (2, 127, 0.2093743802906256)}\n",
      "{'predict_runtime': 1897.4366, 'predict_samples_per_second': 0.074, 'predict_steps_per_second': 0.037}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:31:37.43\n",
      "  predict_samples_per_second =      0.074\n",
      "  predict_steps_per_second   =      0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.35210962034761906), 2: (4, 0.3254889603704214), 3: (4, 0.3246722808107734), 4: (4, 0.3423401936888695), 5: (4, 0.33838477171957493), 6: (4, 0.34151148702949286), 7: (4, 0.32400622498244047), 8: (4, 0.32905931677669287), 9: (4, 0.33894361928105354), 10: (4, 0.32386273704469204), 11: (4, 0.34204306174069643), 12: (4, 0.32032172940671444), 13: (4, 0.33240129612386227), 14: (4, 0.32728486880660057), 15: (4, 0.319685029797256), 16: (4, 0.3261522622779012), 17: (4, 0.3178842104971409), 18: (4, 0.3215830074623227), 19: (4, 0.32262357510626316), 20: (4, 0.31766601372510195), 21: (4, 0.32318105828016996), 22: (4, 0.3195079928264022), 23: (4, 0.32023326493799686), 24: (4, 0.3232494192197919), 25: (4, 0.3227203767746687), 26: (4, 0.32394339237362146), 27: (4, 0.3224854599684477), 28: (4, 0.3255677344277501), 29: (4, 0.31979333236813545), 30: (4, 0.33918527234345675), 31: (4, 0.32404016330838203), 32: (4, 0.32448074873536825), 33: (4, 0.32123699598014355), 34: (4, 0.32488495390862226), 35: (4, 0.3267381424084306), 36: (4, 0.32357845921069384), 37: (4, 0.32275682780891657), 38: (4, 0.3273919830098748), 39: (4, 0.33599137142300606), 40: (4, 0.31991339661180973), 41: (4, 0.32593307364732027), 42: (4, 0.3299586568027735), 43: (4, 0.32518684584647417), 44: (4, 0.32520810794085264), 45: (4, 0.32405699230730534), 46: (4, 0.33229032438248396), 47: (4, 0.32046370673924685), 48: (4, 0.32380075845867395), 49: (4, 0.3240833282470703), 50: (4, 0.323778391815722), 51: (4, 0.3209379268810153), 52: (4, 0.3286090772598982), 53: (4, 0.3215659623965621), 54: (4, 0.3398189749568701), 55: (4, 0.3258760627359152), 56: (4, 0.32237941678613424), 57: (4, 0.3237014012411237), 58: (4, 0.32137979101389647), 59: (4, 0.32118958327919245), 60: (4, 0.3256113510578871), 61: (4, 0.3249024907127023), 62: (4, 0.32289854623377323), 63: (4, 0.32100263983011246), 64: (4, 0.3236176101490855), 65: (4, 0.3224328951910138), 66: (4, 0.3274215767160058), 67: (4, 0.3182895267382264), 68: (4, 0.3262846525758505), 69: (4, 0.3248638203367591), 70: (4, 0.3295715842396021), 71: (1, 0.2254136260598898)}\n",
      "{1: (4, 127, 0.21083967472741924), 2: (4, 127, 0.21013269074055857), 3: (4, 127, 0.20964314509183168), 4: (4, 127, 0.20973868739945212), 5: (4, 127, 0.20971473938543497), 6: (4, 127, 0.2095550535848056), 7: (4, 127, 0.2095293698128401), 8: (4, 127, 0.2095993686848738), 9: (4, 127, 0.20956958459294217), 10: (4, 127, 0.20945178983571727), 11: (4, 127, 0.2096210794274028), 12: (4, 127, 0.20951530676129765), 13: (4, 127, 0.20962453831544542), 14: (4, 127, 0.21005660980411872), 15: (4, 127, 0.2097750128518174), 16: (4, 127, 0.20994517235012036), 17: (4, 127, 0.20995308785134648), 18: (4, 127, 0.21008427851048744), 19: (4, 127, 0.20994476017021524), 20: (4, 127, 0.2096239634327532), 21: (4, 127, 0.20975032753098433), 22: (4, 127, 0.20982137888552635), 23: (4, 127, 0.20961304932216726), 24: (4, 127, 0.2096149464482515), 25: (4, 127, 0.2097961728087091), 26: (4, 127, 0.20989146890984042), 27: (4, 127, 0.20960512694235392), 28: (4, 127, 0.2096662199212693), 29: (4, 127, 0.2096918096003218), 30: (4, 127, 0.2096151052277506), 31: (4, 127, 0.20959324617760153), 32: (4, 127, 0.21031100105670258), 33: (4, 127, 0.20965825885123623), 34: (4, 127, 0.2097601111699629), 35: (4, 127, 0.20948483354199354), 36: (4, 127, 0.20923721551249816), 37: (4, 127, 0.20926122392315094), 38: (4, 127, 0.2091288148740849), 39: (4, 127, 0.20958835971871698), 40: (4, 127, 0.20923598621069917), 41: (4, 127, 0.2098849676622767), 42: (4, 127, 0.20992681491152038), 43: (4, 127, 0.21010595402409007), 44: (4, 127, 0.20993951893609575), 45: (4, 127, 0.20985683102864683), 46: (4, 127, 0.20986711553583934), 47: (4, 127, 0.2098879832041076), 48: (4, 127, 0.20984442416197202), 49: (4, 127, 0.2099028319765733), 50: (4, 127, 0.20974964540686428), 51: (4, 127, 0.20954732460475814), 52: (4, 127, 0.2095496551185025), 53: (4, 127, 0.20968795998212625), 54: (4, 127, 0.20985222766982523), 55: (4, 127, 0.2096576617781337), 56: (4, 127, 0.20961133527063477), 57: (4, 127, 0.20959850198288602), 58: (4, 127, 0.2096867840077112), 59: (4, 127, 0.20967291473726354), 60: (4, 127, 0.2094362687436849), 61: (4, 127, 0.20969119708339765), 62: (4, 127, 0.20954350977549402), 63: (4, 127, 0.20956439287291737), 64: (4, 127, 0.20958566564450584), 65: (4, 127, 0.2097014236652593), 66: (4, 127, 0.20986807571474728), 67: (4, 127, 0.2094417988344675), 68: (4, 127, 0.20953713352315304), 69: (4, 127, 0.2096162188768856), 70: (4, 127, 0.20957045634753826)}\n",
      "{'predict_runtime': 1904.6017, 'predict_samples_per_second': 0.148, 'predict_steps_per_second': 0.037}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:31:44.60\n",
      "  predict_samples_per_second =      0.148\n",
      "  predict_steps_per_second   =      0.037\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 26\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.2640857957303524), 2: (1, 0.24147358536720276), 3: (1, 0.2347264662384987), 4: (1, 0.23702694941312075), 5: (1, 0.2404686389490962), 6: (1, 0.2355741783976555), 7: (1, 0.2363509787246585), 8: (1, 0.23523574229329824), 9: (1, 0.23553553968667984), 10: (1, 0.23795566149055958), 11: (1, 0.23529626429080963), 12: (1, 0.23503701575100422), 13: (1, 0.23762339539825916), 14: (1, 0.23601050581783056), 15: (1, 0.2381696803495288), 16: (1, 0.23456946294754744), 17: (1, 0.23445165622979403), 18: (1, 0.238143271766603), 19: (1, 0.23459600564092398), 20: (1, 0.23538858629763126), 21: (1, 0.23415021132677794), 22: (1, 0.23441009782254696), 23: (1, 0.2372906543314457), 24: (1, 0.23741381242871284), 25: (1, 0.23849066067487001), 26: (1, 0.23505969997495413), 27: (1, 0.23642906546592712), 28: (1, 0.23589341063052416), 29: (1, 0.2378824781626463), 30: (1, 0.2376757301390171), 31: (1, 0.23463390860706568), 32: (1, 0.23760520201176405), 33: (1, 0.23873140010982752), 34: (1, 0.23892948776483536), 35: (1, 0.23861258197575808), 36: (1, 0.23528498131781816), 37: (1, 0.2348892567679286), 38: (1, 0.23430494405329227), 39: (1, 0.2360149035230279), 40: (1, 0.23661755863577127), 41: (1, 0.23469658102840185), 42: (1, 0.23527064453810453), 43: (1, 0.23773634620010853), 44: (1, 0.23414161801338196), 45: (1, 0.23511970695108175), 46: (1, 0.2371382238343358), 47: (1, 0.23411990981549025), 48: (1, 0.2360040182247758), 49: (1, 0.23788447584956884), 50: (1, 0.2357067819684744), 51: (1, 0.23502379097044468), 52: (1, 0.23808094579726458), 53: (1, 0.2375350808724761), 54: (1, 0.23743252363055944), 55: (1, 0.23473298456519842), 56: (1, 0.23765917122364044), 57: (1, 0.23728929553180933), 58: (1, 0.23523047007620335), 59: (1, 0.23739398457109928), 60: (1, 0.23446494061499834), 61: (1, 0.23846859391778708), 62: (1, 0.2350478945299983), 63: (1, 0.23719781823456287), 64: (1, 0.23465846944600344), 65: (1, 0.23659833520650864), 66: (1, 0.23579752445220947), 67: (1, 0.23844414297491312), 68: (1, 0.2386811301112175), 69: (1, 0.23812922649085522), 70: (1, 0.25301410257816315), 71: (1, 0.2341415649279952)}\n",
      "{1: (1, 127, 0.141816108238216), 2: (1, 127, 0.14133126034922017), 3: (1, 127, 0.1415132615260604), 4: (1, 127, 0.14150360694492425), 5: (1, 127, 0.1410083909643682), 6: (1, 127, 0.14122918049445538), 7: (1, 127, 0.14101215405023004), 8: (1, 127, 0.1415633446001631), 9: (1, 127, 0.14136345769594036), 10: (1, 127, 0.14104091493398185), 11: (1, 127, 0.14126335672564863), 12: (1, 127, 0.14153484303474895), 13: (1, 127, 0.14166200688974126), 14: (1, 127, 0.14111537291983686), 15: (1, 127, 0.140984733926323), 16: (1, 127, 0.1409731742185284), 17: (1, 127, 0.14109379089782087), 18: (1, 127, 0.1409579636822418), 19: (1, 127, 0.1409266320841871), 20: (1, 127, 0.14092971322192685), 21: (1, 127, 0.1410055733395843), 22: (1, 127, 0.14087116264364147), 23: (1, 127, 0.1409559993396007), 24: (1, 127, 0.14092787383784225), 25: (1, 127, 0.1408338006659169), 26: (1, 127, 0.14078506349226622), 27: (1, 127, 0.14084923272497776), 28: (1, 127, 0.14092179156810514), 29: (1, 127, 0.1408981826581706), 30: (1, 127, 0.14073865276974018), 31: (1, 127, 0.14080674474046925), 32: (1, 127, 0.14071653613923338), 33: (1, 127, 0.14091583708755848), 34: (1, 127, 0.14073915085865288), 35: (1, 127, 0.14088631471193683), 36: (1, 127, 0.14160651883007738), 37: (1, 127, 0.14126595990424315), 38: (1, 127, 0.14069683163419483), 39: (1, 127, 0.1406061233380648), 40: (1, 127, 0.14061801783799185), 41: (1, 127, 0.14063128374340966), 42: (1, 127, 0.14056661552712907), 43: (1, 127, 0.14053982678859486), 44: (1, 127, 0.14060325130057616), 45: (1, 127, 0.1405553494132762), 46: (1, 127, 0.14059047788146914), 47: (1, 127, 0.14075217130557288), 48: (1, 127, 0.1406115182257426), 49: (1, 127, 0.14050406232974896), 50: (1, 127, 0.14058958246981298), 51: (1, 127, 0.14064994282052506), 52: (1, 127, 0.14054738496261554), 53: (1, 127, 0.14067208748604135), 54: (1, 127, 0.1406475175832083), 55: (1, 127, 0.14064646961798113), 56: (1, 127, 0.14064081791260347), 57: (1, 127, 0.1404780165152991), 58: (1, 127, 0.1405661414106061), 59: (1, 127, 0.14058144780711865), 60: (1, 127, 0.140516282081252), 61: (1, 127, 0.14061416677514635), 62: (1, 127, 0.14065277266250117), 63: (1, 127, 0.14080229785850668), 64: (1, 127, 0.14063885653992808), 65: (1, 127, 0.14074632336979542), 66: (1, 127, 0.140674944835033), 67: (1, 127, 0.14068407250758935), 68: (1, 127, 0.140786547514456), 69: (1, 127, 0.14063491029884873), 70: (1, 127, 0.14083268897475923)}\n",
      "{'predict_runtime': 1287.0882, 'predict_samples_per_second': 0.055, 'predict_steps_per_second': 0.055}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:21:27.08\n",
      "  predict_samples_per_second =      0.055\n",
      "  predict_steps_per_second   =      0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2855823580175638), 2: (2, 0.26648207288235426), 3: (2, 0.2793302424252033), 4: (2, 0.2691226238384843), 5: (2, 0.2598133534193039), 6: (2, 0.25790454633533955), 7: (2, 0.2755750576034188), 8: (2, 0.27543046046048403), 9: (2, 0.2772236494347453), 10: (2, 0.2658739434555173), 11: (2, 0.2669228408485651), 12: (2, 0.2589800050482154), 13: (2, 0.2563777370378375), 14: (2, 0.2561495592817664), 15: (2, 0.2749830475077033), 16: (2, 0.2751080961897969), 17: (2, 0.2749418495222926), 18: (2, 0.2758389478549361), 19: (2, 0.2767472779378295), 20: (2, 0.27407469041645527), 21: (2, 0.2539881868287921), 22: (2, 0.2671828204765916), 23: (2, 0.2724057510495186), 24: (2, 0.27498465962707996), 25: (2, 0.2755989348515868), 26: (2, 0.25542200170457363), 27: (2, 0.2661375366151333), 28: (2, 0.26673523895442486), 29: (2, 0.2662261947989464), 30: (2, 0.2676198408007622), 31: (2, 0.2545463824644685), 32: (2, 0.25647740066051483), 33: (2, 0.27502192184329033), 34: (2, 0.276211597956717), 35: (2, 0.2752837771549821), 36: (2, 0.27881504502147436), 37: (2, 0.27488159108906984), 38: (2, 0.27541589457541704), 39: (2, 0.2757544098421931), 40: (2, 0.2598313158378005), 41: (2, 0.25609995890408754), 42: (2, 0.27395226154476404), 43: (2, 0.26782772317528725), 44: (2, 0.27638902235776186), 45: (2, 0.2739024516195059), 46: (2, 0.2742284080013633), 47: (2, 0.27347679529339075), 48: (2, 0.2755347117781639), 49: (2, 0.2745093144476414), 50: (2, 0.25575497280806303), 51: (2, 0.2561385193839669), 52: (2, 0.2769137052819133), 53: (2, 0.2753726337105036), 54: (2, 0.27421967778354883), 55: (2, 0.2747679306194186), 56: (2, 0.2765739196911454), 57: (2, 0.27775066532194614), 58: (2, 0.27472654078155756), 59: (2, 0.2741918470710516), 60: (2, 0.27538304310292006), 61: (2, 0.27750007901340723), 62: (2, 0.27538000233471394), 63: (2, 0.2761275041848421), 64: (2, 0.2746650306507945), 65: (2, 0.2762642838060856), 66: (2, 0.27635418251156807), 67: (2, 0.2754414323717356), 68: (2, 0.27624540217220783), 69: (2, 0.2591698607429862), 70: (2, 0.2739099198952317), 71: (1, 0.257701869122684)}\n",
      "{1: (2, 127, 0.2180369718982948), 2: (2, 127, 0.21796680541753066), 3: (2, 127, 0.2177322428292177), 4: (2, 127, 0.21760064218281291), 5: (2, 127, 0.2174450208718969), 6: (2, 127, 0.21745261967944818), 7: (2, 127, 0.21731790510834906), 8: (2, 127, 0.21723539677749235), 9: (2, 127, 0.21737983583758666), 10: (2, 127, 0.21732467914542813), 11: (2, 127, 0.2173242450317764), 12: (2, 127, 0.21751496778053092), 13: (2, 127, 0.21725817023241145), 14: (2, 127, 0.2173939411066414), 15: (2, 127, 0.21725523223235146), 16: (2, 127, 0.21741140223159564), 17: (2, 127, 0.21721526362207227), 18: (2, 127, 0.21734320238144614), 19: (2, 127, 0.21732298342701722), 20: (2, 127, 0.21733462945448132), 21: (2, 127, 0.21760310638901287), 22: (2, 127, 0.2172848246331642), 23: (2, 127, 0.21737548593050382), 24: (2, 127, 0.2173209816114757), 25: (2, 127, 0.21736283781461593), 26: (2, 127, 0.21750202829267565), 27: (2, 127, 0.2172897652040903), 28: (2, 127, 0.21742398834486645), 29: (2, 127, 0.21730435004560497), 30: (2, 127, 0.2172873331468523), 31: (2, 127, 0.2175025572178988), 32: (2, 127, 0.21732852995160998), 33: (2, 127, 0.21731601370219875), 34: (2, 127, 0.21733935840251878), 35: (2, 127, 0.217605006668394), 36: (2, 127, 0.21769409430924597), 37: (2, 127, 0.21715109577534472), 38: (2, 127, 0.21737057480257094), 39: (2, 127, 0.21730015233276398), 40: (2, 127, 0.21729265487070862), 41: (2, 127, 0.2173473680406574), 42: (2, 127, 0.21805908571283414), 43: (2, 127, 0.21735042188404582), 44: (2, 127, 0.21734215223824416), 45: (2, 127, 0.21727407037273166), 46: (2, 127, 0.2174064037353387), 47: (2, 127, 0.217284067702575), 48: (2, 127, 0.21735767757622745), 49: (2, 127, 0.21762952898577678), 50: (2, 127, 0.21782525695537722), 51: (2, 127, 0.21766119786926846), 52: (2, 127, 0.21730699700369374), 53: (2, 127, 0.21734928432118705), 54: (2, 127, 0.21742658824549885), 55: (2, 127, 0.21742006221155483), 56: (2, 127, 0.217283969422377), 57: (2, 127, 0.21728206529304034), 58: (2, 127, 0.21743434237125586), 59: (2, 127, 0.21734569673463117), 60: (2, 127, 0.21735191196349896), 61: (2, 127, 0.217573837289132), 62: (2, 127, 0.21721036888395004), 63: (2, 127, 0.21734323673038267), 64: (2, 127, 0.21721408457502606), 65: (2, 127, 0.21719910902535822), 66: (2, 127, 0.21727783427991737), 67: (2, 127, 0.21720678964263107), 68: (2, 127, 0.21748290087030395), 69: (2, 127, 0.2173240017292537), 70: (2, 127, 0.21727515036958878)}\n",
      "{'predict_runtime': 1969.849, 'predict_samples_per_second': 0.072, 'predict_steps_per_second': 0.036}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:32:49.84\n",
      "  predict_samples_per_second =      0.072\n",
      "  predict_steps_per_second   =      0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3668547635897994), 2: (4, 0.3340737968683243), 3: (4, 0.33474580850452185), 4: (4, 0.33365550078451633), 5: (4, 0.33414612524211407), 6: (4, 0.33163709472864866), 7: (4, 0.33532367181032896), 8: (4, 0.33518499229103327), 9: (4, 0.33047060761600733), 10: (4, 0.33068027533590794), 11: (4, 0.3313099378719926), 12: (4, 0.3307246658951044), 13: (4, 0.3317684531211853), 14: (4, 0.3337153308093548), 15: (4, 0.33023238088935614), 16: (4, 0.33278508111834526), 17: (4, 0.33044280856847763), 18: (4, 0.351878697052598), 19: (4, 0.3332982650026679), 20: (4, 0.3302593696862459), 21: (4, 0.33016575034707785), 22: (4, 0.33126612938940525), 23: (4, 0.3321010386571288), 24: (4, 0.3288076566532254), 25: (4, 0.33348939195275307), 26: (4, 0.3345827804878354), 27: (4, 0.3320959573611617), 28: (4, 0.33214937802404165), 29: (4, 0.3332547452300787), 30: (4, 0.33442443143576384), 31: (4, 0.33327221404761076), 32: (4, 0.33438047114759684), 33: (4, 0.33829249534755945), 34: (4, 0.33459556940943), 35: (4, 0.33165052346885204), 36: (4, 0.33088371250778437), 37: (4, 0.3304427471011877), 38: (4, 0.3299693036824465), 39: (4, 0.33153311256319284), 40: (4, 0.3335888274013996), 41: (4, 0.33031410444527864), 42: (4, 0.33276783488690853), 43: (4, 0.33383612148463726), 44: (4, 0.3313639108091593), 45: (4, 0.33226915914565325), 46: (4, 0.3344699749723077), 47: (4, 0.3348280591890216), 48: (4, 0.33371304254978895), 49: (4, 0.33113093208521605), 50: (4, 0.3296186290681362), 51: (4, 0.33338167518377304), 52: (4, 0.3338980684056878), 53: (4, 0.333038117736578), 54: (4, 0.32922757137566805), 55: (4, 0.33266590256243944), 56: (4, 0.33145259600132704), 57: (4, 0.3300037616863847), 58: (4, 0.32936338894069195), 59: (4, 0.33239803463220596), 60: (4, 0.3316310839727521), 61: (4, 0.3303488390520215), 62: (4, 0.33043223805725574), 63: (4, 0.3299467833712697), 64: (4, 0.33141625486314297), 65: (4, 0.33280831947922707), 66: (4, 0.3317683218047023), 67: (4, 0.33152766339480877), 68: (4, 0.3302065199241042), 69: (4, 0.3301258999854326), 70: (4, 0.3291287524625659), 71: (1, 0.2341463891789317)}\n",
      "{1: (4, 127, 0.21886349220826165), 2: (4, 127, 0.21797153692487187), 3: (4, 127, 0.21776120446065045), 4: (4, 127, 0.2177496675519258), 5: (4, 127, 0.2176712385019449), 6: (4, 127, 0.21751727718918576), 7: (4, 127, 0.21738902865139048), 8: (4, 127, 0.21757258553292572), 9: (4, 127, 0.21822010059877645), 10: (4, 127, 0.21756077614268216), 11: (4, 127, 0.21756003776521193), 12: (4, 127, 0.21747895646253673), 13: (4, 127, 0.21731910633847235), 14: (4, 127, 0.2175540944165367), 15: (4, 127, 0.21753040167290394), 16: (4, 127, 0.21733272520047942), 17: (4, 127, 0.21736691950079728), 18: (4, 127, 0.2174444903700253), 19: (4, 127, 0.21751908119767904), 20: (4, 127, 0.21747326831824668), 21: (4, 127, 0.21757173272011082), 22: (4, 127, 0.21744620337290324), 23: (4, 127, 0.21750001310128866), 24: (4, 127, 0.21725943998440983), 25: (4, 127, 0.21733313113245672), 26: (4, 127, 0.21745283624494638), 27: (4, 127, 0.2172136854703032), 28: (4, 127, 0.21736726261616693), 29: (4, 127, 0.21741282756579675), 30: (4, 127, 0.21723324696966043), 31: (4, 127, 0.2172806215817182), 32: (4, 127, 0.21744558410939036), 33: (4, 127, 0.2172280405684719), 34: (4, 127, 0.21741413316271435), 35: (4, 127, 0.21746761857817962), 36: (4, 127, 0.2173370982659614), 37: (4, 127, 0.21733507519133213), 38: (4, 127, 0.2175605267682296), 39: (4, 127, 0.21737340855316853), 40: (4, 127, 0.21759945110923898), 41: (4, 127, 0.21733162497118938), 42: (4, 127, 0.21742354948660286), 43: (4, 127, 0.2172701311569045), 44: (4, 127, 0.21734175402084438), 45: (4, 127, 0.21737905545526837), 46: (4, 127, 0.21734898476531422), 47: (4, 127, 0.2171976747885933), 48: (4, 127, 0.2173636223842192), 49: (4, 127, 0.21732288845411435), 50: (4, 127, 0.21730651919854674), 51: (4, 127, 0.21726081193256097), 52: (4, 127, 0.21745573087617404), 53: (4, 127, 0.217416034813413), 54: (4, 127, 0.21755178309390394), 55: (4, 127, 0.21735743662034432), 56: (4, 127, 0.21751278319110082), 57: (4, 127, 0.2174226590322228), 58: (4, 127, 0.21740204769766003), 59: (4, 127, 0.21736336598451447), 60: (4, 127, 0.21728926957181588), 61: (4, 127, 0.21720385856515778), 62: (4, 127, 0.21735852241046785), 63: (4, 127, 0.2173893746120606), 64: (4, 127, 0.21738541220116803), 65: (4, 127, 0.21721640153692698), 66: (4, 127, 0.21729761915002752), 67: (4, 127, 0.21717777374515854), 68: (4, 127, 0.21732272745997416), 69: (4, 127, 0.2178328921871744), 70: (4, 127, 0.2171757445545999)}\n",
      "{'predict_runtime': 1974.5091, 'predict_samples_per_second': 0.142, 'predict_steps_per_second': 0.036}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:32:54.50\n",
      "  predict_samples_per_second =      0.142\n",
      "  predict_steps_per_second   =      0.036\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 27\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3812389653176069), 2: (1, 0.22998365107923746), 3: (1, 0.2269703969359398), 4: (1, 0.22597832046449184), 5: (1, 0.22886131517589092), 6: (1, 0.22627849597483873), 7: (1, 0.2259436696767807), 8: (1, 0.22672499157488346), 9: (1, 0.2253676187247038), 10: (1, 0.23012482188642025), 11: (1, 0.22595801576972008), 12: (1, 0.2267563370987773), 13: (1, 0.22488545905798674), 14: (1, 0.2274000095203519), 15: (1, 0.23405727092176676), 16: (1, 0.22657989989966154), 17: (1, 0.2263333834707737), 18: (1, 0.22546682506799698), 19: (1, 0.22718052472919226), 20: (1, 0.22381591331213713), 21: (1, 0.2370341969653964), 22: (1, 0.22718238458037376), 23: (1, 0.22837701998651028), 24: (1, 0.22732689417898655), 25: (1, 0.22572630178183317), 26: (1, 0.2267102412879467), 27: (1, 0.2276238612830639), 28: (1, 0.2248970242217183), 29: (1, 0.24300160817801952), 30: (1, 0.2309029335156083), 31: (1, 0.22785610891878605), 32: (1, 0.2282390035688877), 33: (1, 0.22495273407548666), 34: (1, 0.22638591844588518), 35: (1, 0.22568824421614408), 36: (1, 0.22674794401973486), 37: (1, 0.22444555070251226), 38: (1, 0.22789803985506296), 39: (1, 0.22586437407881021), 40: (1, 0.227118200622499), 41: (1, 0.23110193386673927), 42: (1, 0.22709928266704082), 43: (1, 0.22668131906539202), 44: (1, 0.22464447282254696), 45: (1, 0.2260705567896366), 46: (1, 0.22467549238353968), 47: (1, 0.22733718156814575), 48: (1, 0.2255202941596508), 49: (1, 0.22705094516277313), 50: (1, 0.22558988444507122), 51: (1, 0.22613610606640577), 52: (1, 0.2249853704124689), 53: (1, 0.22662384156137705), 54: (1, 0.22576594073325396), 55: (1, 0.22887720447033644), 56: (1, 0.23602153174579144), 57: (1, 0.22767715994268656), 58: (1, 0.2239127941429615), 59: (1, 0.2268168507143855), 60: (1, 0.23173392284661531), 61: (1, 0.22616610955446959), 62: (1, 0.2250100327655673), 63: (1, 0.22557113599032164), 64: (1, 0.22537003923207521), 65: (1, 0.2281583845615387), 66: (1, 0.22759859263896942), 67: (1, 0.2251971121877432), 68: (1, 0.22627468779683113), 69: (1, 0.2264791475608945), 70: (1, 0.22787353955209255), 71: (1, 0.22486966662108898)}\n",
      "{1: (1, 255, 0.13426160655696603), 2: (1, 255, 0.13410039832267692), 3: (1, 255, 0.13419377594163603), 4: (1, 255, 0.13446292539364568), 5: (1, 255, 0.1342143331818721), 6: (1, 255, 0.13418594964359906), 7: (1, 255, 0.13622901496276552), 8: (1, 255, 0.13368962801554624), 9: (1, 255, 0.13385746207307367), 10: (1, 255, 0.13392993800853398), 11: (1, 255, 0.13395740337596804), 12: (1, 255, 0.13410016275650147), 13: (1, 255, 0.13406551111051265), 14: (1, 255, 0.1339378514418415), 15: (1, 255, 0.13384892843371513), 16: (1, 255, 0.13533686355267668), 17: (1, 255, 0.13388473960917954), 18: (1, 255, 0.13377429745068736), 19: (1, 255, 0.1351127499568404), 20: (1, 255, 0.13397416592228648), 21: (1, 255, 0.1351070106796482), 22: (1, 255, 0.13386666777306327), 23: (1, 255, 0.13388626546617233), 24: (1, 255, 0.13378728344013877), 25: (1, 255, 0.1338007952031844), 26: (1, 255, 0.13396575519924656), 27: (1, 255, 0.13382064261491977), 28: (1, 255, 0.13412037567765106), 29: (1, 255, 0.13810979145779914), 30: (1, 255, 0.13477668116490046), 31: (1, 255, 0.13357335567912634), 32: (1, 255, 0.1340898846221321), 33: (1, 255, 0.13392527528180212), 34: (1, 255, 0.133909496993703), 35: (1, 255, 0.13379842611212356), 36: (1, 255, 0.13406856857313246), 37: (1, 255, 0.13412365825737224), 38: (1, 255, 0.13381196905438805), 39: (1, 255, 0.1334328133101557), 40: (1, 255, 0.1349886624836454), 41: (1, 255, 0.13372772613942038), 42: (1, 255, 0.13360143907952543), 43: (1, 255, 0.1336310656704739), 44: (1, 255, 0.13345105369009225), 45: (1, 255, 0.13341078103757373), 46: (1, 255, 0.13348098632459546), 47: (1, 255, 0.13347346652299166), 48: (1, 255, 0.13350363224379572), 49: (1, 255, 0.1335639643099378), 50: (1, 255, 0.13351680141526695), 51: (1, 255, 0.13354081132394427), 52: (1, 255, 0.13342314977198838), 53: (1, 255, 0.13339887362557884), 54: (1, 255, 0.13363399557477118), 55: (1, 255, 0.13412574263033913), 56: (1, 255, 0.1334517603009647), 57: (1, 255, 0.13361083530985257), 58: (1, 255, 0.13361621190081624), 59: (1, 255, 0.13356191613802723), 60: (1, 255, 0.13360267372107973), 61: (1, 255, 0.1337755144409397), 62: (1, 255, 0.1335911300690735), 63: (1, 255, 0.13345715905010117), 64: (1, 255, 0.1335825618246899), 65: (1, 255, 0.13365410426083732), 66: (1, 255, 0.1336289692779674), 67: (1, 255, 0.13363274396123254), 68: (1, 255, 0.13362431552845475), 69: (1, 255, 0.1335939583021636), 70: (1, 255, 0.1337913644116591)}\n",
      "{'predict_runtime': 2441.7159, 'predict_samples_per_second': 0.029, 'predict_steps_per_second': 0.029}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:40:41.71\n",
      "  predict_samples_per_second =      0.029\n",
      "  predict_steps_per_second   =      0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2832146342843771), 2: (2, 0.24823001772165298), 3: (2, 0.25600885786116123), 4: (2, 0.2688243268057704), 5: (2, 0.26176791079342365), 6: (2, 0.24772409442812204), 7: (2, 0.24517658352851868), 8: (2, 0.27698673121631145), 9: (2, 0.26206178590655327), 10: (2, 0.2741430336609483), 11: (2, 0.2900028983131051), 12: (2, 0.25470288190990686), 13: (2, 0.2929015550762415), 14: (2, 0.25952804554253817), 15: (2, 0.26133853010833263), 16: (2, 0.24518354795873165), 17: (2, 0.24368008598685265), 18: (2, 0.2755804620683193), 19: (2, 0.26028604060411453), 20: (2, 0.2511130180209875), 21: (2, 0.2634795131161809), 22: (2, 0.2512905951589346), 23: (2, 0.24885615427047014), 24: (2, 0.24395980034023523), 25: (2, 0.29332064278423786), 26: (2, 0.25075083039700985), 27: (2, 0.25225856248289347), 28: (2, 0.2462345026433468), 29: (2, 0.2902012877166271), 30: (2, 0.2511015348136425), 31: (2, 0.28689754754304886), 32: (2, 0.28997810930013657), 33: (2, 0.24800733104348183), 34: (2, 0.2716960133984685), 35: (2, 0.2615068219602108), 36: (2, 0.28338393568992615), 37: (2, 0.2924454202875495), 38: (2, 0.24285048991441727), 39: (2, 0.2643233984708786), 40: (2, 0.24652579613029957), 41: (2, 0.2588277328759432), 42: (2, 0.2842464642599225), 43: (2, 0.2602642262354493), 44: (2, 0.24613710027188063), 45: (2, 0.24913055542856455), 46: (2, 0.29328170884400606), 47: (2, 0.2523605963215232), 48: (2, 0.2897385787218809), 49: (2, 0.24383709579706192), 50: (2, 0.260024837218225), 51: (2, 0.2593995127826929), 52: (2, 0.25986048858612776), 53: (2, 0.2972617605701089), 54: (2, 0.26912005338817835), 55: (2, 0.29047407768666744), 56: (2, 0.2897403761744499), 57: (2, 0.2624439597129822), 58: (2, 0.26069836039096117), 59: (2, 0.25151983462274075), 60: (2, 0.2857603905722499), 61: (2, 0.26611021626740694), 62: (2, 0.24563869182020426), 63: (2, 0.24784929770976305), 64: (2, 0.24809914268553257), 65: (2, 0.26136418897658587), 66: (2, 0.27693519834429026), 67: (2, 0.2507976498454809), 68: (2, 0.2859365437179804), 69: (2, 0.29418609756976366), 70: (2, 0.24072307627648115), 71: (1, 0.2654176289215684)}\n",
      "{1: (2, 255, 0.20728164934644513), 2: (2, 255, 0.2071592972376475), 3: (2, 255, 0.20726770641391767), 4: (2, 255, 0.20724828760413563), 5: (2, 255, 0.20741707164355938), 6: (2, 255, 0.2072119576053), 7: (2, 255, 0.20737301958542245), 8: (2, 255, 0.20724600737220517), 9: (2, 255, 0.20764891804360291), 10: (2, 255, 0.20717936173884893), 11: (2, 255, 0.20720702167600394), 12: (2, 255, 0.207000437850023), 13: (2, 255, 0.20713582488470803), 14: (2, 255, 0.20680585852002395), 15: (2, 255, 0.20679997788267393), 16: (2, 255, 0.2066908581693675), 17: (2, 255, 0.20667125361734162), 18: (2, 255, 0.2067005319447786), 19: (2, 255, 0.20683501343808922), 20: (2, 255, 0.20684745922757714), 21: (2, 255, 0.20682385359324662), 22: (2, 255, 0.2069463642533211), 23: (2, 255, 0.20697095527806703), 24: (2, 255, 0.2067370908553986), 25: (2, 255, 0.2068640741830071), 26: (2, 255, 0.2069136216688682), 27: (2, 255, 0.20700090342000418), 28: (2, 255, 0.2068340772068968), 29: (2, 255, 0.207498970021512), 30: (2, 255, 0.20723822239932477), 31: (2, 255, 0.20652718156868335), 32: (2, 255, 0.20670511149527396), 33: (2, 255, 0.20663797220616947), 34: (2, 255, 0.20664715987137136), 35: (2, 255, 0.20655924479166668), 36: (2, 255, 0.2067325250592594), 37: (2, 255, 0.20701357044790888), 38: (2, 255, 0.20649602836107506), 39: (2, 255, 0.20670779927761532), 40: (2, 255, 0.20650647220147006), 41: (2, 255, 0.2065471528097987), 42: (2, 255, 0.20655976315850721), 43: (2, 255, 0.2068727165095362), 44: (2, 255, 0.20684270186751497), 45: (2, 255, 0.2065695859163123), 46: (2, 255, 0.20652292568017455), 47: (2, 255, 0.20658869737868799), 48: (2, 255, 0.20664066202646378), 49: (2, 255, 0.20667866354479508), 50: (2, 255, 0.20688581331541725), 51: (2, 255, 0.20682977798084418), 52: (2, 255, 0.20651358647235468), 53: (2, 255, 0.20658490706746485), 54: (2, 255, 0.20659975617685739), 55: (2, 255, 0.20676197623286177), 56: (2, 255, 0.20706868235240963), 57: (2, 255, 0.20729932155387074), 58: (2, 255, 0.20704765526176083), 59: (2, 255, 0.2069613495403353), 60: (2, 255, 0.2065608660416568), 61: (2, 255, 0.20692841230581205), 62: (2, 255, 0.20682977815249973), 63: (2, 255, 0.2067556028966518), 64: (2, 255, 0.20726737166371415), 65: (2, 255, 0.20681366009966415), 66: (2, 255, 0.20667290904504412), 67: (2, 255, 0.20680804330782562), 68: (2, 255, 0.20669717199223883), 69: (2, 255, 0.20679880845561333), 70: (2, 255, 0.20695367418960028)}\n",
      "{'predict_runtime': 3745.7048, 'predict_samples_per_second': 0.038, 'predict_steps_per_second': 0.019}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:02:25.70\n",
      "  predict_samples_per_second =      0.038\n",
      "  predict_steps_per_second   =      0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3548546452075243), 2: (4, 0.31980495899915695), 3: (4, 0.3196030370891094), 4: (4, 0.3244875203818083), 5: (4, 0.3245651386678219), 6: (4, 0.33512463606894016), 7: (4, 0.3202176671475172), 8: (4, 0.3263340648263693), 9: (4, 0.32397217117249966), 10: (4, 0.3195195123553276), 11: (4, 0.3259550053626299), 12: (4, 0.3184768809005618), 13: (4, 0.31928132101893425), 14: (4, 0.32596080284565687), 15: (4, 0.32143955398350954), 16: (4, 0.32059193309396505), 17: (4, 0.3220374062657356), 18: (4, 0.3188820695504546), 19: (4, 0.32194733433425426), 20: (4, 0.3223525704815984), 21: (4, 0.31931164395064116), 22: (4, 0.319640938192606), 23: (4, 0.31817978899925947), 24: (4, 0.32171612698584795), 25: (4, 0.32438596710562706), 26: (4, 0.31993401516228914), 27: (4, 0.343926970846951), 28: (4, 0.3206900963559747), 29: (4, 0.3215040946379304), 30: (4, 0.3238133676350117), 31: (4, 0.31938811764121056), 32: (4, 0.3219430083408952), 33: (4, 0.3229864053428173), 34: (4, 0.3220658851787448), 35: (4, 0.3196241622790694), 36: (4, 0.32488604076206684), 37: (4, 0.3237642729654908), 38: (4, 0.3303337274119258), 39: (4, 0.3243562839925289), 40: (4, 0.3192535322159529), 41: (4, 0.32063778582960367), 42: (4, 0.32077960297465324), 43: (4, 0.32298109866678715), 44: (4, 0.32353731989860535), 45: (4, 0.31973749306052923), 46: (4, 0.319971258752048), 47: (4, 0.3174981167539954), 48: (4, 0.31892864126712084), 49: (4, 0.3183312760666013), 50: (4, 0.31721015740185976), 51: (4, 0.32258396595716476), 52: (4, 0.32177742570638657), 53: (4, 0.3206625273451209), 54: (4, 0.3215071363374591), 55: (4, 0.318274793215096), 56: (4, 0.3182083237916231), 57: (4, 0.32053477596491575), 58: (4, 0.32049307506531477), 59: (4, 0.322068496607244), 60: (4, 0.3182297497987747), 61: (4, 0.3225409397855401), 62: (4, 0.3237016061320901), 63: (4, 0.31833700835704803), 64: (4, 0.3250330714508891), 65: (4, 0.3190702171996236), 66: (4, 0.3321183994412422), 67: (4, 0.32943415734916925), 68: (4, 0.3181064957752824), 69: (4, 0.32150974590331316), 70: (4, 0.3151174886152148), 71: (1, 0.2237604632973671)}\n",
      "{1: (4, 255, 0.20811952493500477), 2: (4, 255, 0.20822449920735522), 3: (4, 255, 0.20801737148899074), 4: (4, 255, 0.20799103660837692), 5: (4, 255, 0.20791966013756452), 6: (4, 255, 0.20814708664502), 7: (4, 255, 0.20846687363205002), 8: (4, 255, 0.20791605659121393), 9: (4, 255, 0.20793773485165015), 10: (4, 255, 0.2080585493176591), 11: (4, 255, 0.2081529583343688), 12: (4, 255, 0.20841485052643455), 13: (4, 255, 0.20852439941874906), 14: (4, 255, 0.20834996278452522), 15: (4, 255, 0.20802255638820283), 16: (4, 255, 0.2079183839517189), 17: (4, 255, 0.20778377555748995), 18: (4, 255, 0.20787898735965), 19: (4, 255, 0.20807486953688603), 20: (4, 255, 0.20827756650453688), 21: (4, 255, 0.20805809688115237), 22: (4, 255, 0.20790488246609182), 23: (4, 255, 0.20787484137816173), 24: (4, 255, 0.2079416710481632), 25: (4, 255, 0.20805601476527313), 26: (4, 255, 0.2079168349285336), 27: (4, 255, 0.20855558904289614), 28: (4, 255, 0.20812644802545216), 29: (4, 255, 0.20794050883063497), 30: (4, 255, 0.20793035554096978), 31: (4, 255, 0.20793598619673181), 32: (4, 255, 0.2079285965757627), 33: (4, 255, 0.20813835361132435), 34: (4, 255, 0.20835164865369307), 35: (4, 255, 0.20787100488064336), 36: (4, 255, 0.2076956546335828), 37: (4, 255, 0.2076354340887537), 38: (4, 255, 0.20760181760232824), 39: (4, 255, 0.2076067519721155), 40: (4, 255, 0.20797347729185633), 41: (4, 255, 0.20809187091813952), 42: (4, 255, 0.20757095769924275), 43: (4, 255, 0.2075587519828011), 44: (4, 255, 0.20773103167394213), 45: (4, 255, 0.2076448411772064), 46: (4, 255, 0.2076583391384167), 47: (4, 255, 0.20767639430933724), 48: (4, 255, 0.20765135064721107), 49: (4, 255, 0.20769013257733748), 50: (4, 255, 0.20757119467883717), 51: (4, 255, 0.20759847587814517), 52: (4, 255, 0.2076131382957101), 53: (4, 255, 0.2077061035834691), 54: (4, 255, 0.20781217789752227), 55: (4, 255, 0.20762251276230695), 56: (4, 255, 0.2077033346336262), 57: (4, 255, 0.20768581949101358), 58: (4, 255, 0.20763545135656994), 59: (4, 255, 0.20761587683330565), 60: (4, 255, 0.20758724281308696), 61: (4, 255, 0.20767543979865663), 62: (4, 255, 0.2077241325020498), 63: (4, 255, 0.20767775456256726), 64: (4, 255, 0.208044517387216), 65: (4, 255, 0.2080758450698911), 66: (4, 255, 0.20812607999598864), 67: (4, 255, 0.20780634744567614), 68: (4, 255, 0.20799190857465946), 69: (4, 255, 0.2077194426793094), 70: (4, 255, 0.20788933513868674)}\n",
      "{'predict_runtime': 3767.817, 'predict_samples_per_second': 0.075, 'predict_steps_per_second': 0.019}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:02:47.81\n",
      "  predict_samples_per_second =      0.075\n",
      "  predict_steps_per_second   =      0.019\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 26\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.2653845399618149), 2: (1, 0.2370297210291028), 3: (1, 0.23321971576660872), 4: (1, 0.23680386319756508), 5: (1, 0.23331116326153278), 6: (1, 0.23632160760462284), 7: (1, 0.2335040494799614), 8: (1, 0.23419910110533237), 9: (1, 0.23631434701383114), 10: (1, 0.236434874124825), 11: (1, 0.2358426908031106), 12: (1, 0.23304471280425787), 13: (1, 0.23617583699524403), 14: (1, 0.23619226645678282), 15: (1, 0.23452975321561098), 16: (1, 0.23527186643332243), 17: (1, 0.23482449911534786), 18: (1, 0.2344606351107359), 19: (1, 0.23909842129796743), 20: (1, 0.2341310577467084), 21: (1, 0.23626853432506323), 22: (1, 0.23440678417682648), 23: (1, 0.23580375779420137), 24: (1, 0.23345663398504257), 25: (1, 0.23568362835794687), 26: (1, 0.23429004289209843), 27: (1, 0.23719019163399935), 28: (1, 0.23547246865928173), 29: (1, 0.23468635883182287), 30: (1, 0.23600583337247372), 31: (1, 0.2374187372624874), 32: (1, 0.23339156154543161), 33: (1, 0.23344113025814295), 34: (1, 0.2328822175040841), 35: (1, 0.23630890808999538), 36: (1, 0.2375249145552516), 37: (1, 0.2370255384594202), 38: (1, 0.23443202767521143), 39: (1, 0.23419320117682219), 40: (1, 0.23473738506436348), 41: (1, 0.2347832629457116), 42: (1, 0.2336996365338564), 43: (1, 0.23814062494784594), 44: (1, 0.23781966790556908), 45: (1, 0.23741589300334454), 46: (1, 0.23263188637793064), 47: (1, 0.23542588483542204), 48: (1, 0.23430225625634193), 49: (1, 0.233473245985806), 50: (1, 0.23523057624697685), 51: (1, 0.2375529780983925), 52: (1, 0.23466046154499054), 53: (1, 0.23532868456095457), 54: (1, 0.23415200784802437), 55: (1, 0.23647987004369497), 56: (1, 0.2358187474310398), 57: (1, 0.23595133516937494), 58: (1, 0.2362654423341155), 59: (1, 0.2370712673291564), 60: (1, 0.23492008168250322), 61: (1, 0.23521693795919418), 62: (1, 0.2338677030056715), 63: (1, 0.23601766768842936), 64: (1, 0.23546206392347813), 65: (1, 0.23337700869888067), 66: (1, 0.23731399327516556), 67: (1, 0.23550076317042112), 68: (1, 0.23528378549963236), 69: (1, 0.23435675632208586), 70: (1, 0.23911273200064898), 71: (1, 0.23492999002337456)}\n",
      "{1: (1, 255, 0.1384871188843367), 2: (1, 255, 0.13806790036751942), 3: (1, 255, 0.1379030222621034), 4: (1, 255, 0.13855603068482641), 5: (1, 255, 0.13914400968773694), 6: (1, 255, 0.13936818677785934), 7: (1, 255, 0.1393090133610017), 8: (1, 255, 0.13889517436790116), 9: (1, 255, 0.1384156589816306), 10: (1, 255, 0.1380578043085395), 11: (1, 255, 0.13812217118182019), 12: (1, 255, 0.13810102836612392), 13: (1, 255, 0.13791370705208358), 14: (1, 255, 0.1380496695966405), 15: (1, 255, 0.1381310182130512), 16: (1, 255, 0.13812035998950403), 17: (1, 255, 0.1379360078267899), 18: (1, 255, 0.13778469536599575), 19: (1, 255, 0.1379528559744358), 20: (1, 255, 0.13779698403953922), 21: (1, 255, 0.1378856682273395), 22: (1, 255, 0.13785046986943367), 23: (1, 255, 0.13808970945138557), 24: (1, 255, 0.13805138320826432), 25: (1, 255, 0.13785650333499208), 26: (1, 255, 0.13786527715331198), 27: (1, 255, 0.13801616409464795), 28: (1, 255, 0.1380861564703724), 29: (1, 255, 0.13813619460253154), 30: (1, 255, 0.13805725345862846), 31: (1, 255, 0.13803070933357173), 32: (1, 255, 0.13804555144160985), 33: (1, 255, 0.13795948803570926), 34: (1, 255, 0.13800321777588598), 35: (1, 255, 0.1379181325946953), 36: (1, 255, 0.13797133541209441), 37: (1, 255, 0.13799178401263906), 38: (1, 255, 0.13808787265682923), 39: (1, 255, 0.1380613364973197), 40: (1, 255, 0.13793233374827632), 41: (1, 255, 0.13809111846574382), 42: (1, 255, 0.13801170860362402), 43: (1, 255, 0.13799905562955958), 44: (1, 255, 0.13786116256287284), 45: (1, 255, 0.137815986467781), 46: (1, 255, 0.13783360508215778), 47: (1, 255, 0.13783809776034425), 48: (1, 255, 0.13782905044362825), 49: (1, 255, 0.13784265137259283), 50: (1, 255, 0.13794486690677848), 51: (1, 255, 0.13800827656671696), 52: (1, 255, 0.1379155662458609), 53: (1, 255, 0.13804605858875255), 54: (1, 255, 0.13800360182044552), 55: (1, 255, 0.13822604963446364), 56: (1, 255, 0.13817786097015236), 57: (1, 255, 0.13823020954561585), 58: (1, 255, 0.13819120642455185), 59: (1, 255, 0.13823211666050494), 60: (1, 255, 0.13825979551629108), 61: (1, 255, 0.13818422041322087), 62: (1, 255, 0.13808737971326884), 63: (1, 255, 0.13819825958241436), 64: (1, 255, 0.1382061280310154), 65: (1, 255, 0.1381376302673244), 66: (1, 255, 0.1382356362819087), 67: (1, 255, 0.13817340883554197), 68: (1, 255, 0.13810511056114647), 69: (1, 255, 0.13803768121801754), 70: (1, 255, 0.138101683191809)}\n",
      "{'predict_runtime': 2517.2483, 'predict_samples_per_second': 0.028, 'predict_steps_per_second': 0.028}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:41:57.24\n",
      "  predict_samples_per_second =      0.028\n",
      "  predict_steps_per_second   =      0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2880315100774169), 2: (2, 0.2908354476094246), 3: (2, 0.25906463246792555), 4: (2, 0.2552883252501488), 5: (2, 0.26389741618186235), 6: (2, 0.2576406477019191), 7: (2, 0.25122777093201876), 8: (2, 0.29666284937411547), 9: (2, 0.25787615310400724), 10: (2, 0.27511306665837765), 11: (2, 0.2569020055234432), 12: (2, 0.3015211522579193), 13: (2, 0.27964960411190987), 14: (2, 0.26992586348205805), 15: (2, 0.27035343926399946), 16: (2, 0.2608817471191287), 17: (2, 0.2943758312612772), 18: (2, 0.2850176403298974), 19: (2, 0.27054242696613073), 20: (2, 0.29799775034189224), 21: (2, 0.2550905020907521), 22: (2, 0.25978616811335087), 23: (2, 0.2559328330680728), 24: (2, 0.28567556105554104), 25: (2, 0.25307812448590994), 26: (2, 0.2705481220036745), 27: (2, 0.25451713614165783), 28: (2, 0.2862038007006049), 29: (2, 0.25905392318964005), 30: (2, 0.2968990979716182), 31: (2, 0.26783820148557425), 32: (2, 0.2594182873144746), 33: (2, 0.2524848375469446), 34: (2, 0.301426705904305), 35: (2, 0.26618413906544447), 36: (2, 0.25834664050489664), 37: (2, 0.3005963144823909), 38: (2, 0.30082695186138153), 39: (2, 0.25373484287410975), 40: (2, 0.3049487825483084), 41: (2, 0.25988960172981024), 42: (2, 0.25777102168649435), 43: (2, 0.301055402494967), 44: (2, 0.2603860814124346), 45: (2, 0.266539310105145), 46: (2, 0.25836771447211504), 47: (2, 0.2671186635270715), 48: (2, 0.2565346648916602), 49: (2, 0.2584827234968543), 50: (2, 0.2650463776662946), 51: (2, 0.2588636986911297), 52: (2, 0.30119459982961416), 53: (2, 0.2672963012009859), 54: (2, 0.2521498342975974), 55: (2, 0.29513936024159193), 56: (2, 0.2594582810997963), 57: (2, 0.2586715193465352), 58: (2, 0.25399790331721306), 59: (2, 0.2594797406345606), 60: (2, 0.2539881942793727), 61: (2, 0.26025620102882385), 62: (2, 0.30872581247240305), 63: (2, 0.29511007852852345), 64: (2, 0.25657312385737896), 65: (2, 0.2611874211579561), 66: (2, 0.2576559605076909), 67: (2, 0.30539773032069206), 68: (2, 0.26102822180837393), 69: (2, 0.3035340020433068), 70: (2, 0.2993239788338542), 71: (1, 0.24768729507923126)}\n",
      "{1: (2, 255, 0.21485323580894986), 2: (2, 255, 0.2145753562121707), 3: (2, 255, 0.21451449656457294), 4: (2, 255, 0.21445084488128915), 5: (2, 255, 0.21464452682902999), 6: (2, 255, 0.2145794857585547), 7: (2, 255, 0.21442307345934358), 8: (2, 255, 0.2144217575443726), 9: (2, 255, 0.21448100058033187), 10: (2, 255, 0.21452595950560827), 11: (2, 255, 0.21442264834163235), 12: (2, 255, 0.21465688251762413), 13: (2, 255, 0.21488043945282698), 14: (2, 255, 0.21439528216553086), 15: (2, 255, 0.21434187603858756), 16: (2, 255, 0.2144985503024038), 17: (2, 255, 0.2143258868479261), 18: (2, 255, 0.21447696297192106), 19: (2, 255, 0.21426760802666348), 20: (2, 255, 0.21434675400674927), 21: (2, 255, 0.2143874727116496), 22: (2, 255, 0.2144071201994723), 23: (2, 255, 0.21434271900969393), 24: (2, 255, 0.2145016774608224), 25: (2, 255, 0.21433426572703848), 26: (2, 255, 0.2145646797894847), 27: (2, 255, 0.21459762732699222), 28: (2, 255, 0.21456918345727757), 29: (2, 255, 0.2144607150525439), 30: (2, 255, 0.21451927995053577), 31: (2, 255, 0.21454452891998432), 32: (2, 255, 0.21466460519050265), 33: (2, 255, 0.21449554054906556), 34: (2, 255, 0.2145530980555158), 35: (2, 255, 0.2146539484753328), 36: (2, 255, 0.21453061119525457), 37: (2, 255, 0.21437348125173766), 38: (2, 255, 0.2145840749692391), 39: (2, 255, 0.21455938017324488), 40: (2, 255, 0.21449539602971546), 41: (2, 255, 0.21468308428119795), 42: (2, 255, 0.21445941972893243), 43: (2, 255, 0.21467252362008188), 44: (2, 255, 0.2147337737328866), 45: (2, 255, 0.21483558976986245), 46: (2, 255, 0.21454442198589152), 47: (2, 255, 0.21490780874064155), 48: (2, 255, 0.2146839363756133), 49: (2, 255, 0.21478230257463807), 50: (2, 255, 0.21472477001667606), 51: (2, 255, 0.21468711850397726), 52: (2, 255, 0.21488003683294735), 53: (2, 255, 0.21477717723989603), 54: (2, 255, 0.21477699100825132), 55: (2, 255, 0.21485413577699777), 56: (2, 255, 0.2149480534827008), 57: (2, 255, 0.21505672639856735), 58: (2, 255, 0.2149789885964756), 59: (2, 255, 0.21497552350674773), 60: (2, 255, 0.2146392816714212), 61: (2, 255, 0.2146300643353778), 62: (2, 255, 0.21465892402053463), 63: (2, 255, 0.2146531596268509), 64: (2, 255, 0.21473678777396094), 65: (2, 255, 0.21471329810207382), 66: (2, 255, 0.2143742757904179), 67: (2, 255, 0.2146623666051264), 68: (2, 255, 0.2145849179841724), 69: (2, 255, 0.21439965708802144), 70: (2, 255, 0.2147559790926821)}\n",
      "{'predict_runtime': 3885.1457, 'predict_samples_per_second': 0.036, 'predict_steps_per_second': 0.018}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:04:45.14\n",
      "  predict_samples_per_second =      0.036\n",
      "  predict_steps_per_second   =      0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.367356326431036), 2: (4, 0.33207286335527897), 3: (4, 0.33185848500579596), 4: (4, 0.3461343413218856), 5: (4, 0.32973221130669117), 6: (4, 0.33766166772693396), 7: (4, 0.33525543566793203), 8: (4, 0.33421423844993114), 9: (4, 0.33680170867592096), 10: (4, 0.33336064871400595), 11: (4, 0.33952672593295574), 12: (4, 0.33260587602853775), 13: (4, 0.3308082688599825), 14: (4, 0.33159933891147375), 15: (4, 0.3511916743591428), 16: (4, 0.3341770498082042), 17: (4, 0.3326396169140935), 18: (4, 0.33105581533163786), 19: (4, 0.3329448942095041), 20: (4, 0.33250694908201694), 21: (4, 0.33144433982670307), 22: (4, 0.3294866429641843), 23: (4, 0.33749149087816477), 24: (4, 0.3340923096984625), 25: (4, 0.33344908710569143), 26: (4, 0.33206983376294374), 27: (4, 0.3304278813302517), 28: (4, 0.33088403660804033), 29: (4, 0.33567288145422935), 30: (4, 0.33440811559557915), 31: (4, 0.33431186713278294), 32: (4, 0.3340729670599103), 33: (4, 0.33603675477206707), 34: (4, 0.336718687787652), 35: (4, 0.3344155428931117), 36: (4, 0.3312093410640955), 37: (4, 0.3299249242991209), 38: (4, 0.3467956716194749), 39: (4, 0.33316519763320684), 40: (4, 0.3339394796639681), 41: (4, 0.331850572489202), 42: (4, 0.33159877452999353), 43: (4, 0.3319337423890829), 44: (4, 0.3328227624297142), 45: (4, 0.3306810352951288), 46: (4, 0.3296827469021082), 47: (4, 0.3340278873220086), 48: (4, 0.3341477867215872), 49: (4, 0.3308709030970931), 50: (4, 0.3316904241219163), 51: (4, 0.3330619363114238), 52: (4, 0.3340814560651779), 53: (4, 0.3467791089788079), 54: (4, 0.33022131118923426), 55: (4, 0.3323818864300847), 56: (4, 0.3357526771724224), 57: (4, 0.3313690172508359), 58: (4, 0.33066081535071135), 59: (4, 0.3333720751106739), 60: (4, 0.3351166155189276), 61: (4, 0.3373018903657794), 62: (4, 0.3309579622000456), 63: (4, 0.335013585165143), 64: (4, 0.3311135107651353), 65: (4, 0.33183528296649456), 66: (4, 0.33558608032763004), 67: (4, 0.333305605687201), 68: (4, 0.33266366459429264), 69: (4, 0.3357007196173072), 70: (4, 0.3298092959448695), 71: (1, 0.23905744589865208)}\n",
      "{1: (4, 255, 0.2173128688817515), 2: (4, 255, 0.21630982237995838), 3: (4, 255, 0.21614777727746495), 4: (4, 255, 0.2163124187283364), 5: (4, 255, 0.21617378544646734), 6: (4, 255, 0.21612128434593186), 7: (4, 255, 0.21618161523605095), 8: (4, 255, 0.21630676196997656), 9: (4, 255, 0.21620111140039036), 10: (4, 255, 0.21631671032850064), 11: (4, 255, 0.21625520725752792), 12: (4, 255, 0.21628004319454525), 13: (4, 255, 0.21616633053795964), 14: (4, 255, 0.2161594425821129), 15: (4, 255, 0.2162461848893002), 16: (4, 255, 0.2160071661622793), 17: (4, 255, 0.2160811834366006), 18: (4, 255, 0.21604047191566697), 19: (4, 255, 0.2161107582131437), 20: (4, 255, 0.2159971632647748), 21: (4, 255, 0.21608872544020413), 22: (4, 255, 0.21608535557181813), 23: (4, 255, 0.21605847522835522), 24: (4, 255, 0.21606540771237776), 25: (4, 255, 0.21612223989385015), 26: (4, 255, 0.21617316360786265), 27: (4, 255, 0.2161467819273764), 28: (4, 255, 0.2160698252675288), 29: (4, 255, 0.21612422904912748), 30: (4, 255, 0.21612051088070752), 31: (4, 255, 0.21607372160708788), 32: (4, 255, 0.21601086264366612), 33: (4, 255, 0.2161301411140491), 34: (4, 255, 0.21607648475351288), 35: (4, 255, 0.21611238281589512), 36: (4, 255, 0.2160399451851845), 37: (4, 255, 0.21612991477709775), 38: (4, 255, 0.21607090690921918), 39: (4, 255, 0.21612157425751874), 40: (4, 255, 0.2159046121745133), 41: (4, 255, 0.2160873437263802), 42: (4, 255, 0.21596390146616043), 43: (4, 255, 0.21579407362596076), 44: (4, 255, 0.2160006346984529), 45: (4, 255, 0.2159954501060294), 46: (4, 255, 0.2159497540553703), 47: (4, 255, 0.2159379567476172), 48: (4, 255, 0.21596834534669623), 49: (4, 255, 0.21610216895374013), 50: (4, 255, 0.21590309737651955), 51: (4, 255, 0.21590103343421338), 52: (4, 255, 0.21599690403570146), 53: (4, 255, 0.2159682050895165), 54: (4, 255, 0.21606323825305), 55: (4, 255, 0.2159708102799806), 56: (4, 255, 0.21600893241736818), 57: (4, 255, 0.21602219781089646), 58: (4, 255, 0.2159330866646533), 59: (4, 255, 0.21586055210700222), 60: (4, 255, 0.21585889877203632), 61: (4, 255, 0.21603186785006057), 62: (4, 255, 0.21596045775302486), 63: (4, 255, 0.21613665984980032), 64: (4, 255, 0.21598730386764395), 65: (4, 255, 0.21605354852097877), 66: (4, 255, 0.2161580530926585), 67: (4, 255, 0.21600584498077047), 68: (4, 255, 0.21599321745189967), 69: (4, 255, 0.21597113125026227), 70: (4, 255, 0.21604617616052138)}\n",
      "{'predict_runtime': 3916.1088, 'predict_samples_per_second': 0.072, 'predict_steps_per_second': 0.018}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:05:16.10\n",
      "  predict_samples_per_second =      0.072\n",
      "  predict_steps_per_second   =      0.018\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 27\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
