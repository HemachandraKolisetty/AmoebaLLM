{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 28, 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.37158614210784435), 2: (1, 0.23594911396503448), 3: (1, 0.23459357116371393), 4: (1, 0.2383503457531333), 5: (1, 0.23442856222391129), 6: (1, 0.2344961604103446), 7: (1, 0.23315346706658602), 8: (1, 0.23288781009614468), 9: (1, 0.23287802934646606), 10: (1, 0.23173210211098194), 11: (1, 0.23360260110348463), 12: (1, 0.23226020578294992), 13: (1, 0.23296329844743013), 14: (1, 0.23201205860823393), 15: (1, 0.23154095374047756), 16: (1, 0.23265437968075275), 17: (1, 0.23214315250515938), 18: (1, 0.23450520541518927), 19: (1, 0.23111447133123875), 20: (1, 0.23359185364097357), 21: (1, 0.23194618988782167), 22: (1, 0.23370613995939493), 23: (1, 0.23262059222906828), 24: (1, 0.23466154653578997), 25: (1, 0.23458688706159592), 26: (1, 0.23337311949580908), 27: (1, 0.23454089555889368), 28: (1, 0.23309308011084795), 29: (1, 0.2331709172576666), 30: (1, 0.23275481164455414), 31: (1, 0.23359041195362806), 32: (1, 0.23279460985213518), 33: (1, 0.23101471923291683), 34: (1, 0.23537676967680454), 35: (1, 0.23364992626011372), 36: (1, 0.2307446300983429), 37: (1, 0.23305275198072195), 38: (1, 0.2339183408766985), 39: (1, 0.23195897229015827), 40: (1, 0.23195870220661163), 41: (1, 0.23494134563952684), 42: (1, 0.23462276998907328), 43: (1, 0.23307678569108248), 44: (1, 0.23062275350093842), 45: (1, 0.2330033639445901), 46: (1, 0.23204008489847183), 47: (1, 0.231741557829082), 48: (1, 0.23157470859587193), 49: (1, 0.23317207861691713), 50: (1, 0.2334302058443427), 51: (1, 0.23330301698297262)}\n",
      "{1: (1, 127, 0.14235241059213877), 2: (1, 127, 0.14196095400761197), 3: (1, 127, 0.14224629451000081), 4: (1, 127, 0.14309440225392112), 5: (1, 127, 0.14168613447301734), 6: (1, 127, 0.1417117680635626), 7: (1, 127, 0.14153452123713306), 8: (1, 127, 0.14152307770999634), 9: (1, 127, 0.14168727477851112), 10: (1, 127, 0.14164016719203532), 11: (1, 127, 0.14145082074738158), 12: (1, 127, 0.14145513617352942), 13: (1, 127, 0.14151895096833547), 14: (1, 127, 0.14174911577078536), 15: (1, 127, 0.1415881832298918), 16: (1, 127, 0.14163633080302027), 17: (1, 127, 0.14156587963821146), 18: (1, 127, 0.14150108078743998), 19: (1, 127, 0.14154837427910152), 20: (1, 127, 0.14161460464600267), 21: (1, 127, 0.1418665902263771), 22: (1, 127, 0.14204942594890987), 23: (1, 127, 0.14174844895848843), 24: (1, 127, 0.14181518391156056), 25: (1, 127, 0.14161489183801834), 26: (1, 127, 0.14148688596475312), 27: (1, 127, 0.14144801813375762), 28: (1, 127, 0.14152349521383994), 29: (1, 127, 0.14146260771988414), 30: (1, 127, 0.14138008244188988), 31: (1, 127, 0.1415186353453149), 32: (1, 127, 0.14135517811358678), 33: (1, 127, 0.141222871216674), 34: (1, 127, 0.1413443715817581), 35: (1, 127, 0.1412987287603612), 36: (1, 127, 0.14126164189679183), 37: (1, 127, 0.14123335454290306), 38: (1, 127, 0.1412846055908466), 39: (1, 127, 0.14118363128197708), 40: (1, 127, 0.14123826165954897), 41: (1, 127, 0.14159206001044022), 42: (1, 127, 0.1417472274225997), 43: (1, 127, 0.1417019489609937), 44: (1, 127, 0.14175796335724394), 45: (1, 127, 0.1414140421955839), 46: (1, 127, 0.14132374781733892), 47: (1, 127, 0.14141342254340883), 48: (1, 127, 0.14126888068583537), 49: (1, 127, 0.14152603813513057), 50: (1, 127, 0.14186936001638023)}\n",
      "{'predict_runtime': 929.2097, 'predict_samples_per_second': 0.055, 'predict_steps_per_second': 0.055}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:29.20\n",
      "  predict_samples_per_second =      0.055\n",
      "  predict_steps_per_second   =      0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.27027625869959593), 2: (2, 0.2418506247922778), 3: (2, 0.26284884102642536), 4: (2, 0.24805885925889015), 5: (2, 0.2609839094802737), 6: (2, 0.24601281061768532), 7: (2, 0.2638017237186432), 8: (2, 0.24658774305135012), 9: (2, 0.2581167882308364), 10: (2, 0.2462464440613985), 11: (2, 0.25066165067255497), 12: (2, 0.24139000847935677), 13: (2, 0.24485083762556314), 14: (2, 0.2627596966922283), 15: (2, 0.24596227705478668), 16: (2, 0.2653650864958763), 17: (2, 0.25471889413893223), 18: (2, 0.26188699062913656), 19: (2, 0.24508447665721178), 20: (2, 0.24719396978616714), 21: (2, 0.2406057920306921), 22: (2, 0.24238106049597263), 23: (2, 0.2655609669163823), 24: (2, 0.2411812199279666), 25: (2, 0.24476211704313755), 26: (2, 0.26494298595935106), 27: (2, 0.24329499900341034), 28: (2, 0.24395302031189203), 29: (2, 0.24503025505691767), 30: (2, 0.24441570974886417), 31: (2, 0.2452314393594861), 32: (2, 0.24620354641228914), 33: (2, 0.24204971082508564), 34: (2, 0.2439705766737461), 35: (2, 0.2656149407848716), 36: (2, 0.25403356831520796), 37: (2, 0.2586260652169585), 38: (2, 0.2450335379689932), 39: (2, 0.25681117083877325), 40: (2, 0.26142033841460943), 41: (2, 0.26208555791527033), 42: (2, 0.2495747096836567), 43: (2, 0.2606007419526577), 44: (2, 0.2451543565839529), 45: (2, 0.26277232356369495), 46: (2, 0.2457856759428978), 47: (2, 0.24551787693053484), 48: (2, 0.24096968676894903), 49: (2, 0.24597944784909487), 50: (2, 0.2618216648697853), 51: (1, 0.23558161407709122)}\n",
      "{1: (2, 127, 0.22129220287425547), 2: (2, 127, 0.22098930782132495), 3: (2, 127, 0.2208889020152214), 4: (2, 127, 0.22104362028790273), 5: (2, 127, 0.22075891727948282), 6: (2, 127, 0.22088133248933187), 7: (2, 127, 0.22094139560147769), 8: (2, 127, 0.22092264884804177), 9: (2, 127, 0.22062390984776686), 10: (2, 127, 0.2205709547361755), 11: (2, 127, 0.22078446147039416), 12: (2, 127, 0.22096063220858808), 13: (2, 127, 0.2206114282846216), 14: (2, 127, 0.22066490211355405), 15: (2, 127, 0.2208247774786602), 16: (2, 127, 0.22073431293971427), 17: (2, 127, 0.22065866599226092), 18: (2, 127, 0.22074265484734784), 19: (2, 127, 0.22103860363452218), 20: (2, 127, 0.22114180697230842), 21: (2, 127, 0.22102244101523413), 22: (2, 127, 0.22084358089610817), 23: (2, 127, 0.2209279462548457), 24: (2, 127, 0.2209058247403953), 25: (2, 127, 0.22085860109792685), 26: (2, 127, 0.22074356887078894), 27: (2, 127, 0.2206994697348926), 28: (2, 127, 0.22162487043258478), 29: (2, 127, 0.22096243739773438), 30: (2, 127, 0.22081574966295028), 31: (2, 127, 0.22070664820796626), 32: (2, 127, 0.22119152375797588), 33: (2, 127, 0.22105299899222577), 34: (2, 127, 0.22054351121920535), 35: (2, 127, 0.2204584340220244), 36: (2, 127, 0.2203289793188295), 37: (2, 127, 0.22050190402385522), 38: (2, 127, 0.22029539505679777), 39: (2, 127, 0.2203566225714923), 40: (2, 127, 0.220338390304113), 41: (2, 127, 0.22037507178569873), 42: (2, 127, 0.22032755242264646), 43: (2, 127, 0.22041851362785486), 44: (2, 127, 0.22038900293409824), 45: (2, 127, 0.22053403008406555), 46: (2, 127, 0.22048054537992542), 47: (2, 127, 0.22046379056414517), 48: (2, 127, 0.22040669908967075), 49: (2, 127, 0.2204088050593424), 50: (2, 127, 0.22048465216048355)}\n",
      "{'predict_runtime': 1432.399, 'predict_samples_per_second': 0.071, 'predict_steps_per_second': 0.036}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:52.39\n",
      "  predict_samples_per_second =      0.071\n",
      "  predict_steps_per_second   =      0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.29420244973152876), 2: (4, 0.258859533816576), 3: (4, 0.28727872762829065), 4: (4, 0.28419425059109926), 5: (4, 0.2678328575566411), 6: (4, 0.26212628092616796), 7: (4, 0.2824036553502083), 8: (4, 0.27379430271685123), 9: (4, 0.26057254523038864), 10: (4, 0.26113871578127146), 11: (4, 0.26333945896476507), 12: (4, 0.26340718753635883), 13: (4, 0.2610942218452692), 14: (4, 0.2730212826281786), 15: (4, 0.2610712517052889), 16: (4, 0.28413192089647055), 17: (4, 0.2706795074045658), 18: (4, 0.26361756678670645), 19: (4, 0.2615806693211198), 20: (4, 0.26740195136517286), 21: (4, 0.26218111999332905), 22: (4, 0.28278869949281216), 23: (4, 0.26561553683131933), 24: (4, 0.28144512232393026), 25: (4, 0.2629453865811229), 26: (4, 0.2645792765542865), 27: (4, 0.2617958774790168), 28: (4, 0.2736134883016348), 29: (4, 0.2626815941184759), 30: (4, 0.2598597966134548), 31: (4, 0.28322181291878223), 32: (4, 0.26265148911625147), 33: (4, 0.2680801544338465), 34: (4, 0.2852794472128153), 35: (4, 0.2582583362236619), 36: (4, 0.26262340508401394), 37: (4, 0.28591211698949337), 38: (4, 0.26110706105828285), 39: (4, 0.2769383192062378), 40: (4, 0.2603616090491414), 41: (4, 0.2605288764461875), 42: (4, 0.26452402863651514), 43: (4, 0.2609335593879223), 44: (4, 0.2603969257324934), 45: (4, 0.26481086388230324), 46: (4, 0.2789386799558997), 47: (4, 0.2774149663746357), 48: (4, 0.262590067461133), 49: (4, 0.2640200797468424), 50: (4, 0.26037000212818384), 51: (1, 0.25441479962319136)}\n",
      "{1: (4, 127, 0.22165325264937766), 2: (4, 127, 0.2210734225956239), 3: (4, 127, 0.2212740546972381), 4: (4, 127, 0.22110320433358274), 5: (4, 127, 0.22106194500554735), 6: (4, 127, 0.22092480846776033), 7: (4, 127, 0.22114948422362016), 8: (4, 127, 0.22104234185333796), 9: (4, 127, 0.22133765493585603), 10: (4, 127, 0.22095688063592658), 11: (4, 127, 0.2211853346134734), 12: (4, 127, 0.22109971080327362), 13: (4, 127, 0.2210814941117144), 14: (4, 127, 0.22123459897436729), 15: (4, 127, 0.22161214238428695), 16: (4, 127, 0.2215972149040638), 17: (4, 127, 0.2215026652836424), 18: (4, 127, 0.22114291246687098), 19: (4, 127, 0.22115031020407835), 20: (4, 127, 0.22108583502090118), 21: (4, 127, 0.22107013290762667), 22: (4, 127, 0.2210858035905976), 23: (4, 127, 0.22129745225561417), 24: (4, 127, 0.22251758708317917), 25: (4, 127, 0.22246466354855637), 26: (4, 127, 0.22110354634163182), 27: (4, 127, 0.2211278350363801), 28: (4, 127, 0.22148515426326454), 29: (4, 127, 0.2211152514164138), 30: (4, 127, 0.22093969807175434), 31: (4, 127, 0.22095730096307092), 32: (4, 127, 0.2208482881230632), 33: (4, 127, 0.22085052257858392), 34: (4, 127, 0.22080688969063478), 35: (4, 127, 0.22068190413314526), 36: (4, 127, 0.2206519824328033), 37: (4, 127, 0.2208570932353458), 38: (4, 127, 0.22063350984020028), 39: (4, 127, 0.22081159945489384), 40: (4, 127, 0.22097190110907544), 41: (4, 127, 0.22107536237921535), 42: (4, 127, 0.22094087987610206), 43: (4, 127, 0.22073383497323576), 44: (4, 127, 0.220632535552122), 45: (4, 127, 0.22072571570303026), 46: (4, 127, 0.22071668625200594), 47: (4, 127, 0.22062639010644805), 48: (4, 127, 0.2206992675132287), 49: (4, 127, 0.22115434176017215), 50: (4, 127, 0.22109980111956362)}\n",
      "{'predict_runtime': 1435.6462, 'predict_samples_per_second': 0.14, 'predict_steps_per_second': 0.036}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:55.64\n",
      "  predict_samples_per_second =       0.14\n",
      "  predict_steps_per_second   =      0.036\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 28\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.26662260852754116), 2: (1, 0.23961183987557888), 3: (1, 0.23901114705950022), 4: (1, 0.24176187440752983), 5: (1, 0.24198519065976143), 6: (1, 0.23916300386190414), 7: (1, 0.24084524530917406), 8: (1, 0.24067559652030468), 9: (1, 0.24159174505621195), 10: (1, 0.23939112853258848), 11: (1, 0.24027871899306774), 12: (1, 0.23942735698074102), 13: (1, 0.2434828383848071), 14: (1, 0.24016808718442917), 15: (1, 0.24029119405895472), 16: (1, 0.2409945260733366), 17: (1, 0.23948673252016306), 18: (1, 0.23915311601012945), 19: (1, 0.24250397738069296), 20: (1, 0.24049414042383432), 21: (1, 0.24131327029317617), 22: (1, 0.242043761536479), 23: (1, 0.2418396035209298), 24: (1, 0.2406056858599186), 25: (1, 0.23918862361460924), 26: (1, 0.2416319940239191), 27: (1, 0.2414922658354044), 28: (1, 0.24077991303056479), 29: (1, 0.23906029295176268), 30: (1, 0.23946380708366632), 31: (1, 0.23919641971588135), 32: (1, 0.24023414868861437), 33: (1, 0.24085352011024952), 34: (1, 0.23985575046390295), 35: (1, 0.24060351215302944), 36: (1, 0.24121435545384884), 37: (1, 0.2395184552296996), 38: (1, 0.2387497816234827), 39: (1, 0.240686540491879), 40: (1, 0.24206192418932915), 41: (1, 0.239282195456326), 42: (1, 0.23911532666534185), 43: (1, 0.24017501436173916), 44: (1, 0.23865335062146187), 45: (1, 0.2401530249044299), 46: (1, 0.23885334935039282), 47: (1, 0.23957726918160915), 48: (1, 0.24137829802930355), 49: (1, 0.24317494686692953), 50: (1, 0.2414553863927722), 51: (1, 0.23915293160825968)}\n",
      "{1: (1, 127, 0.1460827642274419), 2: (1, 127, 0.14600287128503867), 3: (1, 127, 0.1459973425215741), 4: (1, 127, 0.14593125730166284), 5: (1, 127, 0.14596712884793836), 6: (1, 127, 0.14591613068707346), 7: (1, 127, 0.14599021321059916), 8: (1, 127, 0.14607527373197277), 9: (1, 127, 0.1460212504960538), 10: (1, 127, 0.146042962690566), 11: (1, 127, 0.14589602030139034), 12: (1, 127, 0.14589329791350628), 13: (1, 127, 0.1461418370576942), 14: (1, 127, 0.14615913910981942), 15: (1, 127, 0.14618451413735162), 16: (1, 127, 0.1460445626294167), 17: (1, 127, 0.1462712496020428), 18: (1, 127, 0.14594174130255078), 19: (1, 127, 0.14663581059526976), 20: (1, 127, 0.14659165280805095), 21: (1, 127, 0.14651459232559355), 22: (1, 127, 0.14606280717998743), 23: (1, 127, 0.14602264470794774), 24: (1, 127, 0.14598128122578222), 25: (1, 127, 0.1459722693965543), 26: (1, 127, 0.1460035970566545), 27: (1, 127, 0.14605472785398715), 28: (1, 127, 0.14603220533550254), 29: (1, 127, 0.14603523229520152), 30: (1, 127, 0.14607191098281952), 31: (1, 127, 0.14601061615623592), 32: (1, 127, 0.14582856580263048), 33: (1, 127, 0.14580273915698208), 34: (1, 127, 0.14574180110027707), 35: (1, 127, 0.14572509466927117), 36: (1, 127, 0.14566217324747813), 37: (1, 127, 0.14570087523705613), 38: (1, 127, 0.14581898307999758), 39: (1, 127, 0.14574777270395925), 40: (1, 127, 0.14570095875542463), 41: (1, 127, 0.1458114897612277), 42: (1, 127, 0.1456591900159407), 43: (1, 127, 0.14570820684302746), 44: (1, 127, 0.1458136727080101), 45: (1, 127, 0.14580742750082196), 46: (1, 127, 0.14590359394123234), 47: (1, 127, 0.14578322880703398), 48: (1, 127, 0.14584350779535263), 49: (1, 127, 0.14579421963073372), 50: (1, 127, 0.14581635268771742)}\n",
      "{'predict_runtime': 957.7022, 'predict_samples_per_second': 0.053, 'predict_steps_per_second': 0.053}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:57.70\n",
      "  predict_samples_per_second =      0.053\n",
      "  predict_steps_per_second   =      0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.2765782782807946), 2: (2, 0.27201148122549057), 3: (2, 0.27232623659074306), 4: (2, 0.2541576772928238), 5: (2, 0.2713824072852731), 6: (2, 0.2653464749455452), 7: (2, 0.27152822259813547), 8: (2, 0.2510153707116842), 9: (2, 0.2613742398098111), 10: (2, 0.25229711551219225), 11: (2, 0.2544178497046232), 12: (2, 0.270239794626832), 13: (2, 0.25552884582430124), 14: (2, 0.27364881336688995), 15: (2, 0.25489215087145567), 16: (2, 0.2547850236296654), 17: (2, 0.27325134817510843), 18: (2, 0.25427709706127644), 19: (2, 0.27295904979109764), 20: (2, 0.2545732222497463), 21: (2, 0.2534520346671343), 22: (2, 0.2758044134825468), 23: (2, 0.27794784866273403), 24: (2, 0.2536693913862109), 25: (2, 0.2727481694892049), 26: (2, 0.2559522334486246), 27: (2, 0.269415196031332), 28: (2, 0.2734157294034958), 29: (2, 0.27765102963894606), 30: (2, 0.2754160352051258), 31: (2, 0.25731161423027515), 32: (2, 0.273909660987556), 33: (2, 0.2714936789125204), 34: (2, 0.2534726979210973), 35: (2, 0.2714219791814685), 36: (2, 0.255197387188673), 37: (2, 0.27158350497484207), 38: (2, 0.26874365843832493), 39: (2, 0.25117857195436954), 40: (2, 0.2724833441898227), 41: (2, 0.25164095498621464), 42: (2, 0.2706349855288863), 43: (2, 0.2520932098850608), 44: (2, 0.2555299997329712), 45: (2, 0.25461483001708984), 46: (2, 0.24907339364290237), 47: (2, 0.2580457981675863), 48: (2, 0.2739077443256974), 49: (2, 0.27155593037605286), 50: (2, 0.273949570953846), 51: (1, 0.244281854480505)}\n",
      "{1: (2, 127, 0.22868910846923748), 2: (2, 127, 0.22865105857412646), 3: (2, 127, 0.22871245982814728), 4: (2, 127, 0.22927128539721328), 5: (2, 127, 0.22878145563643515), 6: (2, 127, 0.22821577086927383), 7: (2, 127, 0.22815728376025524), 8: (2, 127, 0.2280291176115082), 9: (2, 127, 0.22797026391339115), 10: (2, 127, 0.22814547929795473), 11: (2, 127, 0.22784658013219675), 12: (2, 127, 0.22822953626425482), 13: (2, 127, 0.22791444585753942), 14: (2, 127, 0.22796551223961622), 15: (2, 127, 0.22804629543106855), 16: (2, 127, 0.2280247001358726), 17: (2, 127, 0.22809914782584653), 18: (2, 127, 0.2281237350791458), 19: (2, 127, 0.22825049326615773), 20: (2, 127, 0.22813491042204728), 21: (2, 127, 0.2280137963798337), 22: (2, 127, 0.2284769524827482), 23: (2, 127, 0.22868001964089907), 24: (2, 127, 0.22861629208975184), 25: (2, 127, 0.22878507674327048), 26: (2, 127, 0.22853620412693484), 27: (2, 127, 0.2284309892937189), 28: (2, 127, 0.22852945791953427), 29: (2, 127, 0.22870002310048407), 30: (2, 127, 0.2284047129292657), 31: (2, 127, 0.228369847453368), 32: (2, 127, 0.2283815700912804), 33: (2, 127, 0.22849867616112776), 34: (2, 127, 0.22846245998150017), 35: (2, 127, 0.2283960775596889), 36: (2, 127, 0.2284556517054833), 37: (2, 127, 0.2282970772953484), 38: (2, 127, 0.22849046176402119), 39: (2, 127, 0.22842422990847056), 40: (2, 127, 0.22843632437875422), 41: (2, 127, 0.228405343207318), 42: (2, 127, 0.22832626614748963), 43: (2, 127, 0.22852763527725625), 44: (2, 127, 0.22842408196751293), 45: (2, 127, 0.22853939131811613), 46: (2, 127, 0.2284809218382272), 47: (2, 127, 0.22854784805708983), 48: (2, 127, 0.22860011559595741), 49: (2, 127, 0.22842421263867008), 50: (2, 127, 0.2285450424808334)}\n",
      "{'predict_runtime': 1482.3138, 'predict_samples_per_second': 0.068, 'predict_steps_per_second': 0.034}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:42.31\n",
      "  predict_samples_per_second =      0.068\n",
      "  predict_steps_per_second   =      0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.30754712224006653), 2: (4, 0.26870310865342617), 3: (4, 0.27113079000264406), 4: (4, 0.28840885404497385), 5: (4, 0.28572203405201435), 6: (4, 0.2743268320336938), 7: (4, 0.2748369947075844), 8: (4, 0.2713813344016671), 9: (4, 0.279967475682497), 10: (4, 0.2898131748661399), 11: (4, 0.2841429067775607), 12: (4, 0.27247087843716145), 13: (4, 0.271019103936851), 14: (4, 0.26775976084172726), 15: (4, 0.2923275316134095), 16: (4, 0.2695241281762719), 17: (4, 0.26788860745728016), 18: (4, 0.2673728121444583), 19: (4, 0.26859238743782043), 20: (4, 0.27105164900422096), 21: (4, 0.28618354722857475), 22: (4, 0.29088415298610926), 23: (4, 0.2886249478906393), 24: (4, 0.2701832475140691), 25: (4, 0.2730325534939766), 26: (4, 0.27131668105721474), 27: (4, 0.2697160495445132), 28: (4, 0.2697818884626031), 29: (4, 0.27291759103536606), 30: (4, 0.2716626552864909), 31: (4, 0.2735706828534603), 32: (4, 0.2721445979550481), 33: (4, 0.2917508948594332), 34: (4, 0.26785694621503353), 35: (4, 0.2696609953418374), 36: (4, 0.27254840079694986), 37: (4, 0.267064212821424), 38: (4, 0.2687664721161127), 39: (4, 0.2927547888830304), 40: (4, 0.28556592017412186), 41: (4, 0.2742679584771395), 42: (4, 0.2933474611490965), 43: (4, 0.2664005970582366), 44: (4, 0.26859030965715647), 45: (4, 0.2923534298315644), 46: (4, 0.26945765130221844), 47: (4, 0.27466680109500885), 48: (4, 0.287578321993351), 49: (4, 0.26698210928589106), 50: (4, 0.26897485740482807), 51: (1, 0.24111852329224348)}\n",
      "{1: (4, 127, 0.23121397971637606), 2: (4, 127, 0.22927741938101964), 3: (4, 127, 0.22884843480868602), 4: (4, 127, 0.2286472186064861), 5: (4, 127, 0.2284751943803913), 6: (4, 127, 0.22847605418179215), 7: (4, 127, 0.2283774644767088), 8: (4, 127, 0.22819995308866886), 9: (4, 127, 0.2282557497607676), 10: (4, 127, 0.22824365287784518), 11: (4, 127, 0.22826185361958864), 12: (4, 127, 0.2281756824630452), 13: (4, 127, 0.228165254319512), 14: (4, 127, 0.22811878122770646), 15: (4, 127, 0.2282364775580684), 16: (4, 127, 0.2281580268823373), 17: (4, 127, 0.2281549456785983), 18: (4, 127, 0.22840423414146338), 19: (4, 127, 0.22832833998286584), 20: (4, 127, 0.22819267487608072), 21: (4, 127, 0.22812163980868388), 22: (4, 127, 0.22810245692495287), 23: (4, 127, 0.22828893846736883), 24: (4, 127, 0.2283603092875537), 25: (4, 127, 0.22817860157265674), 26: (4, 127, 0.22827546462768644), 27: (4, 127, 0.22840606690362447), 28: (4, 127, 0.2282841058418624), 29: (4, 127, 0.2281119468453245), 30: (4, 127, 0.22828300395525816), 31: (4, 127, 0.2282084728349147), 32: (4, 127, 0.22821569716279197), 33: (4, 127, 0.22821219800054793), 34: (4, 127, 0.22827984724105813), 35: (4, 127, 0.22824265548270048), 36: (4, 127, 0.22841134264801197), 37: (4, 127, 0.22818360083890477), 38: (4, 127, 0.22819023041098607), 39: (4, 127, 0.22792715319674314), 40: (4, 127, 0.22832924857236972), 41: (4, 127, 0.22804420768451972), 42: (4, 127, 0.22826759958654408), 43: (4, 127, 0.2282882757103584), 44: (4, 127, 0.22816949655983862), 45: (4, 127, 0.22811777491533147), 46: (4, 127, 0.2281116927555931), 47: (4, 127, 0.22797208157639334), 48: (4, 127, 0.22827855329667254), 49: (4, 127, 0.22806986323814457), 50: (4, 127, 0.22805119684244704)}\n",
      "{'predict_runtime': 1482.4879, 'predict_samples_per_second': 0.136, 'predict_steps_per_second': 0.034}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:42.48\n",
      "  predict_samples_per_second =      0.136\n",
      "  predict_steps_per_second   =      0.034\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 29\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 28, 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.4002138199284673), 2: (1, 0.24670670740306377), 3: (1, 0.24530184362083673), 4: (1, 0.24699073284864426), 5: (1, 0.24351644422858953), 6: (1, 0.2448193384334445), 7: (1, 0.24969003070145845), 8: (1, 0.2485555736348033), 9: (1, 0.2459538746625185), 10: (1, 0.24389556888490915), 11: (1, 0.2427951106801629), 12: (1, 0.24149319622665644), 13: (1, 0.2451570937409997), 14: (1, 0.24194488115608692), 15: (1, 0.24171924404799938), 16: (1, 0.24659294728189707), 17: (1, 0.2454489404335618), 18: (1, 0.24692017305642366), 19: (1, 0.25149480905383825), 20: (1, 0.25075049698352814), 21: (1, 0.2835359312593937), 22: (1, 0.2474676063284278), 23: (1, 0.24766975361853838), 24: (1, 0.2463333671912551), 25: (1, 0.24450166057795286), 26: (1, 0.25103274267166853), 27: (1, 0.2427420513704419), 28: (1, 0.24088820163160563), 29: (1, 0.24074974469840527), 30: (1, 0.24233233463019133), 31: (1, 0.2525805253535509), 32: (1, 0.24055326730012894), 33: (1, 0.2418487910181284), 34: (1, 0.24434799142181873), 35: (1, 0.24084597267210484), 36: (1, 0.24239950347691774), 37: (1, 0.24440804962068796), 38: (1, 0.24157102312892675), 39: (1, 0.2415578132495284), 40: (1, 0.24717642832547426), 41: (1, 0.24335350282490253), 42: (1, 0.24970730673521757), 43: (1, 0.24781296029686928), 44: (1, 0.24914048332720995), 45: (1, 0.24497243203222752), 46: (1, 0.24716686643660069), 47: (1, 0.24791603814810514), 48: (1, 0.2432035431265831), 49: (1, 0.24195529893040657), 50: (1, 0.2466650614514947), 51: (1, 0.24968668539077044), 52: (1, 0.24179458804428577), 53: (1, 0.24240592028945684), 54: (1, 0.24821532424539328), 55: (1, 0.24687597900629044), 56: (1, 0.2454875549301505), 57: (1, 0.25174651201814413), 58: (1, 0.24833745136857033), 59: (1, 0.24829402193427086), 60: (1, 0.24554147571325302), 61: (1, 0.24090490769594908), 62: (1, 0.2438041241839528), 63: (1, 0.25367039907723665), 64: (1, 0.244357087649405), 65: (1, 0.2452419763430953), 66: (1, 0.24702534638345242), 67: (1, 0.24762229900807142), 68: (1, 0.24955751560628414), 69: (1, 0.24407219048589468), 70: (1, 0.2448321608826518), 71: (1, 0.2501687491312623)}\n",
      "{1: (1, 127, 0.1455504776044624), 2: (1, 127, 0.14480700455312653), 3: (1, 127, 0.14803731678361734), 4: (1, 127, 0.14701424583088696), 5: (1, 127, 0.14503521103353248), 6: (1, 127, 0.1463447017595172), 7: (1, 127, 0.14634239218953088), 8: (1, 127, 0.14835223075237094), 9: (1, 127, 0.14592861069557), 10: (1, 127, 0.14488062021271217), 11: (1, 127, 0.14489842166640157), 12: (1, 127, 0.1447725770995021), 13: (1, 127, 0.1459492471025098), 14: (1, 127, 0.1446001266283313), 15: (1, 127, 0.14575057631490504), 16: (1, 127, 0.1480631796408474), 17: (1, 127, 0.1472387796737195), 18: (1, 127, 0.1472391917289594), 19: (1, 127, 0.14604417872651826), 20: (1, 127, 0.15006033892149295), 21: (1, 127, 0.14744682380504262), 22: (1, 127, 0.14946471422353363), 23: (1, 127, 0.1455458091337263), 24: (1, 127, 0.1459414631450974), 25: (1, 127, 0.15026979532650137), 26: (1, 127, 0.14810329762940097), 27: (1, 127, 0.14497899255297314), 28: (1, 127, 0.14501843872062098), 29: (1, 127, 0.1444929179948146), 30: (1, 127, 0.1443782950289489), 31: (1, 127, 0.14450115815362358), 32: (1, 127, 0.14462600151208913), 33: (1, 127, 0.14472781387194406), 34: (1, 127, 0.14452910017016835), 35: (1, 127, 0.14467727592376273), 36: (1, 127, 0.14455580651232108), 37: (1, 127, 0.14466858787212786), 38: (1, 127, 0.14483926682842999), 39: (1, 127, 0.1448380238647888), 40: (1, 127, 0.14475473517361354), 41: (1, 127, 0.14597347485062878), 42: (1, 127, 0.14545458728286226), 43: (1, 127, 0.14594558935876437), 44: (1, 127, 0.14684718886141), 45: (1, 127, 0.1468566188544739), 46: (1, 127, 0.14616949144956165), 47: (1, 127, 0.14531199717674198), 48: (1, 127, 0.14488855839567624), 49: (1, 127, 0.1446663041958424), 50: (1, 127, 0.14467273249224885), 51: (1, 127, 0.14461765708915125), 52: (1, 127, 0.14499683486752388), 53: (1, 127, 0.14484727433259328), 54: (1, 127, 0.14751167029993037), 55: (1, 127, 0.14744453613213668), 56: (1, 127, 0.14696377657324544), 57: (1, 127, 0.14764017597808848), 58: (1, 127, 0.1488489127006587), 59: (1, 127, 0.14527784963321733), 60: (1, 127, 0.14493685388042937), 61: (1, 127, 0.14452093104853875), 62: (1, 127, 0.14697507648604122), 63: (1, 127, 0.1470333415516249), 64: (1, 127, 0.14647176594099426), 65: (1, 127, 0.14655087147582704), 66: (1, 127, 0.14838098296088967), 67: (1, 127, 0.14719206838333232), 68: (1, 127, 0.1449053769300538), 69: (1, 127, 0.14614954637730215), 70: (1, 127, 0.14738333665245162)}\n",
      "{'predict_runtime': 1334.8007, 'predict_samples_per_second': 0.053, 'predict_steps_per_second': 0.053}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:14.80\n",
      "  predict_samples_per_second =      0.053\n",
      "  predict_steps_per_second   =      0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.290149980224669), 2: (2, 0.26685552205890417), 3: (2, 0.27947053499519825), 4: (2, 0.28250346798449755), 5: (2, 0.288328611291945), 6: (2, 0.3119004340842366), 7: (2, 0.2843033466488123), 8: (2, 0.2716617863625288), 9: (2, 0.2806291002780199), 10: (2, 0.26493673492223024), 11: (2, 0.26549464743584394), 12: (2, 0.2870817231014371), 13: (2, 0.272882959805429), 14: (2, 0.2847477002069354), 15: (2, 0.2781327171251178), 16: (2, 0.29290172550827265), 17: (2, 0.2727720309048891), 18: (2, 0.26807614509016275), 19: (2, 0.26999973226338625), 20: (2, 0.27489136438816786), 21: (2, 0.2841018168255687), 22: (2, 0.2870494620874524), 23: (2, 0.2756524095311761), 24: (2, 0.28647786285728216), 25: (2, 0.27097482420504093), 26: (2, 0.2641902333125472), 27: (2, 0.2845373749732971), 28: (2, 0.2658759346231818), 29: (2, 0.2735635032877326), 30: (2, 0.2738780090585351), 31: (2, 0.26419319305568933), 32: (2, 0.26416214276105165), 33: (2, 0.2813613712787628), 34: (2, 0.2826894158497453), 35: (2, 0.26196925807744265), 36: (2, 0.2778188409283757), 37: (2, 0.2925231587141752), 38: (2, 0.30276177916675806), 39: (2, 0.2886076048016548), 40: (2, 0.2678289581090212), 41: (2, 0.2965482510626316), 42: (2, 0.285717798396945), 43: (2, 0.28344971407204866), 44: (2, 0.28238469548523426), 45: (2, 0.26350007858127356), 46: (2, 0.2766309343278408), 47: (2, 0.26586459018290043), 48: (2, 0.27190967835485935), 49: (2, 0.26301215309649706), 50: (2, 0.28375437017530203), 51: (2, 0.26754255034029484), 52: (2, 0.26809485349804163), 53: (2, 0.29275382217019796), 54: (2, 0.26836160011589527), 55: (2, 0.2783626625314355), 56: (2, 0.2718925280496478), 57: (2, 0.2884633932262659), 58: (2, 0.26585901249200106), 59: (2, 0.26452915742993355), 60: (2, 0.2712890477851033), 61: (2, 0.2861433541402221), 62: (2, 0.268402760848403), 63: (2, 0.2811807319521904), 64: (2, 0.27109767962247133), 65: (2, 0.2824294865131378), 66: (2, 0.28245279751718044), 67: (2, 0.28446139208972454), 68: (2, 0.2850801954045892), 69: (2, 0.271334576420486), 70: (2, 0.2796120988205075), 71: (1, 0.2677534567192197)}\n",
      "{1: (2, 127, 0.22532417041462238), 2: (2, 127, 0.22501514144388474), 3: (2, 127, 0.22478714112309725), 4: (2, 127, 0.2241194547029344), 5: (2, 127, 0.22425754913898904), 6: (2, 127, 0.22460793637795243), 7: (2, 127, 0.22505308904017754), 8: (2, 127, 0.2239667596588806), 9: (2, 127, 0.22506333160852118), 10: (2, 127, 0.2252570812289757), 11: (2, 127, 0.22741349581189044), 12: (2, 127, 0.22408334959269038), 13: (2, 127, 0.22808506936714876), 14: (2, 127, 0.22789219755122042), 15: (2, 127, 0.22659266775283288), 16: (2, 127, 0.22611279913964938), 17: (2, 127, 0.22622461462261403), 18: (2, 127, 0.22435281100118254), 19: (2, 127, 0.2267757955953244), 20: (2, 127, 0.22434564766393403), 21: (2, 127, 0.2242224692095687), 22: (2, 127, 0.23029606484287368), 23: (2, 127, 0.22541286436268898), 24: (2, 127, 0.2270149133850153), 25: (2, 127, 0.2269429390384691), 26: (2, 127, 0.22697715571986174), 27: (2, 127, 0.22472674029285278), 28: (2, 127, 0.22409150089452587), 29: (2, 127, 0.22389733176825083), 30: (2, 127, 0.22385145782485721), 31: (2, 127, 0.22402006357644252), 32: (2, 127, 0.22432950870903928), 33: (2, 127, 0.22497043733697708), 34: (2, 127, 0.22370057736384116), 35: (2, 127, 0.2239550040873486), 36: (2, 127, 0.22664198999505814), 37: (2, 127, 0.22531586729254074), 38: (2, 127, 0.22747959208300733), 39: (2, 127, 0.224789388617134), 40: (2, 127, 0.2272044744005236), 41: (2, 127, 0.22469835436543611), 42: (2, 127, 0.22397988376126984), 43: (2, 127, 0.2242520902173843), 44: (2, 127, 0.22404722751330908), 45: (2, 127, 0.22615103315796672), 46: (2, 127, 0.2239946699151256), 47: (2, 127, 0.22390441335444375), 48: (2, 127, 0.22384570337333312), 49: (2, 127, 0.22745973484106655), 50: (2, 127, 0.22363285244420522), 51: (2, 127, 0.2243517143651843), 52: (2, 127, 0.22651524569721906), 53: (2, 127, 0.2273076204436384), 54: (2, 127, 0.22790915773462828), 55: (2, 127, 0.22748304104916459), 56: (2, 127, 0.2258241592033759), 57: (2, 127, 0.2245586424054006), 58: (2, 127, 0.22404910886557552), 59: (2, 127, 0.2238606007212377), 60: (2, 127, 0.22528105132340445), 61: (2, 127, 0.22435147884323842), 62: (2, 127, 0.22595569138657154), 63: (2, 127, 0.22350936263477003), 64: (2, 127, 0.22369700032983006), 65: (2, 127, 0.22369484299808506), 66: (2, 127, 0.22360717061555058), 67: (2, 127, 0.22362432510804708), 68: (2, 127, 0.22597668821534772), 69: (2, 127, 0.225538392895906), 70: (2, 127, 0.22626819322985692)}\n",
      "{'predict_runtime': 2041.0638, 'predict_samples_per_second': 0.069, 'predict_steps_per_second': 0.035}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:34:01.06\n",
      "  predict_samples_per_second =      0.069\n",
      "  predict_steps_per_second   =      0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.38118281960487366), 2: (4, 0.3474802430719137), 3: (4, 0.3434392912313342), 4: (4, 0.3441739222034812), 5: (4, 0.35010174196213484), 6: (4, 0.36748751904815435), 7: (4, 0.3425259608775377), 8: (4, 0.36579175759106874), 9: (4, 0.3843826912343502), 10: (4, 0.34365463722497225), 11: (4, 0.3627021638676524), 12: (4, 0.3431099820882082), 13: (4, 0.348035323433578), 14: (4, 0.3658413551747799), 15: (4, 0.3485545180737972), 16: (4, 0.3558129519224167), 17: (4, 0.3492808388546109), 18: (4, 0.34641184378415346), 19: (4, 0.3483136584982276), 20: (4, 0.34347405657172203), 21: (4, 0.3692392148077488), 22: (4, 0.347910082899034), 23: (4, 0.34834162797778845), 24: (4, 0.3464095713570714), 25: (4, 0.35441481694579124), 26: (4, 0.3494730945676565), 27: (4, 0.35237251967191696), 28: (4, 0.34726678021252155), 29: (4, 0.35241369903087616), 30: (4, 0.36665191128849983), 31: (4, 0.34702374041080475), 32: (4, 0.3453546417877078), 33: (4, 0.34925768431276083), 34: (4, 0.3487863792106509), 35: (4, 0.35399465821683407), 36: (4, 0.3495665602385998), 37: (4, 0.3490751162171364), 38: (4, 0.36319394037127495), 39: (4, 0.364478824660182), 40: (4, 0.3431374030187726), 41: (4, 0.34448776859790087), 42: (4, 0.34436635952442884), 43: (4, 0.3546250890940428), 44: (4, 0.3478288874030113), 45: (4, 0.3462401069700718), 46: (4, 0.3514916440472007), 47: (4, 0.3447810923680663), 48: (4, 0.353308011777699), 49: (4, 0.34342683758586645), 50: (4, 0.3446538234129548), 51: (4, 0.34126291144639254), 52: (4, 0.34436447639018297), 53: (4, 0.34164823684841394), 54: (4, 0.36500858422368765), 55: (4, 0.3408440565690398), 56: (4, 0.35110784508287907), 57: (4, 0.34733057860285044), 58: (4, 0.34330125618726015), 59: (4, 0.34205467998981476), 60: (4, 0.3445162810385227), 61: (4, 0.3430398879572749), 62: (4, 0.35122054163366556), 63: (4, 0.3435742361471057), 64: (4, 0.35650177486240864), 65: (4, 0.3488033339381218), 66: (4, 0.35379145480692387), 67: (4, 0.35370955523103476), 68: (4, 0.38008307944983244), 69: (4, 0.35486429184675217), 70: (4, 0.35437254700809717), 71: (1, 0.24991110153496265)}\n",
      "{1: (4, 127, 0.22994190608481252), 2: (4, 127, 0.22622790620258942), 3: (4, 127, 0.22495595830690673), 4: (4, 127, 0.22536690709892454), 5: (4, 127, 0.22483886751221624), 6: (4, 127, 0.22481129380075013), 7: (4, 127, 0.22461103597347895), 8: (4, 127, 0.2245001648882712), 9: (4, 127, 0.2278514084017535), 10: (4, 127, 0.22579739864651613), 11: (4, 127, 0.2267502908646239), 12: (4, 127, 0.22850398701710964), 13: (4, 127, 0.22702437708902312), 14: (4, 127, 0.2272867076978909), 15: (4, 127, 0.2258970312935513), 16: (4, 127, 0.2254476577234198), 17: (4, 127, 0.22748798129742775), 18: (4, 127, 0.22479094871444497), 19: (4, 127, 0.22426533322106665), 20: (4, 127, 0.2300477205064353), 21: (4, 127, 0.22771945478409295), 22: (4, 127, 0.22625320497166923), 23: (4, 127, 0.23128217639856216), 24: (4, 127, 0.22879990768127553), 25: (4, 127, 0.22440857274501813), 26: (4, 127, 0.22724671215992273), 27: (4, 127, 0.22900364550901212), 28: (4, 127, 0.22703859551010405), 29: (4, 127, 0.22423257691947024), 30: (4, 127, 0.22479062765015392), 31: (4, 127, 0.22390404807066355), 32: (4, 127, 0.22418694083732882), 33: (4, 127, 0.22706355453710855), 34: (4, 127, 0.22536995949032973), 35: (4, 127, 0.22590510869090716), 36: (4, 127, 0.22559760913516827), 37: (4, 127, 0.2244117114120933), 38: (4, 127, 0.22427176504476568), 39: (4, 127, 0.22420630172833683), 40: (4, 127, 0.22425913892862365), 41: (4, 127, 0.22423435505626238), 42: (4, 127, 0.2251523595567294), 43: (4, 127, 0.22412573228641522), 44: (4, 127, 0.2259989003467513), 45: (4, 127, 0.22457346914878745), 46: (4, 127, 0.22478994666268742), 47: (4, 127, 0.22775212381269752), 48: (4, 127, 0.2256843603516775), 49: (4, 127, 0.22453723347738502), 50: (4, 127, 0.22430799603022225), 51: (4, 127, 0.22507088809589468), 52: (4, 127, 0.22439533846056836), 53: (4, 127, 0.224293054506828), 54: (4, 127, 0.22405217846078196), 55: (4, 127, 0.22563730036531846), 56: (4, 127, 0.2251002766177293), 57: (4, 127, 0.22365543276335545), 58: (4, 127, 0.2291920165876), 59: (4, 127, 0.2237897491610543), 60: (4, 127, 0.2267201440702156), 61: (4, 127, 0.22788676282933612), 62: (4, 127, 0.2246043272609786), 63: (4, 127, 0.22444291815425702), 64: (4, 127, 0.22430218406402924), 65: (4, 127, 0.22505480575367925), 66: (4, 127, 0.22774610265825443), 67: (4, 127, 0.22647378385418981), 68: (4, 127, 0.22851627154319776), 69: (4, 127, 0.22441528306349995), 70: (4, 127, 0.2270899371676675)}\n",
      "{'predict_runtime': 2051.1092, 'predict_samples_per_second': 0.137, 'predict_steps_per_second': 0.035}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:34:11.10\n",
      "  predict_samples_per_second =      0.137\n",
      "  predict_steps_per_second   =      0.035\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 28\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.28844601288437843), 2: (1, 0.2531816940754652), 3: (1, 0.2611149111762643), 4: (1, 0.25539037771523), 5: (1, 0.2538241045549512), 6: (1, 0.25772146973758936), 7: (1, 0.2537653250619769), 8: (1, 0.2537268055602908), 9: (1, 0.2548344526439905), 10: (1, 0.249592874199152), 11: (1, 0.2504806127399206), 12: (1, 0.25185033865273), 13: (1, 0.2510857442393899), 14: (1, 0.2493466855958104), 15: (1, 0.25713466480374336), 16: (1, 0.25037611462175846), 17: (1, 0.24911961797624826), 18: (1, 0.2504702415317297), 19: (1, 0.2583864191547036), 20: (1, 0.25136744044721127), 21: (1, 0.25373956374824047), 22: (1, 0.2548947399482131), 23: (1, 0.2531835902482271), 24: (1, 0.2495862813666463), 25: (1, 0.25198308285325766), 26: (1, 0.2690121941268444), 27: (1, 0.26065809186547995), 28: (1, 0.25969779305160046), 29: (1, 0.2740390654653311), 30: (1, 0.25640367064625025), 31: (1, 0.2548988973721862), 32: (1, 0.25204028096050024), 33: (1, 0.25057524628937244), 34: (1, 0.2541429065167904), 35: (1, 0.2544083232060075), 36: (1, 0.24974481761455536), 37: (1, 0.25009014271199703), 38: (1, 0.25247206445783377), 39: (1, 0.2515572551637888), 40: (1, 0.25191669166088104), 41: (1, 0.2503847675397992), 42: (1, 0.25312347523868084), 43: (1, 0.2611870924010873), 44: (1, 0.24970506597310305), 45: (1, 0.2630317797884345), 46: (1, 0.25126196816563606), 47: (1, 0.25505410321056843), 48: (1, 0.2489410536363721), 49: (1, 0.2494757380336523), 50: (1, 0.24931094888597727), 51: (1, 0.2549732644110918), 52: (1, 0.2533390112221241), 53: (1, 0.2539843637496233), 54: (1, 0.2525719814002514), 55: (1, 0.25529299955815077), 56: (1, 0.25477020535618067), 57: (1, 0.2509852387011051), 58: (1, 0.2522751232609153), 59: (1, 0.2576030306518078), 60: (1, 0.24928535893559456), 61: (1, 0.25039187353104353), 62: (1, 0.2504085125401616), 63: (1, 0.24957773182541132), 64: (1, 0.2508096480742097), 65: (1, 0.26167287211865187), 66: (1, 0.2586054755374789), 67: (1, 0.2534387372434139), 68: (1, 0.25252047739923), 69: (1, 0.2536904439330101), 70: (1, 0.26474376395344734), 71: (1, 0.25468507036566734)}\n",
      "{1: (1, 127, 0.1517192882698352), 2: (1, 127, 0.15143255470687245), 3: (1, 127, 0.15251035455936993), 4: (1, 127, 0.1524340624107033), 5: (1, 127, 0.15030806736037958), 6: (1, 127, 0.15234084435423292), 7: (1, 127, 0.15101442873243273), 8: (1, 127, 0.1496336294895434), 9: (1, 127, 0.14995181071388675), 10: (1, 127, 0.14975061347546775), 11: (1, 127, 0.14947223251201505), 12: (1, 127, 0.14981486203192962), 13: (1, 127, 0.14978765145560183), 14: (1, 127, 0.15030357067832562), 15: (1, 127, 0.1498212130212291), 16: (1, 127, 0.1498995896384824), 17: (1, 127, 0.15095141413438273), 18: (1, 127, 0.1507161729785753), 19: (1, 127, 0.1506620793141366), 20: (1, 127, 0.15025506158337348), 21: (1, 127, 0.1503528241933448), 22: (1, 127, 0.14984855223740415), 23: (1, 127, 0.14985700415110026), 24: (1, 127, 0.14988971705453133), 25: (1, 127, 0.15054769675416035), 26: (1, 127, 0.15521241668025104), 27: (1, 127, 0.1523494086792971), 28: (1, 127, 0.15195551236695426), 29: (1, 127, 0.15239564855179683), 30: (1, 127, 0.14952944453043027), 31: (1, 127, 0.14929743280531618), 32: (1, 127, 0.1500436241672499), 33: (1, 127, 0.1492890399462712), 34: (1, 127, 0.1497161983930337), 35: (1, 127, 0.14949556511247486), 36: (1, 127, 0.14936076193373268), 37: (1, 127, 0.14941352004493316), 38: (1, 127, 0.14981403960076373), 39: (1, 127, 0.14977298698234043), 40: (1, 127, 0.14962520325688397), 41: (1, 127, 0.14957801906729307), 42: (1, 127, 0.1505603100224508), 43: (1, 127, 0.14978557225962089), 44: (1, 127, 0.1515028973249352), 45: (1, 127, 0.1495719910855955), 46: (1, 127, 0.1492349768981455), 47: (1, 127, 0.14927589190815846), 48: (1, 127, 0.14918991336672324), 49: (1, 127, 0.14935320239572777), 50: (1, 127, 0.1494685255915044), 51: (1, 127, 0.14956379477961326), 52: (1, 127, 0.14956802881403466), 53: (1, 127, 0.15030751015814975), 54: (1, 127, 0.15137434429599075), 55: (1, 127, 0.1509003672074145), 56: (1, 127, 0.15041595041810527), 57: (1, 127, 0.1497922717762275), 58: (1, 127, 0.15044652672821845), 59: (1, 127, 0.1502219116916572), 60: (1, 127, 0.14974089084178444), 61: (1, 127, 0.14974365370186765), 62: (1, 127, 0.15168223728051805), 63: (1, 127, 0.1490774388007057), 64: (1, 127, 0.15541604087930025), 65: (1, 127, 0.15119440039605136), 66: (1, 127, 0.15295508083718734), 67: (1, 127, 0.15595749526570632), 68: (1, 127, 0.15086088132289216), 69: (1, 127, 0.15287872641457348), 70: (1, 127, 0.14945740012202677)}\n",
      "{'predict_runtime': 1375.8239, 'predict_samples_per_second': 0.052, 'predict_steps_per_second': 0.052}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:55.82\n",
      "  predict_samples_per_second =      0.052\n",
      "  predict_steps_per_second   =      0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.30261226277798414), 2: (2, 0.2731998860836029), 3: (2, 0.2841692380607128), 4: (2, 0.28199402149766684), 5: (2, 0.2715186132118106), 6: (2, 0.27295788563787937), 7: (2, 0.27434470131993294), 8: (2, 0.294744523242116), 9: (2, 0.2907644882798195), 10: (2, 0.29221360106021166), 11: (2, 0.2950114496052265), 12: (2, 0.2747174818068743), 13: (2, 0.2712650718167424), 14: (2, 0.2726838244125247), 15: (2, 0.2931203870102763), 16: (2, 0.2933396240696311), 17: (2, 0.2919044606387615), 18: (2, 0.2942831013351679), 19: (2, 0.2913813553750515), 20: (2, 0.27289417013525963), 21: (2, 0.2831004913896322), 22: (2, 0.29300326481461525), 23: (2, 0.29115791618824005), 24: (2, 0.2967207711189985), 25: (2, 0.29235671181231737), 26: (2, 0.2721377471461892), 27: (2, 0.27148770447820425), 28: (2, 0.2925451984629035), 29: (2, 0.2940069315955043), 30: (2, 0.2829277105629444), 31: (2, 0.29355588648468256), 32: (2, 0.29116933327168226), 33: (2, 0.29412885941565037), 34: (2, 0.2756000952795148), 35: (2, 0.2933263974264264), 36: (2, 0.29245177656412125), 37: (2, 0.2945949723944068), 38: (2, 0.2731606224551797), 39: (2, 0.29182763397693634), 40: (2, 0.2732735900208354), 41: (2, 0.27205251436680555), 42: (2, 0.2924267556518316), 43: (2, 0.29383374005556107), 44: (2, 0.29159661661833525), 45: (2, 0.2964044287800789), 46: (2, 0.2905922159552574), 47: (2, 0.2935370812192559), 48: (2, 0.2903798772022128), 49: (2, 0.293339254334569), 50: (2, 0.29459643829613924), 51: (2, 0.29213146679103374), 52: (2, 0.29435453098267317), 53: (2, 0.28366414457559586), 54: (2, 0.293917965143919), 55: (2, 0.29087863117456436), 56: (2, 0.2913375850766897), 57: (2, 0.2917788000777364), 58: (2, 0.2766881864517927), 59: (2, 0.294865183532238), 60: (2, 0.2921671150252223), 61: (2, 0.29419371113181114), 62: (2, 0.2916366197168827), 63: (2, 0.2952862670645118), 64: (2, 0.29198034573346376), 65: (2, 0.29407143220305443), 66: (2, 0.291307782754302), 67: (2, 0.28564182855188847), 68: (2, 0.29310569167137146), 69: (2, 0.2772877858951688), 70: (2, 0.29194624442607164), 71: (1, 0.2707817004993558)}\n",
      "{1: (2, 127, 0.23124992568045855), 2: (2, 127, 0.23152218291198645), 3: (2, 127, 0.2313995207183239), 4: (2, 127, 0.23068708562710155), 5: (2, 127, 0.23118459065188104), 6: (2, 127, 0.2310703267072012), 7: (2, 127, 0.2307000911801936), 8: (2, 127, 0.23070392776720636), 9: (2, 127, 0.23085806805523126), 10: (2, 127, 0.23080666968965624), 11: (2, 127, 0.2308944245419047), 12: (2, 127, 0.2309257030325729), 13: (2, 127, 0.2308437250569228), 14: (2, 127, 0.23089810534871705), 15: (2, 127, 0.2310229640923382), 16: (2, 127, 0.23090109430752168), 17: (2, 127, 0.2308918968297717), 18: (2, 127, 0.23081388937558714), 19: (2, 127, 0.23099089508480208), 20: (2, 127, 0.23085515901417009), 21: (2, 127, 0.23083017936607045), 22: (2, 127, 0.23090723680522968), 23: (2, 127, 0.2306357226297846), 24: (2, 127, 0.23083420817952927), 25: (2, 127, 0.23080228594696428), 26: (2, 127, 0.2309699325682962), 27: (2, 127, 0.23075206887240954), 28: (2, 127, 0.2307552600235451), 29: (2, 127, 0.23076758514649756), 30: (2, 127, 0.230815829701839), 31: (2, 127, 0.23082276529038515), 32: (2, 127, 0.23066149213475975), 33: (2, 127, 0.2309504418421214), 34: (2, 127, 0.23092750904304304), 35: (2, 127, 0.2308183856836454), 36: (2, 127, 0.2307699877534091), 37: (2, 127, 0.2308288523487336), 38: (2, 127, 0.23079259861553983), 39: (2, 127, 0.23082722964014593), 40: (2, 127, 0.23096320374069487), 41: (2, 127, 0.2307468985654707), 42: (2, 127, 0.23083933671628395), 43: (2, 127, 0.2308043708408794), 44: (2, 127, 0.23095895032449734), 45: (2, 127, 0.23091188310022195), 46: (2, 127, 0.23086233859456431), 47: (2, 127, 0.2310704743841619), 48: (2, 127, 0.23072814722142115), 49: (2, 127, 0.23087237469529306), 50: (2, 127, 0.230750348682948), 51: (2, 127, 0.23075428834610331), 52: (2, 127, 0.23091953266852014), 53: (2, 127, 0.2308135606480513), 54: (2, 127, 0.2309580263865041), 55: (2, 127, 0.23078341650094572), 56: (2, 127, 0.2308633741812678), 57: (2, 127, 0.23092892370003415), 58: (2, 127, 0.23099837898768075), 59: (2, 127, 0.2308216008658367), 60: (2, 127, 0.23078482141204942), 61: (2, 127, 0.2308995799696821), 62: (2, 127, 0.23088930274440547), 63: (2, 127, 0.23075353460547726), 64: (2, 127, 0.23075067468984858), 65: (2, 127, 0.23091020106565296), 66: (2, 127, 0.2308228701851734), 67: (2, 127, 0.23093270374770006), 68: (2, 127, 0.23107370168821315), 69: (2, 127, 0.23074179609841483), 70: (2, 127, 0.23144386324474192)}\n",
      "{'predict_runtime': 2091.9937, 'predict_samples_per_second': 0.067, 'predict_steps_per_second': 0.034}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:34:51.99\n",
      "  predict_samples_per_second =      0.067\n",
      "  predict_steps_per_second   =      0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3832904323935509), 2: (4, 0.35403023567050695), 3: (4, 0.3575170040130615), 4: (4, 0.3524465346708894), 5: (4, 0.35415588319301605), 6: (4, 0.354504119604826), 7: (4, 0.36471423879265785), 8: (4, 0.35670422203838825), 9: (4, 0.3531464943662286), 10: (4, 0.3604311989620328), 11: (4, 0.36030268017202616), 12: (4, 0.35743845254182816), 13: (4, 0.35771602019667625), 14: (4, 0.35486423317342997), 15: (4, 0.36527393106371164), 16: (4, 0.356775039806962), 17: (4, 0.3584854807704687), 18: (4, 0.3536704257130623), 19: (4, 0.3610854698345065), 20: (4, 0.3579431548714638), 21: (4, 0.35898401215672493), 22: (4, 0.3568044984713197), 23: (4, 0.35466139297932386), 24: (4, 0.3554508136585355), 25: (4, 0.3518685959279537), 26: (4, 0.3586735464632511), 27: (4, 0.3619431871920824), 28: (4, 0.35668868850916624), 29: (4, 0.35541783180087805), 30: (4, 0.36094002425670624), 31: (4, 0.3616243163123727), 32: (4, 0.3582517337054014), 33: (4, 0.35362611897289753), 34: (4, 0.3578242789953947), 35: (4, 0.35361687932163477), 36: (4, 0.3521721549332142), 37: (4, 0.3559799809008837), 38: (4, 0.3540245536714792), 39: (4, 0.3527721669524908), 40: (4, 0.3559056604281068), 41: (4, 0.3529381062835455), 42: (4, 0.36212997790426016), 43: (4, 0.3563845045864582), 44: (4, 0.36027725879102945), 45: (4, 0.35498744063079357), 46: (4, 0.35784850735217333), 47: (4, 0.3565189829096198), 48: (4, 0.35618986655026674), 49: (4, 0.35787700675427914), 50: (4, 0.35994302202016115), 51: (4, 0.36556920502334833), 52: (4, 0.3644196391105652), 53: (4, 0.35529351606965065), 54: (4, 0.3533158488571644), 55: (4, 0.3549136705696583), 56: (4, 0.3586328364908695), 57: (4, 0.35656378138810396), 58: (4, 0.3675731709226966), 59: (4, 0.36226507369428873), 60: (4, 0.3577700052410364), 61: (4, 0.3594787549227476), 62: (4, 0.3556099720299244), 63: (4, 0.3571496829390526), 64: (4, 0.35547014232724905), 65: (4, 0.3722036452963948), 66: (4, 0.35548144206404686), 67: (4, 0.3565952992066741), 68: (4, 0.4077978665009141), 69: (4, 0.3602689355611801), 70: (4, 0.3515349579975009), 71: (1, 0.2549115242436528)}\n",
      "{1: (4, 127, 0.2331388920809575), 2: (4, 127, 0.23152471814069928), 3: (4, 127, 0.23158419697626134), 4: (4, 127, 0.23144232249254082), 5: (4, 127, 0.23144880801028622), 6: (4, 127, 0.23139432463501616), 7: (4, 127, 0.23137852514353324), 8: (4, 127, 0.23200827313396405), 9: (4, 127, 0.23458486153766162), 10: (4, 127, 0.2386511152492851), 11: (4, 127, 0.23423263243597559), 12: (4, 127, 0.2331304441785484), 13: (4, 127, 0.23509653903338618), 14: (4, 127, 0.23768929038636796), 15: (4, 127, 0.23590770528072447), 16: (4, 127, 0.23594389014738046), 17: (4, 127, 0.2330951987303735), 18: (4, 127, 0.2369644234074265), 19: (4, 127, 0.2367824737393246), 20: (4, 127, 0.23397948471902627), 21: (4, 127, 0.23477939086577554), 22: (4, 127, 0.23271852905502705), 23: (4, 127, 0.232901207244713), 24: (4, 127, 0.23305697890922544), 25: (4, 127, 0.23277348247686708), 26: (4, 127, 0.23224508808559086), 27: (4, 127, 0.2321234362155903), 28: (4, 127, 0.23284314119616362), 29: (4, 127, 0.2354960953303444), 30: (4, 127, 0.23418193328098988), 31: (4, 127, 0.23380564500057088), 32: (4, 127, 0.2330326617688058), 33: (4, 127, 0.23343953128728107), 34: (4, 127, 0.23242311697365262), 35: (4, 127, 0.23272640189874594), 36: (4, 127, 0.23204182904565662), 37: (4, 127, 0.23225412534652498), 38: (4, 127, 0.2344793111716551), 39: (4, 127, 0.23251008191035957), 40: (4, 127, 0.23203442621184148), 41: (4, 127, 0.2341874248428842), 42: (4, 127, 0.23264520041879236), 43: (4, 127, 0.23260575479380494), 44: (4, 127, 0.23274994324746096), 45: (4, 127, 0.2329644592200208), 46: (4, 127, 0.23189860982013735), 47: (4, 127, 0.23209845312819707), 48: (4, 127, 0.23347243855113353), 49: (4, 127, 0.23290241223679284), 50: (4, 127, 0.2326765622151649), 51: (4, 127, 0.23452042171540927), 52: (4, 127, 0.23563175328721211), 53: (4, 127, 0.23218558557830224), 54: (4, 127, 0.23187275199351584), 55: (4, 127, 0.23381544600468218), 56: (4, 127, 0.23251935296259293), 57: (4, 127, 0.23373531188639834), 58: (4, 127, 0.23445168898008237), 59: (4, 127, 0.23569109685367018), 60: (4, 127, 0.2328643369099756), 61: (4, 127, 0.23292909322057184), 62: (4, 127, 0.23451758021356786), 63: (4, 127, 0.23299635045494385), 64: (4, 127, 0.23383324833102817), 65: (4, 127, 0.2335004880657698), 66: (4, 127, 0.23472852346406678), 67: (4, 127, 0.23306869391322604), 68: (4, 127, 0.23868269399981798), 69: (4, 127, 0.2320261697072213), 70: (4, 127, 0.23423000214636092)}\n",
      "{'predict_runtime': 2120.6196, 'predict_samples_per_second': 0.133, 'predict_steps_per_second': 0.033}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:35:20.61\n",
      "  predict_samples_per_second =      0.133\n",
      "  predict_steps_per_second   =      0.033\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 29\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.40023650135844946), 2: (1, 0.24828640557825565), 3: (1, 0.24439797271043062), 4: (1, 0.2463238900527358), 5: (1, 0.2465179581195116), 6: (1, 0.24523237626999617), 7: (1, 0.24402672052383423), 8: (1, 0.24461187422275543), 9: (1, 0.24672515969723463), 10: (1, 0.24797633476555347), 11: (1, 0.24248880986124277), 12: (1, 0.24471038486808538), 13: (1, 0.24311070423573256), 14: (1, 0.24883175641298294), 15: (1, 0.24406199343502522), 16: (1, 0.2435995489358902), 17: (1, 0.24665401224046946), 18: (1, 0.24521240033209324), 19: (1, 0.2442749422043562), 20: (1, 0.2457781843841076), 21: (1, 0.24653359595686197), 22: (1, 0.24327418394386768), 23: (1, 0.24393509700894356), 24: (1, 0.24322257563471794), 25: (1, 0.24342320300638676), 26: (1, 0.24740316718816757), 27: (1, 0.24276734236627817), 28: (1, 0.24619867093861103), 29: (1, 0.2455182485282421), 30: (1, 0.24621196184307337), 31: (1, 0.2434229962527752), 32: (1, 0.24726162012666464), 33: (1, 0.2465388085693121), 34: (1, 0.24535698257386684), 35: (1, 0.24621957633644342), 36: (1, 0.2420806959271431), 37: (1, 0.24652976263314486), 38: (1, 0.2430418049916625), 39: (1, 0.24619951751083136), 40: (1, 0.24387650471180677), 41: (1, 0.2446901872754097), 42: (1, 0.24851754121482372), 43: (1, 0.2428522789850831), 44: (1, 0.2556013483554125), 45: (1, 0.24684718251228333), 46: (1, 0.2454338287934661), 47: (1, 0.24605461210012436), 48: (1, 0.2438228176906705), 49: (1, 0.24387894757092), 50: (1, 0.24517231155186892), 51: (1, 0.2529516201466322), 52: (1, 0.24321545660495758), 53: (1, 0.24430458340793848), 54: (1, 0.24365471210330725), 55: (1, 0.26041874289512634), 56: (1, 0.24443455319851637), 57: (1, 0.24333497509360313), 58: (1, 0.24597349390387535), 59: (1, 0.24492158740758896), 60: (1, 0.2444899119436741), 61: (1, 0.2446307512000203), 62: (1, 0.2458514366298914), 63: (1, 0.2464020298793912), 64: (1, 0.2437157928943634), 65: (1, 0.24590359721332788), 66: (1, 0.24285298213362694), 67: (1, 0.2448656288906932), 68: (1, 0.24436365440487862), 69: (1, 0.24592876620590687), 70: (1, 0.24547795113176107), 71: (1, 0.24384112004190683)}\n",
      "{1: (1, 255, 0.1461746853356268), 2: (1, 255, 0.14548807223418764), 3: (1, 255, 0.14678127384726322), 4: (1, 255, 0.1465040094529589), 5: (1, 255, 0.14559048588077228), 6: (1, 255, 0.14534272993823477), 7: (1, 255, 0.14533007559823055), 8: (1, 255, 0.14572845713472835), 9: (1, 255, 0.14505966464970627), 10: (1, 255, 0.14510141051940473), 11: (1, 255, 0.14529169488552154), 12: (1, 255, 0.1454106857890592), 13: (1, 255, 0.14516918341464857), 14: (1, 255, 0.14526557686063005), 15: (1, 255, 0.1449091263188451), 16: (1, 255, 0.14496866687036614), 17: (1, 255, 0.14480982966282788), 18: (1, 255, 0.14459515942589324), 19: (1, 255, 0.14457206506939496), 20: (1, 255, 0.14468698423794088), 21: (1, 255, 0.14473051649390484), 22: (1, 255, 0.14497963658296595), 23: (1, 255, 0.14466117121936645), 24: (1, 255, 0.14480250944547793), 25: (1, 255, 0.14482465379086196), 26: (1, 255, 0.1450623777676739), 27: (1, 255, 0.14498025335225403), 28: (1, 255, 0.14493297848704398), 29: (1, 255, 0.144978805956449), 30: (1, 255, 0.14512924700610194), 31: (1, 255, 0.14516847404267857), 32: (1, 255, 0.1453095757092039), 33: (1, 255, 0.14562894965284595), 34: (1, 255, 0.14510069124254527), 35: (1, 255, 0.1449772807239902), 36: (1, 255, 0.14541697102580584), 37: (1, 255, 0.14532430026607185), 38: (1, 255, 0.1454673897292392), 39: (1, 255, 0.14523443757538118), 40: (1, 255, 0.14507762722159717), 41: (1, 255, 0.14496396532757025), 42: (1, 255, 0.1453875395012837), 43: (1, 255, 0.14528350298311196), 44: (1, 255, 0.14514096104631238), 45: (1, 255, 0.14500699641511722), 46: (1, 255, 0.1452469773444475), 47: (1, 255, 0.14759390932672165), 48: (1, 255, 0.14494924298396297), 49: (1, 255, 0.14524696479533233), 50: (1, 255, 0.1450536065899274), 51: (1, 255, 0.14508563954675313), 52: (1, 255, 0.14519614369115408), 53: (1, 255, 0.14519857233572825), 54: (1, 255, 0.14507691327336372), 55: (1, 255, 0.14529362607601226), 56: (1, 255, 0.14579725266598603), 57: (1, 255, 0.14531698330287254), 58: (1, 255, 0.1452007143228662), 59: (1, 255, 0.1451898875080195), 60: (1, 255, 0.1452591000197857), 61: (1, 255, 0.14688782263912406), 62: (1, 255, 0.14615476320260296), 63: (1, 255, 0.14529723115630594), 64: (1, 255, 0.14523052855887833), 65: (1, 255, 0.14524734737899372), 66: (1, 255, 0.14533400443181688), 67: (1, 255, 0.1452465018440111), 68: (1, 255, 0.14526707633380212), 69: (1, 255, 0.1453394256020878), 70: (1, 255, 0.14540033107440845)}\n",
      "{'predict_runtime': 2648.17, 'predict_samples_per_second': 0.027, 'predict_steps_per_second': 0.027}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:44:08.17\n",
      "  predict_samples_per_second =      0.027\n",
      "  predict_steps_per_second   =      0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.3012491362169385), 2: (2, 0.2694693887606263), 3: (2, 0.28037581127136946), 4: (2, 0.2657011142000556), 5: (2, 0.26357956789433956), 6: (2, 0.2660533497110009), 7: (2, 0.2891714181751013), 8: (2, 0.2892042938619852), 9: (2, 0.2772567244246602), 10: (2, 0.3116792906075716), 11: (2, 0.2837429875507951), 12: (2, 0.2805324951186776), 13: (2, 0.26418387424200773), 14: (2, 0.26251991372555494), 15: (2, 0.28055144380778074), 16: (2, 0.26398329716175795), 17: (2, 0.2674431065097451), 18: (2, 0.2685995614156127), 19: (2, 0.2931615049019456), 20: (2, 0.31757323909550905), 21: (2, 0.2777026351541281), 22: (2, 0.2702865693718195), 23: (2, 0.27352188248187304), 24: (2, 0.2714092768728733), 25: (2, 0.29141598381102085), 26: (2, 0.2671651756390929), 27: (2, 0.30684174224734306), 28: (2, 0.26224443409591913), 29: (2, 0.26789319701492786), 30: (2, 0.2764763869345188), 31: (2, 0.31196792237460613), 32: (2, 0.2953928345814347), 33: (2, 0.2683283220976591), 34: (2, 0.26641610264778137), 35: (2, 0.31157813407480717), 36: (2, 0.3052417794242501), 37: (2, 0.3004255946725607), 38: (2, 0.31004127115011215), 39: (2, 0.28057706635445356), 40: (2, 0.27286646608263254), 41: (2, 0.3136327797546983), 42: (2, 0.26563462149351835), 43: (2, 0.27784399688243866), 44: (2, 0.313001767732203), 45: (2, 0.2718424228951335), 46: (2, 0.3154687788337469), 47: (2, 0.2724419152364135), 48: (2, 0.2652771370485425), 49: (2, 0.29204045701771975), 50: (2, 0.31242839992046356), 51: (2, 0.31927050091326237), 52: (2, 0.269411226734519), 53: (2, 0.27143731340765953), 54: (2, 0.265332474373281), 55: (2, 0.28402321692556143), 56: (2, 0.2672350099310279), 57: (2, 0.2823682650923729), 58: (2, 0.3160565346479416), 59: (2, 0.2720529930666089), 60: (2, 0.3115945355966687), 61: (2, 0.29501062631607056), 62: (2, 0.27012641355395317), 63: (2, 0.28968378715217113), 64: (2, 0.3057281235232949), 65: (2, 0.2723733549937606), 66: (2, 0.26434652507305145), 67: (2, 0.31644149776548147), 68: (2, 0.30875358544290066), 69: (2, 0.29806773643940687), 70: (2, 0.3045659316703677), 71: (1, 0.28292203787714243)}\n",
      "{1: (2, 255, 0.2261448518537423), 2: (2, 255, 0.22477824757350426), 3: (2, 255, 0.22460033367296645), 4: (2, 255, 0.22474541076477253), 5: (2, 255, 0.22471241053632077), 6: (2, 255, 0.22452791432539623), 7: (2, 255, 0.22410836855278296), 8: (2, 255, 0.22390421171690902), 9: (2, 255, 0.22397480312661797), 10: (2, 255, 0.22393396991652018), 11: (2, 255, 0.22397817410893883), 12: (2, 255, 0.2240421657213101), 13: (2, 255, 0.22394064986238293), 14: (2, 255, 0.22389660560544214), 15: (2, 255, 0.2240348869459886), 16: (2, 255, 0.2238527348593754), 17: (2, 255, 0.2238912490287832), 18: (2, 255, 0.2237039263816733), 19: (2, 255, 0.2237509680619719), 20: (2, 255, 0.22366910058566752), 21: (2, 255, 0.22393893912142399), 22: (2, 255, 0.2239151158717041), 23: (2, 255, 0.22394456235947563), 24: (2, 255, 0.2244707399358352), 25: (2, 255, 0.22450506535596124), 26: (2, 255, 0.2237213481400235), 27: (2, 255, 0.22380852897961934), 28: (2, 255, 0.22383676679695355), 29: (2, 255, 0.22377638858103868), 30: (2, 255, 0.22371349259845766), 31: (2, 255, 0.22368349784291258), 32: (2, 255, 0.22376441904800196), 33: (2, 255, 0.2239008634917292), 34: (2, 255, 0.22363332140752498), 35: (2, 255, 0.22370412152114452), 36: (2, 255, 0.22363788649512856), 37: (2, 255, 0.2236693032378075), 38: (2, 255, 0.22383311681960727), 39: (2, 255, 0.2238681257209357), 40: (2, 255, 0.22360428058560572), 41: (2, 255, 0.22418510093919786), 42: (2, 255, 0.22423387231195674), 43: (2, 255, 0.22374870269468017), 44: (2, 255, 0.2237559638807879), 45: (2, 255, 0.22389781884849072), 46: (2, 255, 0.22368736923033117), 47: (2, 255, 0.22381512758997726), 48: (2, 255, 0.22367802803934206), 49: (2, 255, 0.22358781419256155), 50: (2, 255, 0.22340086965876468), 51: (2, 255, 0.22373561259432168), 52: (2, 255, 0.22365866440403112), 53: (2, 255, 0.22367461436957706), 54: (2, 255, 0.22368423444967644), 55: (2, 255, 0.22380133239808037), 56: (2, 255, 0.22363326500955166), 57: (2, 255, 0.22368668978120768), 58: (2, 255, 0.2237437934121665), 59: (2, 255, 0.22374167522671176), 60: (2, 255, 0.22340580035439309), 61: (2, 255, 0.2236263592855311), 62: (2, 255, 0.2235871158321114), 63: (2, 255, 0.22330675445789216), 64: (2, 255, 0.22358577237921018), 65: (2, 255, 0.22374978034446638), 66: (2, 255, 0.2233261287942821), 67: (2, 255, 0.22351382611063766), 68: (2, 255, 0.22333857464220594), 69: (2, 255, 0.22341634696532114), 70: (2, 255, 0.2235881334243744)}\n",
      "{'predict_runtime': 4053.1574, 'predict_samples_per_second': 0.035, 'predict_steps_per_second': 0.018}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:07:33.15\n",
      "  predict_samples_per_second =      0.035\n",
      "  predict_steps_per_second   =      0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.37770435214042664), 2: (4, 0.3466687658801675), 3: (4, 0.3547261329367757), 4: (4, 0.3443750599399209), 5: (4, 0.3598593110218644), 6: (4, 0.346417305059731), 7: (4, 0.34646278340369463), 8: (4, 0.3456671517342329), 9: (4, 0.3585778530687094), 10: (4, 0.34407246299088), 11: (4, 0.3581211110576987), 12: (4, 0.3496766574680805), 13: (4, 0.34533535595983267), 14: (4, 0.34394012950360775), 15: (4, 0.34560594893991947), 16: (4, 0.343557202257216), 17: (4, 0.34821584913879633), 18: (4, 0.34346606209874153), 19: (4, 0.3458759030327201), 20: (4, 0.3432742627337575), 21: (4, 0.34727830439805984), 22: (4, 0.34434505738317966), 23: (4, 0.34745231084525585), 24: (4, 0.3488972932100296), 25: (4, 0.3444454735144973), 26: (4, 0.34723220113664865), 27: (4, 0.36554785910993814), 28: (4, 0.34511399269104004), 29: (4, 0.3455865066498518), 30: (4, 0.3448562938719988), 31: (4, 0.34800136741250753), 32: (4, 0.3470027083531022), 33: (4, 0.34294524416327477), 34: (4, 0.3474484411999583), 35: (4, 0.34742586128413677), 36: (4, 0.3497224831953645), 37: (4, 0.3443337753415108), 38: (4, 0.3588620563969016), 39: (4, 0.3452907521277666), 40: (4, 0.34666627552360296), 41: (4, 0.34482670575380325), 42: (4, 0.3446150878444314), 43: (4, 0.3485892806202173), 44: (4, 0.3428076272830367), 45: (4, 0.34337950963526964), 46: (4, 0.3463605949655175), 47: (4, 0.34678935445845127), 48: (4, 0.3461850620806217), 49: (4, 0.34481336548924446), 50: (4, 0.3420436764135957), 51: (4, 0.34612960927188396), 52: (4, 0.35071937553584576), 53: (4, 0.34430925734341145), 54: (4, 0.3477887073531747), 55: (4, 0.3425318347290158), 56: (4, 0.34633688163012266), 57: (4, 0.3471739999949932), 58: (4, 0.34400616586208344), 59: (4, 0.34667909517884254), 60: (4, 0.3449140042066574), 61: (4, 0.34510357957333326), 62: (4, 0.345942959189415), 63: (4, 0.3467403296381235), 64: (4, 0.34401241037994623), 65: (4, 0.3452741950750351), 66: (4, 0.3597350502386689), 67: (4, 0.34409242775291204), 68: (4, 0.3472466906532645), 69: (4, 0.3479573121294379), 70: (4, 0.34327090345323086), 71: (1, 0.2444774080067873)}\n",
      "{1: (4, 255, 0.227875713010629), 2: (4, 255, 0.2256626946997701), 3: (4, 255, 0.22555836705746604), 4: (4, 255, 0.22524578793741323), 5: (4, 255, 0.22535118673215895), 6: (4, 255, 0.2252410930672697), 7: (4, 255, 0.2254717431487698), 8: (4, 255, 0.22523976976380627), 9: (4, 255, 0.22536612626019062), 10: (4, 255, 0.22535871304936853), 11: (4, 255, 0.22525493730516993), 12: (4, 255, 0.22524672094367298), 13: (4, 255, 0.2252683656728443), 14: (4, 255, 0.22527383365029213), 15: (4, 255, 0.22517971168180892), 16: (4, 255, 0.22522265182844564), 17: (4, 255, 0.22505848550548155), 18: (4, 255, 0.22502668222741168), 19: (4, 255, 0.22525618007297024), 20: (4, 255, 0.22509553703095983), 21: (4, 255, 0.22502099521385105), 22: (4, 255, 0.2252854571988185), 23: (4, 255, 0.2253597913638634), 24: (4, 255, 0.2260222864392049), 25: (4, 255, 0.22572834234246436), 26: (4, 255, 0.22536215524682227), 27: (4, 255, 0.22527023493220993), 28: (4, 255, 0.22523121519342942), 29: (4, 255, 0.22611579880410548), 30: (4, 255, 0.22552391304543204), 31: (4, 255, 0.22557717842579472), 32: (4, 255, 0.22520812121676465), 33: (4, 255, 0.22525818716077245), 34: (4, 255, 0.22521430901890876), 35: (4, 255, 0.22520736829542062), 36: (4, 255, 0.22523630635045908), 37: (4, 255, 0.22516903939711697), 38: (4, 255, 0.2251337897726426), 39: (4, 255, 0.22516282368816581), 40: (4, 255, 0.2251825429718284), 41: (4, 255, 0.22517284578187208), 42: (4, 255, 0.22512253023610979), 43: (4, 255, 0.2251663089930719), 44: (4, 255, 0.2252877597130981), 45: (4, 255, 0.2251742078283546), 46: (4, 255, 0.22514849559714398), 47: (4, 255, 0.2251195154426729), 48: (4, 255, 0.2250173534211867), 49: (4, 255, 0.22508655594406174), 50: (4, 255, 0.22481039418820656), 51: (4, 255, 0.22472674921154975), 52: (4, 255, 0.22469123432814492), 53: (4, 255, 0.22455213756172682), 54: (4, 255, 0.22465086454416022), 55: (4, 255, 0.22460116546089742), 56: (4, 255, 0.22453514637023794), 57: (4, 255, 0.2248825779732536), 58: (4, 255, 0.22493015156291862), 59: (4, 255, 0.2246581378630271), 60: (4, 255, 0.22460033675180932), 61: (4, 255, 0.22468819204790919), 62: (4, 255, 0.22476542345887307), 63: (4, 255, 0.22456005005640725), 64: (4, 255, 0.22458563183671704), 65: (4, 255, 0.2247426652696495), 66: (4, 255, 0.22473847914998438), 67: (4, 255, 0.22458718003084263), 68: (4, 255, 0.2246611415353768), 69: (4, 255, 0.22457965406790084), 70: (4, 255, 0.22466084871295036)}\n",
      "{'predict_runtime': 4080.1394, 'predict_samples_per_second': 0.069, 'predict_steps_per_second': 0.017}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:08:00.13\n",
      "  predict_samples_per_second =      0.069\n",
      "  predict_steps_per_second   =      0.017\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 28\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.28862613439559937), 2: (1, 0.2545315930619836), 3: (1, 0.2544731833040714), 4: (1, 0.2546744616702199), 5: (1, 0.2522246679291129), 6: (1, 0.2536687208339572), 7: (1, 0.25159892346709967), 8: (1, 0.25158484373241663), 9: (1, 0.25000105053186417), 10: (1, 0.2552677821367979), 11: (1, 0.2557182163000107), 12: (1, 0.25066410284489393), 13: (1, 0.25167507119476795), 14: (1, 0.2504735542461276), 15: (1, 0.2541937818750739), 16: (1, 0.2522426834329963), 17: (1, 0.2530404347926378), 18: (1, 0.25504205096513033), 19: (1, 0.25158108957111835), 20: (1, 0.2555471546947956), 21: (1, 0.252023383975029), 22: (1, 0.2555590635165572), 23: (1, 0.25141695979982615), 24: (1, 0.25310245994478464), 25: (1, 0.25335297733545303), 26: (1, 0.2547098221257329), 27: (1, 0.25292043201625347), 28: (1, 0.25406323932111263), 29: (1, 0.25265529472380877), 30: (1, 0.2510250583291054), 31: (1, 0.2530142553150654), 32: (1, 0.2522205524146557), 33: (1, 0.2507321806624532), 34: (1, 0.252708506770432), 35: (1, 0.2521710926666856), 36: (1, 0.2520019356161356), 37: (1, 0.25377808418124914), 38: (1, 0.25034461356699467), 39: (1, 0.25556458346545696), 40: (1, 0.2548476606607437), 41: (1, 0.25050590094178915), 42: (1, 0.25484742037951946), 43: (1, 0.25230077002197504), 44: (1, 0.2529387827962637), 45: (1, 0.25276099517941475), 46: (1, 0.2519800625741482), 47: (1, 0.2527175433933735), 48: (1, 0.25334145687520504), 49: (1, 0.2532052267342806), 50: (1, 0.2522615985944867), 51: (1, 0.25225152913480997), 52: (1, 0.2515490371733904), 53: (1, 0.25520495511591434), 54: (1, 0.25376453064382076), 55: (1, 0.25311325769871473), 56: (1, 0.25350073259323835), 57: (1, 0.252636362798512), 58: (1, 0.2527618519961834), 59: (1, 0.2545321127399802), 60: (1, 0.25410902593284845), 61: (1, 0.2513216780498624), 62: (1, 0.25580151472240686), 63: (1, 0.25196086056530476), 64: (1, 0.2560680415481329), 65: (1, 0.2531343763694167), 66: (1, 0.2530362978577614), 67: (1, 0.25463838782161474), 68: (1, 0.25649184733629227), 69: (1, 0.2537333285436034), 70: (1, 0.25219141505658627), 71: (1, 0.25367541890591383)}\n",
      "{1: (1, 255, 0.15068736745446337), 2: (1, 255, 0.15004163155441774), 3: (1, 255, 0.14985810540543468), 4: (1, 255, 0.14995475964730276), 5: (1, 255, 0.15010422677459084), 6: (1, 255, 0.14987012219852677), 7: (1, 255, 0.14984416317413835), 8: (1, 255, 0.1499820140866088), 9: (1, 255, 0.1500923826888788), 10: (1, 255, 0.1500250886833551), 11: (1, 255, 0.1499675413995397), 12: (1, 255, 0.1498322510836171), 13: (1, 255, 0.149993002096958), 14: (1, 255, 0.14998773273226676), 15: (1, 255, 0.14990954808525594), 16: (1, 255, 0.14982949729789705), 17: (1, 255, 0.14963505288549497), 18: (1, 255, 0.14973195471673034), 19: (1, 255, 0.14972342720218734), 20: (1, 255, 0.1498369866470788), 21: (1, 255, 0.14958130098221933), 22: (1, 255, 0.14971934991943486), 23: (1, 255, 0.14980221807445382), 24: (1, 255, 0.1498936335063156), 25: (1, 255, 0.14975616245658374), 26: (1, 255, 0.14966745582938779), 27: (1, 255, 0.14970794165981752), 28: (1, 255, 0.14982964792014922), 29: (1, 255, 0.14978458979623574), 30: (1, 255, 0.14982584247036893), 31: (1, 255, 0.14975865698036026), 32: (1, 255, 0.1498822849463014), 33: (1, 255, 0.14971210008815808), 34: (1, 255, 0.1498314662672141), 35: (1, 255, 0.14982383338844074), 36: (1, 255, 0.14978924795400864), 37: (1, 255, 0.1498202334285951), 38: (1, 255, 0.14982188884168862), 39: (1, 255, 0.149701880747635), 40: (1, 255, 0.14974778342042483), 41: (1, 255, 0.14963581354959923), 42: (1, 255, 0.14988526616829867), 43: (1, 255, 0.15032822198654508), 44: (1, 255, 0.1496752487057272), 45: (1, 255, 0.14952506367117166), 46: (1, 255, 0.14961812064124674), 47: (1, 255, 0.14955837825568868), 48: (1, 255, 0.1495625289887482), 49: (1, 255, 0.14970767461493903), 50: (1, 255, 0.14969388539446335), 51: (1, 255, 0.14970998779377517), 52: (1, 255, 0.14964602898952423), 53: (1, 255, 0.14966944402047233), 54: (1, 255, 0.14956982681418166), 55: (1, 255, 0.1499960711371957), 56: (1, 255, 0.150437604161162), 57: (1, 255, 0.15030155807149176), 58: (1, 255, 0.1503455004344384), 59: (1, 255, 0.15037962628126728), 60: (1, 255, 0.14998871787067722), 61: (1, 255, 0.15004376948391104), 62: (1, 255, 0.14991438866172935), 63: (1, 255, 0.15006842627829198), 64: (1, 255, 0.1500170730346558), 65: (1, 255, 0.15003700155545682), 66: (1, 255, 0.14993264202539827), 67: (1, 255, 0.14992796499647346), 68: (1, 255, 0.1501186390936959), 69: (1, 255, 0.15020019735264428), 70: (1, 255, 0.1500180176952306)}\n",
      "{'predict_runtime': 2731.7137, 'predict_samples_per_second': 0.026, 'predict_steps_per_second': 0.026}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:45:31.71\n",
      "  predict_samples_per_second =      0.026\n",
      "  predict_steps_per_second   =      0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.3071947740390897), 2: (2, 0.31700018141418695), 3: (2, 0.2772838771343231), 4: (2, 0.27064300142228603), 5: (2, 0.2826814819127321), 6: (2, 0.32289157900959253), 7: (2, 0.2786301877349615), 8: (2, 0.28637644834816456), 9: (2, 0.276998657733202), 10: (2, 0.29424926824867725), 11: (2, 0.2745595034211874), 12: (2, 0.3222090061753988), 13: (2, 0.2951147574931383), 14: (2, 0.28898785822093487), 15: (2, 0.3211163878440857), 16: (2, 0.2775522479787469), 17: (2, 0.27889014314860106), 18: (2, 0.27330533880740404), 19: (2, 0.2887595696374774), 20: (2, 0.3190172351896763), 21: (2, 0.277694801799953), 22: (2, 0.28067066706717014), 23: (2, 0.27418262232095003), 24: (2, 0.27573683485388756), 25: (2, 0.28657679818570614), 26: (2, 0.3207181366160512), 27: (2, 0.2976896809414029), 28: (2, 0.27725537586957216), 29: (2, 0.2752901390194893), 30: (2, 0.28936893586069345), 31: (2, 0.31901581492275), 32: (2, 0.32041979767382145), 33: (2, 0.27724013663828373), 34: (2, 0.288402546197176), 35: (2, 0.2754220673814416), 36: (2, 0.2916779890656471), 37: (2, 0.27711945679038763), 38: (2, 0.31693979911506176), 39: (2, 0.27385614439845085), 40: (2, 0.28844414558261633), 41: (2, 0.2848331481218338), 42: (2, 0.27680780086666346), 43: (2, 0.3294785041362047), 44: (2, 0.30089432280510664), 45: (2, 0.2767961695790291), 46: (2, 0.2810092121362686), 47: (2, 0.27915018424391747), 48: (2, 0.2759482990950346), 49: (2, 0.2738996436819434), 50: (2, 0.2874668063595891), 51: (2, 0.2786754993721843), 52: (2, 0.32307915668934584), 53: (2, 0.28930703550577164), 54: (2, 0.2758402293547988), 55: (2, 0.2836451409384608), 56: (2, 0.3197519248351455), 57: (2, 0.2783787017688155), 58: (2, 0.32161840330809355), 59: (2, 0.2779461285099387), 60: (2, 0.27433483861386776), 61: (2, 0.31891896575689316), 62: (2, 0.3211769303306937), 63: (2, 0.31806127447634935), 64: (2, 0.3203609688207507), 65: (2, 0.2796713765710592), 66: (2, 0.27924959175288677), 67: (2, 0.2792485225945711), 68: (2, 0.2887539332732558), 69: (2, 0.27756936103105545), 70: (2, 0.32303681690245867), 71: (1, 0.26657782681286335)}\n",
      "{1: (2, 255, 0.2337721260994965), 2: (2, 255, 0.23198169566617877), 3: (2, 255, 0.23164678960673366), 4: (2, 255, 0.23174235073886082), 5: (2, 255, 0.23167393600166428), 6: (2, 255, 0.23175469790676645), 7: (2, 255, 0.23180164679081416), 8: (2, 255, 0.2316601972077407), 9: (2, 255, 0.23161553134593893), 10: (2, 255, 0.23131291582888247), 11: (2, 255, 0.23130872888015766), 12: (2, 255, 0.23124924946722447), 13: (2, 255, 0.2313088152776746), 14: (2, 255, 0.2312025242905114), 15: (2, 255, 0.23115561569438262), 16: (2, 255, 0.23128877894258967), 17: (2, 255, 0.23118222670666144), 18: (2, 255, 0.23127766212119777), 19: (2, 255, 0.23104458840965642), 20: (2, 255, 0.23120908224772588), 21: (2, 255, 0.2312760940077258), 22: (2, 255, 0.2312269849885328), 23: (2, 255, 0.23129442007664372), 24: (2, 255, 0.2313146408902956), 25: (2, 255, 0.23126946496320705), 26: (2, 255, 0.2312962837809441), 27: (2, 255, 0.23144750606414735), 28: (2, 255, 0.23133782198762193), 29: (2, 255, 0.2313622428396461), 30: (2, 255, 0.23121758195042025), 31: (2, 255, 0.23132340150940067), 32: (2, 255, 0.23212119411750168), 33: (2, 255, 0.23178280754124417), 34: (2, 255, 0.23148359467512836), 35: (2, 255, 0.23169788663439891), 36: (2, 255, 0.23160548993550678), 37: (2, 255, 0.23139203686413226), 38: (2, 255, 0.23164781298050108), 39: (2, 255, 0.23222654333666842), 40: (2, 255, 0.23192858085328458), 41: (2, 255, 0.232075947194415), 42: (2, 255, 0.23236045917751744), 43: (2, 255, 0.23212711924650506), 44: (2, 255, 0.23197598782386267), 45: (2, 255, 0.23218045464041187), 46: (2, 255, 0.23273625109052543), 47: (2, 255, 0.2321504143924982), 48: (2, 255, 0.23215541281536514), 49: (2, 255, 0.23214373581622746), 50: (2, 255, 0.23200085550984917), 51: (2, 255, 0.23211287199428268), 52: (2, 255, 0.23204984331832212), 53: (2, 255, 0.2320030269706074), 54: (2, 255, 0.23211635912531148), 55: (2, 255, 0.23183233876365658), 56: (2, 255, 0.23204049355186085), 57: (2, 255, 0.231973137257292), 58: (2, 255, 0.23192425668239594), 59: (2, 255, 0.23207735079614555), 60: (2, 255, 0.2317938788447018), 61: (2, 255, 0.23191538199271058), 62: (2, 255, 0.2319389460352706), 63: (2, 255, 0.23176686927384021), 64: (2, 255, 0.2321199748957274), 65: (2, 255, 0.23221704107800537), 66: (2, 255, 0.231776101960271), 67: (2, 255, 0.23163054823218024), 68: (2, 255, 0.23257620067646106), 69: (2, 255, 0.23172414046073075), 70: (2, 255, 0.23183889597581298)}\n",
      "{'predict_runtime': 4195.7632, 'predict_samples_per_second': 0.034, 'predict_steps_per_second': 0.017}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:09:55.76\n",
      "  predict_samples_per_second =      0.034\n",
      "  predict_steps_per_second   =      0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/71 33:54 < 35:54, 0.02 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m data_module \u001b[38;5;241m=\u001b[39m make_data_module(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data_module\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m ttft, tbt \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_latencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m ttfts\u001b[38;5;241m.\u001b[39mappend(ttft)\n\u001b[1;32m     21\u001b[0m tbts\u001b[38;5;241m.\u001b[39mappend(tbt)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/profiler.py:285\u001b[0m, in \u001b[0;36mprofile_latencies\u001b[0;34m(model, tokenizer, args, logger, trainer, data_module)\u001b[0m\n\u001b[1;32m    283\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProfiling model for TTFT and TBT latencies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m timing_stopping_criteria \u001b[38;5;241m=\u001b[39m TokenTimingStoppingCriteria()\n\u001b[0;32m--> 285\u001b[0m prediction_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtiming_stopping_criteria\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mprint\u001b[39m(timing_stopping_criteria\u001b[38;5;241m.\u001b[39mttft)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(timing_stopping_criteria\u001b[38;5;241m.\u001b[39mtbt)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer_seq2seq.py:244\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer.py:3678\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3675\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3677\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3678\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3681\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3788\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3791\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3793\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/trainer_seq2seq.py:310\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    306\u001b[0m ):\n\u001b[1;32m    307\u001b[0m     generation_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    308\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     }\n\u001b[0;32m--> 310\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/peft/src/peft/peft_model.py:1325\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1324\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1325\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:1319\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1316\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1319\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:1116\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1105\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1106\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         layer_index\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_index\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:778\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, index, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;66;03m### Self Attention\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# if self.active_width_attn is not None:\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;66;03m#     self.self_attn.set_active_width(self.active_width_attn)\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/transformers/src/transformers/models/llama/modeling_llama.py:703\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, index, cache_position)\u001b[0m\n\u001b[1;32m    700\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    701\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m--> 703\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/peft/src/peft/tuners/lora/bnb.py:590\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m gating_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgating_scores\n\u001b[1;32m    588\u001b[0m hard_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_indices\n\u001b[0;32m--> 590\u001b[0m weight_lora_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([lora_A[indice]\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m gating_scores[indice] \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m hard_indices])\n\u001b[1;32m    592\u001b[0m output_lora_a \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(dropout(x), weight_lora_a)\n\u001b[1;32m    594\u001b[0m weight_lora_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([lora_B[indice]\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m gating_scores[indice] \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m hard_indices])\n",
      "File \u001b[0;32m/coc/scratch/hkolisetty6/AmoebaLLM/peft/src/peft/tuners/lora/bnb.py:590\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    587\u001b[0m gating_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgating_scores\n\u001b[1;32m    588\u001b[0m hard_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_indices\n\u001b[0;32m--> 590\u001b[0m weight_lora_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[43mlora_A\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindice\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m gating_scores[indice] \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m hard_indices])\n\u001b[1;32m    592\u001b[0m output_lora_a \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(dropout(x), weight_lora_a)\n\u001b[1;32m    594\u001b[0m weight_lora_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([lora_B[indice]\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m gating_scores[indice] \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m hard_indices])\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/container.py:334\u001b[0m, in \u001b[0;36mModuleList.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues())[idx])\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_abs_string_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/torch/nn/modules/container.py:314\u001b[0m, in \u001b[0;36mModuleList._get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_abs_string_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the absolute index for the list of modules.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 29\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
