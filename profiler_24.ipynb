{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 24, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.37112699914723635), 2: (1, 0.20714133512228727), 3: (1, 0.20538488496094942), 4: (1, 0.2050504283979535), 5: (1, 0.2135801874101162), 6: (1, 0.20687331724911928), 7: (1, 0.20545219350606203), 8: (1, 0.2027201857417822), 9: (1, 0.2059626467525959), 10: (1, 0.2022735709324479), 11: (1, 0.20370733179152012), 12: (1, 0.2024916773661971), 13: (1, 0.20323113724589348), 14: (1, 0.20261209551244974), 15: (1, 0.20330006629228592), 16: (1, 0.2026505544781685), 17: (1, 0.2048748880624771), 18: (1, 0.20301795843988657), 19: (1, 0.20303585939109325), 20: (1, 0.20151242706924677), 21: (1, 0.2040171455591917), 22: (1, 0.20319936610758305), 23: (1, 0.20321944635361433), 24: (1, 0.20188803132623434), 25: (1, 0.20345592219382524), 26: (1, 0.20452820882201195), 27: (1, 0.20235089492052794), 28: (1, 0.20172498188912868), 29: (1, 0.20336435176432133), 30: (1, 0.20581196248531342), 31: (1, 0.2036622976884246), 32: (1, 0.20244134217500687), 33: (1, 0.20245023164898157), 34: (1, 0.20594562031328678), 35: (1, 0.20214626472443342), 36: (1, 0.20230500306934118), 37: (1, 0.20503551047295332), 38: (1, 0.20560799445956945), 39: (1, 0.2019543256610632), 40: (1, 0.2051471695303917), 41: (1, 0.20257255900651217), 42: (1, 0.20697287563234568), 43: (1, 0.20414356980472803), 44: (1, 0.20254372898489237), 45: (1, 0.2018845472484827), 46: (1, 0.20371995400637388), 47: (1, 0.20400045067071915), 48: (1, 0.20274084620177746), 49: (1, 0.2030446119606495), 50: (1, 0.20489194989204407), 51: (1, 0.20292538218200207)}\n",
      "{1: (1, 127, 0.12573658197560883), 2: (1, 127, 0.12422806015018169), 3: (1, 127, 0.12518021448214692), 4: (1, 127, 0.12892898673001002), 5: (1, 127, 0.1263265924704239), 6: (1, 127, 0.12485617729945211), 7: (1, 127, 0.1246593081810343), 8: (1, 127, 0.12443100252577405), 9: (1, 127, 0.12417506411906302), 10: (1, 127, 0.12430627359531995), 11: (1, 127, 0.1240143952964563), 12: (1, 127, 0.1244959347976709), 13: (1, 127, 0.12436198770970576), 14: (1, 127, 0.12421371434323901), 15: (1, 127, 0.1240550506214692), 16: (1, 127, 0.12431226813007058), 17: (1, 127, 0.12411456157666022), 18: (1, 127, 0.12396863108779502), 19: (1, 127, 0.12405585683148912), 20: (1, 127, 0.12395649628464396), 21: (1, 127, 0.1241355358263639), 22: (1, 127, 0.12408479099257255), 23: (1, 127, 0.12393265075277625), 24: (1, 127, 0.12403301217072592), 25: (1, 127, 0.12414135673178697), 26: (1, 127, 0.12423425194198691), 27: (1, 127, 0.12391202970165906), 28: (1, 127, 0.12403211231512112), 29: (1, 127, 0.12383414687603478), 30: (1, 127, 0.12395650205591063), 31: (1, 127, 0.12399108693971643), 32: (1, 127, 0.12400317830803591), 33: (1, 127, 0.1238570413148896), 34: (1, 127, 0.12400259906206075), 35: (1, 127, 0.1238666888047743), 36: (1, 127, 0.12387063523651812), 37: (1, 127, 0.12382649364844552), 38: (1, 127, 0.12390961355757056), 39: (1, 127, 0.12394894894183152), 40: (1, 127, 0.12435865702151548), 41: (1, 127, 0.12428863662639707), 42: (1, 127, 0.12402485915291028), 43: (1, 127, 0.12401801688728605), 44: (1, 127, 0.12398540368670319), 45: (1, 127, 0.1238706087781571), 46: (1, 127, 0.12459616918908799), 47: (1, 127, 0.1245331596436463), 48: (1, 127, 0.12401261490835684), 49: (1, 127, 0.1240790732879573), 50: (1, 127, 0.12395190413102625)}\n",
      "{'predict_runtime': 815.7266, 'predict_samples_per_second': 0.063, 'predict_steps_per_second': 0.063}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:13:35.72\n",
      "  predict_samples_per_second =      0.063\n",
      "  predict_steps_per_second   =      0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.24205145798623562), 2: (2, 0.21317223086953163), 3: (2, 0.21972443256527185), 4: (2, 0.2166096307337284), 5: (2, 0.2122199907898903), 6: (2, 0.23099155817180872), 7: (2, 0.22029745485633612), 8: (2, 0.2302863448858261), 9: (2, 0.22944653499871492), 10: (2, 0.21823217906057835), 11: (2, 0.23020795546472073), 12: (2, 0.2296868422999978), 13: (2, 0.21467736922204494), 14: (2, 0.22609554324299097), 15: (2, 0.23007853608578444), 16: (2, 0.2307239668443799), 17: (2, 0.22880052961409092), 18: (2, 0.21582960337400436), 19: (2, 0.21757596358656883), 20: (2, 0.21017929073423147), 21: (2, 0.2146038580685854), 22: (2, 0.2300776643678546), 23: (2, 0.20949681848287582), 24: (2, 0.22015790175646544), 25: (2, 0.21324583236128092), 26: (2, 0.23207145929336548), 27: (2, 0.21181931998580694), 28: (2, 0.215249958448112), 29: (2, 0.2189951241016388), 30: (2, 0.2103966334834695), 31: (2, 0.20919067598879337), 32: (2, 0.23434233851730824), 33: (2, 0.2317740060389042), 34: (2, 0.21858901530504227), 35: (2, 0.23110902961343527), 36: (2, 0.23031783755868673), 37: (2, 0.23004092928022146), 38: (2, 0.22450151201337576), 39: (2, 0.2296608304604888), 40: (2, 0.21227738913148642), 41: (2, 0.230598296970129), 42: (2, 0.22908098250627518), 43: (2, 0.23047008644789457), 44: (2, 0.22373061068356037), 45: (2, 0.2135492078959942), 46: (2, 0.2166626201942563), 47: (2, 0.2111231442540884), 48: (2, 0.21382018085569143), 49: (2, 0.21581338625401258), 50: (2, 0.21018628031015396), 51: (1, 0.20078308694064617)}\n",
      "{1: (2, 127, 0.1942385735400901), 2: (2, 127, 0.19325027773963419), 3: (2, 127, 0.19294682293983662), 4: (2, 127, 0.19290205405834387), 5: (2, 127, 0.19273892611881174), 6: (2, 127, 0.1922987014729911), 7: (2, 127, 0.19228137976042634), 8: (2, 127, 0.1921016993367766), 9: (2, 127, 0.19211910328439136), 10: (2, 127, 0.19225512810168774), 11: (2, 127, 0.19213135860948347), 12: (2, 127, 0.19239806550312935), 13: (2, 127, 0.1922150120784448), 14: (2, 127, 0.19206607918893023), 15: (2, 127, 0.1922424063893167), 16: (2, 127, 0.19227269673206676), 17: (2, 127, 0.19254005355687123), 18: (2, 127, 0.19257323087493736), 19: (2, 127, 0.19384232153896036), 20: (2, 127, 0.1929720874846451), 21: (2, 127, 0.19276677551642646), 22: (2, 127, 0.19675299261263976), 23: (2, 127, 0.1924025761696884), 24: (2, 127, 0.19244522836763323), 25: (2, 127, 0.19229783447034013), 26: (2, 127, 0.19258442399363349), 27: (2, 127, 0.19239618500151973), 28: (2, 127, 0.19233491292267335), 29: (2, 127, 0.19254202969870934), 30: (2, 127, 0.1924273878937279), 31: (2, 127, 0.19230714504878352), 32: (2, 127, 0.1923795480530445), 33: (2, 127, 0.19232880097527907), 34: (2, 127, 0.192323562850457), 35: (2, 127, 0.192431644866551), 36: (2, 127, 0.19235676354691972), 37: (2, 127, 0.19233797120267715), 38: (2, 127, 0.19231443948985086), 39: (2, 127, 0.19237256543637496), 40: (2, 127, 0.192284012675344), 41: (2, 127, 0.19225205401853313), 42: (2, 127, 0.19217669295044396), 43: (2, 127, 0.19222569150307517), 44: (2, 127, 0.19236871946280396), 45: (2, 127, 0.19241874840286538), 46: (2, 127, 0.19251557076569853), 47: (2, 127, 0.19251661841559597), 48: (2, 127, 0.1923344356748532), 49: (2, 127, 0.19248492115976537), 50: (2, 127, 0.19246561853141766)}\n",
      "{'predict_runtime': 1249.8965, 'predict_samples_per_second': 0.081, 'predict_steps_per_second': 0.041}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:49.89\n",
      "  predict_samples_per_second =      0.081\n",
      "  predict_steps_per_second   =      0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.2629824401810765), 2: (4, 0.22801770083606243), 3: (4, 0.2636301601305604), 4: (4, 0.2445577885955572), 5: (4, 0.22811303660273552), 6: (4, 0.2258790424093604), 7: (4, 0.24762121867388487), 8: (4, 0.2462778128683567), 9: (4, 0.2287325942888856), 10: (4, 0.22724069189280272), 11: (4, 0.2291074190288782), 12: (4, 0.22576515562832355), 13: (4, 0.24857815075665712), 14: (4, 0.23059558868408203), 15: (4, 0.23175497446209192), 16: (4, 0.24327164981514215), 17: (4, 0.22627170477062464), 18: (4, 0.2448416193947196), 19: (4, 0.23416148219257593), 20: (4, 0.23849145136773586), 21: (4, 0.22640238050371408), 22: (4, 0.2470508459955454), 23: (4, 0.22998967580497265), 24: (4, 0.24140143487602472), 25: (4, 0.22825638949871063), 26: (4, 0.23123322520405054), 27: (4, 0.22711957897990942), 28: (4, 0.24091412220150232), 29: (4, 0.22802375629544258), 30: (4, 0.23369821906089783), 31: (4, 0.24289396405220032), 32: (4, 0.22855084389448166), 33: (4, 0.23501472920179367), 34: (4, 0.22919135354459286), 35: (4, 0.230281719006598), 36: (4, 0.23363733012229204), 37: (4, 0.24847463984042406), 38: (4, 0.22887478861957788), 39: (4, 0.23422821797430515), 40: (4, 0.22925548255443573), 41: (4, 0.24176360853016376), 42: (4, 0.23433362040668726), 43: (4, 0.23082200903445482), 44: (4, 0.22784692142158747), 45: (4, 0.2393020698800683), 46: (4, 0.23348324373364449), 47: (4, 0.24229511339217424), 48: (4, 0.23229755461215973), 49: (4, 0.22545680031180382), 50: (4, 0.22507118433713913), 51: (1, 0.22134046535938978)}\n",
      "{1: (4, 127, 0.19396798875124202), 2: (4, 127, 0.19262448424018744), 3: (4, 127, 0.19268045000233283), 4: (4, 127, 0.19267001252357416), 5: (4, 127, 0.19286736722771577), 6: (4, 127, 0.1925627498586816), 7: (4, 127, 0.19250896410268592), 8: (4, 127, 0.1925529412499915), 9: (4, 127, 0.19257966103398894), 10: (4, 127, 0.19258132922338453), 11: (4, 127, 0.1926226376915189), 12: (4, 127, 0.19253836337506303), 13: (4, 127, 0.19270325671353444), 14: (4, 127, 0.1926821412767951), 15: (4, 127, 0.19262812986940614), 16: (4, 127, 0.19261408208568734), 17: (4, 127, 0.19272662719022335), 18: (4, 127, 0.19280264814802278), 19: (4, 127, 0.19280738829393088), 20: (4, 127, 0.19271033341578375), 21: (4, 127, 0.19250192377334974), 22: (4, 127, 0.19246635693822087), 23: (4, 127, 0.19251438819135971), 24: (4, 127, 0.19262260985450716), 25: (4, 127, 0.1925924433116603), 26: (4, 127, 0.1925485390715125), 27: (4, 127, 0.1924036567825384), 28: (4, 127, 0.1924987671618152), 29: (4, 127, 0.19239423295673658), 30: (4, 127, 0.19247131493294567), 31: (4, 127, 0.19254101415377434), 32: (4, 127, 0.19274341600294423), 33: (4, 127, 0.19256505451539135), 34: (4, 127, 0.19243886057052792), 35: (4, 127, 0.19244457619250055), 36: (4, 127, 0.19261731929695747), 37: (4, 127, 0.19233016850881454), 38: (4, 127, 0.1923279906366402), 39: (4, 127, 0.19246980485572354), 40: (4, 127, 0.19231298492532076), 41: (4, 127, 0.19231552147401834), 42: (4, 127, 0.19242547437049976), 43: (4, 127, 0.19227768919306007), 44: (4, 127, 0.19226339991079774), 45: (4, 127, 0.19218825598020017), 46: (4, 127, 0.1922462629227657), 47: (4, 127, 0.19214452673336418), 48: (4, 127, 0.19221614874664725), 49: (4, 127, 0.19236668295366324), 50: (4, 127, 0.19217980367050866)}\n",
      "{'predict_runtime': 1250.3282, 'predict_samples_per_second': 0.161, 'predict_steps_per_second': 0.041}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:20:50.32\n",
      "  predict_samples_per_second =      0.161\n",
      "  predict_steps_per_second   =      0.041\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 24\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.24065718334168196), 2: (1, 0.2204165542498231), 3: (1, 0.214834276586771), 4: (1, 0.21358083002269268), 5: (1, 0.21044616401195526), 6: (1, 0.2140717627480626), 7: (1, 0.21378526464104652), 8: (1, 0.21250327955931425), 9: (1, 0.21188713517040014), 10: (1, 0.21732979081571102), 11: (1, 0.21302880998700857), 12: (1, 0.21085178386420012), 13: (1, 0.2114216974005103), 14: (1, 0.21091622114181519), 15: (1, 0.21280209999531507), 16: (1, 0.21142501384019852), 17: (1, 0.21415127161890268), 18: (1, 0.2117013894021511), 19: (1, 0.21071805991232395), 20: (1, 0.21144118066877127), 21: (1, 0.21280241385102272), 22: (1, 0.2102164626121521), 23: (1, 0.2109210854396224), 24: (1, 0.2120636710897088), 25: (1, 0.21211715880781412), 26: (1, 0.2098451443016529), 27: (1, 0.21376199927181005), 28: (1, 0.2123792041093111), 29: (1, 0.211132587864995), 30: (1, 0.21194318775087595), 31: (1, 0.21352792903780937), 32: (1, 0.20976807177066803), 33: (1, 0.20992188900709152), 34: (1, 0.2099057687446475), 35: (1, 0.21252428740262985), 36: (1, 0.21480065118521452), 37: (1, 0.21435271482914686), 38: (1, 0.21065915748476982), 39: (1, 0.21472332999110222), 40: (1, 0.21039256919175386), 41: (1, 0.21023062989115715), 42: (1, 0.20971501618623734), 43: (1, 0.21434961073100567), 44: (1, 0.209755914285779), 45: (1, 0.21380461566150188), 46: (1, 0.20972210261970758), 47: (1, 0.21248972043395042), 48: (1, 0.21100463531911373), 49: (1, 0.2121600229293108), 50: (1, 0.2133691878989339), 51: (1, 0.2126027075573802), 52: (1, 0.21016699448227882), 53: (1, 0.21412114705890417), 54: (1, 0.21103843301534653), 55: (1, 0.21261624433100224), 56: (1, 0.21159277576953173), 57: (1, 0.2134081544354558), 58: (1, 0.21015863213688135), 59: (1, 0.21249836310744286), 60: (1, 0.21362070925533772), 61: (1, 0.20975898392498493), 62: (1, 0.21240674331784248), 63: (1, 0.21254415158182383), 64: (1, 0.21285681705921888), 65: (1, 0.2132543809711933), 66: (1, 0.21243868954479694), 67: (1, 0.21208871342241764), 68: (1, 0.2136965049430728), 69: (1, 0.2103298418223858), 70: (1, 0.21313288994133472), 71: (1, 0.2131097400560975)}\n",
      "{1: (1, 127, 0.13017177112459197), 2: (1, 127, 0.1296025113253964), 3: (1, 127, 0.12938556240094223), 4: (1, 127, 0.12917267122694592), 5: (1, 127, 0.12943806593108365), 6: (1, 127, 0.12962057771469196), 7: (1, 127, 0.12947166676625727), 8: (1, 127, 0.12937702646288346), 9: (1, 127, 0.12916422137389266), 10: (1, 127, 0.12915318108009777), 11: (1, 127, 0.1291278718024727), 12: (1, 127, 0.12900462106427574), 13: (1, 127, 0.12914690577725726), 14: (1, 127, 0.12905133511929764), 15: (1, 127, 0.1291016786997243), 16: (1, 127, 0.12958659462660083), 17: (1, 127, 0.12922336004205107), 18: (1, 127, 0.12916379771745345), 19: (1, 127, 0.12909894052335597), 20: (1, 127, 0.12903322756847763), 21: (1, 127, 0.1291043466089044), 22: (1, 127, 0.12904773788951981), 23: (1, 127, 0.1292885019788592), 24: (1, 127, 0.12894592704764735), 25: (1, 127, 0.12899070332838794), 26: (1, 127, 0.12905094187384045), 27: (1, 127, 0.1290380915729549), 28: (1, 127, 0.12895357344064892), 29: (1, 127, 0.12907939053719908), 30: (1, 127, 0.12909135248834694), 31: (1, 127, 0.12906439008381893), 32: (1, 127, 0.12900272083622732), 33: (1, 127, 0.12902026438689607), 34: (1, 127, 0.12884541173414218), 35: (1, 127, 0.12929972434255083), 36: (1, 127, 0.129540884999309), 37: (1, 127, 0.12897090904238656), 38: (1, 127, 0.12900857276862532), 39: (1, 127, 0.1290765735504078), 40: (1, 127, 0.12899003597343062), 41: (1, 127, 0.12910621358800356), 42: (1, 127, 0.12890193800581254), 43: (1, 127, 0.12903258618055366), 44: (1, 127, 0.12910596290823279), 45: (1, 127, 0.1291823953346122), 46: (1, 127, 0.12920571712586354), 47: (1, 127, 0.12900590670009063), 48: (1, 127, 0.129072826187031), 49: (1, 127, 0.12905803573589156), 50: (1, 127, 0.12906862785086387), 51: (1, 127, 0.12921178439910722), 52: (1, 127, 0.12915857623177252), 53: (1, 127, 0.12916929015933765), 54: (1, 127, 0.12920012133650657), 55: (1, 127, 0.12938396852668815), 56: (1, 127, 0.12938745214977837), 57: (1, 127, 0.12928292875390823), 58: (1, 127, 0.12931611125658113), 59: (1, 127, 0.12936959573339055), 60: (1, 127, 0.12988242572980133), 61: (1, 127, 0.12975716652480637), 62: (1, 127, 0.12925769514074242), 63: (1, 127, 0.1297162593173699), 64: (1, 127, 0.1292191234336594), 65: (1, 127, 0.12914820605756963), 66: (1, 127, 0.1298201770602366), 67: (1, 127, 0.13097781995238048), 68: (1, 127, 0.12977231728045022), 69: (1, 127, 0.13015476550437569), 70: (1, 127, 0.13102573811215915)}\n",
      "{'predict_runtime': 1180.9647, 'predict_samples_per_second': 0.06, 'predict_steps_per_second': 0.06}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:40.96\n",
      "  predict_samples_per_second =       0.06\n",
      "  predict_steps_per_second   =       0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.2536078533157706), 2: (2, 0.23998793959617615), 3: (2, 0.23478112742304802), 4: (2, 0.22588948160409927), 5: (2, 0.2289600633084774), 6: (2, 0.22911132220178843), 7: (2, 0.2248005410656333), 8: (2, 0.21828399319201708), 9: (2, 0.2390686348080635), 10: (2, 0.23653075378388166), 11: (2, 0.2187955379486084), 12: (2, 0.23924086149781942), 13: (2, 0.22258232347667217), 14: (2, 0.2392590893432498), 15: (2, 0.22184736095368862), 16: (2, 0.24076856207102537), 17: (2, 0.2393890656530857), 18: (2, 0.2273188754916191), 19: (2, 0.22741605434566736), 20: (2, 0.24290802516043186), 21: (2, 0.2259128699079156), 22: (2, 0.2375592151656747), 23: (2, 0.22162034828215837), 24: (2, 0.227913704700768), 25: (2, 0.2383972741663456), 26: (2, 0.24162269569933414), 27: (2, 0.22716351225972176), 28: (2, 0.24271890334784985), 29: (2, 0.22444639261811972), 30: (2, 0.23806124459952116), 31: (2, 0.22169197350740433), 32: (2, 0.22637501545250416), 33: (2, 0.22156647127121687), 34: (2, 0.2203833842650056), 35: (2, 0.23987441882491112), 36: (2, 0.22159639839082956), 37: (2, 0.24185475520789623), 38: (2, 0.22027083300054073), 39: (2, 0.24072205554693937), 40: (2, 0.22439365461468697), 41: (2, 0.23698508832603693), 42: (2, 0.2255637887865305), 43: (2, 0.24282150994986296), 44: (2, 0.23887876328080893), 45: (2, 0.22411150485277176), 46: (2, 0.23917471896857023), 47: (2, 0.24007101729512215), 48: (2, 0.22253425233066082), 49: (2, 0.22313227411359549), 50: (2, 0.22121991496533155), 51: (2, 0.22406399250030518), 52: (2, 0.2195840636268258), 53: (2, 0.22825157269835472), 54: (2, 0.2378672007471323), 55: (2, 0.22059785947203636), 56: (2, 0.22810124326497316), 57: (2, 0.21884315833449364), 58: (2, 0.22947428468614817), 59: (2, 0.22425217647105455), 60: (2, 0.22288006078451872), 61: (2, 0.22171421349048615), 62: (2, 0.21980025619268417), 63: (2, 0.22193240001797676), 64: (2, 0.2214597761631012), 65: (2, 0.22213115729391575), 66: (2, 0.22495101392269135), 67: (2, 0.23977399338036776), 68: (2, 0.23983170092105865), 69: (2, 0.22284771781414747), 70: (2, 0.21726933121681213), 71: (1, 0.2123258775100112)}\n",
      "{1: (2, 127, 0.20237088512893267), 2: (2, 127, 0.20041808202921405), 3: (2, 127, 0.2019430711190766), 4: (2, 127, 0.20072391981948315), 5: (2, 127, 0.20017809134827355), 6: (2, 127, 0.20004746162398593), 7: (2, 127, 0.20023111570039837), 8: (2, 127, 0.19993372012193747), 9: (2, 127, 0.19991048098373132), 10: (2, 127, 0.2003411530759039), 11: (2, 127, 0.2000025645939736), 12: (2, 127, 0.200063787415389), 13: (2, 127, 0.19984256750427362), 14: (2, 127, 0.2004496685236575), 15: (2, 127, 0.20025941904810235), 16: (2, 127, 0.20022969395215587), 17: (2, 127, 0.20029338290108237), 18: (2, 127, 0.20043593337099383), 19: (2, 127, 0.20091832369771295), 20: (2, 127, 0.2008200605935234), 21: (2, 127, 0.20061373722365522), 22: (2, 127, 0.20045011283052483), 23: (2, 127, 0.20041421057993736), 24: (2, 127, 0.20025491463680437), 25: (2, 127, 0.20023519645525714), 26: (2, 127, 0.20037210466501515), 27: (2, 127, 0.200225336139831), 28: (2, 127, 0.2002941951316994), 29: (2, 127, 0.20031693632032457), 30: (2, 127, 0.20032354422998944), 31: (2, 127, 0.2002365188306476), 32: (2, 127, 0.2002637622159297), 33: (2, 127, 0.20031074713182262), 34: (2, 127, 0.20021580283596055), 35: (2, 127, 0.20027602336362121), 36: (2, 127, 0.20022168270070254), 37: (2, 127, 0.20052114826458411), 38: (2, 127, 0.20037891122505186), 39: (2, 127, 0.20053893801440872), 40: (2, 127, 0.20029121635144387), 41: (2, 127, 0.20033302522579752), 42: (2, 127, 0.20029252008571635), 43: (2, 127, 0.20017601103030555), 44: (2, 127, 0.20030086626863386), 45: (2, 127, 0.20031193739873923), 46: (2, 127, 0.20026507935538065), 47: (2, 127, 0.20019631998569476), 48: (2, 127, 0.2000357536452375), 49: (2, 127, 0.20013570359460717), 50: (2, 127, 0.2002585503001382), 51: (2, 127, 0.20070099890026755), 52: (2, 127, 0.20047565970540515), 53: (2, 127, 0.20018697495564935), 54: (2, 127, 0.20028340110305962), 55: (2, 127, 0.2001770503056331), 56: (2, 127, 0.20027199284884872), 57: (2, 127, 0.20024308629744636), 58: (2, 127, 0.20026902514913186), 59: (2, 127, 0.20012453331164723), 60: (2, 127, 0.20018606571348632), 61: (2, 127, 0.20035049281867706), 62: (2, 127, 0.20021030228350342), 63: (2, 127, 0.20021754602248978), 64: (2, 127, 0.2002135088711273), 65: (2, 127, 0.20060765837121197), 66: (2, 127, 0.20051750938195412), 67: (2, 127, 0.1999251064587766), 68: (2, 127, 0.2001418275465294), 69: (2, 127, 0.20019458322309133), 70: (2, 127, 0.20002264465667366)}\n",
      "{'predict_runtime': 1813.6977, 'predict_samples_per_second': 0.078, 'predict_steps_per_second': 0.039}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:30:13.69\n",
      "  predict_samples_per_second =      0.078\n",
      "  predict_steps_per_second   =      0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.26934090722352266), 2: (4, 0.25636933743953705), 3: (4, 0.25868479907512665), 4: (4, 0.2521082442253828), 5: (4, 0.25629278738051653), 6: (4, 0.23954236041754484), 7: (4, 0.25297438260167837), 8: (4, 0.2394287707284093), 9: (4, 0.24783657118678093), 10: (4, 0.2541077407076955), 11: (4, 0.23838677071034908), 12: (4, 0.2358837705105543), 13: (4, 0.24323319271206856), 14: (4, 0.23533229622989893), 15: (4, 0.25529466290026903), 16: (4, 0.23790927417576313), 17: (4, 0.24345751851797104), 18: (4, 0.24110165610909462), 19: (4, 0.2591903153806925), 20: (4, 0.23871179297566414), 21: (4, 0.25790666975080967), 22: (4, 0.2418245766311884), 23: (4, 0.25230617355555296), 24: (4, 0.23678290378302336), 25: (4, 0.23977991938591003), 26: (4, 0.23824776615947485), 27: (4, 0.2352136019617319), 28: (4, 0.23668324388563633), 29: (4, 0.2370709991082549), 30: (4, 0.2364586852490902), 31: (4, 0.23919489327818155), 32: (4, 0.23630629759281874), 33: (4, 0.2415956137701869), 34: (4, 0.2561560356989503), 35: (4, 0.23741560336202383), 36: (4, 0.25023228302598), 37: (4, 0.25571959745138884), 38: (4, 0.2382837412878871), 39: (4, 0.2531645577400923), 40: (4, 0.24097755830734968), 41: (4, 0.24271176755428314), 42: (4, 0.26042350102216005), 43: (4, 0.23405929282307625), 44: (4, 0.23714104667305946), 45: (4, 0.24132998008280993), 46: (4, 0.256941843777895), 47: (4, 0.23916625324636698), 48: (4, 0.24096721224486828), 49: (4, 0.23558037355542183), 50: (4, 0.23977960366755724), 51: (4, 0.2518549282103777), 52: (4, 0.24406707379966974), 53: (4, 0.23956832569092512), 54: (4, 0.2592776622623205), 55: (4, 0.23610207438468933), 56: (4, 0.25301380176097155), 57: (4, 0.23716246988624334), 58: (4, 0.23872453067451715), 59: (4, 0.23918245639652014), 60: (4, 0.23955670185387135), 61: (4, 0.23984464723616838), 62: (4, 0.2371912468224764), 63: (4, 0.24047914799302816), 64: (4, 0.25710371043533087), 65: (4, 0.2387404479086399), 66: (4, 0.2478381246328354), 67: (4, 0.23641434125602245), 68: (4, 0.24546224996447563), 69: (4, 0.24089429061859846), 70: (4, 0.25319028086960316), 71: (1, 0.21198651660233736)}\n",
      "{1: (4, 127, 0.20232617599141645), 2: (4, 127, 0.20070789891522467), 3: (4, 127, 0.20041127054856753), 4: (4, 127, 0.20047521727584947), 5: (4, 127, 0.20040608239250154), 6: (4, 127, 0.2004583444020997), 7: (4, 127, 0.20049011663306415), 8: (4, 127, 0.2008216849080925), 9: (4, 127, 0.20082303600048457), 10: (4, 127, 0.20085370407887096), 11: (4, 127, 0.2005658384529859), 12: (4, 127, 0.2005511277802582), 13: (4, 127, 0.20066539732753996), 14: (4, 127, 0.20051038686890066), 15: (4, 127, 0.2008652657519762), 16: (4, 127, 0.2005456762725678), 17: (4, 127, 0.2006732232384677), 18: (4, 127, 0.2006355946458231), 19: (4, 127, 0.20202775911142037), 20: (4, 127, 0.2013247158217031), 21: (4, 127, 0.20090179911660633), 22: (4, 127, 0.20071809216013808), 23: (4, 127, 0.20192262731257857), 24: (4, 127, 0.20116617614916693), 25: (4, 127, 0.20045896616625034), 26: (4, 127, 0.20043732684956292), 27: (4, 127, 0.2007027321502449), 28: (4, 127, 0.20036665478530596), 29: (4, 127, 0.2003263916864287), 30: (4, 127, 0.200260999429179), 31: (4, 127, 0.20040918453266537), 32: (4, 127, 0.20070283037911016), 33: (4, 127, 0.20036435706584943), 34: (4, 127, 0.20029611437486147), 35: (4, 127, 0.2000803955368639), 36: (4, 127, 0.200137545816659), 37: (4, 127, 0.2002047018741998), 38: (4, 127, 0.20020945866658227), 39: (4, 127, 0.20015554369141267), 40: (4, 127, 0.2002972548856862), 41: (4, 127, 0.19999349944469497), 42: (4, 127, 0.200088309916103), 43: (4, 127, 0.20001608189782055), 44: (4, 127, 0.20015867455591133), 45: (4, 127, 0.2003105432528445), 46: (4, 127, 0.20017800524126828), 47: (4, 127, 0.2003072690013356), 48: (4, 127, 0.200641044635531), 49: (4, 127, 0.20033801933677178), 50: (4, 127, 0.20018061697776393), 51: (4, 127, 0.2002315626619017), 52: (4, 127, 0.20018651021101813), 53: (4, 127, 0.20000307925602817), 54: (4, 127, 0.20018660620324255), 55: (4, 127, 0.20001218806013582), 56: (4, 127, 0.2001465221236306), 57: (4, 127, 0.200418826977275), 58: (4, 127, 0.20057155766825038), 59: (4, 127, 0.20025804110868708), 60: (4, 127, 0.20006199307945066), 61: (4, 127, 0.20004227061528623), 62: (4, 127, 0.20008066482841969), 63: (4, 127, 0.199904628303342), 64: (4, 127, 0.20015927668162217), 65: (4, 127, 0.19996610996643388), 66: (4, 127, 0.19992422982757016), 67: (4, 127, 0.19990630972191809), 68: (4, 127, 0.2000487041036327), 69: (4, 127, 0.20036386046558619), 70: (4, 127, 0.2004958163858868)}\n",
      "{'predict_runtime': 1815.7514, 'predict_samples_per_second': 0.155, 'predict_steps_per_second': 0.039}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:30:15.75\n",
      "  predict_samples_per_second =      0.155\n",
      "  predict_steps_per_second   =      0.039\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 25\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 24, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3696984928101301), 2: (1, 0.21475411113351583), 3: (1, 0.2206636918708682), 4: (1, 0.2104758219793439), 5: (1, 0.2083059372380376), 6: (1, 0.21072067879140377), 7: (1, 0.21010892651975155), 8: (1, 0.20998973678797483), 9: (1, 0.20861919410526752), 10: (1, 0.21073816996067762), 11: (1, 0.20975740067660809), 12: (1, 0.2095042346045375), 13: (1, 0.21067941095679998), 14: (1, 0.2114046011120081), 15: (1, 0.2124005202203989), 16: (1, 0.20839152671396732), 17: (1, 0.20978703070431948), 18: (1, 0.2162805162370205), 19: (1, 0.2101071672514081), 20: (1, 0.20861621666699648), 21: (1, 0.20896555110812187), 22: (1, 0.2097265226766467), 23: (1, 0.2099957587197423), 24: (1, 0.2082536593079567), 25: (1, 0.21134096384048462), 26: (1, 0.21033717598766088), 27: (1, 0.20980518404394388), 28: (1, 0.20789219718426466), 29: (1, 0.21077893301844597), 30: (1, 0.20878256671130657), 31: (1, 0.21023984998464584), 32: (1, 0.20801808591932058), 33: (1, 0.21138185635209084), 34: (1, 0.2106622252613306), 35: (1, 0.2091216528788209), 36: (1, 0.2078110696747899), 37: (1, 0.21138427779078484), 38: (1, 0.2105135265737772), 39: (1, 0.2082494543865323), 40: (1, 0.2151734633371234), 41: (1, 0.21075977478176355), 42: (1, 0.20860464125871658), 43: (1, 0.21032513957470655), 44: (1, 0.2085422109812498), 45: (1, 0.21291493996977806), 46: (1, 0.20905022602528334), 47: (1, 0.2085433518514037), 48: (1, 0.21022247150540352), 49: (1, 0.20931313186883926), 50: (1, 0.21004778519272804), 51: (1, 0.20875211991369724), 52: (1, 0.2101164236664772), 53: (1, 0.20953452121466398), 54: (1, 0.20950396172702312), 55: (1, 0.21013029385358095), 56: (1, 0.2127569830045104), 57: (1, 0.20870931074023247), 58: (1, 0.20864269230514765), 59: (1, 0.20982570853084326), 60: (1, 0.21025255415588617), 61: (1, 0.20906383730471134), 62: (1, 0.20888239983469248), 63: (1, 0.21009175572544336), 64: (1, 0.21062424965202808), 65: (1, 0.20982801727950573), 66: (1, 0.2078846925869584), 67: (1, 0.20966119039803743), 68: (1, 0.2126538958400488), 69: (1, 0.2085430733859539), 70: (1, 0.20956030301749706), 71: (1, 0.20737568754702806)}\n",
      "{1: (1, 127, 0.12848266221465557), 2: (1, 127, 0.12405822197283346), 3: (1, 127, 0.12357045690287051), 4: (1, 127, 0.12384068860313086), 5: (1, 127, 0.1235783579795966), 6: (1, 127, 0.12409327074328041), 7: (1, 127, 0.12431303911116415), 8: (1, 127, 0.12367832236813278), 9: (1, 127, 0.12375909959765401), 10: (1, 127, 0.12444628775853106), 11: (1, 127, 0.12465548725784059), 12: (1, 127, 0.12474982362739213), 13: (1, 127, 0.1239394167452816), 14: (1, 127, 0.12392860080489493), 15: (1, 127, 0.1237140749544492), 16: (1, 127, 0.12447527886962327), 17: (1, 127, 0.13111389954171077), 18: (1, 127, 0.12447985012348242), 19: (1, 127, 0.12398703234255548), 20: (1, 127, 0.12404308671234396), 21: (1, 127, 0.12406146436871036), 22: (1, 127, 0.12419333871395334), 23: (1, 127, 0.12399902697065919), 24: (1, 127, 0.12408397611465276), 25: (1, 127, 0.12395801095981297), 26: (1, 127, 0.12386993736058004), 27: (1, 127, 0.12393272440059214), 28: (1, 127, 0.12390705218582641), 29: (1, 127, 0.12383286990811974), 30: (1, 127, 0.12397726443339521), 31: (1, 127, 0.12382412497247533), 32: (1, 127, 0.12392958445019844), 33: (1, 127, 0.12396541206298146), 34: (1, 127, 0.12404459656956862), 35: (1, 127, 0.12390976909577377), 36: (1, 127, 0.12401084561546252), 37: (1, 127, 0.1239109292450383), 38: (1, 127, 0.12394773038324174), 39: (1, 127, 0.12394265020926168), 40: (1, 127, 0.12391968952917208), 41: (1, 127, 0.12406222871321393), 42: (1, 127, 0.1239838929494887), 43: (1, 127, 0.124029564069892), 44: (1, 127, 0.12405420660855264), 45: (1, 127, 0.12401632460816873), 46: (1, 127, 0.12389458178388556), 47: (1, 127, 0.12396050416167796), 48: (1, 127, 0.12397836134805688), 49: (1, 127, 0.12396555748130159), 50: (1, 127, 0.12391841101394159), 51: (1, 127, 0.12398530652849224), 52: (1, 127, 0.12403987643609601), 53: (1, 127, 0.12397895053058393), 54: (1, 127, 0.12397436246891895), 55: (1, 127, 0.12396646390749713), 56: (1, 127, 0.1240177988844711), 57: (1, 127, 0.12393775075586058), 58: (1, 127, 0.12381514147892007), 59: (1, 127, 0.12390194030287932), 60: (1, 127, 0.12402438475772387), 61: (1, 127, 0.12386572488590958), 62: (1, 127, 0.12382329080811166), 63: (1, 127, 0.123938113627002), 64: (1, 127, 0.12393225739732033), 65: (1, 127, 0.12380978330881812), 66: (1, 127, 0.12372706946366885), 67: (1, 127, 0.12370939431785363), 68: (1, 127, 0.12381908089274496), 69: (1, 127, 0.12360971720199886), 70: (1, 127, 0.12377295896821604)}\n",
      "{'predict_runtime': 1134.4002, 'predict_samples_per_second': 0.063, 'predict_steps_per_second': 0.063}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:18:54.40\n",
      "  predict_samples_per_second =      0.063\n",
      "  predict_steps_per_second   =      0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2717793229967356), 2: (2, 0.24582297820597887), 3: (2, 0.23192629124969244), 4: (2, 0.24697108194231987), 5: (2, 0.22645248286426067), 6: (2, 0.24484638776630163), 7: (2, 0.23760711308568716), 8: (2, 0.23509795311838388), 9: (2, 0.2287342380732298), 10: (2, 0.22905021347105503), 11: (2, 0.2259274097159505), 12: (2, 0.24514254555106163), 13: (2, 0.22521929908543825), 14: (2, 0.2298777149990201), 15: (2, 0.24597523640841246), 16: (2, 0.24525789450854063), 17: (2, 0.22879305761307478), 18: (2, 0.23761376459151506), 19: (2, 0.22990193497389555), 20: (2, 0.24264243710786104), 21: (2, 0.24542695377022028), 22: (2, 0.24400571081787348), 23: (2, 0.22933146357536316), 24: (2, 0.22940627206116915), 25: (2, 0.23613202385604382), 26: (2, 0.2273902976885438), 27: (2, 0.2426456082612276), 28: (2, 0.2443463383242488), 29: (2, 0.2291392870247364), 30: (2, 0.24539286736398935), 31: (2, 0.2447173735126853), 32: (2, 0.24440595787018538), 33: (2, 0.2319634836167097), 34: (2, 0.23665545880794525), 35: (2, 0.2433218415826559), 36: (2, 0.23249792773276567), 37: (2, 0.23727888241410255), 38: (2, 0.2277752524241805), 39: (2, 0.24590423051267862), 40: (2, 0.23325776029378176), 41: (2, 0.23906427156180143), 42: (2, 0.2420356273651123), 43: (2, 0.22951411549001932), 44: (2, 0.2332004914060235), 45: (2, 0.24459326826035976), 46: (2, 0.24533898942172527), 47: (2, 0.24677173234522343), 48: (2, 0.24600788205862045), 49: (2, 0.24486185610294342), 50: (2, 0.24432826228439808), 51: (2, 0.24629670847207308), 52: (2, 0.22698581498116255), 53: (2, 0.24423138238489628), 54: (2, 0.23190283868461847), 55: (2, 0.24539716076105833), 56: (2, 0.24901205766946077), 57: (2, 0.24610186275094748), 58: (2, 0.25171323772519827), 59: (2, 0.2505658306181431), 60: (2, 0.23275522887706757), 61: (2, 0.2466765372082591), 62: (2, 0.23137455433607101), 63: (2, 0.23140528611838818), 64: (2, 0.22954588755965233), 65: (2, 0.2499097092077136), 66: (2, 0.2330486671999097), 67: (2, 0.2330811358988285), 68: (2, 0.22829444147646427), 69: (2, 0.2514416519552469), 70: (2, 0.24392012134194374), 71: (1, 0.22647070419043303)}\n",
      "{1: (2, 127, 0.19236776197519828), 2: (2, 127, 0.19186224602162838), 3: (2, 127, 0.19201155930874855), 4: (2, 127, 0.19193671748599433), 5: (2, 127, 0.19198835665345426), 6: (2, 127, 0.19199966873944274), 7: (2, 127, 0.1919555932826062), 8: (2, 127, 0.1919935012720232), 9: (2, 127, 0.1921332524796053), 10: (2, 127, 0.1919712913992602), 11: (2, 127, 0.19184339354474714), 12: (2, 127, 0.1920798696636215), 13: (2, 127, 0.19192327905856954), 14: (2, 127, 0.19185892282068495), 15: (2, 127, 0.1919790649507928), 16: (2, 127, 0.19196542180839957), 17: (2, 127, 0.19194700785245247), 18: (2, 127, 0.19193844827200016), 19: (2, 127, 0.1919077193276502), 20: (2, 127, 0.19188287285134548), 21: (2, 127, 0.19186826759406667), 22: (2, 127, 0.1918935667298089), 23: (2, 127, 0.19187030455786883), 24: (2, 127, 0.19209271171460235), 25: (2, 127, 0.19213673803867318), 26: (2, 127, 0.19222664264008754), 27: (2, 127, 0.1921544743511151), 28: (2, 127, 0.1920644338279376), 29: (2, 127, 0.1920765577632142), 30: (2, 127, 0.19204542638484653), 31: (2, 127, 0.19204371806791448), 32: (2, 127, 0.19204765791440104), 33: (2, 127, 0.19212978198303013), 34: (2, 127, 0.19209049155891644), 35: (2, 127, 0.19217970404832616), 36: (2, 127, 0.19214749251910318), 37: (2, 127, 0.19216989822627054), 38: (2, 127, 0.19215770639244498), 39: (2, 127, 0.1925488914707749), 40: (2, 127, 0.19222186188998186), 41: (2, 127, 0.19180946323404632), 42: (2, 127, 0.1917836091033821), 43: (2, 127, 0.19172128744599387), 44: (2, 127, 0.19177838367974664), 45: (2, 127, 0.19178358620164668), 46: (2, 127, 0.1918003285069048), 47: (2, 127, 0.1917622419968834), 48: (2, 127, 0.1917180738917838), 49: (2, 127, 0.19170041557577416), 50: (2, 127, 0.1916383824963856), 51: (2, 127, 0.1919273720012875), 52: (2, 127, 0.19181527753954564), 53: (2, 127, 0.19175000669156003), 54: (2, 127, 0.19170502607717993), 55: (2, 127, 0.19182083911196454), 56: (2, 127, 0.1922335233099348), 57: (2, 127, 0.19207607833741921), 58: (2, 127, 0.1921736954337382), 59: (2, 127, 0.1923419518586923), 60: (2, 127, 0.19208820226536258), 61: (2, 127, 0.19213789685328644), 62: (2, 127, 0.1922287167834602), 63: (2, 127, 0.19214230750900085), 64: (2, 127, 0.19204194180110074), 65: (2, 127, 0.19216399268782514), 66: (2, 127, 0.19221327475851446), 67: (2, 127, 0.19230609789021372), 68: (2, 127, 0.19234538944364768), 69: (2, 127, 0.19243997166769242), 70: (2, 127, 0.19234443810130433)}\n",
      "{'predict_runtime': 1739.8305, 'predict_samples_per_second': 0.081, 'predict_steps_per_second': 0.041}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:28:59.83\n",
      "  predict_samples_per_second =      0.081\n",
      "  predict_steps_per_second   =      0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3361430037766695), 2: (4, 0.29627238865941763), 3: (4, 0.2955695167183876), 4: (4, 0.2978271506726742), 5: (4, 0.29915351513773203), 6: (4, 0.2998485565185547), 7: (4, 0.2974392771720886), 8: (4, 0.31297542434185743), 9: (4, 0.31117064598947763), 10: (4, 0.30003831535577774), 11: (4, 0.3180102873593569), 12: (4, 0.29571755696088076), 13: (4, 0.2947388291358948), 14: (4, 0.31255593057721853), 15: (4, 0.30583935882896185), 16: (4, 0.2953238720074296), 17: (4, 0.29472449980676174), 18: (4, 0.29665159806609154), 19: (4, 0.2926519336178899), 20: (4, 0.29500425700098276), 21: (4, 0.3141442136839032), 22: (4, 0.295315645635128), 23: (4, 0.2940380210056901), 24: (4, 0.30009808856993914), 25: (4, 0.30066283233463764), 26: (4, 0.29386642295867205), 27: (4, 0.3001179387792945), 28: (4, 0.29529172647744417), 29: (4, 0.2978877564892173), 30: (4, 0.31477382592856884), 31: (4, 0.2962764548137784), 32: (4, 0.29777002800256014), 33: (4, 0.2980911750346422), 34: (4, 0.3023950345814228), 35: (4, 0.29632716719061136), 36: (4, 0.29968804679811), 37: (4, 0.3010712107643485), 38: (4, 0.3125835945829749), 39: (4, 0.3110046945512295), 40: (4, 0.2971895383670926), 41: (4, 0.29802026972174644), 42: (4, 0.29929741378873587), 43: (4, 0.29493748489767313), 44: (4, 0.2961988802999258), 45: (4, 0.30035607144236565), 46: (4, 0.29935087356716394), 47: (4, 0.29561561811715364), 48: (4, 0.29672979563474655), 49: (4, 0.2944615427404642), 50: (4, 0.3021218627691269), 51: (4, 0.29925825726240873), 52: (4, 0.3018733663484454), 53: (4, 0.2956667495891452), 54: (4, 0.3153829062357545), 55: (4, 0.29806167259812355), 56: (4, 0.29661847185343504), 57: (4, 0.30031386855989695), 58: (4, 0.29690886102616787), 59: (4, 0.3012984683737159), 60: (4, 0.29429651517421007), 61: (4, 0.2973897187039256), 62: (4, 0.29939357470721006), 63: (4, 0.30163343995809555), 64: (4, 0.3004965241998434), 65: (4, 0.3014707947149873), 66: (4, 0.30250258184969425), 67: (4, 0.29888799600303173), 68: (4, 0.3012816486880183), 69: (4, 0.3007059572264552), 70: (4, 0.31346024572849274), 71: (1, 0.21070130728185177)}\n",
      "{1: (4, 127, 0.19261602307926481), 2: (4, 127, 0.19235695417471757), 3: (4, 127, 0.1924592123887553), 4: (4, 127, 0.19221150586161556), 5: (4, 127, 0.19225864102110618), 6: (4, 127, 0.1922139430667941), 7: (4, 127, 0.1922073998583818), 8: (4, 127, 0.19215752788650708), 9: (4, 127, 0.19230945787473222), 10: (4, 127, 0.19210940023781511), 11: (4, 127, 0.19232277477556092), 12: (4, 127, 0.19235474570089672), 13: (4, 127, 0.19219875455225313), 14: (4, 127, 0.19228626238402186), 15: (4, 127, 0.19230266110458244), 16: (4, 127, 0.19221497972415189), 17: (4, 127, 0.1923099813880179), 18: (4, 127, 0.19239535987171835), 19: (4, 127, 0.19222743318628843), 20: (4, 127, 0.1921066615554526), 21: (4, 127, 0.192315431649056), 22: (4, 127, 0.19213871479650416), 23: (4, 127, 0.19215476025247902), 24: (4, 127, 0.19204690978371017), 25: (4, 127, 0.19218125244910558), 26: (4, 127, 0.19206504769417948), 27: (4, 127, 0.19222503955527317), 28: (4, 127, 0.19213343061154753), 29: (4, 127, 0.19214555556614568), 30: (4, 127, 0.1919876820679138), 31: (4, 127, 0.19235079190657128), 32: (4, 127, 0.19222649469179667), 33: (4, 127, 0.19209780972304308), 34: (4, 127, 0.1920960730191056), 35: (4, 127, 0.19212674326080037), 36: (4, 127, 0.19199059098430976), 37: (4, 127, 0.1921904612640579), 38: (4, 127, 0.19193415032098377), 39: (4, 127, 0.19223391216277608), 40: (4, 127, 0.19212465838888498), 41: (4, 127, 0.1922412636491844), 42: (4, 127, 0.1919991149251738), 43: (4, 127, 0.19217867857417253), 44: (4, 127, 0.1921093453484492), 45: (4, 127, 0.19202482101954813), 46: (4, 127, 0.1919997656849895), 47: (4, 127, 0.1920456884824854), 48: (4, 127, 0.1920567215310307), 49: (4, 127, 0.19204025553524728), 50: (4, 127, 0.19200241805501575), 51: (4, 127, 0.19197572682668843), 52: (4, 127, 0.19205288657199915), 53: (4, 127, 0.19199203457096664), 54: (4, 127, 0.19199221155892207), 55: (4, 127, 0.1920795361621408), 56: (4, 127, 0.19200919930067822), 57: (4, 127, 0.19203740510884232), 58: (4, 127, 0.19202349069491614), 59: (4, 127, 0.19215745552200972), 60: (4, 127, 0.19206317173918402), 61: (4, 127, 0.19206484263454834), 62: (4, 127, 0.19201779898666727), 63: (4, 127, 0.19215642481191655), 64: (4, 127, 0.19222062390561648), 65: (4, 127, 0.19216967334486837), 66: (4, 127, 0.19201737431090649), 67: (4, 127, 0.19190578972260783), 68: (4, 127, 0.191974535738448), 69: (4, 127, 0.19214296187677488), 70: (4, 127, 0.19205462406792745)}\n",
      "{'predict_runtime': 1745.138, 'predict_samples_per_second': 0.161, 'predict_steps_per_second': 0.041}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:29:05.13\n",
      "  predict_samples_per_second =      0.161\n",
      "  predict_steps_per_second   =      0.041\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 24\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.24593247566372156), 2: (1, 0.21789889223873615), 3: (1, 0.2207213882356882), 4: (1, 0.21678834781050682), 5: (1, 0.2168400352820754), 6: (1, 0.2195851244032383), 7: (1, 0.21978424210101366), 8: (1, 0.22063231095671654), 9: (1, 0.21911820024251938), 10: (1, 0.21740814205259085), 11: (1, 0.21891613397747278), 12: (1, 0.21902412455528975), 13: (1, 0.2196642067283392), 14: (1, 0.2179204486310482), 15: (1, 0.2200592616572976), 16: (1, 0.22022693138569593), 17: (1, 0.22043847851455212), 18: (1, 0.21684195194393396), 19: (1, 0.2162913791835308), 20: (1, 0.21832401491701603), 21: (1, 0.2191741056740284), 22: (1, 0.2176989335566759), 23: (1, 0.21889297012239695), 24: (1, 0.21794625092297792), 25: (1, 0.2186254821717739), 26: (1, 0.22042589262127876), 27: (1, 0.21912012062966824), 28: (1, 0.21847871597856283), 29: (1, 0.2167183980345726), 30: (1, 0.219107530079782), 31: (1, 0.21653997246176004), 32: (1, 0.22027310635894537), 33: (1, 0.22073759231716394), 34: (1, 0.22042734548449516), 35: (1, 0.2211922872811556), 36: (1, 0.2170414375141263), 37: (1, 0.21730741392821074), 38: (1, 0.21642964519560337), 39: (1, 0.216799751855433), 40: (1, 0.21900557447224855), 41: (1, 0.22080188244581223), 42: (1, 0.2197532979771495), 43: (1, 0.22046419978141785), 44: (1, 0.2203702898696065), 45: (1, 0.22058658674359322), 46: (1, 0.2195804798975587), 47: (1, 0.2183579644188285), 48: (1, 0.21665219590067863), 49: (1, 0.21836492512375116), 50: (1, 0.21792446170002222), 51: (1, 0.21765726432204247), 52: (1, 0.2193641047924757), 53: (1, 0.2204561112448573), 54: (1, 0.21804406214505434), 55: (1, 0.2171186525374651), 56: (1, 0.21753272786736488), 57: (1, 0.2200836492702365), 58: (1, 0.21956643369048834), 59: (1, 0.21936748642474413), 60: (1, 0.2179380040615797), 61: (1, 0.2211489761248231), 62: (1, 0.21930897887796164), 63: (1, 0.21966554503887892), 64: (1, 0.220369016751647), 65: (1, 0.2205537548288703), 66: (1, 0.21699967700988054), 67: (1, 0.21668638195842505), 68: (1, 0.2201203303411603), 69: (1, 0.21999428234994411), 70: (1, 0.22941286116838455), 71: (1, 0.21603803988546133)}\n",
      "{1: (1, 127, 0.12902918527650786), 2: (1, 127, 0.12901707879436297), 3: (1, 127, 0.12930737457817465), 4: (1, 127, 0.12897396689706195), 5: (1, 127, 0.12898840945888693), 6: (1, 127, 0.12897275597971725), 7: (1, 127, 0.1288031991717853), 8: (1, 127, 0.12897568377189514), 9: (1, 127, 0.12889207000514186), 10: (1, 127, 0.12892779961639034), 11: (1, 127, 0.12908870812622816), 12: (1, 127, 0.1290958620842517), 13: (1, 127, 0.12909807185605754), 14: (1, 127, 0.12897813679489095), 15: (1, 127, 0.12896557232203681), 16: (1, 127, 0.1290611427086662), 17: (1, 127, 0.12901125017436235), 18: (1, 127, 0.12895293720799872), 19: (1, 127, 0.1290014064760776), 20: (1, 127, 0.12906061832272397), 21: (1, 127, 0.12904752628863092), 22: (1, 127, 0.128999042625385), 23: (1, 127, 0.12911746004875016), 24: (1, 127, 0.12907991311182893), 25: (1, 127, 0.12901413059375416), 26: (1, 127, 0.1289667857253528), 27: (1, 127, 0.12890318561873332), 28: (1, 127, 0.12892481057691996), 29: (1, 127, 0.12887613579454854), 30: (1, 127, 0.12898447756164186), 31: (1, 127, 0.12881811734611595), 32: (1, 127, 0.12891115938261974), 33: (1, 127, 0.12903834321338126), 34: (1, 127, 0.12898415472270466), 35: (1, 127, 0.12911340561292067), 36: (1, 127, 0.12921514627560388), 37: (1, 127, 0.12916237107060086), 38: (1, 127, 0.1291821061626194), 39: (1, 127, 0.1290336605234761), 40: (1, 127, 0.12903691897183422), 41: (1, 127, 0.12893144673425852), 42: (1, 127, 0.1291229419894223), 43: (1, 127, 0.1290839850301231), 44: (1, 127, 0.12909684737953614), 45: (1, 127, 0.12915848890744794), 46: (1, 127, 0.12911934595496402), 47: (1, 127, 0.1291044998664673), 48: (1, 127, 0.12907950140125168), 49: (1, 127, 0.12900520075024582), 50: (1, 127, 0.12896081517765842), 51: (1, 127, 0.12900344519252618), 52: (1, 127, 0.1290805738375295), 53: (1, 127, 0.12908182913569485), 54: (1, 127, 0.12905400067450493), 55: (1, 127, 0.12907153515394512), 56: (1, 127, 0.12906662989261114), 57: (1, 127, 0.12894115077815657), 58: (1, 127, 0.12896194348595744), 59: (1, 127, 0.12916723486241394), 60: (1, 127, 0.1290975871209906), 61: (1, 127, 0.12905716480995258), 62: (1, 127, 0.1290134002021917), 63: (1, 127, 0.1291049057837781), 64: (1, 127, 0.1291575878198574), 65: (1, 127, 0.12898092691265928), 66: (1, 127, 0.12897210031395823), 67: (1, 127, 0.1289589579957794), 68: (1, 127, 0.12902238131977442), 69: (1, 127, 0.12890975948012484), 70: (1, 127, 0.1290177831308931)}\n",
      "{'predict_runtime': 1179.0198, 'predict_samples_per_second': 0.06, 'predict_steps_per_second': 0.06}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:19:39.01\n",
      "  predict_samples_per_second =       0.06\n",
      "  predict_steps_per_second   =       0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2697489019483328), 2: (2, 0.24965946190059185), 3: (2, 0.23652342800050974), 4: (2, 0.25428163819015026), 5: (2, 0.23670070711523294), 6: (2, 0.2582069616764784), 7: (2, 0.25407877191901207), 8: (2, 0.25414644181728363), 9: (2, 0.2531620943918824), 10: (2, 0.252870537340641), 11: (2, 0.25323901418596506), 12: (2, 0.2591253248974681), 13: (2, 0.23950694780796766), 14: (2, 0.2346359770745039), 15: (2, 0.25871681049466133), 16: (2, 0.23643096629530191), 17: (2, 0.25527477264404297), 18: (2, 0.2540958672761917), 19: (2, 0.25265675596892834), 20: (2, 0.23957733158022165), 21: (2, 0.23664322588592768), 22: (2, 0.24178563337773085), 23: (2, 0.238244385458529), 24: (2, 0.2546202037483454), 25: (2, 0.23988865595310926), 26: (2, 0.23850269336253405), 27: (2, 0.24502856750041246), 28: (2, 0.24702350329607725), 29: (2, 0.23506317473948002), 30: (2, 0.25298128370195627), 31: (2, 0.23580851592123508), 32: (2, 0.2556499531492591), 33: (2, 0.23558058962225914), 34: (2, 0.25445676781237125), 35: (2, 0.2551156906411052), 36: (2, 0.2528519667685032), 37: (2, 0.2537391157820821), 38: (2, 0.25586647167801857), 39: (2, 0.2535358304157853), 40: (2, 0.2532439026981592), 41: (2, 0.23724843189120293), 42: (2, 0.24520991928875446), 43: (2, 0.2554436083883047), 44: (2, 0.25525944121181965), 45: (2, 0.25377269834280014), 46: (2, 0.25425609294325113), 47: (2, 0.255657447502017), 48: (2, 0.25267486181110144), 49: (2, 0.24711103830486536), 50: (2, 0.25498921517282724), 51: (2, 0.25369412172585726), 52: (2, 0.2545228209346533), 53: (2, 0.2555625792592764), 54: (2, 0.2584324674680829), 55: (2, 0.25597184617072344), 56: (2, 0.2542383661493659), 57: (2, 0.2526815449818969), 58: (2, 0.25554479099810123), 59: (2, 0.2542302357032895), 60: (2, 0.2524118786677718), 61: (2, 0.25483414996415377), 62: (2, 0.2468147948384285), 63: (2, 0.25354328006505966), 64: (2, 0.2551808310672641), 65: (2, 0.2554246988147497), 66: (2, 0.2525691706687212), 67: (2, 0.2553823683410883), 68: (2, 0.2550825420767069), 69: (2, 0.23790960386395454), 70: (2, 0.25425284169614315), 71: (1, 0.23650403879582882)}\n",
      "{1: (2, 127, 0.20068203921862474), 2: (2, 127, 0.20065648528915925), 3: (2, 127, 0.20030855880243573), 4: (2, 127, 0.20040411421457144), 5: (2, 127, 0.19989707542392682), 6: (2, 127, 0.1999219504779014), 7: (2, 127, 0.19983387299204672), 8: (2, 127, 0.19958165533635325), 9: (2, 127, 0.19966145571115917), 10: (2, 127, 0.1995595600236002), 11: (2, 127, 0.19956244011299581), 12: (2, 127, 0.19998124493359345), 13: (2, 127, 0.19994898889155135), 14: (2, 127, 0.20006531588439866), 15: (2, 127, 0.19990690305506384), 16: (2, 127, 0.19946362667783038), 17: (2, 127, 0.19941385364614603), 18: (2, 127, 0.19941782847956174), 19: (2, 127, 0.19936632703784413), 20: (2, 127, 0.19946346698167522), 21: (2, 127, 0.19949527789552615), 22: (2, 127, 0.19953940716374108), 23: (2, 127, 0.1994079226246617), 24: (2, 127, 0.1995093121860675), 25: (2, 127, 0.19944099768790907), 26: (2, 127, 0.19936784741094732), 27: (2, 127, 0.199307214864713), 28: (2, 127, 0.19957143058780374), 29: (2, 127, 0.19950806248317085), 30: (2, 127, 0.19943524785633163), 31: (2, 127, 0.19938856449828843), 32: (2, 127, 0.19950872397152927), 33: (2, 127, 0.19941304739212662), 34: (2, 127, 0.19953923907834947), 35: (2, 127, 0.1993583550779369), 36: (2, 127, 0.19950027374448034), 37: (2, 127, 0.1993367837771304), 38: (2, 127, 0.1994594111525285), 39: (2, 127, 0.19938290678698012), 40: (2, 127, 0.1996166604886374), 41: (2, 127, 0.1996297007939947), 42: (2, 127, 0.19940751639935445), 43: (2, 127, 0.19958803402333278), 44: (2, 127, 0.1994062248896074), 45: (2, 127, 0.19957245355398637), 46: (2, 127, 0.1995291467169373), 47: (2, 127, 0.19948932190433027), 48: (2, 127, 0.19949015548203405), 49: (2, 127, 0.19962646959598843), 50: (2, 127, 0.19959570449138955), 51: (2, 127, 0.1995240519204595), 52: (2, 127, 0.19946053649819506), 53: (2, 127, 0.19939695893398185), 54: (2, 127, 0.1994371598322443), 55: (2, 127, 0.19949165158941756), 56: (2, 127, 0.19938927843404097), 57: (2, 127, 0.19938954499029504), 58: (2, 127, 0.19950804134874833), 59: (2, 127, 0.1995251611769786), 60: (2, 127, 0.19937010718817552), 61: (2, 127, 0.1994836443785842), 62: (2, 127, 0.19939127282100164), 63: (2, 127, 0.19943518624237672), 64: (2, 127, 0.19940662738229112), 65: (2, 127, 0.199387561801205), 66: (2, 127, 0.1993767617226351), 67: (2, 127, 0.1994782139393171), 68: (2, 127, 0.19961350923037435), 69: (2, 127, 0.19950324093820307), 70: (2, 127, 0.1994910550443089)}\n",
      "{'predict_runtime': 1808.4818, 'predict_samples_per_second': 0.078, 'predict_steps_per_second': 0.039}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:30:08.48\n",
      "  predict_samples_per_second =      0.078\n",
      "  predict_steps_per_second   =      0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3494840292260051), 2: (4, 0.3100220803171396), 3: (4, 0.3062907140702009), 4: (4, 0.30897089187055826), 5: (4, 0.31210354529321194), 6: (4, 0.309306176379323), 7: (4, 0.3067865679040551), 8: (4, 0.3104728739708662), 9: (4, 0.30625481344759464), 10: (4, 0.30923706851899624), 11: (4, 0.307334060780704), 12: (4, 0.3093738155439496), 13: (4, 0.3074504481628537), 14: (4, 0.3094415459781885), 15: (4, 0.30815887078642845), 16: (4, 0.30843642726540565), 17: (4, 0.30579666793346405), 18: (4, 0.31388365384191275), 19: (4, 0.3071978408843279), 20: (4, 0.30839853733778), 21: (4, 0.3090301100164652), 22: (4, 0.308527366258204), 23: (4, 0.30593208596110344), 24: (4, 0.30872797314077616), 25: (4, 0.310423512943089), 26: (4, 0.3064683796837926), 27: (4, 0.3082933183759451), 28: (4, 0.30997052788734436), 29: (4, 0.308346807025373), 30: (4, 0.31053300108760595), 31: (4, 0.3111096750944853), 32: (4, 0.3091194573789835), 33: (4, 0.31164971739053726), 34: (4, 0.311185403726995), 35: (4, 0.3118339776992798), 36: (4, 0.30824547819793224), 37: (4, 0.3089308002963662), 38: (4, 0.30465198028832674), 39: (4, 0.3071515616029501), 40: (4, 0.3090486181899905), 41: (4, 0.3083337265998125), 42: (4, 0.3090908983722329), 43: (4, 0.30877593252807856), 44: (4, 0.30814474914222956), 45: (4, 0.3098282888531685), 46: (4, 0.30628449004143476), 47: (4, 0.3103129640221596), 48: (4, 0.3117980360984802), 49: (4, 0.30465313978493214), 50: (4, 0.3078789720311761), 51: (4, 0.3079970395192504), 52: (4, 0.30967128090560436), 53: (4, 0.30721061024814844), 54: (4, 0.3060435736551881), 55: (4, 0.3088251408189535), 56: (4, 0.31112900376319885), 57: (4, 0.3087556818500161), 58: (4, 0.30696723237633705), 59: (4, 0.3095464911311865), 60: (4, 0.30692039150744677), 61: (4, 0.30876654107123613), 62: (4, 0.3074764357879758), 63: (4, 0.3058765446767211), 64: (4, 0.3062725402414799), 65: (4, 0.30554928816854954), 66: (4, 0.30548988934606314), 67: (4, 0.31040581222623587), 68: (4, 0.30831498466432095), 69: (4, 0.30588220432400703), 70: (4, 0.30309673864394426), 71: (1, 0.21449927240610123)}\n",
      "{1: (4, 127, 0.2008728694508043), 2: (4, 127, 0.2002190767941395), 3: (4, 127, 0.19997354961315714), 4: (4, 127, 0.19985768855292732), 5: (4, 127, 0.1999285112274444), 6: (4, 127, 0.1997773579035805), 7: (4, 127, 0.1997673497791952), 8: (4, 127, 0.19987770686234077), 9: (4, 127, 0.1999004830085621), 10: (4, 127, 0.19995171519539018), 11: (4, 127, 0.1999517936611504), 12: (4, 127, 0.2001807668546992), 13: (4, 127, 0.20000661410919324), 14: (4, 127, 0.20009183250807636), 15: (4, 127, 0.19996852147590927), 16: (4, 127, 0.19996367337724824), 17: (4, 127, 0.19983708307029693), 18: (4, 127, 0.199905302639552), 19: (4, 127, 0.20018961502048443), 20: (4, 127, 0.2001739220884372), 21: (4, 127, 0.20099760069123168), 22: (4, 127, 0.2004165280698322), 23: (4, 127, 0.20018874313388987), 24: (4, 127, 0.19978960800006634), 25: (4, 127, 0.19981724487280283), 26: (4, 127, 0.1999211246441082), 27: (4, 127, 0.19985920289810014), 28: (4, 127, 0.1998896062022119), 29: (4, 127, 0.19993970668544686), 30: (4, 127, 0.19989414048916476), 31: (4, 127, 0.2001454164897363), 32: (4, 127, 0.20002119084013495), 33: (4, 127, 0.19997949466314607), 34: (4, 127, 0.19987240870021225), 35: (4, 127, 0.19979372864046435), 36: (4, 127, 0.20001303597434064), 37: (4, 127, 0.19972453695377262), 38: (4, 127, 0.199716479444187), 39: (4, 127, 0.19975916876303634), 40: (4, 127, 0.19988684968538875), 41: (4, 127, 0.20092186786410376), 42: (4, 127, 0.20006185732635223), 43: (4, 127, 0.19984667163019573), 44: (4, 127, 0.1996658749687742), 45: (4, 127, 0.19983639736021833), 46: (4, 127, 0.1997822089135412), 47: (4, 127, 0.1995805450165131), 48: (4, 127, 0.19966440227645355), 49: (4, 127, 0.19977338340016096), 50: (4, 127, 0.1996429486156214), 51: (4, 127, 0.19965405813528328), 52: (4, 127, 0.19971033713714345), 53: (4, 127, 0.199816807275858), 54: (4, 127, 0.19971021707719705), 55: (4, 127, 0.199738732942446), 56: (4, 127, 0.20024875482529636), 57: (4, 127, 0.19987500310824144), 58: (4, 127, 0.2000016403479839), 59: (4, 127, 0.19981791373107613), 60: (4, 127, 0.1997917780256647), 61: (4, 127, 0.19978991092923354), 62: (4, 127, 0.19979843806006073), 63: (4, 127, 0.1997030226029749), 64: (4, 127, 0.19988746374229513), 65: (4, 127, 0.19977756208322178), 66: (4, 127, 0.19991417298108105), 67: (4, 127, 0.19968067986641344), 68: (4, 127, 0.19985756919697278), 69: (4, 127, 0.19973019561107), 70: (4, 127, 0.1997511726694079)}\n",
      "{'predict_runtime': 1815.5202, 'predict_samples_per_second': 0.155, 'predict_steps_per_second': 0.039}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:30:15.52\n",
      "  predict_samples_per_second =      0.155\n",
      "  predict_steps_per_second   =      0.039\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 25\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3802434215322137), 2: (1, 0.21676772460341454), 3: (1, 0.21278148237615824), 4: (1, 0.21183236502110958), 5: (1, 0.21315081883221865), 6: (1, 0.21489709801971912), 7: (1, 0.21181429643183947), 8: (1, 0.21642578206956387), 9: (1, 0.21221183240413666), 10: (1, 0.2119887536391616), 11: (1, 0.2173381419852376), 12: (1, 0.21186984609812498), 13: (1, 0.214619274251163), 14: (1, 0.21216101292520761), 15: (1, 0.21101559698581696), 16: (1, 0.21426329016685486), 17: (1, 0.21200758684426546), 18: (1, 0.21036753617227077), 19: (1, 0.21350938454270363), 20: (1, 0.2109309360384941), 21: (1, 0.2115701986476779), 22: (1, 0.21334564592689276), 23: (1, 0.21133831050246954), 24: (1, 0.21172040794044733), 25: (1, 0.21064156852662563), 26: (1, 0.2112403828650713), 27: (1, 0.21201124414801598), 28: (1, 0.21046277228742838), 29: (1, 0.21271885558962822), 30: (1, 0.21310947183519602), 31: (1, 0.2101066978648305), 32: (1, 0.212298602797091), 33: (1, 0.21056665293872356), 34: (1, 0.21350159775465727), 35: (1, 0.21366155706346035), 36: (1, 0.21275275759398937), 37: (1, 0.20983226224780083), 38: (1, 0.21303199417889118), 39: (1, 0.21131805423647165), 40: (1, 0.2167644714936614), 41: (1, 0.2130222348496318), 42: (1, 0.2132426230236888), 43: (1, 0.21397229470312595), 44: (1, 0.21118247974663973), 45: (1, 0.2130478359758854), 46: (1, 0.2124192239716649), 47: (1, 0.21165534295141697), 48: (1, 0.213017956353724), 49: (1, 0.21330702397972345), 50: (1, 0.21099968254566193), 51: (1, 0.21499138418585062), 52: (1, 0.21518133208155632), 53: (1, 0.21386131085455418), 54: (1, 0.21230968926101923), 55: (1, 0.21255091670900583), 56: (1, 0.21043038181960583), 57: (1, 0.21827654913067818), 58: (1, 0.2244365867227316), 59: (1, 0.21252606716006994), 60: (1, 0.21090690698474646), 61: (1, 0.2118619168177247), 62: (1, 0.2125976476818323), 63: (1, 0.2097796816378832), 64: (1, 0.2135732462629676), 65: (1, 0.21236602123826742), 66: (1, 0.21272764541208744), 67: (1, 0.21277441643178463), 68: (1, 0.21471259370446205), 69: (1, 0.20955571439117193), 70: (1, 0.21860716678202152), 71: (1, 0.2102741962298751)}\n",
      "{1: (1, 255, 0.1268130991315725), 2: (1, 255, 0.12558693499760884), 3: (1, 255, 0.12581224318082426), 4: (1, 255, 0.12766397876628474), 5: (1, 255, 0.12611513582660872), 6: (1, 255, 0.1261048023789829), 7: (1, 255, 0.1273309657058003), 8: (1, 255, 0.12914409657538523), 9: (1, 255, 0.12673631351002876), 10: (1, 255, 0.12679895931014828), 11: (1, 255, 0.12658830305890126), 12: (1, 255, 0.1299628382804347), 13: (1, 255, 0.12600681022101756), 14: (1, 255, 0.12600341867655515), 15: (1, 255, 0.12608022822030618), 16: (1, 255, 0.1267645133440109), 17: (1, 255, 0.12547812532706587), 18: (1, 255, 0.12558139726957854), 19: (1, 255, 0.12564974977616586), 20: (1, 255, 0.12585214744230697), 21: (1, 255, 0.1261846805027887), 22: (1, 255, 0.12588802686728098), 23: (1, 255, 0.12566687087071876), 24: (1, 255, 0.12551823303322582), 25: (1, 255, 0.12617815062038454), 26: (1, 255, 0.12600209396697726), 27: (1, 255, 0.1256519817765437), 28: (1, 255, 0.12555921197521921), 29: (1, 255, 0.12532525698782182), 30: (1, 255, 0.12554578587924148), 31: (1, 255, 0.12540640638885545), 32: (1, 255, 0.1256922545824565), 33: (1, 255, 0.12538080235541452), 34: (1, 255, 0.1256571305806146), 35: (1, 255, 0.12542725130185192), 36: (1, 255, 0.12560167254186144), 37: (1, 255, 0.12564080939354266), 38: (1, 255, 0.12561630441569815), 39: (1, 255, 0.1254099557468412), 40: (1, 255, 0.12544734516345402), 41: (1, 255, 0.12553925381644684), 42: (1, 255, 0.12564626788610922), 43: (1, 255, 0.12571921730961869), 44: (1, 255, 0.12531916192349266), 45: (1, 255, 0.12524648221465304), 46: (1, 255, 0.12524106966368123), 47: (1, 255, 0.1253703710020465), 48: (1, 255, 0.12538661011220778), 49: (1, 255, 0.12545901556663652), 50: (1, 255, 0.12796285169600857), 51: (1, 255, 0.1266560895952816), 52: (1, 255, 0.12660428303859983), 53: (1, 255, 0.12604851297961145), 54: (1, 255, 0.12622601297848365), 55: (1, 255, 0.12638431442353656), 56: (1, 255, 0.12625433948329268), 57: (1, 255, 0.1259281578492008), 58: (1, 255, 0.12641834739376517), 59: (1, 255, 0.12594182299559606), 60: (1, 255, 0.1256744408980012), 61: (1, 255, 0.12591950189249188), 62: (1, 255, 0.12592122452516183), 63: (1, 255, 0.12592621142519456), 64: (1, 255, 0.12590963317483078), 65: (1, 255, 0.12621275320941328), 66: (1, 255, 0.12701788693301233), 67: (1, 255, 0.12651468974483362), 68: (1, 255, 0.12597801867580297), 69: (1, 255, 0.12606489849002922), 70: (1, 255, 0.12588631842723663)}\n",
      "{'predict_runtime': 2297.8383, 'predict_samples_per_second': 0.031, 'predict_steps_per_second': 0.031}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:17.83\n",
      "  predict_samples_per_second =      0.031\n",
      "  predict_steps_per_second   =      0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2597840493544936), 2: (2, 0.23584014363586903), 3: (2, 0.23939127195626497), 4: (2, 0.2805969137698412), 5: (2, 0.23121100943535566), 6: (2, 0.2327738618478179), 7: (2, 0.24562344886362553), 8: (2, 0.2392571745440364), 9: (2, 0.24882116168737411), 10: (2, 0.23111659940332174), 11: (2, 0.23888812866061926), 12: (2, 0.2292547421529889), 13: (2, 0.2551014684140682), 14: (2, 0.22979578468948603), 15: (2, 0.2476218556985259), 16: (2, 0.22705219686031342), 17: (2, 0.22741534281522036), 18: (2, 0.23457190860062838), 19: (2, 0.2715812139213085), 20: (2, 0.23806521762162447), 21: (2, 0.23013399075716734), 22: (2, 0.229635925963521), 23: (2, 0.22945996839553118), 24: (2, 0.23405161779373884), 25: (2, 0.2757389610633254), 26: (2, 0.25953971967101097), 27: (2, 0.23594582546502352), 28: (2, 0.22734439466148615), 29: (2, 0.23348151333630085), 30: (2, 0.23265248257666826), 31: (2, 0.27447890397161245), 32: (2, 0.24630639236420393), 33: (2, 0.23306014761328697), 34: (2, 0.24448605440557003), 35: (2, 0.23913300596177578), 36: (2, 0.2736694822087884), 37: (2, 0.2421532003208995), 38: (2, 0.268141127191484), 39: (2, 0.27352393232285976), 40: (2, 0.2612703777849674), 41: (2, 0.27193625178188086), 42: (2, 0.2661340283229947), 43: (2, 0.2661006087437272), 44: (2, 0.23550661746412516), 45: (2, 0.23601805977523327), 46: (2, 0.2724599139764905), 47: (2, 0.23700597882270813), 48: (2, 0.23659571260213852), 49: (2, 0.2660414883866906), 50: (2, 0.2756198775023222), 51: (2, 0.24507855251431465), 52: (2, 0.23197492584586143), 53: (2, 0.2349052121862769), 54: (2, 0.23270464688539505), 55: (2, 0.24567747488617897), 56: (2, 0.23151154071092606), 57: (2, 0.23658642172813416), 58: (2, 0.24682315159589052), 59: (2, 0.23573678079992533), 60: (2, 0.23492041043937206), 61: (2, 0.2595147415995598), 62: (2, 0.2761491881683469), 63: (2, 0.27350682858377695), 64: (2, 0.2668716963380575), 65: (2, 0.24461801629513502), 66: (2, 0.2599857496097684), 67: (2, 0.24150632321834564), 68: (2, 0.22973936889320612), 69: (2, 0.25959285348653793), 70: (2, 0.26995870377868414), 71: (1, 0.2506518252193928)}\n",
      "{1: (2, 255, 0.1944931788114356), 2: (2, 255, 0.19381031826430675), 3: (2, 255, 0.19378883586648632), 4: (2, 255, 0.19436820929906531), 5: (2, 255, 0.19409193148215612), 6: (2, 255, 0.19379218598718154), 7: (2, 255, 0.19428731679697248), 8: (2, 255, 0.1944796259788906), 9: (2, 255, 0.19405036571563458), 10: (2, 255, 0.1940124478410272), 11: (2, 255, 0.193974371729236), 12: (2, 255, 0.19399100360551885), 13: (2, 255, 0.19394095560134042), 14: (2, 255, 0.19405755277576983), 15: (2, 255, 0.19428788587524026), 16: (2, 255, 0.19397753715953406), 17: (2, 255, 0.19399211051344287), 18: (2, 255, 0.1937442598535734), 19: (2, 255, 0.1939389646272449), 20: (2, 255, 0.19385468691003088), 21: (2, 255, 0.1938265762237065), 22: (2, 255, 0.1938741192331209), 23: (2, 255, 0.19339388187098153), 24: (2, 255, 0.19335528608484595), 25: (2, 255, 0.19330928912203685), 26: (2, 255, 0.19343507631006193), 27: (2, 255, 0.19342608915313203), 28: (2, 255, 0.19345253064644102), 29: (2, 255, 0.19345023294582087), 30: (2, 255, 0.19333179777889858), 31: (2, 255, 0.1932889042385653), 32: (2, 255, 0.19336471214671344), 33: (2, 255, 0.19325668615672517), 34: (2, 255, 0.1932474147053618), 35: (2, 255, 0.19325923983957252), 36: (2, 255, 0.19333375442919193), 37: (2, 255, 0.1933443303201713), 38: (2, 255, 0.19332796469257743), 39: (2, 255, 0.1935336028937908), 40: (2, 255, 0.19345231233712504), 41: (2, 255, 0.1934045355876579), 42: (2, 255, 0.19335620672825504), 43: (2, 255, 0.19395242578477837), 44: (2, 255, 0.19416000358395133), 45: (2, 255, 0.19363733522009616), 46: (2, 255, 0.19361968604372998), 47: (2, 255, 0.1936545897567389), 48: (2, 255, 0.19356180601479375), 49: (2, 255, 0.1936047563329339), 50: (2, 255, 0.19365400482042164), 51: (2, 255, 0.19376843372250305), 52: (2, 255, 0.19386871376750517), 53: (2, 255, 0.19362854502145566), 54: (2, 255, 0.19364523456304097), 55: (2, 255, 0.19373854246428784), 56: (2, 255, 0.1937322227430402), 57: (2, 255, 0.19378749364073955), 58: (2, 255, 0.19373779726013834), 59: (2, 255, 0.19369888839622337), 60: (2, 255, 0.19337563130493257), 61: (2, 255, 0.19354100785784278), 62: (2, 255, 0.1937012226302542), 63: (2, 255, 0.1934626187837007), 64: (2, 255, 0.1936215388716436), 65: (2, 255, 0.1936237774278019), 66: (2, 255, 0.19352484831184733), 67: (2, 255, 0.1938325312865131), 68: (2, 255, 0.19367007043431786), 69: (2, 255, 0.19327103558051237), 70: (2, 255, 0.19343592147251554)}\n",
      "{'predict_runtime': 3506.9754, 'predict_samples_per_second': 0.04, 'predict_steps_per_second': 0.02}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:58:26.97\n",
      "  predict_samples_per_second =       0.04\n",
      "  predict_steps_per_second   =       0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3373196544125676), 2: (4, 0.29959253035485744), 3: (4, 0.2995834294706583), 4: (4, 0.2994751399382949), 5: (4, 0.3032264970242977), 6: (4, 0.3006082260981202), 7: (4, 0.3013996360823512), 8: (4, 0.3061789507046342), 9: (4, 0.30042210686951876), 10: (4, 0.2997448528185487), 11: (4, 0.29954312555491924), 12: (4, 0.30152204260230064), 13: (4, 0.2951671965420246), 14: (4, 0.29661005921661854), 15: (4, 0.2978829937055707), 16: (4, 0.299596075899899), 17: (4, 0.299771293066442), 18: (4, 0.2991076596081257), 19: (4, 0.2988458313047886), 20: (4, 0.29756551515311), 21: (4, 0.29839123506098986), 22: (4, 0.300193184055388), 23: (4, 0.30186667386442423), 24: (4, 0.2988258274272084), 25: (4, 0.298624649643898), 26: (4, 0.29669064097106457), 27: (4, 0.3297945698723197), 28: (4, 0.2991615207865834), 29: (4, 0.2967958562076092), 30: (4, 0.30016440711915493), 31: (4, 0.29823537822812796), 32: (4, 0.29874074272811413), 33: (4, 0.3023605002090335), 34: (4, 0.3025725372135639), 35: (4, 0.30098928324878216), 36: (4, 0.3006129777058959), 37: (4, 0.2999505288898945), 38: (4, 0.3137580892071128), 39: (4, 0.29757629334926605), 40: (4, 0.29883860889822245), 41: (4, 0.29751421324908733), 42: (4, 0.3025295939296484), 43: (4, 0.2989960936829448), 44: (4, 0.2996967462822795), 45: (4, 0.2994302986189723), 46: (4, 0.2961920537054539), 47: (4, 0.30044570565223694), 48: (4, 0.2984516769647598), 49: (4, 0.2997877914458513), 50: (4, 0.30920766200870275), 51: (4, 0.3009538948535919), 52: (4, 0.3010435542091727), 53: (4, 0.31177484896034), 54: (4, 0.3026762446388602), 55: (4, 0.30158343631774187), 56: (4, 0.3013504780828953), 57: (4, 0.29714256525039673), 58: (4, 0.29990142211318016), 59: (4, 0.30083070136606693), 60: (4, 0.2996063753962517), 61: (4, 0.30127574503421783), 62: (4, 0.29801024217158556), 63: (4, 0.3413446629419923), 64: (4, 0.3011516444385052), 65: (4, 0.2959901224821806), 66: (4, 0.3136487100273371), 67: (4, 0.3057616399601102), 68: (4, 0.2979864375665784), 69: (4, 0.3025119761005044), 70: (4, 0.29485979210585356), 71: (1, 0.21462309826165438)}\n",
      "{1: (4, 255, 0.19545793719224486), 2: (4, 255, 0.19472286348395487), 3: (4, 255, 0.19467244343649523), 4: (4, 255, 0.1947268045050841), 5: (4, 255, 0.19510604596751577), 6: (4, 255, 0.19468640177054147), 7: (4, 255, 0.19482311750670858), 8: (4, 255, 0.19475282523781062), 9: (4, 255, 0.19486474408311585), 10: (4, 255, 0.19485413325475712), 11: (4, 255, 0.1947592147315542), 12: (4, 255, 0.19624825608642663), 13: (4, 255, 0.19478164363433334), 14: (4, 255, 0.19459693894958963), 15: (4, 255, 0.19458385659199134), 16: (4, 255, 0.19450125108819966), 17: (4, 255, 0.19451931123713068), 18: (4, 255, 0.19458296302998182), 19: (4, 255, 0.19459834769368173), 20: (4, 255, 0.19470145967149852), 21: (4, 255, 0.1945852985167328), 22: (4, 255, 0.1945447027427601), 23: (4, 255, 0.19455502819196852), 24: (4, 255, 0.1945836356786244), 25: (4, 255, 0.1947772723786971), 26: (4, 255, 0.19463347883566337), 27: (4, 255, 0.19471977155874756), 28: (4, 255, 0.19471196748462377), 29: (4, 255, 0.1945535998937546), 30: (4, 255, 0.19470446037092046), 31: (4, 255, 0.19467992364045453), 32: (4, 255, 0.1946839087149676), 33: (4, 255, 0.19461754835849884), 34: (4, 255, 0.1946150138024606), 35: (4, 255, 0.19493125738101263), 36: (4, 255, 0.19453011271269882), 37: (4, 255, 0.1944999583722914), 38: (4, 255, 0.19451794337992576), 39: (4, 255, 0.19458512551717314), 40: (4, 255, 0.1945735215008551), 41: (4, 255, 0.19460888578392127), 42: (4, 255, 0.19458352409887547), 43: (4, 255, 0.1943402541691766), 44: (4, 255, 0.194475633157965), 45: (4, 255, 0.1944187017011584), 46: (4, 255, 0.19442453168186488), 47: (4, 255, 0.19440359072577135), 48: (4, 255, 0.19453373544429448), 49: (4, 255, 0.1944769363265996), 50: (4, 255, 0.19446738540907116), 51: (4, 255, 0.19448007644318482), 52: (4, 255, 0.19455877915389982), 53: (4, 255, 0.194505263700643), 54: (4, 255, 0.194514349252716), 55: (4, 255, 0.19430474329228495), 56: (4, 255, 0.1943580530291679), 57: (4, 255, 0.19436959974906023), 58: (4, 255, 0.1943164422085472), 59: (4, 255, 0.194257363947291), 60: (4, 255, 0.19425842010726532), 61: (4, 255, 0.19436163602433368), 62: (4, 255, 0.19424543189724872), 63: (4, 255, 0.19429247044392076), 64: (4, 255, 0.1942599675526806), 65: (4, 255, 0.19441608061247012), 66: (4, 255, 0.19459385092132817), 67: (4, 255, 0.19450344024043456), 68: (4, 255, 0.19452535125116507), 69: (4, 255, 0.194468323104814), 70: (4, 255, 0.1944556776178526)}\n",
      "{'predict_runtime': 3526.9082, 'predict_samples_per_second': 0.08, 'predict_steps_per_second': 0.02}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:58:46.90\n",
      "  predict_samples_per_second =       0.08\n",
      "  predict_steps_per_second   =       0.02\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 24\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.25617212802171707), 2: (1, 0.2206541383638978), 3: (1, 0.2206537565216422), 4: (1, 0.22111100237816572), 5: (1, 0.22123552951961756), 6: (1, 0.21760422177612782), 7: (1, 0.22212136071175337), 8: (1, 0.22198297083377838), 9: (1, 0.2218087324872613), 10: (1, 0.2177574187517166), 11: (1, 0.2233616141602397), 12: (1, 0.22277963999658823), 13: (1, 0.21815036237239838), 14: (1, 0.2216228013858199), 15: (1, 0.21913085039705038), 16: (1, 0.22115105763077736), 17: (1, 0.21851435583084822), 18: (1, 0.22231409326195717), 19: (1, 0.21878756303340197), 20: (1, 0.2205412108451128), 21: (1, 0.21792062278836966), 22: (1, 0.22036294359713793), 23: (1, 0.21843791380524635), 24: (1, 0.21880669984966516), 25: (1, 0.22327573783695698), 26: (1, 0.22198163345456123), 27: (1, 0.2190822260454297), 28: (1, 0.2186252698302269), 29: (1, 0.22306744940578938), 30: (1, 0.2194086005911231), 31: (1, 0.22000202350318432), 32: (1, 0.21911621280014515), 33: (1, 0.23268337920308113), 34: (1, 0.2210124908015132), 35: (1, 0.22073659300804138), 36: (1, 0.22185068111866713), 37: (1, 0.21798910479992628), 38: (1, 0.2220547180622816), 39: (1, 0.21784480568021536), 40: (1, 0.2210676996037364), 41: (1, 0.2182993283495307), 42: (1, 0.2200370691716671), 43: (1, 0.2202122574672103), 44: (1, 0.2171816611662507), 45: (1, 0.2231504926458001), 46: (1, 0.21807405073195696), 47: (1, 0.22088037803769112), 48: (1, 0.22123016323894262), 49: (1, 0.21755317598581314), 50: (1, 0.21905226819217205), 51: (1, 0.22273105569183826), 52: (1, 0.22359765600413084), 53: (1, 0.2184075741097331), 54: (1, 0.22018961422145367), 55: (1, 0.21916829608380795), 56: (1, 0.2234843261539936), 57: (1, 0.21842261403799057), 58: (1, 0.2193630924448371), 59: (1, 0.22167692612856627), 60: (1, 0.21801364701241255), 61: (1, 0.22026427090168), 62: (1, 0.22250710614025593), 63: (1, 0.2201159419491887), 64: (1, 0.2186878975480795), 65: (1, 0.22343715373426676), 66: (1, 0.21862506959587336), 67: (1, 0.2222363268956542), 68: (1, 0.2210084516555071), 69: (1, 0.2206581151112914), 70: (1, 0.21792188566178083), 71: (1, 0.22162707336246967)}\n",
      "{1: (1, 255, 0.1309766756881978), 2: (1, 255, 0.13040203339986356), 3: (1, 255, 0.1303351386760672), 4: (1, 255, 0.13034695555620335), 5: (1, 255, 0.13044885351669555), 6: (1, 255, 0.13037903220118846), 7: (1, 255, 0.13048896673409377), 8: (1, 255, 0.13054696893429055), 9: (1, 255, 0.13086250835627902), 10: (1, 255, 0.1305598002876721), 11: (1, 255, 0.13061631852578298), 12: (1, 255, 0.13051115190062454), 13: (1, 255, 0.13049320224672556), 14: (1, 255, 0.13053043498201114), 15: (1, 255, 0.13055584855815944), 16: (1, 255, 0.13067933452114755), 17: (1, 255, 0.13050579729617812), 18: (1, 255, 0.1305610108937995), 19: (1, 255, 0.13036457982425595), 20: (1, 255, 0.13034447674803873), 21: (1, 255, 0.13040768465794184), 22: (1, 255, 0.13041305600793338), 23: (1, 255, 0.13039623267364267), 24: (1, 255, 0.1304832552979682), 25: (1, 255, 0.13041213069330243), 26: (1, 255, 0.13036457460884954), 27: (1, 255, 0.13041480589731066), 28: (1, 255, 0.13048222698271275), 29: (1, 255, 0.13015920532611655), 30: (1, 255, 0.13036438210995174), 31: (1, 255, 0.13036171612055864), 32: (1, 255, 0.13321889103846807), 33: (1, 255, 0.13337030454593546), 34: (1, 255, 0.13134907260171924), 35: (1, 255, 0.13091214809420645), 36: (1, 255, 0.13077247240671924), 37: (1, 255, 0.13097873993364034), 38: (1, 255, 0.13043424853434166), 39: (1, 255, 0.13041797404122704), 40: (1, 255, 0.13037249761104), 41: (1, 255, 0.13037689246018144), 42: (1, 255, 0.13047439279947795), 43: (1, 255, 0.13053645126010274), 44: (1, 255, 0.1303012951149368), 45: (1, 255, 0.1302736194658221), 46: (1, 255, 0.13022429086998397), 47: (1, 255, 0.13021911668645986), 48: (1, 255, 0.13027822472812498), 49: (1, 255, 0.1303060061791364), 50: (1, 255, 0.13035344714116232), 51: (1, 255, 0.13050379618344937), 52: (1, 255, 0.13032877477725932), 53: (1, 255, 0.1303273123707257), 54: (1, 255, 0.13030541973444176), 55: (1, 255, 0.13059936597139812), 56: (1, 255, 0.13041040021926165), 57: (1, 255, 0.13050236032873977), 58: (1, 255, 0.13045052070097596), 59: (1, 255, 0.1304584108329579), 60: (1, 255, 0.13044114081444694), 61: (1, 255, 0.13069935146646172), 62: (1, 255, 0.13065861215194066), 63: (1, 255, 0.13063167142955695), 64: (1, 255, 0.13076985380521008), 65: (1, 255, 0.1307091058542331), 66: (1, 255, 0.13073508480527238), 67: (1, 255, 0.13072752806120644), 68: (1, 255, 0.13056255064028152), 69: (1, 255, 0.13065397018457162), 70: (1, 255, 0.1307069576107988)}\n",
      "{'predict_runtime': 2380.0025, 'predict_samples_per_second': 0.03, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:39:40.00\n",
      "  predict_samples_per_second =       0.03\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2710271393880248), 2: (2, 0.28817685414105654), 3: (2, 0.24415879510343075), 4: (2, 0.23490943014621735), 5: (2, 0.2532179607078433), 6: (2, 0.2774210134521127), 7: (2, 0.28255569469183683), 8: (2, 0.24319165386259556), 9: (2, 0.23867783416062593), 10: (2, 0.2498709373176098), 11: (2, 0.2404667939990759), 12: (2, 0.26709566451609135), 13: (2, 0.2548351837322116), 14: (2, 0.25584222190082073), 15: (2, 0.27609485015273094), 16: (2, 0.2390991123393178), 17: (2, 0.2863931804895401), 18: (2, 0.2379171857610345), 19: (2, 0.23814323265105486), 20: (2, 0.2801916804164648), 21: (2, 0.2507977169007063), 22: (2, 0.24035046622157097), 23: (2, 0.2413488645106554), 24: (2, 0.27318994142115116), 25: (2, 0.2415856821462512), 26: (2, 0.26850416231900454), 27: (2, 0.2616893509402871), 28: (2, 0.24637267645448446), 29: (2, 0.2471589371562004), 30: (2, 0.25762003753334284), 31: (2, 0.2818986978381872), 32: (2, 0.28674714267253876), 33: (2, 0.24200295470654964), 34: (2, 0.26669572200626135), 35: (2, 0.24352460727095604), 36: (2, 0.2775735864415765), 37: (2, 0.2780364900827408), 38: (2, 0.24227618146687746), 39: (2, 0.2785126743838191), 40: (2, 0.2916429042816162), 41: (2, 0.2549081537872553), 42: (2, 0.24216657038778067), 43: (2, 0.25051295571029186), 44: (2, 0.2425981955602765), 45: (2, 0.25677669141441584), 46: (2, 0.23613394889980555), 47: (2, 0.24906403943896294), 48: (2, 0.24000649340450764), 49: (2, 0.24225419759750366), 50: (2, 0.2572335135191679), 51: (2, 0.2398708937689662), 52: (2, 0.26809039898216724), 53: (2, 0.249196395277977), 54: (2, 0.24357630964368582), 55: (2, 0.24123168736696243), 56: (2, 0.2385754669085145), 57: (2, 0.2423674538731575), 58: (2, 0.2778762159869075), 59: (2, 0.24853685311973095), 60: (2, 0.2421439355239272), 61: (2, 0.23882440384477377), 62: (2, 0.24425884149968624), 63: (2, 0.27835615910589695), 64: (2, 0.28102207835763693), 65: (2, 0.24911862146109343), 66: (2, 0.24011596478521824), 67: (2, 0.27248483151197433), 68: (2, 0.24353942554444075), 69: (2, 0.2697101328521967), 70: (2, 0.2761738495901227), 71: (1, 0.22223061975091696)}\n",
      "{1: (2, 255, 0.20335826442083893), 2: (2, 255, 0.201921420471341), 3: (2, 255, 0.2019111686952266), 4: (2, 255, 0.20187119329896044), 5: (2, 255, 0.20211987786871546), 6: (2, 255, 0.2017391696681871), 7: (2, 255, 0.20188083091348993), 8: (2, 255, 0.2017052298740429), 9: (2, 255, 0.2018490560097145), 10: (2, 255, 0.20183993370509615), 11: (2, 255, 0.2018240463792109), 12: (2, 255, 0.2017460489536033), 13: (2, 255, 0.20170159256998815), 14: (2, 255, 0.20172790354300363), 15: (2, 255, 0.20177182536937444), 16: (2, 255, 0.20159674488811516), 17: (2, 255, 0.20172919907844533), 18: (2, 255, 0.201726687173633), 19: (2, 255, 0.20162822461011362), 20: (2, 255, 0.20160774860311956), 21: (2, 255, 0.20169200676986399), 22: (2, 255, 0.20171327491966531), 23: (2, 255, 0.20178304165236505), 24: (2, 255, 0.20186502283037294), 25: (2, 255, 0.2017134027409495), 26: (2, 255, 0.20231685971512514), 27: (2, 255, 0.20229985400596084), 28: (2, 255, 0.20156673092906383), 29: (2, 255, 0.20125809394042282), 30: (2, 255, 0.20127466424715285), 31: (2, 255, 0.20118521180588242), 32: (2, 255, 0.2013393803408333), 33: (2, 255, 0.20167197636602557), 34: (2, 255, 0.20132582644548486), 35: (2, 255, 0.201202391387493), 36: (2, 255, 0.20110083314425806), 37: (2, 255, 0.2011459842726004), 38: (2, 255, 0.20117265346149604), 39: (2, 255, 0.20109340363346478), 40: (2, 255, 0.20115280692629955), 41: (2, 255, 0.2012976362169081), 42: (2, 255, 0.20114961600698092), 43: (2, 255, 0.20117808498588263), 44: (2, 255, 0.2012344216197437), 45: (2, 255, 0.20142657276900375), 46: (2, 255, 0.2012683849964364), 47: (2, 255, 0.20138002625648296), 48: (2, 255, 0.20129455161080057), 49: (2, 255, 0.20123986887800344), 50: (2, 255, 0.20122735390768332), 51: (2, 255, 0.201178206916095), 52: (2, 255, 0.20127725353208828), 53: (2, 255, 0.2012935427364473), 54: (2, 255, 0.2013305511983002), 55: (2, 255, 0.20124844624204377), 56: (2, 255, 0.2012066890248189), 57: (2, 255, 0.20127200402830744), 58: (2, 255, 0.2013696056407164), 59: (2, 255, 0.2013368362780003), 60: (2, 255, 0.20110842463213438), 61: (2, 255, 0.20136852936052224), 62: (2, 255, 0.20118031536831577), 63: (2, 255, 0.20095952472412118), 64: (2, 255, 0.2013523453627439), 65: (2, 255, 0.20132782255098516), 66: (2, 255, 0.20107023584126843), 67: (2, 255, 0.20127331938813714), 68: (2, 255, 0.2012106939200677), 69: (2, 255, 0.20110022151733145), 70: (2, 255, 0.20145107830564182)}\n",
      "{'predict_runtime': 3648.0965, 'predict_samples_per_second': 0.039, 'predict_steps_per_second': 0.019}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:00:48.09\n",
      "  predict_samples_per_second =      0.039\n",
      "  predict_steps_per_second   =      0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.34170856326818466), 2: (4, 0.3147109551355243), 3: (4, 0.31556664500385523), 4: (4, 0.3259722450748086), 5: (4, 0.3112906627357006), 6: (4, 0.3159663015976548), 7: (4, 0.31484539341181517), 8: (4, 0.3128215866163373), 9: (4, 0.31238780077546835), 10: (4, 0.31057605240494013), 11: (4, 0.32176357228308916), 12: (4, 0.3124437304213643), 13: (4, 0.3117585377767682), 14: (4, 0.3118906458839774), 15: (4, 0.3133738087490201), 16: (4, 0.31401325203478336), 17: (4, 0.3130395822227001), 18: (4, 0.3085702434182167), 19: (4, 0.3105369424447417), 20: (4, 0.31288025341928005), 21: (4, 0.3132445402443409), 22: (4, 0.3110877349972725), 23: (4, 0.314924880862236), 24: (4, 0.30904094874858856), 25: (4, 0.30917596723884344), 26: (4, 0.3106779297813773), 27: (4, 0.3128647133708), 28: (4, 0.3138663927093148), 29: (4, 0.3172248341143131), 30: (4, 0.31455689389258623), 31: (4, 0.3125864276662469), 32: (4, 0.3136298656463623), 33: (4, 0.31617689598351717), 34: (4, 0.31259504705667496), 35: (4, 0.31273017451167107), 36: (4, 0.3143605161458254), 37: (4, 0.3090923270210624), 38: (4, 0.32688218355178833), 39: (4, 0.31073656026273966), 40: (4, 0.30828326754271984), 41: (4, 0.31173587776720524), 42: (4, 0.32010102178901434), 43: (4, 0.3163912948220968), 44: (4, 0.31265617720782757), 45: (4, 0.3135391967371106), 46: (4, 0.31139619182795286), 47: (4, 0.3171109762042761), 48: (4, 0.3109969459474087), 49: (4, 0.31227902229875326), 50: (4, 0.30767857376486063), 51: (4, 0.3105370905250311), 52: (4, 0.3082455787807703), 53: (4, 0.31340472772717476), 54: (4, 0.30800258181989193), 55: (4, 0.316054318100214), 56: (4, 0.3082288075238466), 57: (4, 0.3151702368631959), 58: (4, 0.31157517712563276), 59: (4, 0.3119803015142679), 60: (4, 0.31029207073152065), 61: (4, 0.3127623237669468), 62: (4, 0.30826439522206783), 63: (4, 0.31253222562372684), 64: (4, 0.31280450243502855), 65: (4, 0.3109570238739252), 66: (4, 0.3093954725190997), 67: (4, 0.3160528941079974), 68: (4, 0.31018617283552885), 69: (4, 0.31666087731719017), 70: (4, 0.3076084526255727), 71: (1, 0.21818883251398802)}\n",
      "{1: (4, 255, 0.202735311359021), 2: (4, 255, 0.20236687332976097), 3: (4, 255, 0.20227586172667203), 4: (4, 255, 0.20222911000909174), 5: (4, 255, 0.2022049385287306), 6: (4, 255, 0.20219122509234677), 7: (4, 255, 0.20236441460164153), 8: (4, 255, 0.2023014035806352), 9: (4, 255, 0.2022891284386609), 10: (4, 255, 0.20245899889691205), 11: (4, 255, 0.20231738438574123), 12: (4, 255, 0.2024293706441919), 13: (4, 255, 0.20228197647660387), 14: (4, 255, 0.2023444695434734), 15: (4, 255, 0.2023196973819651), 16: (4, 255, 0.2021221340250443), 17: (4, 255, 0.20213200311888666), 18: (4, 255, 0.20220882122715314), 19: (4, 255, 0.20225450433790684), 20: (4, 255, 0.20206207112573527), 21: (4, 255, 0.2021902189681343), 22: (4, 255, 0.20216964397798567), 23: (4, 255, 0.2021058672345152), 24: (4, 255, 0.20208178101217045), 25: (4, 255, 0.20216472737271995), 26: (4, 255, 0.2023388789199731), 27: (4, 255, 0.20236907236131968), 28: (4, 255, 0.20227360662218988), 29: (4, 255, 0.2022429656639111), 30: (4, 255, 0.2022960133960142), 31: (4, 255, 0.2023064683574964), 32: (4, 255, 0.20231622485991788), 33: (4, 255, 0.20275783987314094), 34: (4, 255, 0.2023702848447012), 35: (4, 255, 0.20225523937420517), 36: (4, 255, 0.20225033989066588), 37: (4, 255, 0.20218695826901525), 38: (4, 255, 0.202161700939577), 39: (4, 255, 0.20226001872443686), 40: (4, 255, 0.20217024087540658), 41: (4, 255, 0.20215231760898056), 42: (4, 255, 0.20477025044315), 43: (4, 255, 0.2031628921189729), 44: (4, 255, 0.20296723395951238), 45: (4, 255, 0.20291973743222508), 46: (4, 255, 0.20289017272857474), 47: (4, 255, 0.20275702115294394), 48: (4, 255, 0.20269244615280746), 49: (4, 255, 0.20252601476203577), 50: (4, 255, 0.20249012645480094), 51: (4, 255, 0.20241302465472152), 52: (4, 255, 0.20248589255280938), 53: (4, 255, 0.20248456643346477), 54: (4, 255, 0.20245496644912397), 55: (4, 255, 0.2025719635225102), 56: (4, 255, 0.202423673535825), 57: (4, 255, 0.2024788534524394), 58: (4, 255, 0.20244306883610347), 59: (4, 255, 0.20249280220299376), 60: (4, 255, 0.20244403386525078), 61: (4, 255, 0.2024998100474477), 62: (4, 255, 0.20241602573397696), 63: (4, 255, 0.2024435455052584), 64: (4, 255, 0.2024076359273464), 65: (4, 255, 0.20248258314369355), 66: (4, 255, 0.20249321691545785), 67: (4, 255, 0.20244130247144723), 68: (4, 255, 0.20282345136225807), 69: (4, 255, 0.2025928092901321), 70: (4, 255, 0.2024569905563897)}\n",
      "{'predict_runtime': 3668.819, 'predict_samples_per_second': 0.077, 'predict_steps_per_second': 0.019}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:01:08.81\n",
      "  predict_samples_per_second =      0.077\n",
      "  predict_steps_per_second   =      0.019\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 25\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
