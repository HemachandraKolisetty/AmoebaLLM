{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.41096428222954273), 2: (1, 0.252347007393837), 3: (1, 0.2484074356034398), 4: (1, 0.24797794967889786), 5: (1, 0.25049701053649187), 6: (1, 0.2501554833725095), 7: (1, 0.24732449743896723), 8: (1, 0.24915887508541346), 9: (1, 0.2510724011808634), 10: (1, 0.247732387855649), 11: (1, 0.24697117507457733), 12: (1, 0.24985122121870518), 13: (1, 0.24820059817284346), 14: (1, 0.24754259455949068), 15: (1, 0.2500841040164232), 16: (1, 0.24788840766996145), 17: (1, 0.2490598140284419), 18: (1, 0.25007771141827106), 19: (1, 0.25070394203066826), 20: (1, 0.24807112105190754), 21: (1, 0.24742824770510197), 22: (1, 0.24989324808120728), 23: (1, 0.24956206046044827), 24: (1, 0.248261253349483), 25: (1, 0.2477419888600707), 26: (1, 0.2519660200923681), 27: (1, 0.24838481936603785), 28: (1, 0.24727748055011034), 29: (1, 0.25234605092555285), 30: (1, 0.24855028558522463), 31: (1, 0.2493332540616393), 32: (1, 0.24991978611797094), 33: (1, 0.24930628202855587), 34: (1, 0.2478879177942872), 35: (1, 0.24742328096181154), 36: (1, 0.24963163491338491), 37: (1, 0.24772327579557896), 38: (1, 0.252956953831017), 39: (1, 0.2514419620856643), 40: (1, 0.25200615357607603), 41: (1, 0.2493463633581996), 42: (1, 0.24866659101098776), 43: (1, 0.250116721726954), 44: (1, 0.24762188084423542), 45: (1, 0.2500441214069724), 46: (1, 0.24896027240902185), 47: (1, 0.24772896617650986), 48: (1, 0.24721725098788738), 49: (1, 0.2495989827439189), 50: (1, 0.2488039117306471), 51: (1, 0.24677081406116486)}\n",
      "{1: (1, 127, 0.15235969762310503), 2: (1, 127, 0.15159504878972693), 3: (1, 127, 0.15161972401267665), 4: (1, 127, 0.15131716669984455), 5: (1, 127, 0.1513438063314346), 6: (1, 127, 0.15118571004910966), 7: (1, 127, 0.1511110605701335), 8: (1, 127, 0.15112284542332718), 9: (1, 127, 0.15138378584625448), 10: (1, 127, 0.15122627320252066), 11: (1, 127, 0.15117482479485705), 12: (1, 127, 0.15122737969440503), 13: (1, 127, 0.1513331694249797), 14: (1, 127, 0.1513746725688652), 15: (1, 127, 0.15147549292351317), 16: (1, 127, 0.1515440952956794), 17: (1, 127, 0.1512710472612869), 18: (1, 127, 0.1513292910311166), 19: (1, 127, 0.15129960384806546), 20: (1, 127, 0.15121732105127), 21: (1, 127, 0.1512409927191462), 22: (1, 127, 0.15144784277759668), 23: (1, 127, 0.15119206845232352), 24: (1, 127, 0.1514884179575354), 25: (1, 127, 0.15141286716363797), 26: (1, 127, 0.15164199516939836), 27: (1, 127, 0.15144439910604493), 28: (1, 127, 0.151327280159013), 29: (1, 127, 0.15130389272052003), 30: (1, 127, 0.15140204949993788), 31: (1, 127, 0.15128580434614514), 32: (1, 127, 0.1512619790833766), 33: (1, 127, 0.15117347730309005), 34: (1, 127, 0.151173692651269), 35: (1, 127, 0.15112554617812785), 36: (1, 127, 0.1517844603096289), 37: (1, 127, 0.15161154371517616), 38: (1, 127, 0.15159336447451763), 39: (1, 127, 0.15150311772572242), 40: (1, 127, 0.15170600193398676), 41: (1, 127, 0.1514500555267015), 42: (1, 127, 0.15109282709276817), 43: (1, 127, 0.15121630718564893), 44: (1, 127, 0.1514030831799967), 45: (1, 127, 0.1513589126329253), 46: (1, 127, 0.15127688693982644), 47: (1, 127, 0.1514168052868111), 48: (1, 127, 0.15113623466665352), 49: (1, 127, 0.15119463814730486), 50: (1, 127, 0.15125127747566916)}\n",
      "{'predict_runtime': 993.2705, 'predict_samples_per_second': 0.051, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:16:33.27\n",
      "  predict_samples_per_second =      0.051\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.29464422911405563), 2: (2, 0.28668786864727736), 3: (2, 0.2638983726501465), 4: (2, 0.2644319338724017), 5: (2, 0.2824899032711983), 6: (2, 0.2611753083765507), 7: (2, 0.28130557388067245), 8: (2, 0.26491131354123354), 9: (2, 0.28143483959138393), 10: (2, 0.28149848617613316), 11: (2, 0.2631815383210778), 12: (2, 0.26458469964563847), 13: (2, 0.26123103499412537), 14: (2, 0.29355061892420053), 15: (2, 0.2815563604235649), 16: (2, 0.28211191203445196), 17: (2, 0.26767116226255894), 18: (2, 0.2760474346578121), 19: (2, 0.28276046738028526), 20: (2, 0.26156145334243774), 21: (2, 0.25805039051920176), 22: (2, 0.263692463748157), 23: (2, 0.2617711154744029), 24: (2, 0.267616325058043), 25: (2, 0.2876641359180212), 26: (2, 0.2662199055776), 27: (2, 0.2627597637474537), 28: (2, 0.26383405923843384), 29: (2, 0.267483364790678), 30: (2, 0.26487533282488585), 31: (2, 0.26225684955716133), 32: (2, 0.26525784377008677), 33: (2, 0.25885646510869265), 34: (2, 0.2592896791175008), 35: (2, 0.2813808647915721), 36: (2, 0.2885464485734701), 37: (2, 0.28125998098403215), 38: (2, 0.2679755622521043), 39: (2, 0.2641367129981518), 40: (2, 0.2695602383464575), 41: (2, 0.28068473841995), 42: (2, 0.2690256517380476), 43: (2, 0.2806267775595188), 44: (2, 0.26190308947116137), 45: (2, 0.2576074469834566), 46: (2, 0.26046416256576777), 47: (2, 0.26066389959305525), 48: (2, 0.26141921896487474), 49: (2, 0.2603854285553098), 50: (2, 0.2578876055777073), 51: (1, 0.24614052008837461)}\n",
      "{1: (2, 127, 0.2382034341122691), 2: (2, 127, 0.23703300696981), 3: (2, 127, 0.2367801289990779), 4: (2, 127, 0.2367940095260622), 5: (2, 127, 0.23680528820910324), 6: (2, 127, 0.23695782222235062), 7: (2, 127, 0.2366716344584161), 8: (2, 127, 0.23673812404098943), 9: (2, 127, 0.23657384643140505), 10: (2, 127, 0.23673303483244706), 11: (2, 127, 0.2366881839872345), 12: (2, 127, 0.2368929379978987), 13: (2, 127, 0.2366747546090385), 14: (2, 127, 0.2367409356891757), 15: (2, 127, 0.23677238979648182), 16: (2, 127, 0.23934108903264906), 17: (2, 127, 0.2373801415316819), 18: (2, 127, 0.23743052836360895), 19: (2, 127, 0.2367870874600265), 20: (2, 127, 0.23691436254573384), 21: (2, 127, 0.23697473833293425), 22: (2, 127, 0.23681031402171127), 23: (2, 127, 0.23700571330777537), 24: (2, 127, 0.23752824126882113), 25: (2, 127, 0.2374782715740753), 26: (2, 127, 0.23740932724519273), 27: (2, 127, 0.237841391033955), 28: (2, 127, 0.23709316685150458), 29: (2, 127, 0.23715165275053715), 30: (2, 127, 0.23734226235459874), 31: (2, 127, 0.23734152157915625), 32: (2, 127, 0.2371633505507365), 33: (2, 127, 0.23698693310005928), 34: (2, 127, 0.2370360716737396), 35: (2, 127, 0.23735383359026016), 36: (2, 127, 0.23746115155518055), 37: (2, 127, 0.23689481762685174), 38: (2, 127, 0.23682739418439977), 39: (2, 127, 0.2369099388955029), 40: (2, 127, 0.23677075711467604), 41: (2, 127, 0.2371178430717761), 42: (2, 127, 0.2368534455281191), 43: (2, 127, 0.23698059697525473), 44: (2, 127, 0.2370615457514609), 45: (2, 127, 0.2372183485513949), 46: (2, 127, 0.2369466319856212), 47: (2, 127, 0.23692678307425083), 48: (2, 127, 0.237090331626924), 49: (2, 127, 0.23693969781972526), 50: (2, 127, 0.23696796024790195)}\n",
      "{'predict_runtime': 1538.4806, 'predict_samples_per_second': 0.066, 'predict_steps_per_second': 0.033}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:38.48\n",
      "  predict_samples_per_second =      0.066\n",
      "  predict_steps_per_second   =      0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.3194158636033535), 2: (4, 0.2797654792666435), 3: (4, 0.29537016805261374), 4: (4, 0.2933364287018776), 5: (4, 0.2799038328230381), 6: (4, 0.28911885526031256), 7: (4, 0.2864157650619745), 8: (4, 0.27860752400010824), 9: (4, 0.27544188871979713), 10: (4, 0.2804445084184408), 11: (4, 0.28029639925807714), 12: (4, 0.28113207779824734), 13: (4, 0.297555816359818), 14: (4, 0.28264404833316803), 15: (4, 0.2802332555875182), 16: (4, 0.30382647924125195), 17: (4, 0.3041335539892316), 18: (4, 0.30119860731065273), 19: (4, 0.2894613929092884), 20: (4, 0.3000021483749151), 21: (4, 0.30223514325916767), 22: (4, 0.30131749249994755), 23: (4, 0.28771999944001436), 24: (4, 0.29235538374632597), 25: (4, 0.28293396160006523), 26: (4, 0.29050895385444164), 27: (4, 0.28081686422228813), 28: (4, 0.2798444041982293), 29: (4, 0.2799371834844351), 30: (4, 0.280430706217885), 31: (4, 0.2801710395142436), 32: (4, 0.29094618279486895), 33: (4, 0.2815942605957389), 34: (4, 0.3086437974125147), 35: (4, 0.27932044584304094), 36: (4, 0.2797401901334524), 37: (4, 0.30020312312990427), 38: (4, 0.27824714593589306), 39: (4, 0.28197248186916113), 40: (4, 0.27612563874572515), 41: (4, 0.29002732783555984), 42: (4, 0.28386610746383667), 43: (4, 0.27911563124507666), 44: (4, 0.2806247239932418), 45: (4, 0.2855376461520791), 46: (4, 0.2853072378784418), 47: (4, 0.3008066499605775), 48: (4, 0.29885733127593994), 49: (4, 0.2791507365182042), 50: (4, 0.2767304442822933), 51: (1, 0.2693477477878332)}\n",
      "{1: (4, 127, 0.2391701969794753), 2: (4, 127, 0.2369481630726006), 3: (4, 127, 0.2370201664808111), 4: (4, 127, 0.23703698890181038), 5: (4, 127, 0.23711312244697583), 6: (4, 127, 0.23689180025904197), 7: (4, 127, 0.2371085745128473), 8: (4, 127, 0.2370415794567799), 9: (4, 127, 0.2369701336394614), 10: (4, 127, 0.23686298460325622), 11: (4, 127, 0.23690157217948926), 12: (4, 127, 0.23685609442951877), 13: (4, 127, 0.2368505325491034), 14: (4, 127, 0.23732282150918105), 15: (4, 127, 0.2369626192889345), 16: (4, 127, 0.2369352840033807), 17: (4, 127, 0.23693482701732652), 18: (4, 127, 0.23706974089878985), 19: (4, 127, 0.23772903656455005), 20: (4, 127, 0.23783224460294866), 21: (4, 127, 0.23805615310300524), 22: (4, 127, 0.23824387154446577), 23: (4, 127, 0.23664823987733896), 24: (4, 127, 0.2367242843528667), 25: (4, 127, 0.23674802744658444), 26: (4, 127, 0.23679343992330898), 27: (4, 127, 0.2367770594845372), 28: (4, 127, 0.23662486982597844), 29: (4, 127, 0.23669707916647664), 30: (4, 127, 0.2367479087506223), 31: (4, 127, 0.2365941955876632), 32: (4, 127, 0.23645119734959105), 33: (4, 127, 0.2364741571936903), 34: (4, 127, 0.2364564324824477), 35: (4, 127, 0.23648962670365187), 36: (4, 127, 0.2364437548355676), 37: (4, 127, 0.2366835307916553), 38: (4, 127, 0.23652724423042432), 39: (4, 127, 0.2365179484871429), 40: (4, 127, 0.23645001454058828), 41: (4, 127, 0.23640972894330428), 42: (4, 127, 0.23695087764324166), 43: (4, 127, 0.23654188679193888), 44: (4, 127, 0.2363027567997223), 45: (4, 127, 0.2364331915329291), 46: (4, 127, 0.23643743746921303), 47: (4, 127, 0.2363355048954135), 48: (4, 127, 0.23635013952235304), 49: (4, 127, 0.23645932849232607), 50: (4, 127, 0.23626269933980282)}\n",
      "{'predict_runtime': 1537.9689, 'predict_samples_per_second': 0.131, 'predict_steps_per_second': 0.033}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:37.96\n",
      "  predict_samples_per_second =      0.131\n",
      "  predict_steps_per_second   =      0.033\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 30\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 50 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.4149784967303276), 2: (1, 0.2684293445199728), 3: (1, 0.2624996844679117), 4: (1, 0.2608691733330488), 5: (1, 0.2628019396215677), 6: (1, 0.261032160371542), 7: (1, 0.2601714516058564), 8: (1, 0.2611187705770135), 9: (1, 0.2633308256044984), 10: (1, 0.26003222446888685), 11: (1, 0.2614854481071234), 12: (1, 0.2620230419561267), 13: (1, 0.26050535030663013), 14: (1, 0.2603214718401432), 15: (1, 0.2608257560059428), 16: (1, 0.2615949073806405), 17: (1, 0.260408672504127), 18: (1, 0.26155316829681396), 19: (1, 0.26197531446814537), 20: (1, 0.2602146342396736), 21: (1, 0.2601866042241454), 22: (1, 0.26119385194033384), 23: (1, 0.261828294955194), 24: (1, 0.26182072702795267), 25: (1, 0.26339869759976864), 26: (1, 0.2637579748407006), 27: (1, 0.262195642106235), 28: (1, 0.2596639031544328), 29: (1, 0.26217033341526985), 30: (1, 0.2603344861418009), 31: (1, 0.2599854292348027), 32: (1, 0.26316315215080976), 33: (1, 0.2606969503685832), 34: (1, 0.2600799798965454), 35: (1, 0.26085933949798346), 36: (1, 0.2623111829161644), 37: (1, 0.26010479871183634), 38: (1, 0.26061269268393517), 39: (1, 0.2619238281622529), 40: (1, 0.2617362402379513), 41: (1, 0.26266062911599874), 42: (1, 0.26242564246058464), 43: (1, 0.26188615895807743), 44: (1, 0.2597674746066332), 45: (1, 0.26228053495287895), 46: (1, 0.262730959802866), 47: (1, 0.2600956913083792), 48: (1, 0.25983044132590294), 49: (1, 0.2616856498643756), 50: (1, 0.2619467871263623), 51: (1, 0.25989120081067085), 52: (1, 0.26222523394972086), 53: (1, 0.26213541626930237), 54: (1, 0.25969368405640125), 55: (1, 0.26081569120287895), 56: (1, 0.2638201666995883), 57: (1, 0.2606673529371619), 58: (1, 0.2604653062298894), 59: (1, 0.2638243967667222), 60: (1, 0.26042305771261454), 61: (1, 0.2617011722177267), 62: (1, 0.26438497100025415), 63: (1, 0.2609074516221881), 64: (1, 0.25981076527386904), 65: (1, 0.26345139276236296), 66: (1, 0.26121003925800323), 67: (1, 0.2617023531347513), 68: (1, 0.2612350881099701), 69: (1, 0.26220533810555935), 70: (1, 0.26288469042629004), 71: (1, 0.26049780659377575)}\n",
      "{1: (1, 127, 0.15677572292547057), 2: (1, 127, 0.1561811871635984), 3: (1, 127, 0.1561070123144726), 4: (1, 127, 0.155950709216766), 5: (1, 127, 0.15586829801478724), 6: (1, 127, 0.1561060698160271), 7: (1, 127, 0.1558894264093769), 8: (1, 127, 0.15639383631839057), 9: (1, 127, 0.15622599685461971), 10: (1, 127, 0.156102797947824), 11: (1, 127, 0.15596223240498247), 12: (1, 127, 0.1560272954727017), 13: (1, 127, 0.15592051355358888), 14: (1, 127, 0.15599509019873978), 15: (1, 127, 0.15590722553109324), 16: (1, 127, 0.15611318946178035), 17: (1, 127, 0.15589241665883327), 18: (1, 127, 0.15592431452301309), 19: (1, 127, 0.15596312079871968), 20: (1, 127, 0.1561796509946777), 21: (1, 127, 0.15597041735176262), 22: (1, 127, 0.15645100057535755), 23: (1, 127, 0.15619594281113994), 24: (1, 127, 0.15593667314424525), 25: (1, 127, 0.15555052369774328), 26: (1, 127, 0.15550702093829086), 27: (1, 127, 0.15539239524445664), 28: (1, 127, 0.1556104005967069), 29: (1, 127, 0.15559033283186474), 30: (1, 127, 0.15555575705595373), 31: (1, 127, 0.15556815774069996), 32: (1, 127, 0.1556935424469118), 33: (1, 127, 0.15569032394275892), 34: (1, 127, 0.15588883825350464), 35: (1, 127, 0.15555665368492913), 36: (1, 127, 0.1557032452294911), 37: (1, 127, 0.15568328204410753), 38: (1, 127, 0.155556791102675), 39: (1, 127, 0.1556155073830462), 40: (1, 127, 0.15559880934860998), 41: (1, 127, 0.15555909889801514), 42: (1, 127, 0.15559192523213589), 43: (1, 127, 0.1557126602260616), 44: (1, 127, 0.155791908539245), 45: (1, 127, 0.1557350301029762), 46: (1, 127, 0.15588310539839775), 47: (1, 127, 0.15565914148098137), 48: (1, 127, 0.15579634751596555), 49: (1, 127, 0.155760977959891), 50: (1, 127, 0.15577307652212738), 51: (1, 127, 0.1558082526784361), 52: (1, 127, 0.15615999085579332), 53: (1, 127, 0.15578829414966539), 54: (1, 127, 0.15582380998938336), 55: (1, 127, 0.1557580317319261), 56: (1, 127, 0.15576807284126365), 57: (1, 127, 0.15551880719213504), 58: (1, 127, 0.1557765331001967), 59: (1, 127, 0.15571282733613112), 60: (1, 127, 0.1557415512016439), 61: (1, 127, 0.15586409829263612), 62: (1, 127, 0.1558579194293482), 63: (1, 127, 0.155749166699669), 64: (1, 127, 0.15577295188623386), 65: (1, 127, 0.15568765290961492), 66: (1, 127, 0.15557115595406434), 67: (1, 127, 0.1556643808671222), 68: (1, 127, 0.15557385896750558), 69: (1, 127, 0.15562157211898583), 70: (1, 127, 0.15578754619497248)}\n",
      "{'predict_runtime': 1423.8108, 'predict_samples_per_second': 0.05, 'predict_steps_per_second': 0.05}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:43.81\n",
      "  predict_samples_per_second =       0.05\n",
      "  predict_steps_per_second   =       0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.3143249563872814), 2: (2, 0.28362221736460924), 3: (2, 0.3041778467595577), 4: (2, 0.306017586030066), 5: (2, 0.30129831098020077), 6: (2, 0.3115349914878607), 7: (2, 0.3028517933562398), 8: (2, 0.2872743560001254), 9: (2, 0.3006984293460846), 10: (2, 0.2882170854136348), 11: (2, 0.28299485705792904), 12: (2, 0.28077199403196573), 13: (2, 0.28402737621217966), 14: (2, 0.30660495162010193), 15: (2, 0.3033615704625845), 16: (2, 0.30553501565009356), 17: (2, 0.28705070074647665), 18: (2, 0.29468154162168503), 19: (2, 0.28350008372217417), 20: (2, 0.2926531359553337), 21: (2, 0.3038301654160023), 22: (2, 0.3030869849026203), 23: (2, 0.30403396394103765), 24: (2, 0.28569977916777134), 25: (2, 0.28682904597371817), 26: (2, 0.2805380402132869), 27: (2, 0.30205056816339493), 28: (2, 0.3050702130421996), 29: (2, 0.30448140017688274), 30: (2, 0.2855898905545473), 31: (2, 0.3062600903213024), 32: (2, 0.29564579389989376), 33: (2, 0.30710580106824636), 34: (2, 0.2844433458521962), 35: (2, 0.3038265099748969), 36: (2, 0.2878962764516473), 37: (2, 0.30264344345778227), 38: (2, 0.28530600760132074), 39: (2, 0.30454965122044086), 40: (2, 0.3003961108624935), 41: (2, 0.30237080808728933), 42: (2, 0.30502347834408283), 43: (2, 0.30902898125350475), 44: (2, 0.30751912854611874), 45: (2, 0.30462008249014616), 46: (2, 0.3058476373553276), 47: (2, 0.2870430890470743), 48: (2, 0.29086651373654604), 49: (2, 0.30036814138293266), 50: (2, 0.2879161583259702), 51: (2, 0.3054368747398257), 52: (2, 0.30648573115468025), 53: (2, 0.30332715902477503), 54: (2, 0.28531116899102926), 55: (2, 0.30332343000918627), 56: (2, 0.3056990634649992), 57: (2, 0.3036327073350549), 58: (2, 0.28777195513248444), 59: (2, 0.30230515263974667), 60: (2, 0.28706058394163847), 61: (2, 0.3047062046825886), 62: (2, 0.3059410508722067), 63: (2, 0.3040851028636098), 64: (2, 0.2873087730258703), 65: (2, 0.28347600903362036), 66: (2, 0.306724582798779), 67: (2, 0.30630745738744736), 68: (2, 0.3032198762521148), 69: (2, 0.30707667116075754), 70: (2, 0.30556394811719656), 71: (1, 0.28240592312067747)}\n",
      "{1: (2, 127, 0.24181143652031742), 2: (2, 127, 0.24112568675415721), 3: (2, 127, 0.24114562857045432), 4: (2, 127, 0.24110840719310553), 5: (2, 127, 0.2411075211460079), 6: (2, 127, 0.24118415771536236), 7: (2, 127, 0.24114687547205002), 8: (2, 127, 0.24103202508014487), 9: (2, 127, 0.24110733126620137), 10: (2, 127, 0.24099803521613203), 11: (2, 127, 0.24122339389543598), 12: (2, 127, 0.24117725890305802), 13: (2, 127, 0.24105309011546647), 14: (2, 127, 0.24116229574658035), 15: (2, 127, 0.24121057916813948), 16: (2, 127, 0.24108497298315285), 17: (2, 127, 0.24105806729396967), 18: (2, 127, 0.24111645525013367), 19: (2, 127, 0.2412365558520546), 20: (2, 127, 0.24106219260564704), 21: (2, 127, 0.2411908178377574), 22: (2, 127, 0.24101149721995113), 23: (2, 127, 0.24103039634362686), 24: (2, 127, 0.24101712912555753), 25: (2, 127, 0.24113309868853391), 26: (2, 127, 0.2411202634428078), 27: (2, 127, 0.2410693366857847), 28: (2, 127, 0.2409004334976354), 29: (2, 127, 0.24120777513919853), 30: (2, 127, 0.24113039104047956), 31: (2, 127, 0.2410394328419031), 32: (2, 127, 0.24105648212428168), 33: (2, 127, 0.24108150170192005), 34: (2, 127, 0.24084322554917317), 35: (2, 127, 0.24103663456222907), 36: (2, 127, 0.24107019987514638), 37: (2, 127, 0.24108056347875848), 38: (2, 127, 0.24104868537035046), 39: (2, 127, 0.24111295038995545), 40: (2, 127, 0.2412287148933007), 41: (2, 127, 0.24114359038199965), 42: (2, 127, 0.24123125685393576), 43: (2, 127, 0.2409842410234837), 44: (2, 127, 0.24118286124100602), 45: (2, 127, 0.24123050361930384), 46: (2, 127, 0.24101836265130774), 47: (2, 127, 0.2411053441464901), 48: (2, 127, 0.24102513826503527), 49: (2, 127, 0.24107557461105697), 50: (2, 127, 0.24115778278471448), 51: (2, 127, 0.2411849131866351), 52: (2, 127, 0.24094435395892916), 53: (2, 127, 0.24114725435167317), 54: (2, 127, 0.24099504635999286), 55: (2, 127, 0.24094151731169833), 56: (2, 127, 0.2409693077426609), 57: (2, 127, 0.24098732820382035), 58: (2, 127, 0.2409331715614425), 59: (2, 127, 0.24095809356287473), 60: (2, 127, 0.24075396985959585), 61: (2, 127, 0.2408164315820327), 62: (2, 127, 0.24077733773298152), 63: (2, 127, 0.24136125034557318), 64: (2, 127, 0.24103408479168426), 65: (2, 127, 0.24116637071550595), 66: (2, 127, 0.24088049671194683), 67: (2, 127, 0.24096146536125676), 68: (2, 127, 0.24095377143413768), 69: (2, 127, 0.24101014053229036), 70: (2, 127, 0.24094486020974756)}\n",
      "{'predict_runtime': 2184.1594, 'predict_samples_per_second': 0.065, 'predict_steps_per_second': 0.033}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:24.15\n",
      "  predict_samples_per_second =      0.065\n",
      "  predict_steps_per_second   =      0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.404134021140635), 2: (4, 0.3796100728213787), 3: (4, 0.37007285468280315), 4: (4, 0.38911854941397905), 5: (4, 0.3720440426841378), 6: (4, 0.37920332979410887), 7: (4, 0.3897829242050648), 8: (4, 0.39091199077665806), 9: (4, 0.38929436076432467), 10: (4, 0.3680062033236027), 11: (4, 0.3911994183436036), 12: (4, 0.36865049321204424), 13: (4, 0.37357556726783514), 14: (4, 0.38843259029090405), 15: (4, 0.36975710559636354), 16: (4, 0.3742634439840913), 17: (4, 0.370361533947289), 18: (4, 0.3687049336731434), 19: (4, 0.3713135654106736), 20: (4, 0.3676233207806945), 21: (4, 0.3698339769616723), 22: (4, 0.3663278706371784), 23: (4, 0.36865120381116867), 24: (4, 0.36834602896124125), 25: (4, 0.3728519370779395), 26: (4, 0.36720674484968185), 27: (4, 0.3706772858276963), 28: (4, 0.36536991130560637), 29: (4, 0.373424356803298), 30: (4, 0.3894442254677415), 31: (4, 0.3708190508186817), 32: (4, 0.36788875702768564), 33: (4, 0.37615166045725346), 34: (4, 0.3742853235453367), 35: (4, 0.3705695690587163), 36: (4, 0.37026300374418497), 37: (4, 0.3719777250662446), 38: (4, 0.3906119344756007), 39: (4, 0.3744792975485325), 40: (4, 0.367905386723578), 41: (4, 0.3731015073135495), 42: (4, 0.3745267214253545), 43: (4, 0.376330160535872), 44: (4, 0.3731954488903284), 45: (4, 0.3817291185259819), 46: (4, 0.3713856926187873), 47: (4, 0.36939639784395695), 48: (4, 0.3721896056085825), 49: (4, 0.3721071667969227), 50: (4, 0.3685679407790303), 51: (4, 0.37008542474359274), 52: (4, 0.37317828740924597), 53: (4, 0.37092121690511703), 54: (4, 0.3676326163113117), 55: (4, 0.3695374047383666), 56: (4, 0.3725427994504571), 57: (4, 0.37138656713068485), 58: (4, 0.3682316346094012), 59: (4, 0.37425808515399694), 60: (4, 0.3702229531481862), 61: (4, 0.37082044687122107), 62: (4, 0.37049480341374874), 63: (4, 0.3741224408149719), 64: (4, 0.37576084211468697), 65: (4, 0.36744331289082766), 66: (4, 0.37292098719626665), 67: (4, 0.3741617649793625), 68: (4, 0.3742635352537036), 69: (4, 0.36959447152912617), 70: (4, 0.3877524062991142), 71: (1, 0.2597374767065048)}\n",
      "{1: (4, 127, 0.24186763365379), 2: (4, 127, 0.24139888998942347), 3: (4, 127, 0.24151661103283326), 4: (4, 127, 0.24152013105816963), 5: (4, 127, 0.24164174266863525), 6: (4, 127, 0.24137245150884307), 7: (4, 127, 0.24187230210985958), 8: (4, 127, 0.24136418338835708), 9: (4, 127, 0.24157464441176005), 10: (4, 127, 0.24144837706841119), 11: (4, 127, 0.24176419058477316), 12: (4, 127, 0.2416478063925866), 13: (4, 127, 0.2414173870897434), 14: (4, 127, 0.24145578739680643), 15: (4, 127, 0.24146344685032378), 16: (4, 127, 0.24140574447957314), 17: (4, 127, 0.24130376176101956), 18: (4, 127, 0.24139143429755225), 19: (4, 127, 0.24152928944970445), 20: (4, 127, 0.2412044413050446), 21: (4, 127, 0.24138701549459865), 22: (4, 127, 0.2410578725742191), 23: (4, 127, 0.24146585662915246), 24: (4, 127, 0.2409994000363655), 25: (4, 127, 0.2411433668279155), 26: (4, 127, 0.24117422197014093), 27: (4, 127, 0.24111076459053934), 28: (4, 127, 0.2411134897210584), 29: (4, 127, 0.24117573089604302), 30: (4, 127, 0.24112743535262393), 31: (4, 127, 0.24101961387218687), 32: (4, 127, 0.241154439967331), 33: (4, 127, 0.24104571602798588), 34: (4, 127, 0.2411517881252986), 35: (4, 127, 0.2413765315963762), 36: (4, 127, 0.24118621403894086), 37: (4, 127, 0.24104104112599076), 38: (4, 127, 0.2411212326709445), 39: (4, 127, 0.24124009815580028), 40: (4, 127, 0.2410823419602133), 41: (4, 127, 0.24123112139416727), 42: (4, 127, 0.24111658261399568), 43: (4, 127, 0.24114516408982004), 44: (4, 127, 0.24118308622507365), 45: (4, 127, 0.24097979278487014), 46: (4, 127, 0.24103713019450348), 47: (4, 127, 0.2410745811831998), 48: (4, 127, 0.240904006711024), 49: (4, 127, 0.2409194651991129), 50: (4, 127, 0.240918633535387), 51: (4, 127, 0.24089511720038306), 52: (4, 127, 0.24077891248945646), 53: (4, 127, 0.24090847894402706), 54: (4, 127, 0.2407234230731416), 55: (4, 127, 0.24086433544197655), 56: (4, 127, 0.24083154437344845), 57: (4, 127, 0.2407666311826645), 58: (4, 127, 0.24108639215742508), 59: (4, 127, 0.24118123383913923), 60: (4, 127, 0.24104440700644114), 61: (4, 127, 0.24115415856124847), 62: (4, 127, 0.24141127905097065), 63: (4, 127, 0.24129920173436403), 64: (4, 127, 0.2414627027015869), 65: (4, 127, 0.24130938034211322), 66: (4, 127, 0.2412783476912717), 67: (4, 127, 0.24127118425869096), 68: (4, 127, 0.24138902542071314), 69: (4, 127, 0.24128694357863795), 70: (4, 127, 0.2412392418010263)}\n",
      "{'predict_runtime': 2190.8235, 'predict_samples_per_second': 0.128, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:30.82\n",
      "  predict_samples_per_second =      0.128\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 30\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.40869997534900904), 2: (1, 0.26538274344056845), 3: (1, 0.2639639237895608), 4: (1, 0.2611910654231906), 5: (1, 0.26302612386643887), 6: (1, 0.2621031356975436), 7: (1, 0.260897820815444), 8: (1, 0.26382046565413475), 9: (1, 0.2669478300958872), 10: (1, 0.2622824553400278), 11: (1, 0.26380954775959253), 12: (1, 0.26261069159954786), 13: (1, 0.2635860312730074), 14: (1, 0.2640712456777692), 15: (1, 0.26235121581703424), 16: (1, 0.26161650475114584), 17: (1, 0.2642762139439583), 18: (1, 0.265512109734118), 19: (1, 0.2631018990650773), 20: (1, 0.26727388985455036), 21: (1, 0.2620281232520938), 22: (1, 0.2633261075243354), 23: (1, 0.26221164129674435), 24: (1, 0.26386683247983456), 25: (1, 0.2632980393245816), 26: (1, 0.26333918888121843), 27: (1, 0.27435989771038294), 28: (1, 0.26169613748788834), 29: (1, 0.2671273984014988), 30: (1, 0.2647811956703663), 31: (1, 0.2605802370235324), 32: (1, 0.26293318904936314), 33: (1, 0.2633322551846504), 34: (1, 0.26198619045317173), 35: (1, 0.26384921837598085), 36: (1, 0.26456556003540754), 37: (1, 0.26106942258775234), 38: (1, 0.26289294101297855), 39: (1, 0.2659990144893527), 40: (1, 0.2610625736415386), 41: (1, 0.26456829253584146), 42: (1, 0.2626129360869527), 43: (1, 0.2616044180467725), 44: (1, 0.26269227359443903), 45: (1, 0.26478215027600527), 46: (1, 0.2647149218246341), 47: (1, 0.26338990684598684), 48: (1, 0.265371804125607), 49: (1, 0.2630059029906988), 50: (1, 0.2659443886950612), 51: (1, 0.26310741156339645), 52: (1, 0.26455272547900677), 53: (1, 0.2652531173080206), 54: (1, 0.26355028711259365), 55: (1, 0.26533039566129446), 56: (1, 0.26297277584671974), 57: (1, 0.2641771314665675), 58: (1, 0.2646308168768883), 59: (1, 0.2631475441157818), 60: (1, 0.26325793378055096), 61: (1, 0.263003115542233), 62: (1, 0.2634576503187418), 63: (1, 0.2630541045218706), 64: (1, 0.2657212344929576), 65: (1, 0.2641223631799221), 66: (1, 0.26220982428640127), 67: (1, 0.2639166945591569), 68: (1, 0.26562583446502686), 69: (1, 0.2636457271873951), 70: (1, 0.26502104103565216), 71: (1, 0.2608447801321745)}\n",
      "{1: (1, 255, 0.1572797410153583), 2: (1, 255, 0.1569512334487894), 3: (1, 255, 0.15674085953072006), 4: (1, 255, 0.15712469641630555), 5: (1, 255, 0.15712594186485399), 6: (1, 255, 0.15695495481292407), 7: (1, 255, 0.15754703850503646), 8: (1, 255, 0.15727495065360678), 9: (1, 255, 0.15713219317224095), 10: (1, 255, 0.16024047709709288), 11: (1, 255, 0.15762031673289398), 12: (1, 255, 0.1571895110366099), 13: (1, 255, 0.15738880990767012), 14: (1, 255, 0.1573984996689593), 15: (1, 255, 0.1571880061215922), 16: (1, 255, 0.15772053137713787), 17: (1, 255, 0.15701622762078163), 18: (1, 255, 0.1577922978201041), 19: (1, 255, 0.15760118889384994), 20: (1, 255, 0.15708250523563108), 21: (1, 255, 0.15731053838104594), 22: (1, 255, 0.15730297115138347), 23: (1, 255, 0.1571426792983331), 24: (1, 255, 0.15735014703709121), 25: (1, 255, 0.15733141236226347), 26: (1, 255, 0.15698640195689365), 27: (1, 255, 0.15675913745208697), 28: (1, 255, 0.15718330540785602), 29: (1, 255, 0.15695585147934218), 30: (1, 255, 0.15705733856222792), 31: (1, 255, 0.1568945799095958), 32: (1, 255, 0.1569799761196562), 33: (1, 255, 0.15700686972807434), 34: (1, 255, 0.15684515314505382), 35: (1, 255, 0.15680959745145895), 36: (1, 255, 0.15692505722171535), 37: (1, 255, 0.15687691602563741), 38: (1, 255, 0.1569339989118424), 39: (1, 255, 0.15679319324519705), 40: (1, 255, 0.15690675550231747), 41: (1, 255, 0.15657572118821098), 42: (1, 255, 0.15670471599727284), 43: (1, 255, 0.15702162721723903), 44: (1, 255, 0.15656293382247288), 45: (1, 255, 0.15648667314181142), 46: (1, 255, 0.15658608332422433), 47: (1, 255, 0.1566246879049668), 48: (1, 255, 0.15664376986450423), 49: (1, 255, 0.15681467036552288), 50: (1, 255, 0.15677224068957216), 51: (1, 255, 0.15676481146730628), 52: (1, 255, 0.1568880044106467), 53: (1, 255, 0.15692625064037594), 54: (1, 255, 0.15700114032290147), 55: (1, 255, 0.1572523086130911), 56: (1, 255, 0.15711420032323575), 57: (1, 255, 0.15731680518125787), 58: (1, 255, 0.15712016805933388), 59: (1, 255, 0.15725467888747943), 60: (1, 255, 0.15725710214499164), 61: (1, 255, 0.15746813373019297), 62: (1, 255, 0.15729620130184818), 63: (1, 255, 0.15707101619930244), 64: (1, 255, 0.15716311910427083), 65: (1, 255, 0.15754727658395673), 66: (1, 255, 0.15766792194735185), 67: (1, 255, 0.15708285142101494), 68: (1, 255, 0.1571057255325072), 69: (1, 255, 0.15705286312629194), 70: (1, 255, 0.1570106437210651)}\n",
      "{'predict_runtime': 2863.6228, 'predict_samples_per_second': 0.025, 'predict_steps_per_second': 0.025}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:47:43.62\n",
      "  predict_samples_per_second =      0.025\n",
      "  predict_steps_per_second   =      0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.30974791664630175), 2: (2, 0.28802705742418766), 3: (2, 0.28949720971286297), 4: (2, 0.2881258763372898), 5: (2, 0.2997578205540776), 6: (2, 0.2881252355873585), 7: (2, 0.3115176912397146), 8: (2, 0.33046106062829494), 9: (2, 0.29880847968161106), 10: (2, 0.3345453720539808), 11: (2, 0.29690233152359724), 12: (2, 0.30296572018414736), 13: (2, 0.33851588424295187), 14: (2, 0.28405344020575285), 15: (2, 0.3060087142512202), 16: (2, 0.2847013818100095), 17: (2, 0.28487126901745796), 18: (2, 0.31679415609687567), 19: (2, 0.3363320380449295), 20: (2, 0.3362631481140852), 21: (2, 0.33587645180523396), 22: (2, 0.2890155706554651), 23: (2, 0.2868665736168623), 24: (2, 0.30375830736011267), 25: (2, 0.31230128556489944), 26: (2, 0.2884448254480958), 27: (2, 0.3292387677356601), 28: (2, 0.28286605048924685), 29: (2, 0.3168356027454138), 30: (2, 0.28730278834700584), 31: (2, 0.2869395921006799), 32: (2, 0.30036723520606756), 33: (2, 0.288482453674078), 34: (2, 0.3151836497709155), 35: (2, 0.2838812032714486), 36: (2, 0.2844606367871165), 37: (2, 0.3335984004661441), 38: (2, 0.3081790320575237), 39: (2, 0.33796887658536434), 40: (2, 0.32941651437431574), 41: (2, 0.33874036744236946), 42: (2, 0.33305537328124046), 43: (2, 0.3166672708466649), 44: (2, 0.3305009100586176), 45: (2, 0.29314745031297207), 46: (2, 0.3333409670740366), 47: (2, 0.2922516204416752), 48: (2, 0.336612886749208), 49: (2, 0.28578458447009325), 50: (2, 0.3354006800800562), 51: (2, 0.2929449509829283), 52: (2, 0.2984088594093919), 53: (2, 0.34031988959759474), 54: (2, 0.29092416260391474), 55: (2, 0.32192476745694876), 56: (2, 0.3296727081760764), 57: (2, 0.29408812429755926), 58: (2, 0.302388746291399), 59: (2, 0.2911935243755579), 60: (2, 0.33631436713039875), 61: (2, 0.3011987777426839), 62: (2, 0.3050733534619212), 63: (2, 0.33478724118322134), 64: (2, 0.30838534142822027), 65: (2, 0.3225949490442872), 66: (2, 0.2911860095337033), 67: (2, 0.2851316975429654), 68: (2, 0.3398607671260834), 69: (2, 0.3325690748170018), 70: (2, 0.28174050617963076), 71: (1, 0.2674124576151371)}\n",
      "{1: (2, 255, 0.2416949078586756), 2: (2, 255, 0.24094253043991093), 3: (2, 255, 0.2410034906192153), 4: (2, 255, 0.24081733702663696), 5: (2, 255, 0.24090364060784672), 6: (2, 255, 0.24142247475318465), 7: (2, 255, 0.24150605312019002), 8: (2, 255, 0.24160557616429001), 9: (2, 255, 0.24151081113400413), 10: (2, 255, 0.2415101307316446), 11: (2, 255, 0.24156827349215745), 12: (2, 255, 0.24152794395956922), 13: (2, 255, 0.24162816372426116), 14: (2, 255, 0.24241613004648802), 15: (2, 255, 0.24180972928948263), 16: (2, 255, 0.24142403087268274), 17: (2, 255, 0.24162960836262096), 18: (2, 255, 0.24152868261524274), 19: (2, 255, 0.24151853695511818), 20: (2, 255, 0.2415648378504842), 21: (2, 255, 0.24173385468402914), 22: (2, 255, 0.24166631797219024), 23: (2, 255, 0.24169265935380085), 24: (2, 255, 0.2415156545957514), 25: (2, 255, 0.24162220610123056), 26: (2, 255, 0.24165771475390477), 27: (2, 255, 0.24174345281048149), 28: (2, 255, 0.24146205773029258), 29: (2, 255, 0.24152515237676161), 30: (2, 255, 0.24144954881539532), 31: (2, 255, 0.24136625408541923), 32: (2, 255, 0.24180415039699452), 33: (2, 255, 0.24145482950204727), 34: (2, 255, 0.24153144416928876), 35: (2, 255, 0.24154820384859454), 36: (2, 255, 0.24152969749388742), 37: (2, 255, 0.2415229915622987), 38: (2, 255, 0.24173593303444338), 39: (2, 255, 0.24146398527949464), 40: (2, 255, 0.2413466366080969), 41: (2, 255, 0.2413427236179511), 42: (2, 255, 0.24131644375841407), 43: (2, 255, 0.24157320212061498), 44: (2, 255, 0.24182154855818724), 45: (2, 255, 0.24161645105364277), 46: (2, 255, 0.24163507360088474), 47: (2, 255, 0.2414542617203266), 48: (2, 255, 0.24163810778774467), 49: (2, 255, 0.24162578882613017), 50: (2, 255, 0.24184085403149033), 51: (2, 255, 0.24167014795410283), 52: (2, 255, 0.24153139088668074), 53: (2, 255, 0.24158807827488465), 54: (2, 255, 0.24161161672250897), 55: (2, 255, 0.24171859615062383), 56: (2, 255, 0.24174523893743755), 57: (2, 255, 0.2416535638820599), 58: (2, 255, 0.2414813514104953), 59: (2, 255, 0.2413817787031625), 60: (2, 255, 0.2411166309287735), 61: (2, 255, 0.24162946750647296), 62: (2, 255, 0.2414131755045816), 63: (2, 255, 0.24118265490978957), 64: (2, 255, 0.24134831169583634), 65: (2, 255, 0.24141528573544585), 66: (2, 255, 0.24137166322154158), 67: (2, 255, 0.24168421447496205), 68: (2, 255, 0.24110714750108767), 69: (2, 255, 0.2413120184678073), 70: (2, 255, 0.24143692556330387)}\n",
      "{'predict_runtime': 4372.9261, 'predict_samples_per_second': 0.032, 'predict_steps_per_second': 0.016}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:12:52.92\n",
      "  predict_samples_per_second =      0.032\n",
      "  predict_steps_per_second   =      0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3973395014181733), 2: (4, 0.37213993817567825), 3: (4, 0.3873319234699011), 4: (4, 0.3710708376020193), 5: (4, 0.37279548682272434), 6: (4, 0.3748523611575365), 7: (4, 0.3725409675389528), 8: (4, 0.4193959180265665), 9: (4, 0.37639584951102734), 10: (4, 0.3734486345201731), 11: (4, 0.37528548017144203), 12: (4, 0.3759458316490054), 13: (4, 0.36927133798599243), 14: (4, 0.3719539372250438), 15: (4, 0.3743009576573968), 16: (4, 0.37119247298687696), 17: (4, 0.37123149167746305), 18: (4, 0.3715799069032073), 19: (4, 0.3721081893891096), 20: (4, 0.368910176679492), 21: (4, 0.37102633994072676), 22: (4, 0.3751569213345647), 23: (4, 0.3720628162845969), 24: (4, 0.36994051933288574), 25: (4, 0.3678650427609682), 26: (4, 0.37283784337341785), 27: (4, 0.4062747089192271), 28: (4, 0.37182533368468285), 29: (4, 0.36818521562963724), 30: (4, 0.3707328150048852), 31: (4, 0.3738363590091467), 32: (4, 0.37600629311054945), 33: (4, 0.3730859076604247), 34: (4, 0.36981559451669455), 35: (4, 0.3745522992685437), 36: (4, 0.3733131214976311), 37: (4, 0.379508969374001), 38: (4, 0.3845143923535943), 39: (4, 0.3729333421215415), 40: (4, 0.38087411038577557), 41: (4, 0.3721177587285638), 42: (4, 0.372610691934824), 43: (4, 0.3710829894989729), 44: (4, 0.37144160456955433), 45: (4, 0.37483084481209517), 46: (4, 0.36885939072817564), 47: (4, 0.37145879957824945), 48: (4, 0.37166102696210146), 49: (4, 0.37282996252179146), 50: (4, 0.370522147975862), 51: (4, 0.3724448150023818), 52: (4, 0.3697824738919735), 53: (4, 0.37318423483520746), 54: (4, 0.3689525034278631), 55: (4, 0.3717330200597644), 56: (4, 0.37058540247380733), 57: (4, 0.3723826399073005), 58: (4, 0.3710215650498867), 59: (4, 0.3745462838560343), 60: (4, 0.3699120059609413), 61: (4, 0.3727292828261852), 62: (4, 0.37048431672155857), 63: (4, 0.37742071878165007), 64: (4, 0.3729819171130657), 65: (4, 0.3698298819363117), 66: (4, 0.37646382581442595), 67: (4, 0.3721358049660921), 68: (4, 0.37079507019370794), 69: (4, 0.38144957553595304), 70: (4, 0.36794320959597826), 71: (1, 0.2666021268814802)}\n",
      "{1: (4, 255, 0.24302206798365303), 2: (4, 255, 0.2433591208256343), 3: (4, 255, 0.2428753362639862), 4: (4, 255, 0.242887495516562), 5: (4, 255, 0.24285988943906975), 6: (4, 255, 0.24279625316095702), 7: (4, 255, 0.24332802194152392), 8: (4, 255, 0.24331377260386944), 9: (4, 255, 0.24264866267057025), 10: (4, 255, 0.24276297443418526), 11: (4, 255, 0.2424930558777323), 12: (4, 255, 0.2428301696099487), 13: (4, 255, 0.2430138758182818), 14: (4, 255, 0.24323515980413146), 15: (4, 255, 0.24280431035394762), 16: (4, 255, 0.24277764230820478), 17: (4, 255, 0.2424914074112095), 18: (4, 255, 0.2429834183634204), 19: (4, 255, 0.24257275813861806), 20: (4, 255, 0.24238356404079525), 21: (4, 255, 0.24252303378546938), 22: (4, 255, 0.2425829749590918), 23: (4, 255, 0.24234983116461367), 24: (4, 255, 0.24245044721984396), 25: (4, 255, 0.24249556227861083), 26: (4, 255, 0.2424619084881509), 27: (4, 255, 0.24250227185148818), 28: (4, 255, 0.24255214202053407), 29: (4, 255, 0.24252407187413352), 30: (4, 255, 0.24242807456164384), 31: (4, 255, 0.24287310603859963), 32: (4, 255, 0.2423450424244591), 33: (4, 255, 0.2425588390077738), 34: (4, 255, 0.24251177993183043), 35: (4, 255, 0.24242454630633195), 36: (4, 255, 0.24234668592392813), 37: (4, 255, 0.24231390080542542), 38: (4, 255, 0.24228394217423949), 39: (4, 255, 0.24231234991959497), 40: (4, 255, 0.24237086450790657), 41: (4, 255, 0.2423421604522303), 42: (4, 255, 0.24241616096274526), 43: (4, 255, 0.24308771533051543), 44: (4, 255, 0.24327814355857816), 45: (4, 255, 0.24286189151599127), 46: (4, 255, 0.24270733200086683), 47: (4, 255, 0.24258283079035725), 48: (4, 255, 0.24263084652450154), 49: (4, 255, 0.2428107682177249), 50: (4, 255, 0.24255773261116415), 51: (4, 255, 0.24269446847120338), 52: (4, 255, 0.24267944386776755), 53: (4, 255, 0.24250231727081187), 54: (4, 255, 0.24259891956679377), 55: (4, 255, 0.24258561415561275), 56: (4, 255, 0.24254167886706543), 57: (4, 255, 0.24258434616540578), 58: (4, 255, 0.24249516116710854), 59: (4, 255, 0.24253300144245812), 60: (4, 255, 0.24252984156722532), 61: (4, 255, 0.24250054469733845), 62: (4, 255, 0.24257672663924157), 63: (4, 255, 0.24261999017759867), 64: (4, 255, 0.24263060241572412), 65: (4, 255, 0.2427479043822078), 66: (4, 255, 0.24276178883132982), 67: (4, 255, 0.24263977820382399), 68: (4, 255, 0.2426695458627507), 69: (4, 255, 0.24249707626945832), 70: (4, 255, 0.24263487493655844)}\n",
      "{'predict_runtime': 4397.82, 'predict_samples_per_second': 0.064, 'predict_steps_per_second': 0.016}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 1:13:17.81\n",
      "  predict_samples_per_second =      0.064\n",
      "  predict_steps_per_second   =      0.016\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 30\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
