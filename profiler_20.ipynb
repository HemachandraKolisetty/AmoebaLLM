{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 20, 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.3357008593156934), 2: (1, 0.17590597085654736), 3: (1, 0.18027340807020664), 4: (1, 0.1782472226768732), 5: (1, 0.17430302128195763), 6: (1, 0.1868349090218544), 7: (1, 0.17556175589561462), 8: (1, 0.1741384845227003), 9: (1, 0.1736690392717719), 10: (1, 0.17307489644736052), 11: (1, 0.1713251881301403), 12: (1, 0.17146717850118876), 13: (1, 0.17215076833963394), 14: (1, 0.17267207335680723), 15: (1, 0.1719717001542449), 16: (1, 0.17253245413303375), 17: (1, 0.1715168757364154), 18: (1, 0.17446238081902266), 19: (1, 0.1726302532479167), 20: (1, 0.1707500834017992), 21: (1, 0.18963549099862576), 22: (1, 0.17549395747482777), 23: (1, 0.17110356036573648), 24: (1, 0.17567132599651814), 25: (1, 0.17249180376529694), 26: (1, 0.17329977359622717), 27: (1, 0.1731029748916626), 28: (1, 0.1703785676509142), 29: (1, 0.1713571259751916), 30: (1, 0.1720207966864109), 31: (1, 0.17314661387354136), 32: (1, 0.17225416470319033), 33: (1, 0.17073061130940914), 34: (1, 0.17116108536720276), 35: (1, 0.17152425274252892), 36: (1, 0.17662375140935183), 37: (1, 0.17062928341329098), 38: (1, 0.17107529658824205), 39: (1, 0.17143660224974155), 40: (1, 0.1745873847976327), 41: (1, 0.17164740897715092), 42: (1, 0.17044190410524607), 43: (1, 0.17075033020228148), 44: (1, 0.17034147400408983), 45: (1, 0.17368441447615623), 46: (1, 0.17252207826822996), 47: (1, 0.17281337548047304), 48: (1, 0.17149502970278263), 49: (1, 0.17511152662336826), 50: (1, 0.17253682855516672), 51: (1, 0.1708585862070322), 52: (1, 0.173447135835886), 53: (1, 0.1718911351636052), 54: (1, 0.17189710400998592), 55: (1, 0.17185127455741167), 56: (1, 0.17040356155484915), 57: (1, 0.17013473436236382), 58: (1, 0.17224809899926186), 59: (1, 0.1725575365126133), 60: (1, 0.1701784124597907), 61: (1, 0.17137342877686024), 62: (1, 0.17138075921684504), 63: (1, 0.17183817271143198), 64: (1, 0.1720010917633772), 65: (1, 0.17271772306412458), 66: (1, 0.17046749964356422), 67: (1, 0.17215619888156652), 68: (1, 0.17186314240098), 69: (1, 0.17072679568082094), 70: (1, 0.17282330058515072), 71: (1, 0.17007062397897243)}\n",
      "{1: (1, 127, 0.10379241555049194), 2: (1, 127, 0.10263070316002594), 3: (1, 127, 0.10372476368467873), 4: (1, 127, 0.11005337108806597), 5: (1, 127, 0.10604292710172379), 6: (1, 127, 0.10534652682593254), 7: (1, 127, 0.1058006845487971), 8: (1, 127, 0.10659217382011217), 9: (1, 127, 0.1061730236988368), 10: (1, 127, 0.1065977376878379), 11: (1, 127, 0.1067201135401416), 12: (1, 127, 0.10577686626728125), 13: (1, 127, 0.1046663755770978), 14: (1, 127, 0.10453544978023045), 15: (1, 127, 0.10457768647630852), 16: (1, 127, 0.10484229889881658), 17: (1, 127, 0.10499624741505685), 18: (1, 127, 0.10487232734192545), 19: (1, 127, 0.10469244240130496), 20: (1, 127, 0.10599250496020467), 21: (1, 127, 0.11279057709162864), 22: (1, 127, 0.10485251658544766), 23: (1, 127, 0.10486099115154875), 24: (1, 127, 0.10512094323589342), 25: (1, 127, 0.10503771283671143), 26: (1, 127, 0.10490987619282457), 27: (1, 127, 0.10484913025990011), 28: (1, 127, 0.10487645170761375), 29: (1, 127, 0.10491120510947281), 30: (1, 127, 0.1047292651065926), 31: (1, 127, 0.10477699409788988), 32: (1, 127, 0.10477168310257629), 33: (1, 127, 0.10463838662042863), 34: (1, 127, 0.10468170708998686), 35: (1, 127, 0.10464355025411122), 36: (1, 127, 0.10463680998664203), 37: (1, 127, 0.10463849142721789), 38: (1, 127, 0.10480605957545633), 39: (1, 127, 0.1051431857929455), 40: (1, 127, 0.10521899548718544), 41: (1, 127, 0.10513975741855038), 42: (1, 127, 0.10512323120212931), 43: (1, 127, 0.10465011275630062), 44: (1, 127, 0.10482742031669523), 45: (1, 127, 0.10471240574068676), 46: (1, 127, 0.10458403613095678), 47: (1, 127, 0.10468539096209711), 48: (1, 127, 0.10481309147888986), 49: (1, 127, 0.10458818143306989), 50: (1, 127, 0.10459144625402107), 51: (1, 127, 0.10460743463532192), 52: (1, 127, 0.10453373814867002), 53: (1, 127, 0.10456253368202156), 54: (1, 127, 0.10457717563487648), 55: (1, 127, 0.10453855353370896), 56: (1, 127, 0.1046757905590018), 57: (1, 127, 0.10463804461237952), 58: (1, 127, 0.10452945460015395), 59: (1, 127, 0.10459785701663006), 60: (1, 127, 0.10458477101046738), 61: (1, 127, 0.10457006093173281), 62: (1, 127, 0.10454558238651104), 63: (1, 127, 0.1045383029199374), 64: (1, 127, 0.1045118199925371), 65: (1, 127, 0.10499750106324127), 66: (1, 127, 0.1053388389854098), 67: (1, 127, 0.10529185991411603), 68: (1, 127, 0.1053201856282283), 69: (1, 127, 0.1052027736225818), 70: (1, 127, 0.10461495735308551)}\n",
      "{'predict_runtime': 959.9228, 'predict_samples_per_second': 0.074, 'predict_steps_per_second': 0.074}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:59.92\n",
      "  predict_samples_per_second =      0.074\n",
      "  predict_steps_per_second   =      0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.20944281667470932), 2: (2, 0.18342932499945164), 3: (2, 0.178860348649323), 4: (2, 0.19723666086792946), 5: (2, 0.18412740528583527), 6: (2, 0.17918347381055355), 7: (2, 0.18911614641547203), 8: (2, 0.18019916210323572), 9: (2, 0.18891624826937914), 10: (2, 0.1815628558397293), 11: (2, 0.18332232348620892), 12: (2, 0.19560094829648733), 13: (2, 0.1954795392230153), 14: (2, 0.19829422608017921), 15: (2, 0.1952276211231947), 16: (2, 0.1930121872574091), 17: (2, 0.1851660404354334), 18: (2, 0.19453733786940575), 19: (2, 0.17962773703038692), 20: (2, 0.18081298097968102), 21: (2, 0.1829597158357501), 22: (2, 0.17786321602761745), 23: (2, 0.1779330763965845), 24: (2, 0.18300154525786638), 25: (2, 0.19564220495522022), 26: (2, 0.19824878312647343), 27: (2, 0.18112453632056713), 28: (2, 0.18565625324845314), 29: (2, 0.1938108755275607), 30: (2, 0.17687840573489666), 31: (2, 0.18344905879348516), 32: (2, 0.19691265746951103), 33: (2, 0.1768409674987197), 34: (2, 0.17847222741693258), 35: (2, 0.19748483039438725), 36: (2, 0.19119522627443075), 37: (2, 0.1936559472233057), 38: (2, 0.19367489591240883), 39: (2, 0.19352400675415993), 40: (2, 0.1946027623489499), 41: (2, 0.19443334452807903), 42: (2, 0.18483885284513235), 43: (2, 0.1927196215838194), 44: (2, 0.1948007568717003), 45: (2, 0.18264122400432825), 46: (2, 0.1798545867204666), 47: (2, 0.1819441905245185), 48: (2, 0.18102343939244747), 49: (2, 0.17980755399912596), 50: (2, 0.1928529618307948), 51: (2, 0.18289871606975794), 52: (2, 0.19458469934761524), 53: (2, 0.1872025141492486), 54: (2, 0.19518479146063328), 55: (2, 0.19468328822404146), 56: (2, 0.19700864050537348), 57: (2, 0.19823215436190367), 58: (2, 0.18047507666051388), 59: (2, 0.17687973845750093), 60: (2, 0.17867850605398417), 61: (2, 0.1805217256769538), 62: (2, 0.19337680470198393), 63: (2, 0.17923010792583227), 64: (2, 0.19629837106913328), 65: (2, 0.18269879557192326), 66: (2, 0.1792174754664302), 67: (2, 0.19629197753965855), 68: (2, 0.19618469756096601), 69: (2, 0.18291702028363943), 70: (2, 0.17718672566115856), 71: (1, 0.1868824027478695)}\n",
      "{1: (2, 127, 0.16200075764942357), 2: (2, 127, 0.16185133377691424), 3: (2, 127, 0.16165318615059918), 4: (2, 127, 0.16176565273804225), 5: (2, 127, 0.16167771112261795), 6: (2, 127, 0.16193861947724902), 7: (2, 127, 0.16154060486381447), 8: (2, 127, 0.1615453469750332), 9: (2, 127, 0.1616982423634393), 10: (2, 127, 0.16142210528606504), 11: (2, 127, 0.16143616753828338), 12: (2, 127, 0.16219684704551546), 13: (2, 127, 0.16198007502101772), 14: (2, 127, 0.16190580013171424), 15: (2, 127, 0.16141313989830064), 16: (2, 127, 0.16140936148594917), 17: (2, 127, 0.1612147566913737), 18: (2, 127, 0.16180303479420152), 19: (2, 127, 0.1614561373235907), 20: (2, 127, 0.16145410866835924), 21: (2, 127, 0.16180820153718153), 22: (2, 127, 0.1615560800203775), 23: (2, 127, 0.1615518376187194), 24: (2, 127, 0.16242046388760795), 25: (2, 127, 0.16264065709991718), 26: (2, 127, 0.16270281359788), 27: (2, 127, 0.16580810988923228), 28: (2, 127, 0.16203485750483246), 29: (2, 127, 0.16198638539878638), 30: (2, 127, 0.16209494064408025), 31: (2, 127, 0.16221463126607064), 32: (2, 127, 0.1614128393011065), 33: (2, 127, 0.1613802606327914), 34: (2, 127, 0.16145422055906666), 35: (2, 127, 0.16142060812269374), 36: (2, 127, 0.16140083175181874), 37: (2, 127, 0.1614120076080476), 38: (2, 127, 0.16151316618678843), 39: (2, 127, 0.1614136342252568), 40: (2, 127, 0.16137683438503836), 41: (2, 127, 0.16144726556674469), 42: (2, 127, 0.161518725419901), 43: (2, 127, 0.16129751671398954), 44: (2, 127, 0.16141252790203714), 45: (2, 127, 0.16156348229686576), 46: (2, 127, 0.16199212368049726), 47: (2, 127, 0.16205477099279014), 48: (2, 127, 0.16187298551612483), 49: (2, 127, 0.16139969921223526), 50: (2, 127, 0.1614055860142304), 51: (2, 127, 0.161466807955656), 52: (2, 127, 0.1613786025486124), 53: (2, 127, 0.16141895646244053), 54: (2, 127, 0.1614391007643985), 55: (2, 127, 0.16133232638386524), 56: (2, 127, 0.16131947259235335), 57: (2, 127, 0.16158421791532612), 58: (2, 127, 0.1615514136469505), 59: (2, 127, 0.16151245198703892), 60: (2, 127, 0.1614806552116913), 61: (2, 127, 0.1613687451958187), 62: (2, 127, 0.16144423334910643), 63: (2, 127, 0.161704333381742), 64: (2, 127, 0.16190771386027336), 65: (2, 127, 0.16191101120418216), 66: (2, 127, 0.16142003496331492), 67: (2, 127, 0.1613344887022193), 68: (2, 127, 0.16139613768804495), 69: (2, 127, 0.16149142581060177), 70: (2, 127, 0.16138380234987718)}\n",
      "{'predict_runtime': 1464.1597, 'predict_samples_per_second': 0.096, 'predict_steps_per_second': 0.048}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:24.15\n",
      "  predict_samples_per_second =      0.096\n",
      "  predict_steps_per_second   =      0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.22871690057218075), 2: (4, 0.2003589365631342), 3: (4, 0.22107135504484177), 4: (4, 0.21298392862081528), 5: (4, 0.1968389144167304), 6: (4, 0.19479867722839117), 7: (4, 0.19753587525337934), 8: (4, 0.20322252810001373), 9: (4, 0.1963310856372118), 10: (4, 0.20811751950532198), 11: (4, 0.21170133724808693), 12: (4, 0.19852322060614824), 13: (4, 0.19547146372497082), 14: (4, 0.2005687141790986), 15: (4, 0.19301694259047508), 16: (4, 0.19841970689594746), 17: (4, 0.19145300798118114), 18: (4, 0.19606051314622164), 19: (4, 0.20511371735483408), 20: (4, 0.20662035886198282), 21: (4, 0.20101462956517935), 22: (4, 0.19760431721806526), 23: (4, 0.19689718447625637), 24: (4, 0.19853869453072548), 25: (4, 0.19486708287149668), 26: (4, 0.19914576318114996), 27: (4, 0.19483548030257225), 28: (4, 0.19542671274393797), 29: (4, 0.19507272634655237), 30: (4, 0.19633529987186193), 31: (4, 0.20995235536247492), 32: (4, 0.19296520575881004), 33: (4, 0.20444785431027412), 34: (4, 0.20604275446385145), 35: (4, 0.19326074793934822), 36: (4, 0.2022532345727086), 37: (4, 0.20365591812878847), 38: (4, 0.19372927770018578), 39: (4, 0.20274713542312384), 40: (4, 0.19230450317263603), 41: (4, 0.195895591750741), 42: (4, 0.1962356846779585), 43: (4, 0.19028261117637157), 44: (4, 0.19336586631834507), 45: (4, 0.19482589792460203), 46: (4, 0.19495913572609425), 47: (4, 0.20006183627992868), 48: (4, 0.19750467408448458), 49: (4, 0.19065128173679113), 50: (4, 0.19662477169185877), 51: (4, 0.20894065126776695), 52: (4, 0.1925562871620059), 53: (4, 0.19438756443560123), 54: (4, 0.20775501150637865), 55: (4, 0.19425558298826218), 56: (4, 0.19530914071947336), 57: (4, 0.2014300199225545), 58: (4, 0.1947890156880021), 59: (4, 0.19565955363214016), 60: (4, 0.2014831965789199), 61: (4, 0.19600069802254438), 62: (4, 0.1953308843076229), 63: (4, 0.2036122791469097), 64: (4, 0.2019647266715765), 65: (4, 0.19637154042720795), 66: (4, 0.20529016759246588), 67: (4, 0.19418887328356504), 68: (4, 0.19457061775028706), 69: (4, 0.2052672542631626), 70: (4, 0.19275078736245632), 71: (1, 0.1708786878734827)}\n",
      "{1: (4, 127, 0.16471968360949218), 2: (4, 127, 0.16241255249300107), 3: (4, 127, 0.16330347436032897), 4: (4, 127, 0.16286977216249376), 5: (4, 127, 0.1628222259084188), 6: (4, 127, 0.16213281495921958), 7: (4, 127, 0.16201679638080943), 8: (4, 127, 0.1620319356452527), 9: (4, 127, 0.1620867450934226), 10: (4, 127, 0.1622288559717456), 11: (4, 127, 0.16223484394323873), 12: (4, 127, 0.16207073010709577), 13: (4, 127, 0.16193503455999564), 14: (4, 127, 0.16178291224999222), 15: (4, 127, 0.16185096291986506), 16: (4, 127, 0.16192751798016114), 17: (4, 127, 0.16189447173658084), 18: (4, 127, 0.16185861141750896), 19: (4, 127, 0.16188647596561534), 20: (4, 127, 0.16196003017991079), 21: (4, 127, 0.1618194694110141), 22: (4, 127, 0.16180298577876776), 23: (4, 127, 0.16177261941222928), 24: (4, 127, 0.16216452249626476), 25: (4, 127, 0.16184645591993033), 26: (4, 127, 0.16220425152931156), 27: (4, 127, 0.16239864330034792), 28: (4, 127, 0.16272796774063053), 29: (4, 127, 0.16245995773603833), 30: (4, 127, 0.16239051250960884), 31: (4, 127, 0.16213604898052655), 32: (4, 127, 0.1623587634957095), 33: (4, 127, 0.16175428828532537), 34: (4, 127, 0.1619632035919179), 35: (4, 127, 0.1617360163670708), 36: (4, 127, 0.16169613883573944), 37: (4, 127, 0.16178063227699732), 38: (4, 127, 0.16167063264572246), 39: (4, 127, 0.1617736177166968), 40: (4, 127, 0.16171971762068862), 41: (4, 127, 0.16192290544011226), 42: (4, 127, 0.16193441275184547), 43: (4, 127, 0.1618687077095424), 44: (4, 127, 0.1620176355977814), 45: (4, 127, 0.16221141614254533), 46: (4, 127, 0.16220122389495373), 47: (4, 127, 0.16138072054481178), 48: (4, 127, 0.16136379807630158), 49: (4, 127, 0.1613228122051072), 50: (4, 127, 0.1612231814060507), 51: (4, 127, 0.16128364990018015), 52: (4, 127, 0.1613377595731006), 53: (4, 127, 0.16124645597118092), 54: (4, 127, 0.1612901205827636), 55: (4, 127, 0.16135097831106326), 56: (4, 127, 0.16137095078767286), 57: (4, 127, 0.16124391926848514), 58: (4, 127, 0.16138989306018342), 59: (4, 127, 0.16131951524986057), 60: (4, 127, 0.1612606327394097), 61: (4, 127, 0.16145534931469385), 62: (4, 127, 0.16124005097250535), 63: (4, 127, 0.16135402533453047), 64: (4, 127, 0.16137769450910214), 65: (4, 127, 0.16120768512973166), 66: (4, 127, 0.16127107717008807), 67: (4, 127, 0.16128379186454017), 68: (4, 127, 0.16136125494967998), 69: (4, 127, 0.16137893431211317), 70: (4, 127, 0.16149740661017772)}\n",
      "{'predict_runtime': 1466.354, 'predict_samples_per_second': 0.192, 'predict_steps_per_second': 0.048}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:26.35\n",
      "  predict_samples_per_second =      0.192\n",
      "  predict_steps_per_second   =      0.048\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 20\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/71 00:28 < 16:01, 0.07 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.2072306191548705), 2: (1, 0.18174615036696196), 3: (1, 0.18096941988915205), 4: (1, 0.1797074843198061), 5: (1, 0.18054139334708452), 6: (1, 0.17978190165013075), 7: (1, 0.17993714939802885), 8: (1, 0.1805356815457344), 9: (1, 0.18177479691803455), 10: (1, 0.17968733981251717), 11: (1, 0.17938283272087574), 12: (1, 0.17860086262226105), 13: (1, 0.18036146089434624), 14: (1, 0.18008814379572868), 15: (1, 0.18031386099755764), 16: (1, 0.17845199164003134), 17: (1, 0.17955091875046492), 18: (1, 0.1797045860439539), 19: (1, 0.17934687994420528), 20: (1, 0.18032776936888695), 21: (1, 0.18193175923079252), 22: (1, 0.18167425226420164), 23: (1, 0.18044374510645866), 24: (1, 0.17862590495496988), 25: (1, 0.17801676131784916), 26: (1, 0.18185423780232668), 27: (1, 0.18038890324532986), 28: (1, 0.1781952390447259), 29: (1, 0.17920677736401558), 30: (1, 0.18066325969994068), 31: (1, 0.17986989859491587), 32: (1, 0.18076025694608688), 33: (1, 0.18052303045988083), 34: (1, 0.1824164167046547), 35: (1, 0.1836578929796815), 36: (1, 0.17886974848806858), 37: (1, 0.18555057980120182), 38: (1, 0.17948079947382212), 39: (1, 0.18077593483030796), 40: (1, 0.17838365212082863), 41: (1, 0.17840215098112822), 42: (1, 0.1790487626567483), 43: (1, 0.17893391381949186), 44: (1, 0.18060613237321377), 45: (1, 0.18008086923509836), 46: (1, 0.1819084184244275), 47: (1, 0.1827782578766346), 48: (1, 0.1821468248963356), 49: (1, 0.18075307924300432), 50: (1, 0.20706020388752222), 51: (1, 0.18009348679333925), 52: (1, 0.18058024067431688), 53: (1, 0.17935059498995543), 54: (1, 0.1813513720408082), 55: (1, 0.17988722771406174), 56: (1, 0.17915234714746475), 57: (1, 0.18086394481360912), 58: (1, 0.1779970796778798), 59: (1, 0.18092378415167332), 60: (1, 0.17944860644638538), 61: (1, 0.17866158485412598), 62: (1, 0.18044930510222912), 63: (1, 0.1812348049134016), 64: (1, 0.18640656489878893), 65: (1, 0.18036686535924673), 66: (1, 0.17963049188256264), 67: (1, 0.17826184816658497), 68: (1, 0.17880092095583677), 69: (1, 0.18036722298711538), 70: (1, 0.18546593375504017), 71: (1, 0.1775881750509143)}\n",
      "{1: (1, 127, 0.10984717063811117), 2: (1, 127, 0.10990521176828175), 3: (1, 127, 0.10979257011419441), 4: (1, 127, 0.1099361891630949), 5: (1, 127, 0.11002636881999847), 6: (1, 127, 0.1099618298668913), 7: (1, 127, 0.11046159733086824), 8: (1, 127, 0.10999279926113022), 9: (1, 127, 0.11008884948421652), 10: (1, 127, 0.11013703648822279), 11: (1, 127, 0.11008884680024751), 12: (1, 127, 0.10993307678571601), 13: (1, 127, 0.11026282700174671), 14: (1, 127, 0.11036860397980204), 15: (1, 127, 0.11023070146953028), 16: (1, 127, 0.11075528763879941), 17: (1, 127, 0.11022025240423876), 18: (1, 127, 0.1101752193057983), 19: (1, 127, 0.11057036760167813), 20: (1, 127, 0.1103568636174277), 21: (1, 127, 0.11026580603133271), 22: (1, 127, 0.11032111344375009), 23: (1, 127, 0.11011485514179693), 24: (1, 127, 0.1104561235961013), 25: (1, 127, 0.11036172274529464), 26: (1, 127, 0.11030302477604527), 27: (1, 127, 0.11014789590010728), 28: (1, 127, 0.11084377370393417), 29: (1, 127, 0.11082970499845705), 30: (1, 127, 0.11068322893789434), 31: (1, 127, 0.11079809945223369), 32: (1, 127, 0.11028109878800281), 33: (1, 127, 0.11014594637796166), 34: (1, 127, 0.10991135629729962), 35: (1, 127, 0.11000003233023985), 36: (1, 127, 0.10990276862317183), 37: (1, 127, 0.10991723559738144), 38: (1, 127, 0.10993353294311312), 39: (1, 127, 0.11007004432145535), 40: (1, 127, 0.11004077983418788), 41: (1, 127, 0.1104073650166979), 42: (1, 127, 0.11000021169416782), 43: (1, 127, 0.11007608551766694), 44: (1, 127, 0.11013312838736951), 45: (1, 127, 0.10994017525304725), 46: (1, 127, 0.11106934622076788), 47: (1, 127, 0.11109574668578745), 48: (1, 127, 0.11121841517871055), 49: (1, 127, 0.10985544108323694), 50: (1, 127, 0.11017067371097607), 51: (1, 127, 0.10993457944169054), 52: (1, 127, 0.1099092254019159), 53: (1, 127, 0.11028300631996685), 54: (1, 127, 0.11062190845960707), 55: (1, 127, 0.11057215603435133), 56: (1, 127, 0.11054900718310218), 57: (1, 127, 0.11045596196396848), 58: (1, 127, 0.11043307199839532), 59: (1, 127, 0.1102405604576384), 60: (1, 127, 0.11016629414823581), 61: (1, 127, 0.11024932886701165), 62: (1, 127, 0.11027917883351562), 63: (1, 127, 0.11023232984671912), 64: (1, 127, 0.11016157372143325), 65: (1, 127, 0.11023497555815563), 66: (1, 127, 0.1099927252759849), 67: (1, 127, 0.10991556712198915), 68: (1, 127, 0.10987242863432864), 69: (1, 127, 0.10984368731568414), 70: (1, 127, 0.1099948539200613)}\n",
      "{'predict_runtime': 1006.8019, 'predict_samples_per_second': 0.071, 'predict_steps_per_second': 0.071}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:16:46.80\n",
      "  predict_samples_per_second =      0.071\n",
      "  predict_steps_per_second   =      0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.22316023986786604), 2: (2, 0.1930084265768528), 3: (2, 0.18758493941277266), 4: (2, 0.20361463353037834), 5: (2, 0.18742291908711195), 6: (2, 0.187971961684525), 7: (2, 0.20249741524457932), 8: (2, 0.20330187678337097), 9: (2, 0.19869673810899258), 10: (2, 0.18723685946315527), 11: (2, 0.2024165652692318), 12: (2, 0.20352757070213556), 13: (2, 0.1925766570493579), 14: (2, 0.2044015796855092), 15: (2, 0.1877377424389124), 16: (2, 0.20272563956677914), 17: (2, 0.20164239034056664), 18: (2, 0.1970440037548542), 19: (2, 0.19103271141648293), 20: (2, 0.19196016248315573), 21: (2, 0.18723017536103725), 22: (2, 0.20345730800181627), 23: (2, 0.18593041133135557), 24: (2, 0.2037842534482479), 25: (2, 0.20268150512129068), 26: (2, 0.18554516416043043), 27: (2, 0.20347029529511929), 28: (2, 0.20446779392659664), 29: (2, 0.20297070033848286), 30: (2, 0.20269034802913666), 31: (2, 0.18692036904394627), 32: (2, 0.19083012361079454), 33: (2, 0.19113317038863897), 34: (2, 0.1896632257848978), 35: (2, 0.20340994838625193), 36: (2, 0.18762892950326204), 37: (2, 0.20248552691191435), 38: (2, 0.19444048963487148), 39: (2, 0.1997965481132269), 40: (2, 0.19033634569495916), 41: (2, 0.1950956406071782), 42: (2, 0.19355601910501719), 43: (2, 0.20124594029039145), 44: (2, 0.1869852328673005), 45: (2, 0.20388924796134233), 46: (2, 0.20307629648596048), 47: (2, 0.20454972982406616), 48: (2, 0.2031374154612422), 49: (2, 0.19126438163220882), 50: (2, 0.2001202804967761), 51: (2, 0.2034481903538108), 52: (2, 0.20266889967024326), 53: (2, 0.1901178527623415), 54: (2, 0.20087530929595232), 55: (2, 0.20490126125514507), 56: (2, 0.18760021217167377), 57: (2, 0.1877593295648694), 58: (2, 0.18501476105302572), 59: (2, 0.1877218196168542), 60: (2, 0.186904389411211), 61: (2, 0.20398327056318521), 62: (2, 0.20300279092043638), 63: (2, 0.1890776827931404), 64: (2, 0.1877611167728901), 65: (2, 0.1924589527770877), 66: (2, 0.19358473923057318), 67: (2, 0.194202552549541), 68: (2, 0.19000667985528708), 69: (2, 0.19047001376748085), 70: (2, 0.18849131651222706), 71: (1, 0.17804510705173016)}\n",
      "{1: (2, 127, 0.1693799251573175), 2: (2, 127, 0.16922607380662144), 3: (2, 127, 0.1689997665276091), 4: (2, 127, 0.16907937927391586), 5: (2, 127, 0.16923719860877343), 6: (2, 127, 0.16942911902369243), 7: (2, 127, 0.1694186064231349), 8: (2, 127, 0.16918475829856836), 9: (2, 127, 0.16901462762726574), 10: (2, 127, 0.16903103560238608), 11: (2, 127, 0.16892733936029392), 12: (2, 127, 0.16919791291460512), 13: (2, 127, 0.1688784892546145), 14: (2, 127, 0.1691233443506942), 15: (2, 127, 0.168925452361426), 16: (2, 127, 0.1691542432430809), 17: (2, 127, 0.16951842964663516), 18: (2, 127, 0.16980606568317244), 19: (2, 127, 0.1697212148267101), 20: (2, 127, 0.16925181362660616), 21: (2, 127, 0.16910393783954655), 22: (2, 127, 0.16926629619130235), 23: (2, 127, 0.16905561649042555), 24: (2, 127, 0.16904993482139402), 25: (2, 127, 0.16917931323680352), 26: (2, 127, 0.1690368902407528), 27: (2, 127, 0.1690536487891566), 28: (2, 127, 0.16903827794072196), 29: (2, 127, 0.16914707924584), 30: (2, 127, 0.16915537419868268), 31: (2, 127, 0.1690827767166683), 32: (2, 127, 0.16926606234867037), 33: (2, 127, 0.16923450840651755), 34: (2, 127, 0.16918569388176044), 35: (2, 127, 0.16913492583090395), 36: (2, 127, 0.16956453406669963), 37: (2, 127, 0.16959640902181075), 38: (2, 127, 0.16935587243917655), 39: (2, 127, 0.1690562627182936), 40: (2, 127, 0.1690472882959669), 41: (2, 127, 0.16906687739033868), 42: (2, 127, 0.16902173378717478), 43: (2, 127, 0.16909005107930092), 44: (2, 127, 0.16912318783716893), 45: (2, 127, 0.16895376062973982), 46: (2, 127, 0.16909339985128227), 47: (2, 127, 0.16900673036382893), 48: (2, 127, 0.16911982084206473), 49: (2, 127, 0.16915666740241014), 50: (2, 127, 0.16911654862919895), 51: (2, 127, 0.16912078589024976), 52: (2, 127, 0.1691139153256191), 53: (2, 127, 0.16896340256835532), 54: (2, 127, 0.16902087353844578), 55: (2, 127, 0.1691383607685566), 56: (2, 127, 0.1691532512745402), 57: (2, 127, 0.16911972158654467), 58: (2, 127, 0.1692110758758788), 59: (2, 127, 0.16906141515410555), 60: (2, 127, 0.1691161830227558), 61: (2, 127, 0.16899285107616366), 62: (2, 127, 0.1692471014350418), 63: (2, 127, 0.16917615871524483), 64: (2, 127, 0.1692366042416396), 65: (2, 127, 0.16911815687662035), 66: (2, 127, 0.1692311271482448), 67: (2, 127, 0.1690725623006661), 68: (2, 127, 0.16909970357779444), 69: (2, 127, 0.16908906812332278), 70: (2, 127, 0.16911246857833206)}\n",
      "{'predict_runtime': 1531.6541, 'predict_samples_per_second': 0.092, 'predict_steps_per_second': 0.046}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:31.65\n",
      "  predict_samples_per_second =      0.092\n",
      "  predict_steps_per_second   =      0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.23579750768840313), 2: (4, 0.208179478533566), 3: (4, 0.20044946670532227), 4: (4, 0.2168203368782997), 5: (4, 0.22134470473974943), 6: (4, 0.20367062836885452), 7: (4, 0.20563083421438932), 8: (4, 0.19988050125539303), 9: (4, 0.22078923881053925), 10: (4, 0.21987954899668694), 11: (4, 0.20525855757296085), 12: (4, 0.219351414591074), 13: (4, 0.20161047950387), 14: (4, 0.22498922795057297), 15: (4, 0.22830895893275738), 16: (4, 0.2040344811975956), 17: (4, 0.21864705067127943), 18: (4, 0.208058824762702), 19: (4, 0.22161812614649534), 20: (4, 0.20483554061502218), 21: (4, 0.20758141856640577), 22: (4, 0.2204651888459921), 23: (4, 0.20898894034326077), 24: (4, 0.20124463085085154), 25: (4, 0.2165678022429347), 26: (4, 0.20192818250507116), 27: (4, 0.20453060138970613), 28: (4, 0.20337935537099838), 29: (4, 0.203808699734509), 30: (4, 0.20325548574328423), 31: (4, 0.2094163130968809), 32: (4, 0.20419862400740385), 33: (4, 0.20587213430553675), 34: (4, 0.20305971708148718), 35: (4, 0.20373665913939476), 36: (4, 0.21747159771621227), 37: (4, 0.20859985053539276), 38: (4, 0.20198517758399248), 39: (4, 0.21647942811250687), 40: (4, 0.20576132275164127), 41: (4, 0.2023975420743227), 42: (4, 0.20336253009736538), 43: (4, 0.20243077166378498), 44: (4, 0.2004806138575077), 45: (4, 0.22282863315194845), 46: (4, 0.22075233608484268), 47: (4, 0.20465992484241724), 48: (4, 0.2177600311115384), 49: (4, 0.21291800774633884), 50: (4, 0.20179773587733507), 51: (4, 0.21293174754828215), 52: (4, 0.20984171237796545), 53: (4, 0.2050338787958026), 54: (4, 0.21251328103244305), 55: (4, 0.20027833245694637), 56: (4, 0.22045511659234762), 57: (4, 0.20494344178587198), 58: (4, 0.21514425612986088), 59: (4, 0.20140781998634338), 60: (4, 0.21721191238611937), 61: (4, 0.20381613168865442), 62: (4, 0.2034028461202979), 63: (4, 0.19884935673326254), 64: (4, 0.21828420646488667), 65: (4, 0.20170775428414345), 66: (4, 0.2200741870328784), 67: (4, 0.2083323895931244), 68: (4, 0.20237859524786472), 69: (4, 0.20343045331537724), 70: (4, 0.21551820635795593), 71: (1, 0.18046054244041443)}\n",
      "{1: (4, 127, 0.1700107040925054), 2: (4, 127, 0.17050610711490075), 3: (4, 127, 0.17037791161849272), 4: (4, 127, 0.17011723803048293), 5: (4, 127, 0.1696451558900161), 6: (4, 127, 0.16990102610484822), 7: (4, 127, 0.16965032336632097), 8: (4, 127, 0.1696252594298617), 9: (4, 127, 0.16957819188292336), 10: (4, 127, 0.1697538524836771), 11: (4, 127, 0.1696776176443485), 12: (4, 127, 0.16967616501579605), 13: (4, 127, 0.169563116916404), 14: (4, 127, 0.1715847583575629), 15: (4, 127, 0.1700254064933287), 16: (4, 127, 0.16974644268327577), 17: (4, 127, 0.17002081331305616), 18: (4, 127, 0.16962287277276591), 19: (4, 127, 0.16943198425592634), 20: (4, 127, 0.16945878996359787), 21: (4, 127, 0.16955111413372784), 22: (4, 127, 0.1693364363677037), 23: (4, 127, 0.1696130607687817), 24: (4, 127, 0.16944266286656612), 25: (4, 127, 0.16945528206012145), 26: (4, 127, 0.16972844665650072), 27: (4, 127, 0.1695864285951055), 28: (4, 127, 0.1695841369475788), 29: (4, 127, 0.16946012112422018), 30: (4, 127, 0.1694113502542921), 31: (4, 127, 0.1694818108349921), 32: (4, 127, 0.1695508113512256), 33: (4, 127, 0.16950081411279797), 34: (4, 127, 0.16963441758673256), 35: (4, 127, 0.1693060824236884), 36: (4, 127, 0.16933336043657046), 37: (4, 127, 0.16945520027973285), 38: (4, 127, 0.16937165233621918), 39: (4, 127, 0.16927183782461824), 40: (4, 127, 0.16939266640546286), 41: (4, 127, 0.16935966183673443), 42: (4, 127, 0.1695254326424026), 43: (4, 127, 0.16940525655935365), 44: (4, 127, 0.16929018207070395), 45: (4, 127, 0.1695165623522063), 46: (4, 127, 0.1692837066361754), 47: (4, 127, 0.16925926645117717), 48: (4, 127, 0.16941487069762362), 49: (4, 127, 0.16943442072044676), 50: (4, 127, 0.16936318651868368), 51: (4, 127, 0.16926165604157242), 52: (4, 127, 0.16928952628761296), 53: (4, 127, 0.16918623442284939), 54: (4, 127, 0.1690725206551472), 55: (4, 127, 0.16895115901312724), 56: (4, 127, 0.16943151813264437), 57: (4, 127, 0.1692978516147714), 58: (4, 127, 0.1694775653533696), 59: (4, 127, 0.16910944730190075), 60: (4, 127, 0.16922477121633572), 61: (4, 127, 0.1691870465434677), 62: (4, 127, 0.16959361528875086), 63: (4, 127, 0.16940667819759742), 64: (4, 127, 0.16956697090521572), 65: (4, 127, 0.169365063353669), 66: (4, 127, 0.1695328659751988), 67: (4, 127, 0.16953003908852188), 68: (4, 127, 0.16948270777929722), 69: (4, 127, 0.169404677122714), 70: (4, 127, 0.16958970206195678)}\n",
      "{'predict_runtime': 1536.1074, 'predict_samples_per_second': 0.183, 'predict_steps_per_second': 0.046}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:36.10\n",
      "  predict_samples_per_second =      0.183\n",
      "  predict_steps_per_second   =      0.046\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 21\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 20, 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.34021101519465446), 2: (1, 0.18178568501025438), 3: (1, 0.1808568174019456), 4: (1, 0.17791674099862576), 5: (1, 0.17585987597703934), 6: (1, 0.1758188046514988), 7: (1, 0.17825087811797857), 8: (1, 0.17717702127993107), 9: (1, 0.17706896271556616), 10: (1, 0.17530629131942987), 11: (1, 0.17548255994915962), 12: (1, 0.17717727087438107), 13: (1, 0.1770545421168208), 14: (1, 0.1767378058284521), 15: (1, 0.1751653952524066), 16: (1, 0.17593369632959366), 17: (1, 0.17702853307127953), 18: (1, 0.17546126060187817), 19: (1, 0.17789796367287636), 20: (1, 0.1761898323893547), 21: (1, 0.17793174274265766), 22: (1, 0.1771186627447605), 23: (1, 0.17683031596243382), 24: (1, 0.17675438709557056), 25: (1, 0.176231162622571), 26: (1, 0.17678663693368435), 27: (1, 0.1819420251995325), 28: (1, 0.18122322391718626), 29: (1, 0.1801994265988469), 30: (1, 0.17980836052447557), 31: (1, 0.17696435563266277), 32: (1, 0.17637489084154367), 33: (1, 0.18087007012218237), 34: (1, 0.1755324313417077), 35: (1, 0.18182066828012466), 36: (1, 0.18366573564708233), 37: (1, 0.17793861404061317), 38: (1, 0.17790923546999693), 39: (1, 0.17655352037400007), 40: (1, 0.17750855907797813), 41: (1, 0.17697852477431297), 42: (1, 0.1769930049777031), 43: (1, 0.1824578521773219), 44: (1, 0.18255516979843378), 45: (1, 0.17854455765336752), 46: (1, 0.18124824669212103), 47: (1, 0.17763263825327158), 48: (1, 0.17692949809134007), 49: (1, 0.17734943237155676), 50: (1, 0.17764008790254593), 51: (1, 0.17488238122314215), 52: (1, 0.1780088245868683), 53: (1, 0.17676513735204935), 54: (1, 0.17579061444848776), 55: (1, 0.17729634698480368), 56: (1, 0.1773530663922429), 57: (1, 0.17477542627602816), 58: (1, 0.17598732188344002), 59: (1, 0.17590949311852455), 60: (1, 0.17465616762638092), 61: (1, 0.17492195591330528), 62: (1, 0.1767202727496624), 63: (1, 0.1774806147441268), 64: (1, 0.17573732510209084), 65: (1, 0.17562411725521088), 66: (1, 0.1767473043873906), 67: (1, 0.17513197381049395), 68: (1, 0.1762050213292241), 69: (1, 0.17742388602346182), 70: (1, 0.1755181895568967), 71: (1, 0.17603876162320375)}\n",
      "{1: (1, 127, 0.10545097895729261), 2: (1, 127, 0.10467754597005648), 3: (1, 127, 0.10440329553222093), 4: (1, 127, 0.10496571214180293), 5: (1, 127, 0.10462655201114303), 6: (1, 127, 0.10511814975949722), 7: (1, 127, 0.10531468725374599), 8: (1, 127, 0.10413174128057215), 9: (1, 127, 0.10404958899360238), 10: (1, 127, 0.10388149275613112), 11: (1, 127, 0.10381384297296053), 12: (1, 127, 0.10407133992233379), 13: (1, 127, 0.1036717996191908), 14: (1, 127, 0.10373490421086784), 15: (1, 127, 0.10371657061265914), 16: (1, 127, 0.10374219887193263), 17: (1, 127, 0.10380061533243402), 18: (1, 127, 0.10457795263656716), 19: (1, 127, 0.10435149141066656), 20: (1, 127, 0.10468654517143026), 21: (1, 127, 0.10497494648379369), 22: (1, 127, 0.10400433051509886), 23: (1, 127, 0.10428024638502852), 24: (1, 127, 0.10381030085254607), 25: (1, 127, 0.10385109065467213), 26: (1, 127, 0.10379494365862035), 27: (1, 127, 0.10721875741109839), 28: (1, 127, 0.10476935225150247), 29: (1, 127, 0.10459537284932738), 30: (1, 127, 0.10554146479199251), 31: (1, 127, 0.10416587561691605), 32: (1, 127, 0.10417398517790037), 33: (1, 127, 0.10398315116176456), 34: (1, 127, 0.10511316560707458), 35: (1, 127, 0.10749553237843701), 36: (1, 127, 0.10685331886267568), 37: (1, 127, 0.10486152672802838), 38: (1, 127, 0.10482680829109874), 39: (1, 127, 0.10466519236476637), 40: (1, 127, 0.10436159574727374), 41: (1, 127, 0.1048817425291604), 42: (1, 127, 0.11022634363520568), 43: (1, 127, 0.10837179533843919), 44: (1, 127, 0.10543260063360056), 45: (1, 127, 0.10447728084620293), 46: (1, 127, 0.10428180987763358), 47: (1, 127, 0.10413584446783845), 48: (1, 127, 0.1041569120624638), 49: (1, 127, 0.10410035277650816), 50: (1, 127, 0.10417534540752023), 51: (1, 127, 0.10394018427945498), 52: (1, 127, 0.10403970441978982), 53: (1, 127, 0.10388055176833483), 54: (1, 127, 0.10402418796237059), 55: (1, 127, 0.10381579834703855), 56: (1, 127, 0.10396956975065817), 57: (1, 127, 0.1040997588273695), 58: (1, 127, 0.1038238132357832), 59: (1, 127, 0.1038952247261649), 60: (1, 127, 0.10391877372345822), 61: (1, 127, 0.1038116755139992), 62: (1, 127, 0.1038593202096036), 63: (1, 127, 0.10385727957917715), 64: (1, 127, 0.10391939339763302), 65: (1, 127, 0.10377613992584268), 66: (1, 127, 0.10401351459500358), 67: (1, 127, 0.10372969468571538), 68: (1, 127, 0.10368743727320996), 69: (1, 127, 0.1038148183610261), 70: (1, 127, 0.10391465936765426)}\n",
      "{'predict_runtime': 955.0995, 'predict_samples_per_second': 0.074, 'predict_steps_per_second': 0.074}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:55.09\n",
      "  predict_samples_per_second =      0.074\n",
      "  predict_steps_per_second   =      0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2186789633706212), 2: (2, 0.20865610986948013), 3: (2, 0.1985504673793912), 4: (2, 0.20502185262739658), 5: (2, 0.19138530269265175), 6: (2, 0.2054100390523672), 7: (2, 0.20569466520100832), 8: (2, 0.19760894123464823), 9: (2, 0.19409457221627235), 10: (2, 0.19203552696853876), 11: (2, 0.18878628499805927), 12: (2, 0.20617187023162842), 13: (2, 0.1911349780857563), 14: (2, 0.20628095977008343), 15: (2, 0.20418856386095285), 16: (2, 0.20987164787948132), 17: (2, 0.18955772649496794), 18: (2, 0.19250816199928522), 19: (2, 0.19473862554877996), 20: (2, 0.19123500678688288), 21: (2, 0.1984111424535513), 22: (2, 0.19831923488527536), 23: (2, 0.20036461018025875), 24: (2, 0.19367832876741886), 25: (2, 0.19497278425842524), 26: (2, 0.18995517306029797), 27: (2, 0.1944473497569561), 28: (2, 0.19055005442351103), 29: (2, 0.2063859272748232), 30: (2, 0.19804424606263638), 31: (2, 0.2039598971605301), 32: (2, 0.20528303273022175), 33: (2, 0.2057179370895028), 34: (2, 0.19463386666029692), 35: (2, 0.19641004595905542), 36: (2, 0.19979062769562006), 37: (2, 0.20537568163126707), 38: (2, 0.197561863809824), 39: (2, 0.20750805735588074), 40: (2, 0.20520719327032566), 41: (2, 0.20233307778835297), 42: (2, 0.2104542227461934), 43: (2, 0.19483758602291346), 44: (2, 0.2059749150648713), 45: (2, 0.2092974353581667), 46: (2, 0.19422901421785355), 47: (2, 0.19956490211188793), 48: (2, 0.19638110883533955), 49: (2, 0.2093883566558361), 50: (2, 0.19553665909916162), 51: (2, 0.20704402402043343), 52: (2, 0.20680593699216843), 53: (2, 0.20083061791956425), 54: (2, 0.19433551281690598), 55: (2, 0.20630724262446165), 56: (2, 0.1946645500138402), 57: (2, 0.20040487311780453), 58: (2, 0.19486551824957132), 59: (2, 0.19787649251520634), 60: (2, 0.19911825843155384), 61: (2, 0.2030481519177556), 62: (2, 0.20676508825272322), 63: (2, 0.20622329600155354), 64: (2, 0.19432667456567287), 65: (2, 0.21031516790390015), 66: (2, 0.19498255848884583), 67: (2, 0.20986934285610914), 68: (2, 0.20808265451341867), 69: (2, 0.20851337909698486), 70: (2, 0.21038481686264277), 71: (1, 0.1871535498648882)}\n",
      "{1: (2, 127, 0.16145040515780917), 2: (2, 127, 0.160914916141824), 3: (2, 127, 0.16080359451648757), 4: (2, 127, 0.1609130039092476), 5: (2, 127, 0.1607395088974768), 6: (2, 127, 0.16097753237580925), 7: (2, 127, 0.16072063670149), 8: (2, 127, 0.1608358637290442), 9: (2, 127, 0.16088319724557673), 10: (2, 127, 0.16078891657938169), 11: (2, 127, 0.16085834282736375), 12: (2, 127, 0.16083047067467857), 13: (2, 127, 0.16089580964121059), 14: (2, 127, 0.16091625865431516), 15: (2, 127, 0.16091604649609936), 16: (2, 127, 0.16106210970209808), 17: (2, 127, 0.16089300968955586), 18: (2, 127, 0.1609019809512524), 19: (2, 127, 0.16094715582338845), 20: (2, 127, 0.1609226978845953), 21: (2, 127, 0.16094758873438741), 22: (2, 127, 0.16090349353644556), 23: (2, 127, 0.16090738714679959), 24: (2, 127, 0.16098251340426797), 25: (2, 127, 0.16089366029537333), 26: (2, 127, 0.16083842224815464), 27: (2, 127, 0.16093997989495204), 28: (2, 127, 0.1608518084188498), 29: (2, 127, 0.1610426126106635), 30: (2, 127, 0.16102143879393188), 31: (2, 127, 0.1609438382470467), 32: (2, 127, 0.1607706716548153), 33: (2, 127, 0.1606923074234189), 34: (2, 127, 0.16086064681674786), 35: (2, 127, 0.16110671791211356), 36: (2, 127, 0.1607643136989296), 37: (2, 127, 0.16070916020406747), 38: (2, 127, 0.16073191019992425), 39: (2, 127, 0.16064713722256224), 40: (2, 127, 0.1606116499531809), 41: (2, 127, 0.16061707206187756), 42: (2, 127, 0.16063013853959915), 43: (2, 127, 0.16063066353420102), 44: (2, 127, 0.16059827528835283), 45: (2, 127, 0.16068848985151982), 46: (2, 127, 0.16064843616822339), 47: (2, 127, 0.16061667830309295), 48: (2, 127, 0.16063767745650895), 49: (2, 127, 0.16060917033982558), 50: (2, 127, 0.16066321501816352), 51: (2, 127, 0.16069032338367203), 52: (2, 127, 0.1606461032271737), 53: (2, 127, 0.16069696485761584), 54: (2, 127, 0.16061417396935657), 55: (2, 127, 0.16076260713464396), 56: (2, 127, 0.16069569195965377), 57: (2, 127, 0.1607036357452198), 58: (2, 127, 0.16071205607461414), 59: (2, 127, 0.16059280874750276), 60: (2, 127, 0.1606534146740446), 61: (2, 127, 0.1607891643038533), 62: (2, 127, 0.16064595921683733), 63: (2, 127, 0.16059679186748943), 64: (2, 127, 0.1607019093151637), 65: (2, 127, 0.16064415536234228), 66: (2, 127, 0.16061391211371487), 67: (2, 127, 0.1607614135677655), 68: (2, 127, 0.16067881344663582), 69: (2, 127, 0.16052953742708512), 70: (2, 127, 0.1605631161011814)}\n",
      "{'predict_runtime': 1456.8165, 'predict_samples_per_second': 0.097, 'predict_steps_per_second': 0.049}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:16.81\n",
      "  predict_samples_per_second =      0.097\n",
      "  predict_steps_per_second   =      0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.28315296582877636), 2: (4, 0.2536229621618986), 3: (4, 0.2469628695398569), 4: (4, 0.25406970735639334), 5: (4, 0.2527905823662877), 6: (4, 0.2621056931093335), 7: (4, 0.2482189554721117), 8: (4, 0.2554020220413804), 9: (4, 0.25995390862226486), 10: (4, 0.2478055413812399), 11: (4, 0.26328224036842585), 12: (4, 0.24748428538441658), 13: (4, 0.24640576727688313), 14: (4, 0.26383952517062426), 15: (4, 0.24726188741624355), 16: (4, 0.2620356557890773), 17: (4, 0.24577285535633564), 18: (4, 0.24730916786938906), 19: (4, 0.2478635013103485), 20: (4, 0.24635724071413279), 21: (4, 0.25243990775197744), 22: (4, 0.25049031246453524), 23: (4, 0.245457349345088), 24: (4, 0.2489780792966485), 25: (4, 0.2535531362518668), 26: (4, 0.2510593356564641), 27: (4, 0.25401607155799866), 28: (4, 0.24786102306097746), 29: (4, 0.25271479692310095), 30: (4, 0.2633229633793235), 31: (4, 0.24794262368232012), 32: (4, 0.2507169097661972), 33: (4, 0.2510526170954108), 34: (4, 0.2517702281475067), 35: (4, 0.24764658603817225), 36: (4, 0.25080209970474243), 37: (4, 0.2561721969395876), 38: (4, 0.24771328642964363), 39: (4, 0.24796364270150661), 40: (4, 0.25031565595418215), 41: (4, 0.2497412133961916), 42: (4, 0.2520765159279108), 43: (4, 0.2532228920608759), 44: (4, 0.25103186815977097), 45: (4, 0.2574209840968251), 46: (4, 0.25424113124608994), 47: (4, 0.2510467981919646), 48: (4, 0.24866969510912895), 49: (4, 0.24764626752585173), 50: (4, 0.2488487744703889), 51: (4, 0.25410844292491674), 52: (4, 0.24925257917493582), 53: (4, 0.2480547046288848), 54: (4, 0.26452739257365465), 55: (4, 0.2484001601114869), 56: (4, 0.2530020158737898), 57: (4, 0.2510013598948717), 58: (4, 0.2496289862319827), 59: (4, 0.2544930586591363), 60: (4, 0.25411450397223234), 61: (4, 0.24790545739233494), 62: (4, 0.25256688334047794), 63: (4, 0.24574765469878912), 64: (4, 0.2510319212451577), 65: (4, 0.24893454648554325), 66: (4, 0.2543546827509999), 67: (4, 0.25173763185739517), 68: (4, 0.24793317820876837), 69: (4, 0.2518122736364603), 70: (4, 0.2612012615427375), 71: (1, 0.17695340141654015)}\n",
      "{1: (4, 127, 0.16130326020230693), 2: (4, 127, 0.16105196268598396), 3: (4, 127, 0.16107337126933682), 4: (4, 127, 0.16104720435361927), 5: (4, 127, 0.16103994208351363), 6: (4, 127, 0.16099658411172196), 7: (4, 127, 0.16103331668405083), 8: (4, 127, 0.1609400896003514), 9: (4, 127, 0.16105670108657888), 10: (4, 127, 0.16084644923675953), 11: (4, 127, 0.16108753075309862), 12: (4, 127, 0.16100477306978908), 13: (4, 127, 0.16089062788707065), 14: (4, 127, 0.16106422169236687), 15: (4, 127, 0.16097184554417068), 16: (4, 127, 0.16098026931285858), 17: (4, 127, 0.16090954314389333), 18: (4, 127, 0.16110004879915574), 19: (4, 127, 0.1610453877172719), 20: (4, 127, 0.16089516821662037), 21: (4, 127, 0.16104207107958596), 22: (4, 127, 0.16096615150394872), 23: (4, 127, 0.16094012631059396), 24: (4, 127, 0.16080158485437002), 25: (4, 127, 0.1609651705132812), 26: (4, 127, 0.1610207615170892), 27: (4, 127, 0.16093612803278243), 28: (4, 127, 0.16088525090718597), 29: (4, 127, 0.16094008736371054), 30: (4, 127, 0.16089950051657329), 31: (4, 127, 0.16109113780942957), 32: (4, 127, 0.16106020684141342), 33: (4, 127, 0.1611004491285311), 34: (4, 127, 0.16103360180809037), 35: (4, 127, 0.16101265756604005), 36: (4, 127, 0.16087366297371744), 37: (4, 127, 0.16124037175813294), 38: (4, 127, 0.16098736534555128), 39: (4, 127, 0.1611454879175725), 40: (4, 127, 0.16110784314778143), 41: (4, 127, 0.16109389464891566), 42: (4, 127, 0.16097549777331316), 43: (4, 127, 0.16097637185988228), 44: (4, 127, 0.16093254338685922), 45: (4, 127, 0.16095346313585915), 46: (4, 127, 0.16148636086044585), 47: (4, 127, 0.16102813006796707), 48: (4, 127, 0.16094953413524732), 49: (4, 127, 0.16093608602060108), 50: (4, 127, 0.16082358023694415), 51: (4, 127, 0.16089003080663483), 52: (4, 127, 0.1609422601026109), 53: (4, 127, 0.16080361022430611), 54: (4, 127, 0.16092541737584617), 55: (4, 127, 0.16088211669872596), 56: (4, 127, 0.1610175985036286), 57: (4, 127, 0.16097390356906285), 58: (4, 127, 0.16087185893589118), 59: (4, 127, 0.1608430513906784), 60: (4, 127, 0.16112408966676692), 61: (4, 127, 0.16091147219894206), 62: (4, 127, 0.16085139417096855), 63: (4, 127, 0.16083271360743467), 64: (4, 127, 0.16093123045669297), 65: (4, 127, 0.16079248753412972), 66: (4, 127, 0.16080375864192492), 67: (4, 127, 0.16080561692379122), 68: (4, 127, 0.16080971670843017), 69: (4, 127, 0.16076968000893752), 70: (4, 127, 0.16073674818603542)}\n",
      "{'predict_runtime': 1462.0723, 'predict_samples_per_second': 0.192, 'predict_steps_per_second': 0.049}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:24:22.07\n",
      "  predict_samples_per_second =      0.192\n",
      "  predict_steps_per_second   =      0.049\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 20\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.2144467057660222), 2: (1, 0.1865801364183426), 3: (1, 0.1871821191161871), 4: (1, 0.18393821828067303), 5: (1, 0.18390716891735792), 6: (1, 0.18639142904430628), 7: (1, 0.18513997457921505), 8: (1, 0.18608478270471096), 9: (1, 0.18669369630515575), 10: (1, 0.18696105480194092), 11: (1, 0.1835193233564496), 12: (1, 0.18420689646154642), 13: (1, 0.18349945452064276), 14: (1, 0.1858129482716322), 15: (1, 0.18443469237536192), 16: (1, 0.18662831746041775), 17: (1, 0.1870480626821518), 18: (1, 0.18578774761408567), 19: (1, 0.18434722442179918), 20: (1, 0.18352665472775698), 21: (1, 0.18512734677642584), 22: (1, 0.18630078341811895), 23: (1, 0.1839479999616742), 24: (1, 0.18475445173680782), 25: (1, 0.18580984883010387), 26: (1, 0.18719727266579866), 27: (1, 0.18599221669137478), 28: (1, 0.18488746043294668), 29: (1, 0.1869663055986166), 30: (1, 0.1868298565968871), 31: (1, 0.18706248421221972), 32: (1, 0.18744643963873386), 33: (1, 0.18347692769020796), 34: (1, 0.1862520156428218), 35: (1, 0.1857335204258561), 36: (1, 0.1842967662960291), 37: (1, 0.1839576018974185), 38: (1, 0.18677343800663948), 39: (1, 0.18754549883306026), 40: (1, 0.1850803392007947), 41: (1, 0.18466262333095074), 42: (1, 0.18413458950817585), 43: (1, 0.18374964501708746), 44: (1, 0.18514688778668642), 45: (1, 0.1849704310297966), 46: (1, 0.18353508040308952), 47: (1, 0.1838294481858611), 48: (1, 0.1857150848954916), 49: (1, 0.18655897676944733), 50: (1, 0.1833351654931903), 51: (1, 0.18557805754244328), 52: (1, 0.18470731005072594), 53: (1, 0.18696502316743135), 54: (1, 0.18561382871121168), 55: (1, 0.18682008609175682), 56: (1, 0.18418016843497753), 57: (1, 0.18742503877729177), 58: (1, 0.18640238139778376), 59: (1, 0.1871452433988452), 60: (1, 0.1845311550423503), 61: (1, 0.18645867239683867), 62: (1, 0.18616257514804602), 63: (1, 0.18729198444634676), 64: (1, 0.18380397651344538), 65: (1, 0.18645393382757902), 66: (1, 0.184112592600286), 67: (1, 0.18643639516085386), 68: (1, 0.186366505920887), 69: (1, 0.18528724927455187), 70: (1, 0.19174702186137438), 71: (1, 0.1861294899135828)}\n",
      "{1: (1, 127, 0.10917501494757773), 2: (1, 127, 0.10890967729611425), 3: (1, 127, 0.10893824623208347), 4: (1, 127, 0.10912045138323401), 5: (1, 127, 0.10892347213408844), 6: (1, 127, 0.10885441412518579), 7: (1, 127, 0.10876208166115162), 8: (1, 127, 0.10878112063721174), 9: (1, 127, 0.10874754920836509), 10: (1, 127, 0.10883765765209133), 11: (1, 127, 0.10894443055130834), 12: (1, 127, 0.10887729054624874), 13: (1, 127, 0.1088780475281707), 14: (1, 127, 0.10880058757432802), 15: (1, 127, 0.1088441723195), 16: (1, 127, 0.10881344330181757), 17: (1, 127, 0.10894844546092777), 18: (1, 127, 0.10890841734133602), 19: (1, 127, 0.10895324514548141), 20: (1, 127, 0.10894903320613808), 21: (1, 127, 0.10887072545542258), 22: (1, 127, 0.1089039680394014), 23: (1, 127, 0.10896029452404637), 24: (1, 127, 0.10892003317048231), 25: (1, 127, 0.1088040169680447), 26: (1, 127, 0.1087767986184734), 27: (1, 127, 0.10877519845962524), 28: (1, 127, 0.1087680984523118), 29: (1, 127, 0.10875263483094888), 30: (1, 127, 0.10876145873834768), 31: (1, 127, 0.1087054896175744), 32: (1, 127, 0.10875828290636849), 33: (1, 127, 0.10878176906505438), 34: (1, 127, 0.10881586596516409), 35: (1, 127, 0.10881230529163062), 36: (1, 127, 0.10879312707184571), 37: (1, 127, 0.10880160545856934), 38: (1, 127, 0.10889273884845531), 39: (1, 127, 0.10880973052204125), 40: (1, 127, 0.10880047210499527), 41: (1, 127, 0.10887311123252853), 42: (1, 127, 0.10893403890535353), 43: (1, 127, 0.10910267847788147), 44: (1, 127, 0.10891345107385259), 45: (1, 127, 0.1090433116063593), 46: (1, 127, 0.10895356575511103), 47: (1, 127, 0.10899794264513207), 48: (1, 127, 0.10890685919466919), 49: (1, 127, 0.10889488178503326), 50: (1, 127, 0.10891152060348687), 51: (1, 127, 0.1088997966455897), 52: (1, 127, 0.10884551637197339), 53: (1, 127, 0.1092946498808781), 54: (1, 127, 0.10909898067259882), 55: (1, 127, 0.10890789548536454), 56: (1, 127, 0.10883543550176179), 57: (1, 127, 0.1087755704019952), 58: (1, 127, 0.10886314006038303), 59: (1, 127, 0.10888078693652481), 60: (1, 127, 0.10885502487479702), 61: (1, 127, 0.10880838072030094), 62: (1, 127, 0.10896199351308618), 63: (1, 127, 0.10889630161196463), 64: (1, 127, 0.10875674611412164), 65: (1, 127, 0.10876529404204192), 66: (1, 127, 0.10869212451530254), 67: (1, 127, 0.10870215131013881), 68: (1, 127, 0.10873909983930626), 69: (1, 127, 0.10870625902935276), 70: (1, 127, 0.1087718750900171)}\n",
      "{'predict_runtime': 994.8677, 'predict_samples_per_second': 0.071, 'predict_steps_per_second': 0.071}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:16:34.86\n",
      "  predict_samples_per_second =      0.071\n",
      "  predict_steps_per_second   =      0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.23302563838660717), 2: (2, 0.2015846660360694), 3: (2, 0.22186570428311825), 4: (2, 0.21482473891228437), 5: (2, 0.20082015730440617), 6: (2, 0.20073716808110476), 7: (2, 0.21590205747634172), 8: (2, 0.20219855196774006), 9: (2, 0.21000510919839144), 10: (2, 0.21526691690087318), 11: (2, 0.21612845733761787), 12: (2, 0.20442333724349737), 13: (2, 0.20087432116270065), 14: (2, 0.1981543842703104), 15: (2, 0.21596966218203306), 16: (2, 0.2149081639945507), 17: (2, 0.21885220892727375), 18: (2, 0.21559313777834177), 19: (2, 0.21503302548080683), 20: (2, 0.20330146607011557), 21: (2, 0.2009399849921465), 22: (2, 0.20700402185320854), 23: (2, 0.215661458671093), 24: (2, 0.21399411000311375), 25: (2, 0.21111963503062725), 26: (2, 0.20284622441977262), 27: (2, 0.20082886796444654), 28: (2, 0.2166616702452302), 29: (2, 0.2147431829944253), 30: (2, 0.2149841021746397), 31: (2, 0.2045749258249998), 32: (2, 0.20956220664083958), 33: (2, 0.20375174656510353), 34: (2, 0.20784697774797678), 35: (2, 0.21529479045420885), 36: (2, 0.21549545787274837), 37: (2, 0.21499462518841028), 38: (2, 0.2186060631647706), 39: (2, 0.2161061828956008), 40: (2, 0.2006432069465518), 41: (2, 0.20052302908152342), 42: (2, 0.21505889482796192), 43: (2, 0.21606290340423584), 44: (2, 0.21767486538738012), 45: (2, 0.21478419937193394), 46: (2, 0.21657584886997938), 47: (2, 0.21727052237838507), 48: (2, 0.21392203215509653), 49: (2, 0.20161799807101488), 50: (2, 0.2161075659096241), 51: (2, 0.21565037220716476), 52: (2, 0.20870540663599968), 53: (2, 0.2104014465585351), 54: (2, 0.21576314326375723), 55: (2, 0.21590268053114414), 56: (2, 0.21677327156066895), 57: (2, 0.21329443342983723), 58: (2, 0.21466849744319916), 59: (2, 0.2182848248630762), 60: (2, 0.20108492951840162), 61: (2, 0.2081941356882453), 62: (2, 0.21694440208375454), 63: (2, 0.21473438758403063), 64: (2, 0.2143629528582096), 65: (2, 0.21795139089226723), 66: (2, 0.21002501528710127), 67: (2, 0.21545220259577036), 68: (2, 0.21742530912160873), 69: (2, 0.20429349411278963), 70: (2, 0.21901362109929323), 71: (1, 0.19792013242840767)}\n",
      "{1: (2, 127, 0.16888292320805975), 2: (2, 127, 0.168639644254439), 3: (2, 127, 0.16845005688323514), 4: (2, 127, 0.16847631336725133), 5: (2, 127, 0.16859067242416576), 6: (2, 127, 0.16852707280887394), 7: (2, 127, 0.16862757886781937), 8: (2, 127, 0.16843791665348012), 9: (2, 127, 0.168468243772472), 10: (2, 127, 0.16854866093215276), 11: (2, 127, 0.16840230061958625), 12: (2, 127, 0.168542798535209), 13: (2, 127, 0.16842304734791827), 14: (2, 127, 0.16846226292156327), 15: (2, 127, 0.16860292972190175), 16: (2, 127, 0.16846710390697314), 17: (2, 127, 0.16848870267812896), 18: (2, 127, 0.16849843763900318), 19: (2, 127, 0.1685345686576146), 20: (2, 127, 0.1685691832264108), 21: (2, 127, 0.16858884988455322), 22: (2, 127, 0.16864312949817717), 23: (2, 127, 0.1684685160853262), 24: (2, 127, 0.1684507067777275), 25: (2, 127, 0.1684175870183298), 26: (2, 127, 0.1685439119716798), 27: (2, 127, 0.16845818410268215), 28: (2, 127, 0.1684769460066097), 29: (2, 127, 0.16850213325164448), 30: (2, 127, 0.16861926956380915), 31: (2, 127, 0.16851449204887461), 32: (2, 127, 0.16889424042732226), 33: (2, 127, 0.1685627079678802), 34: (2, 127, 0.16863628171794998), 35: (2, 127, 0.168581779261567), 36: (2, 127, 0.1686396219173637), 37: (2, 127, 0.16866824792067367), 38: (2, 127, 0.16847946247687257), 39: (2, 127, 0.16860017077044004), 40: (2, 127, 0.16885353770019032), 41: (2, 127, 0.16864441604331487), 42: (2, 127, 0.16857724404329155), 43: (2, 127, 0.1687334540087407), 44: (2, 127, 0.16861661241983805), 45: (2, 127, 0.16856337298353122), 46: (2, 127, 0.16857956775911445), 47: (2, 127, 0.16847622504560497), 48: (2, 127, 0.16859309618749957), 49: (2, 127, 0.16861239609521206), 50: (2, 127, 0.16856338443806557), 51: (2, 127, 0.16862395764365207), 52: (2, 127, 0.16854323085221484), 53: (2, 127, 0.16869105458787576), 54: (2, 127, 0.16853824677312468), 55: (2, 127, 0.16849792225829024), 56: (2, 127, 0.16855724364167124), 57: (2, 127, 0.1686165906034234), 58: (2, 127, 0.16865607867325386), 59: (2, 127, 0.16875376298612965), 60: (2, 127, 0.1686926365676006), 61: (2, 127, 0.168554535318958), 62: (2, 127, 0.16861170561118857), 63: (2, 127, 0.16855314639433633), 64: (2, 127, 0.1684932129486926), 65: (2, 127, 0.16861243618608224), 66: (2, 127, 0.1684668433419832), 67: (2, 127, 0.16855155872401056), 68: (2, 127, 0.1687069990870169), 69: (2, 127, 0.1684979559619009), 70: (2, 127, 0.16851143437753044)}\n",
      "{'predict_runtime': 1527.4675, 'predict_samples_per_second': 0.092, 'predict_steps_per_second': 0.046}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:27.46\n",
      "  predict_samples_per_second =      0.092\n",
      "  predict_steps_per_second   =      0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.29165524896234274), 2: (4, 0.2639893777668476), 3: (4, 0.25972095876932144), 4: (4, 0.26041627023369074), 5: (4, 0.2604227615520358), 6: (4, 0.2620275430381298), 7: (4, 0.2640943890437484), 8: (4, 0.2595749534666538), 9: (4, 0.2608458288013935), 10: (4, 0.2631582226604223), 11: (4, 0.2582133188843727), 12: (4, 0.26326502952724695), 13: (4, 0.26092334650456905), 14: (4, 0.26331666950136423), 15: (4, 0.2656082818284631), 16: (4, 0.25965892244130373), 17: (4, 0.26135800313204527), 18: (4, 0.2703444566577673), 19: (4, 0.260258917696774), 20: (4, 0.25976659171283245), 21: (4, 0.2618722692131996), 22: (4, 0.26002885960042477), 23: (4, 0.2588866939768195), 24: (4, 0.2597772339358926), 25: (4, 0.26035525649785995), 26: (4, 0.2614011652767658), 27: (4, 0.25896707363426685), 28: (4, 0.2610491905361414), 29: (4, 0.2586182486265898), 30: (4, 0.2618642309680581), 31: (4, 0.26178898196667433), 32: (4, 0.26016801223158836), 33: (4, 0.25894374679774046), 34: (4, 0.27007849514484406), 35: (4, 0.262039209716022), 36: (4, 0.26027734111994505), 37: (4, 0.25847394205629826), 38: (4, 0.2577579813078046), 39: (4, 0.26266192365437746), 40: (4, 0.2613083301112056), 41: (4, 0.264076167717576), 42: (4, 0.2593879038468003), 43: (4, 0.26445964351296425), 44: (4, 0.2621385520324111), 45: (4, 0.2597159007564187), 46: (4, 0.2592573659494519), 47: (4, 0.2613419611006975), 48: (4, 0.26029290445148945), 49: (4, 0.2599519584327936), 50: (4, 0.26413760893046856), 51: (4, 0.259209668263793), 52: (4, 0.2629452645778656), 53: (4, 0.261039855889976), 54: (4, 0.2593306368216872), 55: (4, 0.26058429200202227), 56: (4, 0.26273517683148384), 57: (4, 0.25979018211364746), 58: (4, 0.2591468086466193), 59: (4, 0.26107359677553177), 60: (4, 0.25937354285269976), 61: (4, 0.2593043716624379), 62: (4, 0.25747924391180277), 63: (4, 0.2627089824527502), 64: (4, 0.2611200315877795), 65: (4, 0.26034212950617075), 66: (4, 0.2576473616063595), 67: (4, 0.26061408687382936), 68: (4, 0.26128805987536907), 69: (4, 0.2593071823939681), 70: (4, 0.2622955571860075), 71: (1, 0.18562752287834883)}\n",
      "{1: (4, 127, 0.16949908151547974), 2: (4, 127, 0.16925139343146028), 3: (4, 127, 0.16912153652891165), 4: (4, 127, 0.16900610708902905), 5: (4, 127, 0.16900357575427125), 6: (4, 127, 0.16905571754992477), 7: (4, 127, 0.16914559762895576), 8: (4, 127, 0.16913239704811667), 9: (4, 127, 0.16903867528546512), 10: (4, 127, 0.16897972216316332), 11: (4, 127, 0.16896337539133593), 12: (4, 127, 0.16893203669469656), 13: (4, 127, 0.16904732639952672), 14: (4, 127, 0.16896878525350742), 15: (4, 127, 0.16903709851234683), 16: (4, 127, 0.16887417779575417), 17: (4, 127, 0.16893377430795684), 18: (4, 127, 0.16905133909450507), 19: (4, 127, 0.16905103575467595), 20: (4, 127, 0.16899525180576355), 21: (4, 127, 0.16897933005435964), 22: (4, 127, 0.16895113696204864), 23: (4, 127, 0.1688965515666238), 24: (4, 127, 0.16888999568635787), 25: (4, 127, 0.16894033631148536), 26: (4, 127, 0.16899488820129727), 27: (4, 127, 0.16886204112995798), 28: (4, 127, 0.16884949642020886), 29: (4, 127, 0.16887334229673925), 30: (4, 127, 0.16889152272538407), 31: (4, 127, 0.16898028971994017), 32: (4, 127, 0.1690104926063672), 33: (4, 127, 0.1687745197316793), 34: (4, 127, 0.16880742542621657), 35: (4, 127, 0.16877726664928), 36: (4, 127, 0.16887952883793847), 37: (4, 127, 0.16875370591145566), 38: (4, 127, 0.16866633537276757), 39: (4, 127, 0.1687942671728885), 40: (4, 127, 0.16881192814353413), 41: (4, 127, 0.1689558569048568), 42: (4, 127, 0.16895672313018342), 43: (4, 127, 0.16887264056351242), 44: (4, 127, 0.16889923543295288), 45: (4, 127, 0.1690341932039092), 46: (4, 127, 0.16891405169712745), 47: (4, 127, 0.1689027023729025), 48: (4, 127, 0.16881344001740217), 49: (4, 127, 0.16877166750862843), 50: (4, 127, 0.16889314047669565), 51: (4, 127, 0.1687839996788328), 52: (4, 127, 0.16881914949411247), 53: (4, 127, 0.16881575730196605), 54: (4, 127, 0.16883748254232753), 55: (4, 127, 0.16883114951948716), 56: (4, 127, 0.1686871941824715), 57: (4, 127, 0.1686494959386315), 58: (4, 127, 0.1686475236467489), 59: (4, 127, 0.1686708780709566), 60: (4, 127, 0.1687394306210317), 61: (4, 127, 0.16861004760034207), 62: (4, 127, 0.16866393652781259), 63: (4, 127, 0.1685689570543569), 64: (4, 127, 0.16870253694456394), 65: (4, 127, 0.1686933746590741), 66: (4, 127, 0.16859818304940236), 67: (4, 127, 0.16852927396411266), 68: (4, 127, 0.16859108021878821), 69: (4, 127, 0.16852944735877626), 70: (4, 127, 0.17023491141510996)}\n",
      "{'predict_runtime': 1533.8166, 'predict_samples_per_second': 0.183, 'predict_steps_per_second': 0.046}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:33.81\n",
      "  predict_samples_per_second =      0.183\n",
      "  predict_steps_per_second   =      0.046\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 21\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.21834824420511723), 2: (1, 0.18149768188595772), 3: (1, 0.1876185704022646), 4: (1, 0.1814559819176793), 5: (1, 0.18361561745405197), 6: (1, 0.18186032865196466), 7: (1, 0.17886976432055235), 8: (1, 0.18274412862956524), 9: (1, 0.18208814691752195), 10: (1, 0.18052067514508963), 11: (1, 0.18015866912901402), 12: (1, 0.17800526600331068), 13: (1, 0.18200126942247152), 14: (1, 0.17814261466264725), 15: (1, 0.1801881603896618), 16: (1, 0.17832049261778593), 17: (1, 0.18118305783718824), 18: (1, 0.1790215354412794), 19: (1, 0.1790777537971735), 20: (1, 0.18039969820529222), 21: (1, 0.18347814306616783), 22: (1, 0.1811963701620698), 23: (1, 0.1859032353386283), 24: (1, 0.17958549968898296), 25: (1, 0.17775745131075382), 26: (1, 0.1818058444187045), 27: (1, 0.1799698444083333), 28: (1, 0.17748744506388903), 29: (1, 0.1833518771454692), 30: (1, 0.1791525473818183), 31: (1, 0.18739132583141327), 32: (1, 0.1787759391590953), 33: (1, 0.17981815617531538), 34: (1, 0.18052257783710957), 35: (1, 0.17845201306045055), 36: (1, 0.18018667213618755), 37: (1, 0.17795386910438538), 38: (1, 0.1813933691009879), 39: (1, 0.18133082892745733), 40: (1, 0.17915494553744793), 41: (1, 0.18051125016063452), 42: (1, 0.1807726165279746), 43: (1, 0.18041715119034052), 44: (1, 0.18020772375166416), 45: (1, 0.17949861381202936), 46: (1, 0.1782087478786707), 47: (1, 0.1810468239709735), 48: (1, 0.17818106710910797), 49: (1, 0.1796715408563614), 50: (1, 0.17843040637671947), 51: (1, 0.18057850003242493), 52: (1, 0.17907313909381628), 53: (1, 0.18505448661744595), 54: (1, 0.17990642879158258), 55: (1, 0.18088700715452433), 56: (1, 0.18306023068726063), 57: (1, 0.18098411615937948), 58: (1, 0.17930444702506065), 59: (1, 0.17946329526603222), 60: (1, 0.1786850644275546), 61: (1, 0.17897584103047848), 62: (1, 0.17877007462084293), 63: (1, 0.17984353099018335), 64: (1, 0.1796580133959651), 65: (1, 0.18182226829230785), 66: (1, 0.1829992737621069), 67: (1, 0.18056497164070606), 68: (1, 0.18034267611801624), 69: (1, 0.17959441617131233), 70: (1, 0.17883670423179865), 71: (1, 0.17680432088673115)}\n",
      "{1: (1, 255, 0.10862617122703323), 2: (1, 255, 0.10750889749284469), 3: (1, 255, 0.10855815447136467), 4: (1, 255, 0.10770458057887998), 5: (1, 255, 0.10728224724092904), 6: (1, 255, 0.10647010535878294), 7: (1, 255, 0.10788571660352105), 8: (1, 255, 0.10720583044503834), 9: (1, 255, 0.10784228600780754), 10: (1, 255, 0.10734547174663521), 11: (1, 255, 0.10696191696048367), 12: (1, 255, 0.10733220697764088), 13: (1, 255, 0.10698840335814976), 14: (1, 255, 0.10702903937621444), 15: (1, 255, 0.10698986856960783), 16: (1, 255, 0.10671927612274885), 17: (1, 255, 0.1069247145680528), 18: (1, 255, 0.10919246794473307), 19: (1, 255, 0.1066139803395844), 20: (1, 255, 0.10695817560030549), 21: (1, 255, 0.10763097168037704), 22: (1, 255, 0.1066519762480668), 23: (1, 255, 0.10707726655710562), 24: (1, 255, 0.10709908454879827), 25: (1, 255, 0.1067166748219261), 26: (1, 255, 0.10710447424036615), 27: (1, 255, 0.1088130570948124), 28: (1, 255, 0.10640600348512332), 29: (1, 255, 0.10656626370972862), 30: (1, 255, 0.10664991347082689), 31: (1, 255, 0.10678503087484369), 32: (1, 255, 0.1068622103033989), 33: (1, 255, 0.106582294156154), 34: (1, 255, 0.10735290139256155), 35: (1, 255, 0.10670979886005322), 36: (1, 255, 0.10670678591465249), 37: (1, 255, 0.1067429124870721), 38: (1, 255, 0.10710495362313939), 39: (1, 255, 0.10710818992891148), 40: (1, 255, 0.10666337753189545), 41: (1, 255, 0.10785716479534611), 42: (1, 255, 0.10696919465839279), 43: (1, 255, 0.10654902800406311), 44: (1, 255, 0.10674051661044359), 45: (1, 255, 0.10652707989017168), 46: (1, 255, 0.10677444594820924), 47: (1, 255, 0.10673110759360534), 48: (1, 255, 0.10661048073978985), 49: (1, 255, 0.10679309368863994), 50: (1, 255, 0.10657515045912827), 51: (1, 255, 0.10676972985486774), 52: (1, 255, 0.10721560288220644), 53: (1, 255, 0.10616933312267066), 54: (1, 255, 0.1073978261729958), 55: (1, 255, 0.10760861282401225), 56: (1, 255, 0.10648313243234274), 57: (1, 255, 0.10618798019474043), 58: (1, 255, 0.10660600833156529), 59: (1, 255, 0.10662204008549452), 60: (1, 255, 0.10651539717526996), 61: (1, 255, 0.10642054961154274), 62: (1, 255, 0.1065957192696777), 63: (1, 255, 0.10687066707394871), 64: (1, 255, 0.107095746958957), 65: (1, 255, 0.10692203876872858), 66: (1, 255, 0.10630640186661598), 67: (1, 255, 0.10623742050180833), 68: (1, 255, 0.10641299011003152), 69: (1, 255, 0.10657546528633319), 70: (1, 255, 0.10648797200444866)}\n",
      "{'predict_runtime': 1949.6611, 'predict_samples_per_second': 0.036, 'predict_steps_per_second': 0.036}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:32:29.66\n",
      "  predict_samples_per_second =      0.036\n",
      "  predict_steps_per_second   =      0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.22095893695950508), 2: (2, 0.23694418743252754), 3: (2, 0.19662607554346323), 4: (2, 0.1946875900030136), 5: (2, 0.1982241878286004), 6: (2, 0.19458710122853518), 7: (2, 0.19571181759238243), 8: (2, 0.19646230060607195), 9: (2, 0.19091620482504368), 10: (2, 0.23712828755378723), 11: (2, 0.19818528927862644), 12: (2, 0.19334994722157717), 13: (2, 0.1986045753583312), 14: (2, 0.19538265280425549), 15: (2, 0.19853406585752964), 16: (2, 0.19935195613652468), 17: (2, 0.19522494450211525), 18: (2, 0.1949672382324934), 19: (2, 0.19193699397146702), 20: (2, 0.2003491846844554), 21: (2, 0.19655823055654764), 22: (2, 0.1954697035253048), 23: (2, 0.19626624509692192), 24: (2, 0.19519075751304626), 25: (2, 0.20037432480603456), 26: (2, 0.1956642847508192), 27: (2, 0.19822546653449535), 28: (2, 0.1964078675955534), 29: (2, 0.23441618029028177), 30: (2, 0.19597128219902515), 31: (2, 0.20312078762799501), 32: (2, 0.19378284830600023), 33: (2, 0.20512100402265787), 34: (2, 0.197767810896039), 35: (2, 0.20063745696097612), 36: (2, 0.19309484586119652), 37: (2, 0.1972561962902546), 38: (2, 0.19521430041640997), 39: (2, 0.19893445633351803), 40: (2, 0.20342048443853855), 41: (2, 0.19764225091785192), 42: (2, 0.1978895692154765), 43: (2, 0.1994660720229149), 44: (2, 0.19444377068430185), 45: (2, 0.1952682202681899), 46: (2, 0.19543717801570892), 47: (2, 0.20518194511532784), 48: (2, 0.1976790213957429), 49: (2, 0.1936674676835537), 50: (2, 0.1995284790173173), 51: (2, 0.19863247964531183), 52: (2, 0.1967918910086155), 53: (2, 0.19556000549346209), 54: (2, 0.19557876512408257), 55: (2, 0.1982542835175991), 56: (2, 0.19710466638207436), 57: (2, 0.19349652901291847), 58: (2, 0.19495446234941483), 59: (2, 0.19865931943058968), 60: (2, 0.19651041366159916), 61: (2, 0.1993859987705946), 62: (2, 0.19484857190400362), 63: (2, 0.2018595514819026), 64: (2, 0.1946617653593421), 65: (2, 0.19979751482605934), 66: (2, 0.1941218413412571), 67: (2, 0.2009580209851265), 68: (2, 0.19770761858671904), 69: (2, 0.20429346151649952), 70: (2, 0.19265887700021267), 71: (1, 0.18591391667723656)}\n",
      "{1: (2, 255, 0.16314615197479726), 2: (2, 255, 0.163053638900758), 3: (2, 255, 0.16301763197954963), 4: (2, 255, 0.16341138570843375), 5: (2, 255, 0.16331915799893584), 6: (2, 255, 0.16330210802455744), 7: (2, 255, 0.16305571012929373), 8: (2, 255, 0.16311258950873334), 9: (2, 255, 0.16293809268550546), 10: (2, 255, 0.1629161421720888), 11: (2, 255, 0.16304126676610287), 12: (2, 255, 0.16286140894699916), 13: (2, 255, 0.16297042526523856), 14: (2, 255, 0.1629141356138622), 15: (2, 255, 0.16291989359055079), 16: (2, 255, 0.16297562453603628), 17: (2, 255, 0.16304524547110003), 18: (2, 255, 0.1631490825511077), 19: (2, 255, 0.1632659487681938), 20: (2, 255, 0.16307016923001), 21: (2, 255, 0.16293091353978598), 22: (2, 255, 0.1631801625311959), 23: (2, 255, 0.16310176960393494), 24: (2, 255, 0.16316443802606242), 25: (2, 255, 0.16309667573328696), 26: (2, 255, 0.1632097156937508), 27: (2, 255, 0.16331658453187523), 28: (2, 255, 0.16303616419215414), 29: (2, 255, 0.16302911856887387), 30: (2, 255, 0.16312247576812902), 31: (2, 255, 0.1631237598501292), 32: (2, 255, 0.16301532717896441), 33: (2, 255, 0.1630438609852218), 34: (2, 255, 0.16325661101761987), 35: (2, 255, 0.16372545989705067), 36: (2, 255, 0.16323155873254233), 37: (2, 255, 0.1630018133706614), 38: (2, 255, 0.1628539240316433), 39: (2, 255, 0.16308660944375922), 40: (2, 255, 0.16288244711490824), 41: (2, 255, 0.16278515899298238), 42: (2, 255, 0.1626940630047637), 43: (2, 255, 0.16264773226324833), 44: (2, 255, 0.16263886186129906), 45: (2, 255, 0.16281012709380366), 46: (2, 255, 0.16257642603241929), 47: (2, 255, 0.16283622834393208), 48: (2, 255, 0.1626682169516297), 49: (2, 255, 0.16265002847740465), 50: (2, 255, 0.1626779698529372), 51: (2, 255, 0.16268863641821285), 52: (2, 255, 0.1626700084583432), 53: (2, 255, 0.16261352529639708), 54: (2, 255, 0.16260195800705868), 55: (2, 255, 0.16259052193194043), 56: (2, 255, 0.16257674882517142), 57: (2, 255, 0.16269909632483534), 58: (2, 255, 0.16272248274409304), 59: (2, 255, 0.1626673957698193), 60: (2, 255, 0.16247260667310626), 61: (2, 255, 0.16381807953265368), 62: (2, 255, 0.16325821046005276), 63: (2, 255, 0.16258437373839757), 64: (2, 255, 0.1626058372504571), 65: (2, 255, 0.16274182722702915), 66: (2, 255, 0.1625901578286407), 67: (2, 255, 0.1627035197564492), 68: (2, 255, 0.16252487938047624), 69: (2, 255, 0.1624685132985606), 70: (2, 255, 0.16321156653849517)}\n",
      "{'predict_runtime': 2949.8346, 'predict_samples_per_second': 0.048, 'predict_steps_per_second': 0.024}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:49:09.83\n",
      "  predict_samples_per_second =      0.048\n",
      "  predict_steps_per_second   =      0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.27791742980480194), 2: (4, 0.2526747453957796), 3: (4, 0.2529602413997054), 4: (4, 0.2956258114427328), 5: (4, 0.2717669606208801), 6: (4, 0.27696888986974955), 7: (4, 0.2550398865714669), 8: (4, 0.2903668824583292), 9: (4, 0.2744255382567644), 10: (4, 0.25621695164591074), 11: (4, 0.27691974956542253), 12: (4, 0.2576397452503443), 13: (4, 0.29301659017801285), 14: (4, 0.2563429204747081), 15: (4, 0.2636733651161194), 16: (4, 0.2519900305196643), 17: (4, 0.25090613309293985), 18: (4, 0.2504248274490237), 19: (4, 0.2576609328389168), 20: (4, 0.2754494957625866), 21: (4, 0.25091989524662495), 22: (4, 0.27583569660782814), 23: (4, 0.25239576771855354), 24: (4, 0.269479569979012), 25: (4, 0.24978981539607048), 26: (4, 0.25727575924247503), 27: (4, 0.24713017605245113), 28: (4, 0.2951423218473792), 29: (4, 0.24774899892508984), 30: (4, 0.27811898849904537), 31: (4, 0.25956838112324476), 32: (4, 0.2767164222896099), 33: (4, 0.2540605142712593), 34: (4, 0.27480843383818865), 35: (4, 0.257616912946105), 36: (4, 0.27854773961007595), 37: (4, 0.25830678455531597), 38: (4, 0.276346355676651), 39: (4, 0.25509713031351566), 40: (4, 0.2697324315086007), 41: (4, 0.25274800695478916), 42: (4, 0.2511417753994465), 43: (4, 0.2478945218026638), 44: (4, 0.25612804666161537), 45: (4, 0.25709973461925983), 46: (4, 0.28067844174802303), 47: (4, 0.2510388111695647), 48: (4, 0.2779851024970412), 49: (4, 0.25121391750872135), 50: (4, 0.25481623504310846), 51: (4, 0.25078430119901896), 52: (4, 0.29083500150591135), 53: (4, 0.25516011007130146), 54: (4, 0.25399516336619854), 55: (4, 0.2473659785464406), 56: (4, 0.28494794573634863), 57: (4, 0.2531281104311347), 58: (4, 0.2765649314969778), 59: (4, 0.25709593389183283), 60: (4, 0.25716901291161776), 61: (4, 0.28838072437793016), 62: (4, 0.251515774987638), 63: (4, 0.2559380754828453), 64: (4, 0.2545763486996293), 65: (4, 0.25641632825136185), 66: (4, 0.2819386636838317), 67: (4, 0.25272440910339355), 68: (4, 0.26104956306517124), 69: (4, 0.2571863168850541), 70: (4, 0.2897075628861785), 71: (1, 0.17943019792437553)}\n",
      "{1: (4, 255, 0.1632668097412177), 2: (4, 255, 0.1632458286177294), 3: (4, 255, 0.16330100120063507), 4: (4, 255, 0.16315915898657313), 5: (4, 255, 0.16309050062269556), 6: (4, 255, 0.16310795015637197), 7: (4, 255, 0.16320050516549278), 8: (4, 255, 0.16368606134372599), 9: (4, 255, 0.16361627911089682), 10: (4, 255, 0.16322738916850557), 11: (4, 255, 0.16309011678996624), 12: (4, 255, 0.1630727686608831), 13: (4, 255, 0.1632410812173404), 14: (4, 255, 0.16311982504512165), 15: (4, 255, 0.16323989103456923), 16: (4, 255, 0.16322692305433983), 17: (4, 255, 0.1637253823014451), 18: (4, 255, 0.16322330816776728), 19: (4, 255, 0.16310290575173556), 20: (4, 255, 0.1630812602628972), 21: (4, 255, 0.1630145300252765), 22: (4, 255, 0.16301792954624283), 23: (4, 255, 0.16301434197481357), 24: (4, 255, 0.16297066601395022), 25: (4, 255, 0.163516673913189), 26: (4, 255, 0.16355144896124507), 27: (4, 255, 0.16300265467634387), 28: (4, 255, 0.16302719577124306), 29: (4, 255, 0.1629572635333912), 30: (4, 255, 0.16291775843311174), 31: (4, 255, 0.1630278565573926), 32: (4, 255, 0.16310975319322418), 33: (4, 255, 0.16331638177016786), 34: (4, 255, 0.16370467424173565), 35: (4, 255, 0.16337883399397718), 36: (4, 255, 0.16315467033681333), 37: (4, 255, 0.16309623731409803), 38: (4, 255, 0.16311563480572372), 39: (4, 255, 0.16312965981516184), 40: (4, 255, 0.16312104748087186), 41: (4, 255, 0.16314334165231853), 42: (4, 255, 0.1633947405087597), 43: (4, 255, 0.16362674641696845), 44: (4, 255, 0.1629766267231282), 45: (4, 255, 0.16299712682763737), 46: (4, 255, 0.16304909711813226), 47: (4, 255, 0.16295336563797558), 48: (4, 255, 0.16293032929739532), 49: (4, 255, 0.16289874242947383), 50: (4, 255, 0.1629535321876699), 51: (4, 255, 0.16355580980067744), 52: (4, 255, 0.1633557220811353), 53: (4, 255, 0.16303102022730837), 54: (4, 255, 0.1630541527169008), 55: (4, 255, 0.16282993854918315), 56: (4, 255, 0.16288079017882837), 57: (4, 255, 0.16294386233842256), 58: (4, 255, 0.1629105083461778), 59: (4, 255, 0.16300991990183497), 60: (4, 255, 0.16343998813307753), 61: (4, 255, 0.16302277056098569), 62: (4, 255, 0.1629323882580388), 63: (4, 255, 0.16292780412032323), 64: (4, 255, 0.16287659576856622), 65: (4, 255, 0.1628863528042155), 66: (4, 255, 0.1629782213299882), 67: (4, 255, 0.16285288894147265), 68: (4, 255, 0.16343995441189585), 69: (4, 255, 0.16336117980673032), 70: (4, 255, 0.16302565801888705)}\n",
      "{'predict_runtime': 2957.8121, 'predict_samples_per_second': 0.095, 'predict_steps_per_second': 0.024}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:49:17.81\n",
      "  predict_samples_per_second =      0.095\n",
      "  predict_steps_per_second   =      0.024\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 20\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.21486131194978952), 2: (1, 0.18718239851295948), 3: (1, 0.18791203945875168), 4: (1, 0.18822707515209913), 5: (1, 0.18632058799266815), 6: (1, 0.18656976334750652), 7: (1, 0.18698261957615614), 8: (1, 0.18699139915406704), 9: (1, 0.18690442945808172), 10: (1, 0.18559203390032053), 11: (1, 0.18612259812653065), 12: (1, 0.187090496532619), 13: (1, 0.1875583315268159), 14: (1, 0.18631230480968952), 15: (1, 0.18780056666582823), 16: (1, 0.18757961876690388), 17: (1, 0.18725108169019222), 18: (1, 0.1868398766964674), 19: (1, 0.18841503839939833), 20: (1, 0.18585580866783857), 21: (1, 0.18744949996471405), 22: (1, 0.18760561756789684), 23: (1, 0.18917285837233067), 24: (1, 0.18694949429482222), 25: (1, 0.18735777959227562), 26: (1, 0.18639451079070568), 27: (1, 0.1881451401859522), 28: (1, 0.18831754755228758), 29: (1, 0.1857983861118555), 30: (1, 0.18610079307109118), 31: (1, 0.1861873110756278), 32: (1, 0.18739088717848063), 33: (1, 0.18800152000039816), 34: (1, 0.18528148159384727), 35: (1, 0.1873698467388749), 36: (1, 0.18716649897396564), 37: (1, 0.18783248029649258), 38: (1, 0.18722290825098753), 39: (1, 0.1871186187490821), 40: (1, 0.18627389892935753), 41: (1, 0.18592838197946548), 42: (1, 0.1865933435037732), 43: (1, 0.18738002516329288), 44: (1, 0.1848755544051528), 45: (1, 0.1862329076975584), 46: (1, 0.1853748569265008), 47: (1, 0.18867794889956713), 48: (1, 0.1893480308353901), 49: (1, 0.1855427948758006), 50: (1, 0.1875537410378456), 51: (1, 0.1858377605676651), 52: (1, 0.18752571195363998), 53: (1, 0.18638720363378525), 54: (1, 0.187425191514194), 55: (1, 0.18737358320504427), 56: (1, 0.1854390548542142), 57: (1, 0.18762614857405424), 58: (1, 0.1860396070405841), 59: (1, 0.18495487980544567), 60: (1, 0.18718381319195032), 61: (1, 0.1880562137812376), 62: (1, 0.18749265931546688), 63: (1, 0.1868568668141961), 64: (1, 0.18537661340087652), 65: (1, 0.18657239899039268), 66: (1, 0.18801632151007652), 67: (1, 0.1884532766416669), 68: (1, 0.18565159011632204), 69: (1, 0.18502971716225147), 70: (1, 0.1859743958339095), 71: (1, 0.18666970822960138)}\n",
      "{1: (1, 255, 0.11123754618433761), 2: (1, 255, 0.11067739759809246), 3: (1, 255, 0.11073647681623697), 4: (1, 255, 0.11075313166879555), 5: (1, 255, 0.11074605219650502), 6: (1, 255, 0.11066414880767173), 7: (1, 255, 0.11062492382730924), 8: (1, 255, 0.11092171586465602), 9: (1, 255, 0.11140023691616222), 10: (1, 255, 0.11127685949060262), 11: (1, 255, 0.11063617364521705), 12: (1, 255, 0.11075490642631171), 13: (1, 255, 0.11060306270990301), 14: (1, 255, 0.11073416064986412), 15: (1, 255, 0.1107629516143717), 16: (1, 255, 0.11072361829014969), 17: (1, 255, 0.11102612858601645), 18: (1, 255, 0.11067137601694056), 19: (1, 255, 0.11075074483147439), 20: (1, 255, 0.11066793899106629), 21: (1, 255, 0.11153089674007075), 22: (1, 255, 0.11155498999298788), 23: (1, 255, 0.11119949768352158), 24: (1, 255, 0.11077296786813759), 25: (1, 255, 0.11075918614937394), 26: (1, 255, 0.1108346860307981), 27: (1, 255, 0.11088616184378956), 28: (1, 255, 0.11080699699255181), 29: (1, 255, 0.11106391354080508), 30: (1, 255, 0.11092619434291241), 31: (1, 255, 0.11095581021452067), 32: (1, 255, 0.11085133224944858), 33: (1, 255, 0.1110139723465431), 34: (1, 255, 0.11148433374131426), 35: (1, 255, 0.11164749085757078), 36: (1, 255, 0.11106197733212919), 37: (1, 255, 0.11158386577724241), 38: (1, 255, 0.11084730002444748), 39: (1, 255, 0.11089871587852637), 40: (1, 255, 0.11081395001315018), 41: (1, 255, 0.11089161086608382), 42: (1, 255, 0.11093955151006288), 43: (1, 255, 0.11093241298461662), 44: (1, 255, 0.11082915113691022), 45: (1, 255, 0.11087260528960649), 46: (1, 255, 0.11082422014910216), 47: (1, 255, 0.11095681378216135), 48: (1, 255, 0.11084908026763622), 49: (1, 255, 0.11088414282775393), 50: (1, 255, 0.11075306538784621), 51: (1, 255, 0.11088587863042074), 52: (1, 255, 0.1107199565708345), 53: (1, 255, 0.11084468430455993), 54: (1, 255, 0.1108155068667496), 55: (1, 255, 0.11096713064494086), 56: (1, 255, 0.11090342191723632), 57: (1, 255, 0.11101711127614858), 58: (1, 255, 0.11100333162455582), 59: (1, 255, 0.11094653995744154), 60: (1, 255, 0.11090026872561258), 61: (1, 255, 0.11095777327815691), 62: (1, 255, 0.1108372213720691), 63: (1, 255, 0.11086194924279755), 64: (1, 255, 0.11084237982537232), 65: (1, 255, 0.11089944634586572), 66: (1, 255, 0.11091302717287166), 67: (1, 255, 0.11088000912146241), 68: (1, 255, 0.11081143156716637), 69: (1, 255, 0.11086579325298468), 70: (1, 255, 0.11078744961277527)}\n",
      "{'predict_runtime': 2021.4729, 'predict_samples_per_second': 0.035, 'predict_steps_per_second': 0.035}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:33:41.47\n",
      "  predict_samples_per_second =      0.035\n",
      "  predict_steps_per_second   =      0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.24230966623872519), 2: (2, 0.20085998252034187), 3: (2, 0.22199580911546946), 4: (2, 0.20454951468855143), 5: (2, 0.20363508630543947), 6: (2, 0.20488951075822115), 7: (2, 0.20572311151772738), 8: (2, 0.20817592181265354), 9: (2, 0.20042652916163206), 10: (2, 0.21935456525534391), 11: (2, 0.2027258025482297), 12: (2, 0.20249830465763807), 13: (2, 0.2096260441467166), 14: (2, 0.204091165214777), 15: (2, 0.1998088238760829), 16: (2, 0.2058213260024786), 17: (2, 0.2000212911516428), 18: (2, 0.2047445261850953), 19: (2, 0.2162155956029892), 20: (2, 0.2050248421728611), 21: (2, 0.21203427202999592), 22: (2, 0.20771028101444244), 23: (2, 0.22003717999905348), 24: (2, 0.24285617098212242), 25: (2, 0.20751941204071045), 26: (2, 0.21575295832008123), 27: (2, 0.20983943436294794), 28: (2, 0.20418737828731537), 29: (2, 0.2457590652629733), 30: (2, 0.20300326216965914), 31: (2, 0.22525479923933744), 32: (2, 0.2061210861429572), 33: (2, 0.20336213614791632), 34: (2, 0.20360445324331522), 35: (2, 0.21011619921773672), 36: (2, 0.20819424092769623), 37: (2, 0.2236072551459074), 38: (2, 0.2072709696367383), 39: (2, 0.221824805252254), 40: (2, 0.20764286536723375), 41: (2, 0.24390576221048832), 42: (2, 0.20459516067057848), 43: (2, 0.20945734437555075), 44: (2, 0.24342401698231697), 45: (2, 0.20078900177031755), 46: (2, 0.20360054913908243), 47: (2, 0.24662371817976236), 48: (2, 0.20090923830866814), 49: (2, 0.20907220616936684), 50: (2, 0.20584663283079863), 51: (2, 0.2374444706365466), 52: (2, 0.2174204308539629), 53: (2, 0.20869757886976004), 54: (2, 0.20240430999547243), 55: (2, 0.24319895450025797), 56: (2, 0.20452333614230156), 57: (2, 0.2016965076327324), 58: (2, 0.20578733179718256), 59: (2, 0.20916495192795992), 60: (2, 0.20800488535314798), 61: (2, 0.21084681060165167), 62: (2, 0.2013028971850872), 63: (2, 0.21099086571484804), 64: (2, 0.24222765769809484), 65: (2, 0.20759193412959576), 66: (2, 0.2090917956084013), 67: (2, 0.2447798466309905), 68: (2, 0.2008608216419816), 69: (2, 0.22155014425516129), 70: (2, 0.2249656841158867), 71: (1, 0.19501672685146332)}\n",
      "{1: (2, 255, 0.17015870912183148), 2: (2, 255, 0.17012949986200707), 3: (2, 255, 0.17020991623547732), 4: (2, 255, 0.17024401812357645), 5: (2, 255, 0.17015868991832522), 6: (2, 255, 0.17033673853923878), 7: (2, 255, 0.17020207757093742), 8: (2, 255, 0.1703829555863551), 9: (2, 255, 0.1702343161930056), 10: (2, 255, 0.17017292664112413), 11: (2, 255, 0.17011378859991536), 12: (2, 255, 0.17023394429581423), 13: (2, 255, 0.1702795393472793), 14: (2, 255, 0.17026529767203566), 15: (2, 255, 0.1703160481637015), 16: (2, 255, 0.17016912282389754), 17: (2, 255, 0.17027470333611264), 18: (2, 255, 0.17095444183796643), 19: (2, 255, 0.1709655907516386), 20: (2, 255, 0.17065483983971325), 21: (2, 255, 0.17031423695312412), 22: (2, 255, 0.17041092550053316), 23: (2, 255, 0.17015504464141878), 24: (2, 255, 0.17031674547960945), 25: (2, 255, 0.17026431408217724), 26: (2, 255, 0.17026457699636618), 27: (2, 255, 0.17039813447524518), 28: (2, 255, 0.17026317422734757), 29: (2, 255, 0.17028552292316568), 30: (2, 255, 0.17026320396758177), 31: (2, 255, 0.17035979074152077), 32: (2, 255, 0.17030301464027633), 33: (2, 255, 0.170410647104476), 34: (2, 255, 0.17030893766558639), 35: (2, 255, 0.17029696812524514), 36: (2, 255, 0.1703437290099614), 37: (2, 255, 0.1703360015855116), 38: (2, 255, 0.17037984219690164), 39: (2, 255, 0.17036786348577224), 40: (2, 255, 0.17025786805532728), 41: (2, 255, 0.17050010457123613), 42: (2, 255, 0.1703921530067044), 43: (2, 255, 0.17020470826868334), 44: (2, 255, 0.17046499302355098), 45: (2, 255, 0.17041737042805727), 46: (2, 255, 0.17032204951871843), 47: (2, 255, 0.1704102204747352), 48: (2, 255, 0.17039185304048599), 49: (2, 255, 0.1704315040479688), 50: (2, 255, 0.17037890901168187), 51: (2, 255, 0.17031384290871668), 52: (2, 255, 0.17034102472677534), 53: (2, 255, 0.17036966497042016), 54: (2, 255, 0.17022149703812364), 55: (2, 255, 0.17037451060890568), 56: (2, 255, 0.17030551201280425), 57: (2, 255, 0.1704149719291166), 58: (2, 255, 0.17025854935613918), 59: (2, 255, 0.17033668301780433), 60: (2, 255, 0.1700161353776268), 61: (2, 255, 0.1703436394970791), 62: (2, 255, 0.17024484757772262), 63: (2, 255, 0.17001249840227411), 64: (2, 255, 0.17021838229003491), 65: (2, 255, 0.17019949440351304), 66: (2, 255, 0.17004786090304455), 67: (2, 255, 0.17029234685880296), 68: (2, 255, 0.17017574648500658), 69: (2, 255, 0.1700858202854208), 70: (2, 255, 0.17031753184821677)}\n",
      "{'predict_runtime': 3083.4306, 'predict_samples_per_second': 0.046, 'predict_steps_per_second': 0.023}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:51:23.43\n",
      "  predict_samples_per_second =      0.046\n",
      "  predict_steps_per_second   =      0.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.2933331895619631), 2: (4, 0.2719220854341984), 3: (4, 0.2623293846845627), 4: (4, 0.26345138251781464), 5: (4, 0.2656732453033328), 6: (4, 0.30652979761362076), 7: (4, 0.26178340055048466), 8: (4, 0.2830249471589923), 9: (4, 0.263655767776072), 10: (4, 0.26356202829629183), 11: (4, 0.2713364092633128), 12: (4, 0.26711269840598106), 13: (4, 0.2730466304346919), 14: (4, 0.26462501659989357), 15: (4, 0.2658664816990495), 16: (4, 0.2610757565125823), 17: (4, 0.26218101289123297), 18: (4, 0.2673883531242609), 19: (4, 0.2668744595721364), 20: (4, 0.26734441239386797), 21: (4, 0.26175172813236713), 22: (4, 0.2627322059124708), 23: (4, 0.26490946114063263), 24: (4, 0.26960252597928047), 25: (4, 0.26681272871792316), 26: (4, 0.26613252609968185), 27: (4, 0.26372585259377956), 28: (4, 0.2622687900438905), 29: (4, 0.26189777441322803), 30: (4, 0.274267272092402), 31: (4, 0.26792307384312153), 32: (4, 0.268665443174541), 33: (4, 0.2663450902327895), 34: (4, 0.2656916677951813), 35: (4, 0.26809140015393496), 36: (4, 0.26718822959810495), 37: (4, 0.2657041270285845), 38: (4, 0.2670954493805766), 39: (4, 0.26057332567870617), 40: (4, 0.2624499537050724), 41: (4, 0.2610685005784035), 42: (4, 0.26414888352155685), 43: (4, 0.272416858933866), 44: (4, 0.26537094078958035), 45: (4, 0.26921450439840555), 46: (4, 0.3036261787638068), 47: (4, 0.26208328548818827), 48: (4, 0.26962355989962816), 49: (4, 0.2685180325061083), 50: (4, 0.2627015085890889), 51: (4, 0.26298189628869295), 52: (4, 0.2700048144906759), 53: (4, 0.2630200805142522), 54: (4, 0.2684840876609087), 55: (4, 0.2675795890390873), 56: (4, 0.30393107887357473), 57: (4, 0.2600816339254379), 58: (4, 0.2639066204428673), 59: (4, 0.26116384100168943), 60: (4, 0.26917810924351215), 61: (4, 0.26543191261589527), 62: (4, 0.2646140120923519), 63: (4, 0.2683240696787834), 64: (4, 0.26324671786278486), 65: (4, 0.2799459435045719), 66: (4, 0.2643040046095848), 67: (4, 0.2753973575308919), 68: (4, 0.2676799865439534), 69: (4, 0.2656728392466903), 70: (4, 0.2609169641509652), 71: (1, 0.190729602240026)}\n",
      "{1: (4, 255, 0.17140064970681482), 2: (4, 255, 0.1714843589629905), 3: (4, 255, 0.17130092329108249), 4: (4, 255, 0.17139098228631067), 5: (4, 255, 0.1713861843351932), 6: (4, 255, 0.17140902488620258), 7: (4, 255, 0.17132009864218678), 8: (4, 255, 0.1713756992974702), 9: (4, 255, 0.17142302279597987), 10: (4, 255, 0.17140756116851288), 11: (4, 255, 0.1714896383421386), 12: (4, 255, 0.17145615351185495), 13: (4, 255, 0.17142196422187136), 14: (4, 255, 0.1713370133191347), 15: (4, 255, 0.1713052139307062), 16: (4, 255, 0.17166287222986712), 17: (4, 255, 0.17123435759076885), 18: (4, 255, 0.17137383058594138), 19: (4, 255, 0.171311117321545), 20: (4, 255, 0.17152672423889823), 21: (4, 255, 0.17148607781558645), 22: (4, 255, 0.17147887395877465), 23: (4, 255, 0.1711627056055209), 24: (4, 255, 0.17137727638085684), 25: (4, 255, 0.17126032829503804), 26: (4, 255, 0.17139566606458495), 27: (4, 255, 0.17140572146311694), 28: (4, 255, 0.17131508852848235), 29: (4, 255, 0.1712782395674902), 30: (4, 255, 0.17138830547531445), 31: (4, 255, 0.1713596669883997), 32: (4, 255, 0.1714311313431929), 33: (4, 255, 0.17141020763665438), 34: (4, 255, 0.17134676661123246), 35: (4, 255, 0.17135895911385032), 36: (4, 255, 0.17141589357645487), 37: (4, 255, 0.1714104348720581), 38: (4, 255, 0.17141764163240497), 39: (4, 255, 0.17148297129235432), 40: (4, 255, 0.17161538033727922), 41: (4, 255, 0.1714277402406522), 42: (4, 255, 0.17130454305340262), 43: (4, 255, 0.17134027066549248), 44: (4, 255, 0.17136379155677323), 45: (4, 255, 0.17126668305592793), 46: (4, 255, 0.17140081565754087), 47: (4, 255, 0.1713403466541101), 48: (4, 255, 0.1713595978733079), 49: (4, 255, 0.17134760321647513), 50: (4, 255, 0.17141674194192769), 51: (4, 255, 0.17130981351741972), 52: (4, 255, 0.17136039119944269), 53: (4, 255, 0.17130330461716536), 54: (4, 255, 0.17132152831364497), 55: (4, 255, 0.17108058946608912), 56: (4, 255, 0.171327796216835), 57: (4, 255, 0.17131518415157118), 58: (4, 255, 0.1713305936505397), 59: (4, 255, 0.1712425564178357), 60: (4, 255, 0.17135800401515822), 61: (4, 255, 0.17133210304686253), 62: (4, 255, 0.17149928193539382), 63: (4, 255, 0.17128377412902374), 64: (4, 255, 0.1712091749460966), 65: (4, 255, 0.17114361793021945), 66: (4, 255, 0.17122603654131002), 67: (4, 255, 0.1711914274768502), 68: (4, 255, 0.17155871049446217), 69: (4, 255, 0.17137391861966428), 70: (4, 255, 0.17155372297354773)}\n",
      "{'predict_runtime': 3106.2442, 'predict_samples_per_second': 0.09, 'predict_steps_per_second': 0.023}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:51:46.24\n",
      "  predict_samples_per_second =       0.09\n",
      "  predict_steps_per_second   =      0.023\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 21\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
