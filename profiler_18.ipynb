{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 18, 19, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.3229059483855963), 2: (1, 0.16374231781810522), 3: (1, 0.16038168780505657), 4: (1, 0.15911089442670345), 5: (1, 0.15528948046267033), 6: (1, 0.15506116300821304), 7: (1, 0.1567035038024187), 8: (1, 0.15486466698348522), 9: (1, 0.15448208060115576), 10: (1, 0.15569325722754002), 11: (1, 0.1540289670228958), 12: (1, 0.15704795066267252), 13: (1, 0.15538834128528833), 14: (1, 0.15663206577301025), 15: (1, 0.1543783424422145), 16: (1, 0.15567201655358076), 17: (1, 0.15676600579172373), 18: (1, 0.15774150285869837), 19: (1, 0.15464580059051514), 20: (1, 0.15515766385942698), 21: (1, 0.15538919251412153), 22: (1, 0.15634498931467533), 23: (1, 0.15562507882714272), 24: (1, 0.15421579591929913), 25: (1, 0.15672168601304293), 26: (1, 0.15482899826020002), 27: (1, 0.1562038529664278), 28: (1, 0.15647649951279163), 29: (1, 0.15804565139114857), 30: (1, 0.1553568346425891), 31: (1, 0.1555873416364193), 32: (1, 0.15640329103916883), 33: (1, 0.15631030220538378), 34: (1, 0.15608306508511305), 35: (1, 0.15653344336897135), 36: (1, 0.15545454528182745), 37: (1, 0.15781550761312246), 38: (1, 0.15651590283960104), 39: (1, 0.15525758732110262), 40: (1, 0.15688904747366905), 41: (1, 0.15541861578822136), 42: (1, 0.15571938082575798), 43: (1, 0.1572867427021265), 44: (1, 0.15591722913086414), 45: (1, 0.1554155545309186), 46: (1, 0.15550519432872534), 47: (1, 0.15620163455605507), 48: (1, 0.1571900825947523), 49: (1, 0.15523936599493027), 50: (1, 0.1567791374400258), 51: (1, 0.1542558977380395), 52: (1, 0.15624939370900393), 53: (1, 0.1540895588696003), 54: (1, 0.15399367082864046), 55: (1, 0.15588769875466824), 56: (1, 0.15502226818352938), 57: (1, 0.15694888401776552), 58: (1, 0.1551389954984188), 59: (1, 0.15658292826265097), 60: (1, 0.15417763777077198), 61: (1, 0.15455634240061045), 62: (1, 0.15697305276989937), 63: (1, 0.15516840480268002), 64: (1, 0.1562793105840683), 65: (1, 0.15563303790986538), 66: (1, 0.15407132729887962), 67: (1, 0.15538608189672232), 68: (1, 0.1573396995663643), 69: (1, 0.15626379940658808), 70: (1, 0.15673890430480242), 71: (1, 0.1535346433520317)}\n",
      "{1: (1, 127, 0.09575621361338248), 2: (1, 127, 0.09511248105183595), 3: (1, 127, 0.09504261224229973), 4: (1, 127, 0.09490338696797532), 5: (1, 127, 0.09504257332474932), 6: (1, 127, 0.09490530314583948), 7: (1, 127, 0.09475044190414308), 8: (1, 127, 0.0945509677591521), 9: (1, 127, 0.09450028957725745), 10: (1, 127, 0.0944023242616278), 11: (1, 127, 0.09446148308888665), 12: (1, 127, 0.09442830060088024), 13: (1, 127, 0.09448614999593243), 14: (1, 127, 0.09452852808437713), 15: (1, 127, 0.09478098344732458), 16: (1, 127, 0.09466554943882809), 17: (1, 127, 0.09492547879010205), 18: (1, 127, 0.09555135550725413), 19: (1, 127, 0.09461145865635609), 20: (1, 127, 0.09446172680207125), 21: (1, 127, 0.09468907711103441), 22: (1, 127, 0.09463565746747603), 23: (1, 127, 0.09469590619881088), 24: (1, 127, 0.0948356550524202), 25: (1, 127, 0.09479030176967852), 26: (1, 127, 0.09452718900384631), 27: (1, 127, 0.0945763079464201), 28: (1, 127, 0.09469668498248096), 29: (1, 127, 0.09458938961129958), 30: (1, 127, 0.09470330153804594), 31: (1, 127, 0.09466137552237887), 32: (1, 127, 0.09444128303957267), 33: (1, 127, 0.09417972349979746), 34: (1, 127, 0.0942252415899686), 35: (1, 127, 0.09419375541436625), 36: (1, 127, 0.0941021626111208), 37: (1, 127, 0.09424080850747157), 38: (1, 127, 0.09453890928778592), 39: (1, 127, 0.09416660689932155), 40: (1, 127, 0.09442498782781635), 41: (1, 127, 0.09493754939799469), 42: (1, 127, 0.09861063341221471), 43: (1, 127, 0.09473087665749581), 44: (1, 127, 0.09448323453094547), 45: (1, 127, 0.09446292686620801), 46: (1, 127, 0.09435606425202737), 47: (1, 127, 0.09435295522594311), 48: (1, 127, 0.09425279290569345), 49: (1, 127, 0.09420333513770048), 50: (1, 127, 0.0942444965228673), 51: (1, 127, 0.09432013198645331), 52: (1, 127, 0.09436217634608661), 53: (1, 127, 0.09428153272835522), 54: (1, 127, 0.09427406892591104), 55: (1, 127, 0.09435172004287871), 56: (1, 127, 0.09433363592178803), 57: (1, 127, 0.09436589348181261), 58: (1, 127, 0.09431665301997597), 59: (1, 127, 0.09430487330738954), 60: (1, 127, 0.0942879908050843), 61: (1, 127, 0.09450658042658502), 62: (1, 127, 0.09483423496149188), 63: (1, 127, 0.0947912978228387), 64: (1, 127, 0.09479533548019534), 65: (1, 127, 0.09480440465542744), 66: (1, 127, 0.09469015055196726), 67: (1, 127, 0.09433306326840336), 68: (1, 127, 0.09444837970292475), 69: (1, 127, 0.09437898114528948), 70: (1, 127, 0.09438806630700357)}\n",
      "{'predict_runtime': 864.4399, 'predict_samples_per_second': 0.082, 'predict_steps_per_second': 0.082}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:14:24.43\n",
      "  predict_samples_per_second =      0.082\n",
      "  predict_steps_per_second   =      0.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.20851052273064852), 2: (2, 0.16615252289921045), 3: (2, 0.17584500834345818), 4: (2, 0.16165070608258247), 5: (2, 0.17697305511683226), 6: (2, 0.16516341548413038), 7: (2, 0.16514411382377148), 8: (2, 0.1778855323791504), 9: (2, 0.17511182557791471), 10: (2, 0.16936296317726374), 11: (2, 0.17560841888189316), 12: (2, 0.17349963448941708), 13: (2, 0.16175817232578993), 14: (2, 0.17656181659549475), 15: (2, 0.17393448762595654), 16: (2, 0.17463108990341425), 17: (2, 0.16826208494603634), 18: (2, 0.17474682815372944), 19: (2, 0.16281711868941784), 20: (2, 0.1770730698481202), 21: (2, 0.16293050721287727), 22: (2, 0.1604395965114236), 23: (2, 0.17315093614161015), 24: (2, 0.17650459613651037), 25: (2, 0.17619834002107382), 26: (2, 0.16282663773745298), 27: (2, 0.16514849103987217), 28: (2, 0.16433207970112562), 29: (2, 0.16096101980656385), 30: (2, 0.16082423087209463), 31: (2, 0.16428310982882977), 32: (2, 0.16201487556099892), 33: (2, 0.17469902522861958), 34: (2, 0.16352779790759087), 35: (2, 0.1787828067317605), 36: (2, 0.17372756637632847), 37: (2, 0.1737016374245286), 38: (2, 0.18169942125678062), 39: (2, 0.17323104199022055), 40: (2, 0.1737410258501768), 41: (2, 0.1728310864418745), 42: (2, 0.1775453006848693), 43: (2, 0.17160606011748314), 44: (2, 0.1621546931564808), 45: (2, 0.1667574681341648), 46: (2, 0.16118137445300817), 47: (2, 0.16613723523914814), 48: (2, 0.16397306136786938), 49: (2, 0.16462895274162292), 50: (2, 0.17803998291492462), 51: (2, 0.16238221898674965), 52: (2, 0.16439000517129898), 53: (2, 0.16433350555598736), 54: (2, 0.1766028506681323), 55: (2, 0.17681848630309105), 56: (2, 0.1656483393162489), 57: (2, 0.16316385846585035), 58: (2, 0.16112858429551125), 59: (2, 0.16489910706877708), 60: (2, 0.1781503902748227), 61: (2, 0.16248752735555172), 62: (2, 0.16808786522597075), 63: (2, 0.1677900366485119), 64: (2, 0.16328537836670876), 65: (2, 0.17744171619415283), 66: (2, 0.18072342779487371), 67: (2, 0.16721437126398087), 68: (2, 0.16148932464420795), 69: (2, 0.1793741500005126), 70: (2, 0.16561635676771402), 71: (1, 0.15381451044231653)}\n",
      "{1: (2, 127, 0.1460057306360072), 2: (2, 127, 0.14669930024849853), 3: (2, 127, 0.14568108872429827), 4: (2, 127, 0.1456097404685194), 5: (2, 127, 0.14563878599231636), 6: (2, 127, 0.14563470655744234), 7: (2, 127, 0.14558867794116886), 8: (2, 127, 0.14553155590904746), 9: (2, 127, 0.14563232295097797), 10: (2, 127, 0.14561247859355503), 11: (2, 127, 0.14561166943556916), 12: (2, 127, 0.1457901050182661), 13: (2, 127, 0.1459193553511552), 14: (2, 127, 0.14594815609111325), 15: (2, 127, 0.1460101088787627), 16: (2, 127, 0.14578903233265783), 17: (2, 127, 0.14567766648049899), 18: (2, 127, 0.14586998324283934), 19: (2, 127, 0.14588976094103234), 20: (2, 127, 0.14582558311375343), 21: (2, 127, 0.1458151541635629), 22: (2, 127, 0.1456949110179553), 23: (2, 127, 0.14568750085822474), 24: (2, 127, 0.14567673333927872), 25: (2, 127, 0.14573724600156462), 26: (2, 127, 0.14576548896729946), 27: (2, 127, 0.14578101799390683), 28: (2, 127, 0.1456173868688542), 29: (2, 127, 0.145785217393395), 30: (2, 127, 0.14587722764915134), 31: (2, 127, 0.1461459139845972), 32: (2, 127, 0.1459147901252264), 33: (2, 127, 0.14582340436158922), 34: (2, 127, 0.14555292663817096), 35: (2, 127, 0.14561418718181726), 36: (2, 127, 0.14553053314086256), 37: (2, 127, 0.14556137908719421), 38: (2, 127, 0.14556602250755302), 39: (2, 127, 0.1455539630608648), 40: (2, 127, 0.145665021605907), 41: (2, 127, 0.1456299748667699), 42: (2, 127, 0.14570405093703684), 43: (2, 127, 0.1456417346915861), 44: (2, 127, 0.1461586079259557), 45: (2, 127, 0.14662921708810517), 46: (2, 127, 0.14613517376733579), 47: (2, 127, 0.15020220079202587), 48: (2, 127, 0.14638343597872286), 49: (2, 127, 0.1459362740797086), 50: (2, 127, 0.14581432634245928), 51: (2, 127, 0.1477139070996736), 52: (2, 127, 0.14657079189370467), 53: (2, 127, 0.14622227496313533), 54: (2, 127, 0.14603574500661196), 55: (2, 127, 0.14605173501589402), 56: (2, 127, 0.1460382441117421), 57: (2, 127, 0.14616755960787844), 58: (2, 127, 0.1461679691698138), 59: (2, 127, 0.14605423891696873), 60: (2, 127, 0.146118887538809), 61: (2, 127, 0.146005879082959), 62: (2, 127, 0.14612261337176788), 63: (2, 127, 0.14616549519572672), 64: (2, 127, 0.1459842559580845), 65: (2, 127, 0.1459324835308307), 66: (2, 127, 0.1457754216838892), 67: (2, 127, 0.14606098084175212), 68: (2, 127, 0.14618070664133612), 69: (2, 127, 0.14627362643258543), 70: (2, 127, 0.1464431053687503)}\n",
      "{'predict_runtime': 1321.8897, 'predict_samples_per_second': 0.107, 'predict_steps_per_second': 0.054}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:01.88\n",
      "  predict_samples_per_second =      0.107\n",
      "  predict_steps_per_second   =      0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.20420332439243793), 2: (4, 0.17438629362732172), 3: (4, 0.18063215259462595), 4: (4, 0.18700524792075157), 5: (4, 0.17624281998723745), 6: (4, 0.17623880878090858), 7: (4, 0.18878670502454042), 8: (4, 0.17361936811357737), 9: (4, 0.17712779715657234), 10: (4, 0.1835255641490221), 11: (4, 0.18041915819048882), 12: (4, 0.1875798236578703), 13: (4, 0.17472599260509014), 14: (4, 0.17986831162124872), 15: (4, 0.17611926514655352), 16: (4, 0.17894697096198797), 17: (4, 0.1738631185144186), 18: (4, 0.17787754256278276), 19: (4, 0.1754862479865551), 20: (4, 0.17898614797741175), 21: (4, 0.17781538050621748), 22: (4, 0.17871669959276915), 23: (4, 0.17998476419597864), 24: (4, 0.18296331819146872), 25: (4, 0.1794121889397502), 26: (4, 0.17173792701214552), 27: (4, 0.17634366359561682), 28: (4, 0.18407862354069948), 29: (4, 0.17798999324440956), 30: (4, 0.17493909783661366), 31: (4, 0.18287464510649443), 32: (4, 0.17397050838917494), 33: (4, 0.18077507801353931), 34: (4, 0.1753368591889739), 35: (4, 0.17479919642210007), 36: (4, 0.17638258635997772), 37: (4, 0.18918367754667997), 38: (4, 0.17715658713132143), 39: (4, 0.1786166885867715), 40: (4, 0.17453364748507738), 41: (4, 0.17499594017863274), 42: (4, 0.17603628803044558), 43: (4, 0.17659569066017866), 44: (4, 0.17259957641363144), 45: (4, 0.1745114540681243), 46: (4, 0.17303700000047684), 47: (4, 0.18127319402992725), 48: (4, 0.1770164594054222), 49: (4, 0.17409404087811708), 50: (4, 0.1748406896367669), 51: (4, 0.17948734760284424), 52: (4, 0.1781334923580289), 53: (4, 0.17726369947195053), 54: (4, 0.18368401657789946), 55: (4, 0.17802582867443562), 56: (4, 0.17525504063814878), 57: (4, 0.18166333623230457), 58: (4, 0.1746933339163661), 59: (4, 0.17340237740427256), 60: (4, 0.18565212842077017), 61: (4, 0.1720820190384984), 62: (4, 0.17163943406194448), 63: (4, 0.17874242179095745), 64: (4, 0.17354209162294865), 65: (4, 0.17300800420343876), 66: (4, 0.18368271365761757), 67: (4, 0.17520987894386053), 68: (4, 0.1754936845973134), 69: (4, 0.18049980700016022), 70: (4, 0.17410707846283913), 71: (1, 0.1560006821528077)}\n",
      "{1: (4, 127, 0.14622516327310264), 2: (4, 127, 0.14602332198479046), 3: (4, 127, 0.14597830779146492), 4: (4, 127, 0.14603666291667486), 5: (4, 127, 0.14601148529286226), 6: (4, 127, 0.1459945548091113), 7: (4, 127, 0.1460095928893901), 8: (4, 127, 0.146130031011412), 9: (4, 127, 0.14596944007523885), 10: (4, 127, 0.1458199398929444), 11: (4, 127, 0.14578824065713666), 12: (4, 127, 0.14583893314619936), 13: (4, 127, 0.14593392056889656), 14: (4, 127, 0.14583251977295386), 15: (4, 127, 0.14583654155382725), 16: (4, 127, 0.14624424690131363), 17: (4, 127, 0.14634061967000717), 18: (4, 127, 0.1463466301179073), 19: (4, 127, 0.14622604224361538), 20: (4, 127, 0.14593946669749389), 21: (4, 127, 0.1459188790273244), 22: (4, 127, 0.1458959602934169), 23: (4, 127, 0.14590428783521642), 24: (4, 127, 0.1459222735221109), 25: (4, 127, 0.14588745209703766), 26: (4, 127, 0.1459006762762708), 27: (4, 127, 0.14574551839000127), 28: (4, 127, 0.14594337649966085), 29: (4, 127, 0.14590325942776333), 30: (4, 127, 0.14579491573202563), 31: (4, 127, 0.14575475417664202), 32: (4, 127, 0.14588284579758334), 33: (4, 127, 0.14583326318103262), 34: (4, 127, 0.14576632407031895), 35: (4, 127, 0.14595622908851996), 36: (4, 127, 0.14623538070307004), 37: (4, 127, 0.14606088757016292), 38: (4, 127, 0.1460481033711804), 39: (4, 127, 0.1456392165126763), 40: (4, 127, 0.14574102878453224), 41: (4, 127, 0.14562842560066716), 42: (4, 127, 0.14567806807852637), 43: (4, 127, 0.14578051375239853), 44: (4, 127, 0.1456973254313971), 45: (4, 127, 0.14569040418668525), 46: (4, 127, 0.1457291324146268), 47: (4, 127, 0.1456277144515491), 48: (4, 127, 0.1456289201182878), 49: (4, 127, 0.14573901200916353), 50: (4, 127, 0.14570691541394615), 51: (4, 127, 0.1457092375677871), 52: (4, 127, 0.14566108652603205), 53: (4, 127, 0.1455649318628189), 54: (4, 127, 0.14568116142612508), 55: (4, 127, 0.1461833166618516), 56: (4, 127, 0.14609756165983404), 57: (4, 127, 0.14623733066521058), 58: (4, 127, 0.14624225915094294), 59: (4, 127, 0.1457220154455093), 60: (4, 127, 0.1460039217802366), 61: (4, 127, 0.14586092486948243), 62: (4, 127, 0.1456192658598146), 63: (4, 127, 0.14585236944698207), 64: (4, 127, 0.145781258685793), 65: (4, 127, 0.14566648749297295), 66: (4, 127, 0.14567829194060694), 67: (4, 127, 0.1458316121221058), 68: (4, 127, 0.14565977490118404), 69: (4, 127, 0.1456388503855725), 70: (4, 127, 0.14574529915520057)}\n",
      "{'predict_runtime': 1321.5123, 'predict_samples_per_second': 0.213, 'predict_steps_per_second': 0.054}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:01.51\n",
      "  predict_samples_per_second =      0.213\n",
      "  predict_steps_per_second   =      0.054\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 18\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.191361790522933), 2: (1, 0.16459253430366516), 3: (1, 0.1627401039004326), 4: (1, 0.16378533095121384), 5: (1, 0.16462590172886848), 6: (1, 0.1634617643430829), 7: (1, 0.16263094265013933), 8: (1, 0.1638651480898261), 9: (1, 0.16371668968349695), 10: (1, 0.1626085713505745), 11: (1, 0.163581189699471), 12: (1, 0.16297060530632734), 13: (1, 0.16220967378467321), 14: (1, 0.1646865950897336), 15: (1, 0.16397936269640923), 16: (1, 0.16450570616871119), 17: (1, 0.16496226005256176), 18: (1, 0.16489634104073048), 19: (1, 0.16226202994585037), 20: (1, 0.16417026799172163), 21: (1, 0.16275780275464058), 22: (1, 0.16346219461411238), 23: (1, 0.16279693227261305), 24: (1, 0.16242768615484238), 25: (1, 0.1638596886768937), 26: (1, 0.1623835451900959), 27: (1, 0.1626264126971364), 28: (1, 0.16223267652094364), 29: (1, 0.1624841820448637), 30: (1, 0.16282011847943068), 31: (1, 0.1647534742951393), 32: (1, 0.16326937265694141), 33: (1, 0.1639364343136549), 34: (1, 0.16393035277724266), 35: (1, 0.16404213104397058), 36: (1, 0.16304128244519234), 37: (1, 0.1637346837669611), 38: (1, 0.1622316613793373), 39: (1, 0.16252595745027065), 40: (1, 0.16291922237724066), 41: (1, 0.164532832801342), 42: (1, 0.1632309267297387), 43: (1, 0.16354604251682758), 44: (1, 0.16396594792604446), 45: (1, 0.16222984716296196), 46: (1, 0.1644623214378953), 47: (1, 0.1655408190563321), 48: (1, 0.16457388922572136), 49: (1, 0.1626618206501007), 50: (1, 0.16339057125151157), 51: (1, 0.16294689662754536), 52: (1, 0.1641726614907384), 53: (1, 0.16396260354667902), 54: (1, 0.16268036887049675), 55: (1, 0.16378530487418175), 56: (1, 0.16411333065479994), 57: (1, 0.1645391946658492), 58: (1, 0.1645146058872342), 59: (1, 0.16195792332291603), 60: (1, 0.16450487542897463), 61: (1, 0.16186590399593115), 62: (1, 0.1631956286728382), 63: (1, 0.16356654465198517), 64: (1, 0.1651734346523881), 65: (1, 0.1646917099133134), 66: (1, 0.16463385988026857), 67: (1, 0.16521926410496235), 68: (1, 0.16266745328903198), 69: (1, 0.1651735631749034), 70: (1, 0.16400068625807762), 71: (1, 0.16260786168277264)}\n",
      "{1: (1, 127, 0.09982584207135392), 2: (1, 127, 0.09974471000793177), 3: (1, 127, 0.09967508059962997), 4: (1, 127, 0.09992201231038711), 5: (1, 127, 0.10010072880050563), 6: (1, 127, 0.09998367607270874), 7: (1, 127, 0.10005834532945644), 8: (1, 127, 0.10003277124822374), 9: (1, 127, 0.09982009393375689), 10: (1, 127, 0.0995763693459508), 11: (1, 127, 0.09962886524951364), 12: (1, 127, 0.09962432314531774), 13: (1, 127, 0.09969803825842113), 14: (1, 127, 0.09975401002649717), 15: (1, 127, 0.09965445428324027), 16: (1, 127, 0.0996820534704121), 17: (1, 127, 0.09968560978799589), 18: (1, 127, 0.09955740571168699), 19: (1, 127, 0.09966013696426013), 20: (1, 127, 0.09958659479115892), 21: (1, 127, 0.09970898732660323), 22: (1, 127, 0.09958100095977933), 23: (1, 127, 0.09972172817141992), 24: (1, 127, 0.09953766467973707), 25: (1, 127, 0.09961669573076362), 26: (1, 127, 0.09961417441322344), 27: (1, 127, 0.09965334364807042), 28: (1, 127, 0.09957499124520407), 29: (1, 127, 0.09962755883127217), 30: (1, 127, 0.09960902904666315), 31: (1, 127, 0.0996444646386415), 32: (1, 127, 0.09962572279848217), 33: (1, 127, 0.09962269096217287), 34: (1, 127, 0.09950416169943303), 35: (1, 127, 0.09951718400166494), 36: (1, 127, 0.09958882375407642), 37: (1, 127, 0.09945000086977022), 38: (1, 127, 0.09957629353482658), 39: (1, 127, 0.09952697348524267), 40: (1, 127, 0.09949486411550618), 41: (1, 127, 0.09945525822237017), 42: (1, 127, 0.09947929695600599), 43: (1, 127, 0.09948672011758633), 44: (1, 127, 0.09963455940706759), 45: (1, 127, 0.0995151374899731), 46: (1, 127, 0.09959650091738917), 47: (1, 127, 0.09960968246111485), 48: (1, 127, 0.09957218662960322), 49: (1, 127, 0.09951477976677221), 50: (1, 127, 0.09960290384075539), 51: (1, 127, 0.09959857778139705), 52: (1, 127, 0.09957551975243205), 53: (1, 127, 0.09950002388456675), 54: (1, 127, 0.0995536608709477), 55: (1, 127, 0.09964446460930851), 56: (1, 127, 0.0995034048715093), 57: (1, 127, 0.09959378096414363), 58: (1, 127, 0.09956561614150607), 59: (1, 127, 0.09946826164882014), 60: (1, 127, 0.0995415253491383), 61: (1, 127, 0.099533331961789), 62: (1, 127, 0.09952462464570999), 63: (1, 127, 0.09954295582394665), 64: (1, 127, 0.09941949905812975), 65: (1, 127, 0.0996246694286508), 66: (1, 127, 0.09958904533551668), 67: (1, 127, 0.099588304230078), 68: (1, 127, 0.09967691658108722), 69: (1, 127, 0.09983420767271378), 70: (1, 127, 0.09973734200704755)}\n",
      "{'predict_runtime': 910.0346, 'predict_samples_per_second': 0.078, 'predict_steps_per_second': 0.078}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:10.03\n",
      "  predict_samples_per_second =      0.078\n",
      "  predict_steps_per_second   =      0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.20146652311086655), 2: (2, 0.18494845274835825), 3: (2, 0.1702709821984172), 4: (2, 0.1726636439561844), 5: (2, 0.17409400641918182), 6: (2, 0.176960832439363), 7: (2, 0.18209607247263193), 8: (2, 0.17106529977172613), 9: (2, 0.18502132780849934), 10: (2, 0.17492509447038174), 11: (2, 0.17496003210544586), 12: (2, 0.18522771261632442), 13: (2, 0.1749064428731799), 14: (2, 0.18440819159150124), 15: (2, 0.17041389364749193), 16: (2, 0.1711860243231058), 17: (2, 0.18930335342884064), 18: (2, 0.18985822517424822), 19: (2, 0.18013983871787786), 20: (2, 0.1890930337831378), 21: (2, 0.18359260633587837), 22: (2, 0.1899570832028985), 23: (2, 0.17079534474760294), 24: (2, 0.1693563312292099), 25: (2, 0.17380914837121964), 26: (2, 0.17348538246005774), 27: (2, 0.17504835315048695), 28: (2, 0.19036267139017582), 29: (2, 0.1858452819287777), 30: (2, 0.17351281363517046), 31: (2, 0.1706448057666421), 32: (2, 0.17834569700062275), 33: (2, 0.17099640145897865), 34: (2, 0.17336578480899334), 35: (2, 0.18491486087441444), 36: (2, 0.1754283206537366), 37: (2, 0.19003048073500395), 38: (2, 0.17135948687791824), 39: (2, 0.1845878530293703), 40: (2, 0.17563409637659788), 41: (2, 0.18630125280469656), 42: (2, 0.17564547527581453), 43: (2, 0.18904338125139475), 44: (2, 0.17666131164878607), 45: (2, 0.18803004082292318), 46: (2, 0.1750112809240818), 47: (2, 0.17254942934960127), 48: (2, 0.17586637940257788), 49: (2, 0.17520607821643353), 50: (2, 0.18871576059609652), 51: (2, 0.17313638050109148), 52: (2, 0.189230065792799), 53: (2, 0.1788933640345931), 54: (2, 0.17200584430247545), 55: (2, 0.16850976273417473), 56: (2, 0.17693069577217102), 57: (2, 0.17594407685101032), 58: (2, 0.1703246422111988), 59: (2, 0.16982481628656387), 60: (2, 0.18078703992068768), 61: (2, 0.17014795262366533), 62: (2, 0.16905744560062885), 63: (2, 0.18615888711065054), 64: (2, 0.17030443996191025), 65: (2, 0.1707909945398569), 66: (2, 0.18841861002147198), 67: (2, 0.18813265301287174), 68: (2, 0.18527805618941784), 69: (2, 0.16885102819651365), 70: (2, 0.16860542073845863), 71: (1, 0.1780242007225752)}\n",
      "{1: (2, 127, 0.15357930923071433), 2: (2, 127, 0.15370337864545386), 3: (2, 127, 0.15358229515355404), 4: (2, 127, 0.15364401736186714), 5: (2, 127, 0.15412641816779854), 6: (2, 127, 0.15527664864157129), 7: (2, 127, 0.15458372098899734), 8: (2, 127, 0.15352542121256665), 9: (2, 127, 0.1535371134614968), 10: (2, 127, 0.15370850451290607), 11: (2, 127, 0.1536416816195165), 12: (2, 127, 0.15372238371257238), 13: (2, 127, 0.15356797397166022), 14: (2, 127, 0.15365633677221893), 15: (2, 127, 0.1536201486716003), 16: (2, 127, 0.1535758386828064), 17: (2, 127, 0.15383603699563994), 18: (2, 127, 0.15444882050537923), 19: (2, 127, 0.15470050960984522), 20: (2, 127, 0.1537753190170592), 21: (2, 127, 0.15373851386023554), 22: (2, 127, 0.15362975937790993), 23: (2, 127, 0.15391428096909224), 24: (2, 127, 0.1540508197884508), 25: (2, 127, 0.15394132981795494), 26: (2, 127, 0.15388486255693623), 27: (2, 127, 0.1536434667155616), 28: (2, 127, 0.15377299265393357), 29: (2, 127, 0.15383341959787636), 30: (2, 127, 0.1537785218940593), 31: (2, 127, 0.1536430379478481), 32: (2, 127, 0.15362552319484668), 33: (2, 127, 0.15350624000814955), 34: (2, 127, 0.15349177727255764), 35: (2, 127, 0.15370871447114728), 36: (2, 127, 0.1538994721334985), 37: (2, 127, 0.15366310668067903), 38: (2, 127, 0.1535539922825112), 39: (2, 127, 0.1536893079893326), 40: (2, 127, 0.15353360602001506), 41: (2, 127, 0.15370517045875468), 42: (2, 127, 0.15407692751751875), 43: (2, 127, 0.1539551070634657), 44: (2, 127, 0.15376891096775222), 45: (2, 127, 0.1536047010000531), 46: (2, 127, 0.15371904018386376), 47: (2, 127, 0.1536117068044548), 48: (2, 127, 0.15392313962142298), 49: (2, 127, 0.15361514257809777), 50: (2, 127, 0.15375445667272947), 51: (2, 127, 0.1534879711991924), 52: (2, 127, 0.153582275419782), 53: (2, 127, 0.1535561491449283), 54: (2, 127, 0.15394414958404742), 55: (2, 127, 0.15389664560615077), 56: (2, 127, 0.15364946732957532), 57: (2, 127, 0.15361876921420256), 58: (2, 127, 0.15350218942960886), 59: (2, 127, 0.1533105643759445), 60: (2, 127, 0.15345225679710156), 61: (2, 127, 0.15348634132602085), 62: (2, 127, 0.15336283407078719), 63: (2, 127, 0.15344553158479177), 64: (2, 127, 0.1535982835055219), 65: (2, 127, 0.15343073028777762), 66: (2, 127, 0.15335848331304752), 67: (2, 127, 0.1533347731676158), 68: (2, 127, 0.15355145258051672), 69: (2, 127, 0.1534871305009042), 70: (2, 127, 0.15338770126351925)}\n",
      "{'predict_runtime': 1391.9147, 'predict_samples_per_second': 0.101, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:11.91\n",
      "  predict_samples_per_second =      0.101\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.21702057216316462), 2: (4, 0.18522486835718155), 3: (4, 0.18699884694069624), 4: (4, 0.197987899184227), 5: (4, 0.18054170161485672), 6: (4, 0.18602654710412025), 7: (4, 0.18645710218697786), 8: (4, 0.18589088879525661), 9: (4, 0.19912438560277224), 10: (4, 0.197544751688838), 11: (4, 0.1828784914687276), 12: (4, 0.1840265979990363), 13: (4, 0.18414018582552671), 14: (4, 0.19732168409973383), 15: (4, 0.18256594333797693), 16: (4, 0.18351044319570065), 17: (4, 0.1867250045761466), 18: (4, 0.1853168811649084), 19: (4, 0.19650521222501993), 20: (4, 0.19818862155079842), 21: (4, 0.19370180275291204), 22: (4, 0.18851718306541443), 23: (4, 0.1970588145777583), 24: (4, 0.18246053252369165), 25: (4, 0.19689028523862362), 26: (4, 0.18390203546732664), 27: (4, 0.18465587683022022), 28: (4, 0.1869685584679246), 29: (4, 0.1820097453892231), 30: (4, 0.18061511125415564), 31: (4, 0.18180701788514853), 32: (4, 0.18505742866545916), 33: (4, 0.19794180057942867), 34: (4, 0.1862676041200757), 35: (4, 0.19281760975718498), 36: (4, 0.1984605835750699), 37: (4, 0.18565473146736622), 38: (4, 0.18495537899434566), 39: (4, 0.20238969568163157), 40: (4, 0.18993485160171986), 41: (4, 0.18673343677073717), 42: (4, 0.18341064453125), 43: (4, 0.1857257978990674), 44: (4, 0.1826189048588276), 45: (4, 0.1898654391989112), 46: (4, 0.19791020546108484), 47: (4, 0.1988961948081851), 48: (4, 0.19352346565574408), 49: (4, 0.18574277684092522), 50: (4, 0.18945071287453175), 51: (4, 0.18879562988877296), 52: (4, 0.18909521587193012), 53: (4, 0.18295064847916365), 54: (4, 0.19684278592467308), 55: (4, 0.18397752568125725), 56: (4, 0.18482073489576578), 57: (4, 0.18115236796438694), 58: (4, 0.19179132394492626), 59: (4, 0.18230106309056282), 60: (4, 0.18730702437460423), 61: (4, 0.18358496855944395), 62: (4, 0.18476716335862875), 63: (4, 0.1842336505651474), 64: (4, 0.19262340292334557), 65: (4, 0.19054981507360935), 66: (4, 0.2026212364435196), 67: (4, 0.18388877343386412), 68: (4, 0.18283897452056408), 69: (4, 0.18054124061018229), 70: (4, 0.18796631414443254), 71: (1, 0.16456240694969893)}\n",
      "{1: (4, 127, 0.15374384160468899), 2: (4, 127, 0.15391325769491318), 3: (4, 127, 0.1541186763765657), 4: (4, 127, 0.15417948521409683), 5: (4, 127, 0.15402088807822448), 6: (4, 127, 0.15422747902366823), 7: (4, 127, 0.1538091431496533), 8: (4, 127, 0.1537336893159691), 9: (4, 127, 0.15370221239492649), 10: (4, 127, 0.15380839647094566), 11: (4, 127, 0.15374106852205718), 12: (4, 127, 0.15382284226673326), 13: (4, 127, 0.15362898498685576), 14: (4, 127, 0.15375882431894072), 15: (4, 127, 0.15379237341071209), 16: (4, 127, 0.15378062333911657), 17: (4, 127, 0.15374232303556495), 18: (4, 127, 0.1537041646010411), 19: (4, 127, 0.15365755810277668), 20: (4, 127, 0.15367229812316538), 21: (4, 127, 0.15364769120942653), 22: (4, 127, 0.15374292588726743), 23: (4, 127, 0.15371316611972147), 24: (4, 127, 0.15371443708903912), 25: (4, 127, 0.15378339500643137), 26: (4, 127, 0.15377297745944243), 27: (4, 127, 0.15373095830418462), 28: (4, 127, 0.15368822010923325), 29: (4, 127, 0.15368392509151632), 30: (4, 127, 0.15365241180489383), 31: (4, 127, 0.1535762010112874), 32: (4, 127, 0.15365059642253195), 33: (4, 127, 0.15387889030059493), 34: (4, 127, 0.1539425552771317), 35: (4, 127, 0.1539213415675276), 36: (4, 127, 0.15399140246417814), 37: (4, 127, 0.1537347218007084), 38: (4, 127, 0.1536699397797425), 39: (4, 127, 0.1537022191561817), 40: (4, 127, 0.1537798861862989), 41: (4, 127, 0.15375405782467033), 42: (4, 127, 0.15363485052976317), 43: (4, 127, 0.15369424328031972), 44: (4, 127, 0.15365622938412615), 45: (4, 127, 0.15362227883365914), 46: (4, 127, 0.15377361328876393), 47: (4, 127, 0.15383951385747494), 48: (4, 127, 0.15364202622353562), 49: (4, 127, 0.15368178417158174), 50: (4, 127, 0.15392391310315431), 51: (4, 127, 0.15383915149232769), 52: (4, 127, 0.15360110691623893), 53: (4, 127, 0.153461936252617), 54: (4, 127, 0.1535103406507786), 55: (4, 127, 0.15360300627163076), 56: (4, 127, 0.15362173991321815), 57: (4, 127, 0.15352370428640072), 58: (4, 127, 0.15356645026192892), 59: (4, 127, 0.15353571707896124), 60: (4, 127, 0.15354917977210575), 61: (4, 127, 0.153508559463355), 62: (4, 127, 0.15357534176721346), 63: (4, 127, 0.15367132578573123), 64: (4, 127, 0.15398973516210562), 65: (4, 127, 0.15375738953218215), 66: (4, 127, 0.15373200299144965), 67: (4, 127, 0.15364176295257695), 68: (4, 127, 0.1536987558535234), 69: (4, 127, 0.15368047616935857), 70: (4, 127, 0.15370206656594446)}\n",
      "{'predict_runtime': 1392.7761, 'predict_samples_per_second': 0.202, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:12.77\n",
      "  predict_samples_per_second =      0.202\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 19\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.3057093247771263), 2: (1, 0.2724405424669385), 3: (1, 0.2707458809018135), 4: (1, 0.27013163827359676), 5: (1, 0.268706863746047), 6: (1, 0.26913709845393896), 7: (1, 0.266864943318069), 8: (1, 0.2687482526525855), 9: (1, 0.2661795224994421), 10: (1, 0.2667261650785804), 11: (1, 0.2684461148455739), 12: (1, 0.26926425378769636), 13: (1, 0.27080726716667414), 14: (1, 0.27096701320260763), 15: (1, 0.27651634998619556), 16: (1, 0.26838251389563084), 17: (1, 0.269418690353632), 18: (1, 0.2697276873514056), 19: (1, 0.2686081398278475), 20: (1, 0.26828687358647585), 21: (1, 0.26837630197405815), 22: (1, 0.2678156578913331), 23: (1, 0.2665968118235469), 24: (1, 0.2691281922161579), 25: (1, 0.2683421103283763), 26: (1, 0.26953231543302536), 27: (1, 0.26664438005536795), 28: (1, 0.26893744245171547), 29: (1, 0.2685474371537566), 30: (1, 0.26965043414384127), 31: (1, 0.2690389705821872), 32: (1, 0.270056557841599), 33: (1, 0.26648171804845333), 34: (1, 0.2670561708509922), 35: (1, 0.26767280139029026), 36: (1, 0.2713307710364461), 37: (1, 0.268484752625227), 38: (1, 0.26649963576346636), 39: (1, 0.2667224118486047), 40: (1, 0.26680462062358856), 41: (1, 0.2672482253983617), 42: (1, 0.2701735207810998), 43: (1, 0.2671602638438344), 44: (1, 0.2664974108338356), 45: (1, 0.26913654152303934), 46: (1, 0.2668036753311753), 47: (1, 0.2682832293212414), 48: (1, 0.26896968949586153), 49: (1, 0.2706128805875778), 50: (1, 0.26686773356050253), 51: (1, 0.2699229894205928), 52: (1, 0.2678193710744381), 53: (1, 0.26702145021408796), 54: (1, 0.26935805287212133), 55: (1, 0.26736451499164104), 56: (1, 0.26838251389563084), 57: (1, 0.27068227622658014), 58: (1, 0.26830360293388367), 59: (1, 0.2698262045159936), 60: (1, 0.2670231759548187), 61: (1, 0.267019085586071), 62: (1, 0.26923356018960476), 63: (1, 0.26690674666315317), 64: (1, 0.2668520864099264), 65: (1, 0.26918724924325943), 66: (1, 0.266940894536674), 67: (1, 0.26671785674989223), 68: (1, 0.27630465757101774), 69: (1, 0.2761486880481243), 70: (1, 0.2720796540379524), 71: (1, 0.27111235447227955)}\n",
      "{1: (1, 127, 0.16695139637055595), 2: (1, 127, 0.16559564384565814), 3: (1, 127, 0.16524795308621146), 4: (1, 127, 0.1652369298128866), 5: (1, 127, 0.16513501934149838), 6: (1, 127, 0.16504740902024695), 7: (1, 127, 0.16508085342256104), 8: (1, 127, 0.16495858696032697), 9: (1, 127, 0.16503291711299203), 10: (1, 127, 0.1649662793987966), 11: (1, 127, 0.16502363163625866), 12: (1, 127, 0.16512799073802673), 13: (1, 127, 0.1650827763910134), 14: (1, 127, 0.1650746087653665), 15: (1, 127, 0.16519087788421571), 16: (1, 127, 0.16498278512612102), 17: (1, 127, 0.16511952322651083), 18: (1, 127, 0.16514631487634474), 19: (1, 127, 0.16509630351408025), 20: (1, 127, 0.1652213963936633), 21: (1, 127, 0.1651079248871625), 22: (1, 127, 0.16510296078384157), 23: (1, 127, 0.16489647895713724), 24: (1, 127, 0.16502019477729488), 25: (1, 127, 0.16501645185053349), 26: (1, 127, 0.16501338166133392), 27: (1, 127, 0.16511893753461013), 28: (1, 127, 0.1650881741313249), 29: (1, 127, 0.16497374808518436), 30: (1, 127, 0.1649707534944448), 31: (1, 127, 0.164983519367639), 32: (1, 127, 0.16514454590611335), 33: (1, 127, 0.16497092899375074), 34: (1, 127, 0.1649470789006024), 35: (1, 127, 0.16479721802514136), 36: (1, 127, 0.16485868736104234), 37: (1, 127, 0.1651542810649853), 38: (1, 127, 0.16479629001719512), 39: (1, 127, 0.16458890728623143), 40: (1, 127, 0.16493253997989057), 41: (1, 127, 0.1645680077623312), 42: (1, 127, 0.16505342855404212), 43: (1, 127, 0.16475538377041424), 44: (1, 127, 0.16481672352047885), 45: (1, 127, 0.16481479202345836), 46: (1, 127, 0.1648095445047448), 47: (1, 127, 0.16485747133242332), 48: (1, 127, 0.1649300916795069), 49: (1, 127, 0.16497953400367826), 50: (1, 127, 0.16477136310248627), 51: (1, 127, 0.1648264378162585), 52: (1, 127, 0.16484837976144992), 53: (1, 127, 0.16472299471057542), 54: (1, 127, 0.16497106519417734), 55: (1, 127, 0.1648494464044613), 56: (1, 127, 0.1647575557759897), 57: (1, 127, 0.16482636192446853), 58: (1, 127, 0.16517397759144936), 59: (1, 127, 0.1650053487841304), 60: (1, 127, 0.16511447526015868), 61: (1, 127, 0.16488756089815942), 62: (1, 127, 0.164947958399109), 63: (1, 127, 0.16500311297929193), 64: (1, 127, 0.1649221494852558), 65: (1, 127, 0.16496973154758374), 66: (1, 127, 0.16513839452784126), 67: (1, 127, 0.16952205420009733), 68: (1, 127, 0.16732864040060072), 69: (1, 127, 0.16647411978942908), 70: (1, 127, 0.16609462606537295)}\n",
      "{'predict_runtime': 1508.3515, 'predict_samples_per_second': 0.047, 'predict_steps_per_second': 0.047}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:08.35\n",
      "  predict_samples_per_second =      0.047\n",
      "  predict_steps_per_second   =      0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.30729507375508547), 2: (2, 0.2858282560482621), 3: (2, 0.28084244206547737), 4: (2, 0.2785879373550415), 5: (2, 0.27716760244220495), 6: (2, 0.28476931527256966), 7: (2, 0.2980968626216054), 8: (2, 0.28013161662966013), 9: (2, 0.3032343527302146), 10: (2, 0.2957247169688344), 11: (2, 0.29378053918480873), 12: (2, 0.2783681945875287), 13: (2, 0.2808682043105364), 14: (2, 0.28127089887857437), 15: (2, 0.30540949292480946), 16: (2, 0.29826776403933764), 17: (2, 0.30511417519301176), 18: (2, 0.2850844031199813), 19: (2, 0.2802104176953435), 20: (2, 0.2975689386948943), 21: (2, 0.2833188343793154), 22: (2, 0.2792030116543174), 23: (2, 0.2852140022441745), 24: (2, 0.30026920046657324), 25: (2, 0.29962118715047836), 26: (2, 0.2793655563145876), 27: (2, 0.30422144290059805), 28: (2, 0.3048274954780936), 29: (2, 0.3030076650902629), 30: (2, 0.30327586084604263), 31: (2, 0.30348923802375793), 32: (2, 0.2833337960764766), 33: (2, 0.28042775858193636), 34: (2, 0.2832200564444065), 35: (2, 0.3023027181625366), 36: (2, 0.28456258960068226), 37: (2, 0.3008727738633752), 38: (2, 0.3054214119911194), 39: (2, 0.30310770589858294), 40: (2, 0.2867583418264985), 41: (2, 0.2888842085376382), 42: (2, 0.29274724144488573), 43: (2, 0.3024918017908931), 44: (2, 0.28668379969894886), 45: (2, 0.27632569801062346), 46: (2, 0.305908739566803), 47: (2, 0.28378745168447495), 48: (2, 0.3059427086263895), 49: (2, 0.284510001540184), 50: (2, 0.30627742130309343), 51: (2, 0.2847769074141979), 52: (2, 0.28420959413051605), 53: (2, 0.28030414693057537), 54: (2, 0.2877169521525502), 55: (2, 0.30113047920167446), 56: (2, 0.2990877814590931), 57: (2, 0.2834317898377776), 58: (2, 0.2816013991832733), 59: (2, 0.284483827650547), 60: (2, 0.2857815604656935), 61: (2, 0.2842067675665021), 62: (2, 0.2823028387501836), 63: (2, 0.2799229957163334), 64: (2, 0.28195959236472845), 65: (2, 0.28430744633078575), 66: (2, 0.2870806725695729), 67: (2, 0.2844809414818883), 68: (2, 0.28620550222694874), 69: (2, 0.2868562638759613), 70: (2, 0.28069471288472414), 71: (1, 0.26743163634091616)}\n",
      "{1: (2, 127, 0.25619227260967176), 2: (2, 127, 0.2555937694869642), 3: (2, 127, 0.2555797406596931), 4: (2, 127, 0.2556233933254138), 5: (2, 127, 0.2553844762174046), 6: (2, 127, 0.2555256979466658), 7: (2, 127, 0.2556187255000036), 8: (2, 127, 0.2553585914044282), 9: (2, 127, 0.25545988509094153), 10: (2, 127, 0.2553412224657423), 11: (2, 127, 0.25549419715589894), 12: (2, 127, 0.25551833055444123), 13: (2, 127, 0.25540658433400976), 14: (2, 127, 0.25537307493711314), 15: (2, 127, 0.2551605507335442), 16: (2, 127, 0.25501733180868813), 17: (2, 127, 0.2550855515906074), 18: (2, 127, 0.25529231096610544), 19: (2, 127, 0.2551770945057625), 20: (2, 127, 0.25521022280839484), 21: (2, 127, 0.25526783920413865), 22: (2, 127, 0.255275482671174), 23: (2, 127, 0.2552025573929464), 24: (2, 127, 0.25572207176280537), 25: (2, 127, 0.2558090882009174), 26: (2, 127, 0.25555365848699657), 27: (2, 127, 0.2556542396530744), 28: (2, 127, 0.2555280237451313), 29: (2, 127, 0.25562188006556175), 30: (2, 127, 0.25551832058855634), 31: (2, 127, 0.25559965154434755), 32: (2, 127, 0.2557169687090896), 33: (2, 127, 0.2555508784671116), 34: (2, 127, 0.25560342968536875), 35: (2, 127, 0.2555246183898036), 36: (2, 127, 0.2555034409211142), 37: (2, 127, 0.2558271447343268), 38: (2, 127, 0.2555759051800009), 39: (2, 127, 0.2556327143244035), 40: (2, 127, 0.25559982732965014), 41: (2, 127, 0.25564934428429276), 42: (2, 127, 0.25563105918085716), 43: (2, 127, 0.25566973870869464), 44: (2, 127, 0.25573991544134034), 45: (2, 127, 0.2557045829841706), 46: (2, 127, 0.25564777211645456), 47: (2, 127, 0.25577012967963625), 48: (2, 127, 0.25576495304410385), 49: (2, 127, 0.2559954576546282), 50: (2, 127, 0.25561292698298854), 51: (2, 127, 0.2557402512747941), 52: (2, 127, 0.25573724666683695), 53: (2, 127, 0.25563877057577444), 54: (2, 127, 0.2554788868214319), 55: (2, 127, 0.2556964426968745), 56: (2, 127, 0.25574516468336733), 57: (2, 127, 0.2559117440016955), 58: (2, 127, 0.2557436294897687), 59: (2, 127, 0.2557149571036612), 60: (2, 127, 0.2557241116965732), 61: (2, 127, 0.255904034872752), 62: (2, 127, 0.2558369232546978), 63: (2, 127, 0.2556005116097453), 64: (2, 127, 0.2558503457983061), 65: (2, 127, 0.2557097183408465), 66: (2, 127, 0.25584055628539537), 67: (2, 127, 0.2556323350341184), 68: (2, 127, 0.25566235106203733), 69: (2, 127, 0.2557313155500204), 70: (2, 127, 0.2558085381339385)}\n",
      "{'predict_runtime': 2313.8125, 'predict_samples_per_second': 0.061, 'predict_steps_per_second': 0.031}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:33.81\n",
      "  predict_samples_per_second =      0.061\n",
      "  predict_steps_per_second   =      0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.3287417236715555), 2: (4, 0.3028578581288457), 3: (4, 0.30056053400039673), 4: (4, 0.31751392874866724), 5: (4, 0.3053688080981374), 6: (4, 0.3021896332502365), 7: (4, 0.32459826674312353), 8: (4, 0.30031921435147524), 9: (4, 0.30273395869880915), 10: (4, 0.30333200097084045), 11: (4, 0.32356330845505), 12: (4, 0.3237687349319458), 13: (4, 0.3013761630281806), 14: (4, 0.30358003731817007), 15: (4, 0.30199316516518593), 16: (4, 0.3142064632847905), 17: (4, 0.3117446228861809), 18: (4, 0.32286808360368013), 19: (4, 0.3024650067090988), 20: (4, 0.2997225681319833), 21: (4, 0.3216260764747858), 22: (4, 0.30292927101254463), 23: (4, 0.32266667298972607), 24: (4, 0.3005955470725894), 25: (4, 0.29935242142528296), 26: (4, 0.31719091534614563), 27: (4, 0.2974766520783305), 28: (4, 0.3020996982231736), 29: (4, 0.298404130153358), 30: (4, 0.3027749601751566), 31: (4, 0.32487008534371853), 32: (4, 0.30147773306816816), 33: (4, 0.30644071474671364), 34: (4, 0.31591465324163437), 35: (4, 0.30106996558606625), 36: (4, 0.3240090813487768), 37: (4, 0.30476019345223904), 38: (4, 0.309742733836174), 39: (4, 0.3230473306030035), 40: (4, 0.3018584167584777), 41: (4, 0.29922438599169254), 42: (4, 0.30080991704016924), 43: (4, 0.32425621524453163), 44: (4, 0.300479750148952), 45: (4, 0.3222106480970979), 46: (4, 0.3019948834553361), 47: (4, 0.30045896023511887), 48: (4, 0.3225391935557127), 49: (4, 0.3043046249076724), 50: (4, 0.3222733261063695), 51: (4, 0.30624198261648417), 52: (4, 0.30802609119564295), 53: (4, 0.30135720781981945), 54: (4, 0.3184928996488452), 55: (4, 0.3094212841242552), 56: (4, 0.30230941716581583), 57: (4, 0.3283427134156227), 58: (4, 0.29876251704990864), 59: (4, 0.301299586892128), 60: (4, 0.30053497571498156), 61: (4, 0.3054603077471256), 62: (4, 0.3002557782456279), 63: (4, 0.298863154835999), 64: (4, 0.3033247450366616), 65: (4, 0.3016139855608344), 66: (4, 0.32808524556457996), 67: (4, 0.2996300095692277), 68: (4, 0.3032543072476983), 69: (4, 0.30039755161851645), 70: (4, 0.32062586303800344), 71: (1, 0.2680591018870473)}\n",
      "{1: (4, 127, 0.25750404798726395), 2: (4, 127, 0.25729124399092723), 3: (4, 127, 0.25716211327065636), 4: (4, 127, 0.2568587305420262), 5: (4, 127, 0.2571570909266749), 6: (4, 127, 0.2569467282421359), 7: (4, 127, 0.2574889624388669), 8: (4, 127, 0.25686921757887904), 9: (4, 127, 0.2571215821342088), 10: (4, 127, 0.2568016605539702), 11: (4, 127, 0.2566984964930636), 12: (4, 127, 0.2568676694494298), 13: (4, 127, 0.2570775638253787), 14: (4, 127, 0.2571686023450273), 15: (4, 127, 0.25716773781368113), 16: (4, 127, 0.25699448347179676), 17: (4, 127, 0.257018278345583), 18: (4, 127, 0.25691322449184073), 19: (4, 127, 0.2564307748978063), 20: (4, 127, 0.25620739696562056), 21: (4, 127, 0.2562662282973293), 22: (4, 127, 0.2562849395651752), 23: (4, 127, 0.25636227038784287), 24: (4, 127, 0.25639923300418094), 25: (4, 127, 0.2563077638101742), 26: (4, 127, 0.2564689833597522), 27: (4, 127, 0.2562845814533121), 28: (4, 127, 0.2563128637252595), 29: (4, 127, 0.25614147537248577), 30: (4, 127, 0.25627254197505983), 31: (4, 127, 0.25620902168351833), 32: (4, 127, 0.25629380709807), 33: (4, 127, 0.25611583548267997), 34: (4, 127, 0.2561863510040786), 35: (4, 127, 0.2562250793860184), 36: (4, 127, 0.2561749386359153), 37: (4, 127, 0.25611912009606913), 38: (4, 127, 0.2561150240953865), 39: (4, 127, 0.2561232694461355), 40: (4, 127, 0.2563497581057192), 41: (4, 127, 0.25621295318476794), 42: (4, 127, 0.25615993075395427), 43: (4, 127, 0.2562119341125404), 44: (4, 127, 0.25609105075232863), 45: (4, 127, 0.25612266693176244), 46: (4, 127, 0.25626537121656373), 47: (4, 127, 0.256089411881261), 48: (4, 127, 0.256128809326805), 49: (4, 127, 0.25623844393096334), 50: (4, 127, 0.2558858304057182), 51: (4, 127, 0.25609788122608906), 52: (4, 127, 0.25602025122154415), 53: (4, 127, 0.2561406286022677), 54: (4, 127, 0.2559650334360914), 55: (4, 127, 0.25618016304022917), 56: (4, 127, 0.2559426621438598), 57: (4, 127, 0.25622001716383097), 58: (4, 127, 0.2560360777800477), 59: (4, 127, 0.2561677340198103), 60: (4, 127, 0.255912767583871), 61: (4, 127, 0.2563869696271818), 62: (4, 127, 0.2560005133648909), 63: (4, 127, 0.2560387645796763), 64: (4, 127, 0.25616445033774365), 65: (4, 127, 0.2559818392179496), 66: (4, 127, 0.255938051847785), 67: (4, 127, 0.2561108886711593), 68: (4, 127, 0.25621248130488583), 69: (4, 127, 0.25590981617129926), 70: (4, 127, 0.25611786911718726)}\n",
      "{'predict_runtime': 2322.2428, 'predict_samples_per_second': 0.121, 'predict_steps_per_second': 0.031}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:42.24\n",
      "  predict_samples_per_second =      0.121\n",
      "  predict_steps_per_second   =      0.031\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 32\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 18, 19, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.31943144742399454), 2: (1, 0.16748883295804262), 3: (1, 0.1618646178394556), 4: (1, 0.1631834227591753), 5: (1, 0.16067795362323523), 6: (1, 0.16258931159973145), 7: (1, 0.16234760265797377), 8: (1, 0.1611375082284212), 9: (1, 0.16178714018315077), 10: (1, 0.16064863465726376), 11: (1, 0.1607585223391652), 12: (1, 0.16271742898970842), 13: (1, 0.16222926508635283), 14: (1, 0.16822617501020432), 15: (1, 0.16870010923594236), 16: (1, 0.16385223530232906), 17: (1, 0.16131815500557423), 18: (1, 0.16436105966567993), 19: (1, 0.16024533845484257), 20: (1, 0.16224399488419294), 21: (1, 0.16137922648340464), 22: (1, 0.16186040081083775), 23: (1, 0.16131155658513308), 24: (1, 0.1609410811215639), 25: (1, 0.1619929587468505), 26: (1, 0.16131929773837328), 27: (1, 0.16075939312577248), 28: (1, 0.16014030016958714), 29: (1, 0.16213128808885813), 30: (1, 0.16175343096256256), 31: (1, 0.1620412189513445), 32: (1, 0.16023834887892008), 33: (1, 0.15995896141976118), 34: (1, 0.16171765141189098), 35: (1, 0.16681781224906445), 36: (1, 0.16130560729652643), 37: (1, 0.16178110241889954), 38: (1, 0.16232409607619047), 39: (1, 0.1613224782049656), 40: (1, 0.16219478752464056), 41: (1, 0.16275166161358356), 42: (1, 0.16077648475766182), 43: (1, 0.16001440398395061), 44: (1, 0.1609199233353138), 45: (1, 0.16240710485726595), 46: (1, 0.16251585446298122), 47: (1, 0.16019498091191053), 48: (1, 0.1686038626357913), 49: (1, 0.16262708138674498), 50: (1, 0.16193897183984518), 51: (1, 0.16123376041650772), 52: (1, 0.1606999058276415), 53: (1, 0.16122751962393522), 54: (1, 0.16266482323408127), 55: (1, 0.1624951846897602), 56: (1, 0.16685620415955782), 57: (1, 0.16217285860329866), 58: (1, 0.16155584622174501), 59: (1, 0.16195883136242628), 60: (1, 0.16207692958414555), 61: (1, 0.1615903964266181), 62: (1, 0.16468349937349558), 63: (1, 0.15990886744111776), 64: (1, 0.16106304246932268), 65: (1, 0.16249126568436623), 66: (1, 0.16056046914309263), 67: (1, 0.16241202596575022), 68: (1, 0.15992517583072186), 69: (1, 0.16338686551898718), 70: (1, 0.16172429639846087), 71: (1, 0.15910074673593044)}\n",
      "{1: (1, 127, 0.09683354340464347), 2: (1, 127, 0.09584919801788537), 3: (1, 127, 0.09614110857570969), 4: (1, 127, 0.09603686181197721), 5: (1, 127, 0.09565974557112286), 6: (1, 127, 0.09563774596459752), 7: (1, 127, 0.09608924418218492), 8: (1, 127, 0.09562970466149134), 9: (1, 127, 0.09547981134373841), 10: (1, 127, 0.09578578126448112), 11: (1, 127, 0.09600995695145112), 12: (1, 127, 0.09547668476185696), 13: (1, 127, 0.09697066237930003), 14: (1, 127, 0.10184093571348687), 15: (1, 127, 0.09650321568795077), 16: (1, 127, 0.0955800090982454), 17: (1, 127, 0.09524544629847675), 18: (1, 127, 0.09505546581381419), 19: (1, 127, 0.09505636884471563), 20: (1, 127, 0.09519713612522666), 21: (1, 127, 0.09525048680691503), 22: (1, 127, 0.09674497867575077), 23: (1, 127, 0.0956078203483008), 24: (1, 127, 0.0952722552694439), 25: (1, 127, 0.09505182025792795), 26: (1, 127, 0.09508390198131715), 27: (1, 127, 0.0949778468971412), 28: (1, 127, 0.09493868297889946), 29: (1, 127, 0.09512402912909824), 30: (1, 127, 0.09507353031113157), 31: (1, 127, 0.09506427196008484), 32: (1, 127, 0.09503179208529512), 33: (1, 127, 0.09496641131924598), 34: (1, 127, 0.0952001465631165), 35: (1, 127, 0.09522435380747234), 36: (1, 127, 0.0951452950807655), 37: (1, 127, 0.09545455575282649), 38: (1, 127, 0.0960942478997149), 39: (1, 127, 0.095173964636239), 40: (1, 127, 0.09518440408764157), 41: (1, 127, 0.09517946324538527), 42: (1, 127, 0.09513561789122388), 43: (1, 127, 0.09518887178869698), 44: (1, 127, 0.09739233065748543), 45: (1, 127, 0.0971956472535889), 46: (1, 127, 0.09528841974404384), 47: (1, 127, 0.09564700581896024), 48: (1, 127, 0.09620964209600462), 49: (1, 127, 0.09547509484755712), 50: (1, 127, 0.09589124338217372), 51: (1, 127, 0.09535786590912915), 52: (1, 127, 0.09532707126620482), 53: (1, 127, 0.09552260272674204), 54: (1, 127, 0.09671719434605104), 55: (1, 127, 0.0960641948828899), 56: (1, 127, 0.09537343474794326), 57: (1, 127, 0.09542847052949854), 58: (1, 127, 0.09539384175619976), 59: (1, 127, 0.0952391120436506), 60: (1, 127, 0.09568153776404426), 61: (1, 127, 0.10092954054533497), 62: (1, 127, 0.09754538449539443), 63: (1, 127, 0.09503849982247344), 64: (1, 127, 0.09502757826864015), 65: (1, 127, 0.09505568198331697), 66: (1, 127, 0.09505945742570275), 67: (1, 127, 0.09510049170367127), 68: (1, 127, 0.09506379957420855), 69: (1, 127, 0.09500312756043015), 70: (1, 127, 0.09512864785840897)}\n",
      "{'predict_runtime': 874.8117, 'predict_samples_per_second': 0.081, 'predict_steps_per_second': 0.081}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:14:34.81\n",
      "  predict_samples_per_second =      0.081\n",
      "  predict_steps_per_second   =      0.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.20714367274194956), 2: (2, 0.1874185735359788), 3: (2, 0.17922057397663593), 4: (2, 0.18898969888687134), 5: (2, 0.17349696066230536), 6: (2, 0.17903190664947033), 7: (2, 0.18838613759726286), 8: (2, 0.17983044777065516), 9: (2, 0.1734321340918541), 10: (2, 0.18587110564112663), 11: (2, 0.17593056429177523), 12: (2, 0.19053123146295547), 13: (2, 0.17385117895901203), 14: (2, 0.1887964028865099), 15: (2, 0.18903146125376225), 16: (2, 0.17600554320961237), 17: (2, 0.17292858008295298), 18: (2, 0.18125011213123798), 19: (2, 0.17869872134178877), 20: (2, 0.18678040709346533), 21: (2, 0.1922463122755289), 22: (2, 0.1873270319774747), 23: (2, 0.17277473211288452), 24: (2, 0.17821494955569506), 25: (2, 0.17533469200134277), 26: (2, 0.17319737747311592), 27: (2, 0.18757196981459856), 28: (2, 0.1811302537098527), 29: (2, 0.1877953466027975), 30: (2, 0.18187052570283413), 31: (2, 0.17463484033942223), 32: (2, 0.18152118008583784), 33: (2, 0.18638429325073957), 34: (2, 0.18587895948439837), 35: (2, 0.18044422287493944), 36: (2, 0.18291725497692823), 37: (2, 0.18822728283703327), 38: (2, 0.1838358137756586), 39: (2, 0.1806421224027872), 40: (2, 0.1875467710196972), 41: (2, 0.174840840511024), 42: (2, 0.18763996101915836), 43: (2, 0.1821806440129876), 44: (2, 0.1846401346847415), 45: (2, 0.1871495433151722), 46: (2, 0.18784161563962698), 47: (2, 0.18603350780904293), 48: (2, 0.19106034841388464), 49: (2, 0.18708117492496967), 50: (2, 0.1875168215483427), 51: (2, 0.17896103207021952), 52: (2, 0.18619962688535452), 53: (2, 0.1919856881722808), 54: (2, 0.1810433268547058), 55: (2, 0.18184339813888073), 56: (2, 0.18154066149145365), 57: (2, 0.17902644164860249), 58: (2, 0.18677958101034164), 59: (2, 0.18446481693536043), 60: (2, 0.18714225571602583), 61: (2, 0.18891230504959822), 62: (2, 0.1882046852260828), 63: (2, 0.18300787545740604), 64: (2, 0.17639797180891037), 65: (2, 0.19005818292498589), 66: (2, 0.18071018159389496), 67: (2, 0.19132419861853123), 68: (2, 0.18915012385696173), 69: (2, 0.19162217434495687), 70: (2, 0.1822978137061), 71: (1, 0.1711743250489235)}\n",
      "{1: (2, 127, 0.14651995360499293), 2: (2, 127, 0.14636516420713325), 3: (2, 127, 0.1463516230555618), 4: (2, 127, 0.1463346105420918), 5: (2, 127, 0.14628539619395348), 6: (2, 127, 0.1463965708169881), 7: (2, 127, 0.14624449980305873), 8: (2, 127, 0.1464783443270002), 9: (2, 127, 0.14638157889217607), 10: (2, 127, 0.14641513758316987), 11: (2, 127, 0.14646565900220881), 12: (2, 127, 0.14618728944929096), 13: (2, 127, 0.1462026720602564), 14: (2, 127, 0.14623047420241703), 15: (2, 127, 0.14643998759410043), 16: (2, 127, 0.14633601625251957), 17: (2, 127, 0.14636921014372758), 18: (2, 127, 0.14636519233747494), 19: (2, 127, 0.14636174856325773), 20: (2, 127, 0.14627520534701235), 21: (2, 127, 0.1462427336267951), 22: (2, 127, 0.1462864559657109), 23: (2, 127, 0.14613765025672715), 24: (2, 127, 0.1462440162046453), 25: (2, 127, 0.146188476012917), 26: (2, 127, 0.14623998881383674), 27: (2, 127, 0.14613405354760997), 28: (2, 127, 0.14617907974546349), 29: (2, 127, 0.146267273763972), 30: (2, 127, 0.1462102727304528), 31: (2, 127, 0.1461253464955279), 32: (2, 127, 0.14610152475271873), 33: (2, 127, 0.1462236075170749), 34: (2, 127, 0.14610726802837193), 35: (2, 127, 0.14620866362504134), 36: (2, 127, 0.146212675887358), 37: (2, 127, 0.14619724025700506), 38: (2, 127, 0.1461400077201602), 39: (2, 127, 0.14614914802057066), 40: (2, 127, 0.146281068301283), 41: (2, 127, 0.14610362204715727), 42: (2, 127, 0.14611025789649937), 43: (2, 127, 0.14625235680696064), 44: (2, 127, 0.1461724000506279), 45: (2, 127, 0.14608977539244833), 46: (2, 127, 0.1461595238780412), 47: (2, 127, 0.1462673327086244), 48: (2, 127, 0.14617524460310072), 49: (2, 127, 0.146178287175286), 50: (2, 127, 0.14622052440669123), 51: (2, 127, 0.14626723978903114), 52: (2, 127, 0.14620279190753857), 53: (2, 127, 0.14613795402921795), 54: (2, 127, 0.14620345759784847), 55: (2, 127, 0.14611980741418254), 56: (2, 127, 0.14620522737473718), 57: (2, 127, 0.1462372498381443), 58: (2, 127, 0.1461567753764588), 59: (2, 127, 0.14618941548273084), 60: (2, 127, 0.14613149609915385), 61: (2, 127, 0.14625228650310612), 62: (2, 127, 0.14614157812068546), 63: (2, 127, 0.146233297847798), 64: (2, 127, 0.14622945460952877), 65: (2, 127, 0.1462526955223811), 66: (2, 127, 0.1461800187459494), 67: (2, 127, 0.14615530118082218), 68: (2, 127, 0.1462583044675861), 69: (2, 127, 0.14613222036745369), 70: (2, 127, 0.14615530750208247)}\n",
      "{'predict_runtime': 1325.1485, 'predict_samples_per_second': 0.106, 'predict_steps_per_second': 0.054}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:05.14\n",
      "  predict_samples_per_second =      0.106\n",
      "  predict_steps_per_second   =      0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.26537852082401514), 2: (4, 0.2250212635844946), 3: (4, 0.22514220234006643), 4: (4, 0.23407994862645864), 5: (4, 0.2342278277501464), 6: (4, 0.23966849315911531), 7: (4, 0.23912984877824783), 8: (4, 0.23418184742331505), 9: (4, 0.2259268844500184), 10: (4, 0.2276700045913458), 11: (4, 0.2395966649055481), 12: (4, 0.2290593283250928), 13: (4, 0.2394970953464508), 14: (4, 0.23065454047173262), 15: (4, 0.22402146644890308), 16: (4, 0.24266282934695482), 17: (4, 0.2245942698791623), 18: (4, 0.22501255758106709), 19: (4, 0.22553004045039415), 20: (4, 0.2249956764280796), 21: (4, 0.22999028954654932), 22: (4, 0.22468448989093304), 23: (4, 0.22740108892321587), 24: (4, 0.22656298894435167), 25: (4, 0.2269983235746622), 26: (4, 0.22486745938658714), 27: (4, 0.2271181521937251), 28: (4, 0.22563411016017199), 29: (4, 0.22765523567795753), 30: (4, 0.24022470973432064), 31: (4, 0.22688676603138447), 32: (4, 0.22921082843095064), 33: (4, 0.22735668066889048), 34: (4, 0.22785911429673433), 35: (4, 0.228659275919199), 36: (4, 0.22744059935212135), 37: (4, 0.23227896355092525), 38: (4, 0.2400180334225297), 39: (4, 0.23283718805760145), 40: (4, 0.2261609248816967), 41: (4, 0.22738001123070717), 42: (4, 0.22763820830732584), 43: (4, 0.22628264408558607), 44: (4, 0.2290177522227168), 45: (4, 0.22489925101399422), 46: (4, 0.2284988285973668), 47: (4, 0.22723415400832891), 48: (4, 0.22861798852682114), 49: (4, 0.2265184624120593), 50: (4, 0.22876576613634825), 51: (4, 0.22705936711281538), 52: (4, 0.23174097109586), 53: (4, 0.22636082489043474), 54: (4, 0.24199465196579695), 55: (4, 0.22745891101658344), 56: (4, 0.22908678278326988), 57: (4, 0.22830223198980093), 58: (4, 0.22767100855708122), 59: (4, 0.22752624098211527), 60: (4, 0.22803151607513428), 61: (4, 0.23073374386876822), 62: (4, 0.23354392126202583), 63: (4, 0.226001700386405), 64: (4, 0.2267318917438388), 65: (4, 0.2295989179983735), 66: (4, 0.22486830409616232), 67: (4, 0.22582439240068197), 68: (4, 0.23048747889697552), 69: (4, 0.23104900121688843), 70: (4, 0.23798647057265043), 71: (1, 0.16053251549601555)}\n",
      "{1: (4, 127, 0.14662234777012678), 2: (4, 127, 0.14641955559413264), 3: (4, 127, 0.14638679716589414), 4: (4, 127, 0.14639567454000862), 5: (4, 127, 0.14644772977399545), 6: (4, 127, 0.14631107657795817), 7: (4, 127, 0.146361460337254), 8: (4, 127, 0.14644337834893015), 9: (4, 127, 0.14641390775337698), 10: (4, 127, 0.1463049454174525), 11: (4, 127, 0.14644866255588654), 12: (4, 127, 0.14636051989945137), 13: (4, 127, 0.14639240504044482), 14: (4, 127, 0.14646275232978692), 15: (4, 127, 0.14638627874921625), 16: (4, 127, 0.1463862567788034), 17: (4, 127, 0.1464910413043236), 18: (4, 127, 0.14651163657173866), 19: (4, 127, 0.14644613884037405), 20: (4, 127, 0.14648883243450733), 21: (4, 127, 0.14648065300966343), 22: (4, 127, 0.14644185937647744), 23: (4, 127, 0.14643140342526548), 24: (4, 127, 0.14628765480519515), 25: (4, 127, 0.14643932073047078), 26: (4, 127, 0.1464446162746295), 27: (4, 127, 0.14638441847270633), 28: (4, 127, 0.14626990768354475), 29: (4, 127, 0.14634257880604173), 30: (4, 127, 0.14629357409348168), 31: (4, 127, 0.14632498325530705), 32: (4, 127, 0.1464242855541584), 33: (4, 127, 0.14638753338738925), 34: (4, 127, 0.14633963457272042), 35: (4, 127, 0.1465029481754411), 36: (4, 127, 0.14629707128308186), 37: (4, 127, 0.14635513997160074), 38: (4, 127, 0.14635278164284435), 39: (4, 127, 0.14637637246165455), 40: (4, 127, 0.1463932133697736), 41: (4, 127, 0.14641703230394856), 42: (4, 127, 0.14639229478505184), 43: (4, 127, 0.1464208859480976), 44: (4, 127, 0.14644230394734173), 45: (4, 127, 0.14639519331756773), 46: (4, 127, 0.14641827808355723), 47: (4, 127, 0.14638308753208149), 48: (4, 127, 0.14632274846979013), 49: (4, 127, 0.1463562774391273), 50: (4, 127, 0.14633769623377896), 51: (4, 127, 0.1463898515152767), 52: (4, 127, 0.14636903663906525), 53: (4, 127, 0.1462888455194399), 54: (4, 127, 0.14629143626817803), 55: (4, 127, 0.1463147006400927), 56: (4, 127, 0.14631755129382837), 57: (4, 127, 0.1464617665358416), 58: (4, 127, 0.14636049353642258), 59: (4, 127, 0.1464560217715389), 60: (4, 127, 0.14642821161413755), 61: (4, 127, 0.1463876057812196), 62: (4, 127, 0.14647902437581087), 63: (4, 127, 0.14635083303002155), 64: (4, 127, 0.1463526314212464), 65: (4, 127, 0.14643375967137925), 66: (4, 127, 0.14632652036288357), 67: (4, 127, 0.14640794466359644), 68: (4, 127, 0.14627275206735285), 69: (4, 127, 0.14630067842007857), 70: (4, 127, 0.1463359651544432)}\n",
      "{'predict_runtime': 1329.7434, 'predict_samples_per_second': 0.211, 'predict_steps_per_second': 0.053}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:09.74\n",
      "  predict_samples_per_second =      0.211\n",
      "  predict_steps_per_second   =      0.053\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 18\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.20610681269317865), 2: (1, 0.16825824417173862), 3: (1, 0.16805069707334042), 4: (1, 0.16798446793109179), 5: (1, 0.16986650601029396), 6: (1, 0.16887380834668875), 7: (1, 0.16807089652866125), 8: (1, 0.17063544783741236), 9: (1, 0.1711119618266821), 10: (1, 0.16982787661254406), 11: (1, 0.1698196278885007), 12: (1, 0.1709224432706833), 13: (1, 0.16966769006103277), 14: (1, 0.16932388301938772), 15: (1, 0.17063205875456333), 16: (1, 0.1683410657569766), 17: (1, 0.1702377013862133), 18: (1, 0.16796995885670185), 19: (1, 0.16826981585472822), 20: (1, 0.16776140220463276), 21: (1, 0.17087972536683083), 22: (1, 0.16840906534343958), 23: (1, 0.1715998975560069), 24: (1, 0.1703368304297328), 25: (1, 0.16974466759711504), 26: (1, 0.16908853687345982), 27: (1, 0.169741234742105), 28: (1, 0.1678705783560872), 29: (1, 0.16871221829205751), 30: (1, 0.16822176426649094), 31: (1, 0.16774621047079563), 32: (1, 0.16760656144469976), 33: (1, 0.1706617558375001), 34: (1, 0.17089603282511234), 35: (1, 0.17234441544860601), 36: (1, 0.17029393836855888), 37: (1, 0.17056547664105892), 38: (1, 0.16833977214992046), 39: (1, 0.17398243583738804), 40: (1, 0.1688907165080309), 41: (1, 0.16923377197235823), 42: (1, 0.17027314938604832), 43: (1, 0.1707416446879506), 44: (1, 0.16835609264671803), 45: (1, 0.16845829039812088), 46: (1, 0.1691967835649848), 47: (1, 0.17119809053838253), 48: (1, 0.17075888440012932), 49: (1, 0.1697236867621541), 50: (1, 0.1706708762794733), 51: (1, 0.17087435349822044), 52: (1, 0.16931788064539433), 53: (1, 0.17008590418845415), 54: (1, 0.169910185970366), 55: (1, 0.16932563204318285), 56: (1, 0.1678565200418234), 57: (1, 0.16960523836314678), 58: (1, 0.1681353459134698), 59: (1, 0.17002758476883173), 60: (1, 0.17053890880197287), 61: (1, 0.16815421730279922), 62: (1, 0.1692274548113346), 63: (1, 0.16913552582263947), 64: (1, 0.16897617746144533), 65: (1, 0.17109968233853579), 66: (1, 0.16852072346955538), 67: (1, 0.16982006840407848), 68: (1, 0.1710560042411089), 69: (1, 0.17069742735475302), 70: (1, 0.17005898617208004), 71: (1, 0.16931902524083853)}\n",
      "{1: (1, 127, 0.10044773943780914), 2: (1, 127, 0.10042530256433516), 3: (1, 127, 0.10024765309855693), 4: (1, 127, 0.10031614775263419), 5: (1, 127, 0.1003245874491381), 6: (1, 127, 0.10032726728951367), 7: (1, 127, 0.10025988354193648), 8: (1, 127, 0.10025505086509731), 9: (1, 127, 0.10024448630114005), 10: (1, 127, 0.10017967290853656), 11: (1, 127, 0.10033202942783438), 12: (1, 127, 0.10033355400288903), 13: (1, 127, 0.10029164082040702), 14: (1, 127, 0.10024166245776134), 15: (1, 127, 0.10018357307481485), 16: (1, 127, 0.10024548428294462), 17: (1, 127, 0.1002542361045095), 18: (1, 127, 0.10022701730761002), 19: (1, 127, 0.1002497139247501), 20: (1, 127, 0.10027464460141546), 21: (1, 127, 0.1002048309599086), 22: (1, 127, 0.10021154066239756), 23: (1, 127, 0.10024230877362837), 24: (1, 127, 0.1002260015940103), 25: (1, 127, 0.10010995107930241), 26: (1, 127, 0.10013043923728814), 27: (1, 127, 0.10010293736232548), 28: (1, 127, 0.10015347343319514), 29: (1, 127, 0.10011684786029688), 30: (1, 127, 0.1000704081567723), 31: (1, 127, 0.10010368214905496), 32: (1, 127, 0.10007429420654698), 33: (1, 127, 0.10017527834930288), 34: (1, 127, 0.10018496648738469), 35: (1, 127, 0.10018019476450804), 36: (1, 127, 0.10016930770627626), 37: (1, 127, 0.10016037794343365), 38: (1, 127, 0.10010765902844705), 39: (1, 127, 0.10010800152049056), 40: (1, 127, 0.10018149275684685), 41: (1, 127, 0.10014048235593584), 42: (1, 127, 0.10024324552280696), 43: (1, 127, 0.10010377116735995), 44: (1, 127, 0.10015555834177677), 45: (1, 127, 0.1001173638863357), 46: (1, 127, 0.10084599009385024), 47: (1, 127, 0.1005824702887202), 48: (1, 127, 0.10043544563516153), 49: (1, 127, 0.10046031988247878), 50: (1, 127, 0.10048611404916902), 51: (1, 127, 0.10037221664225492), 52: (1, 127, 0.10031553279373824), 53: (1, 127, 0.10037898863335763), 54: (1, 127, 0.10038952163501283), 55: (1, 127, 0.10038271192901248), 56: (1, 127, 0.10031553262507352), 57: (1, 127, 0.10030627082739993), 58: (1, 127, 0.10028191116880479), 59: (1, 127, 0.10026637156031967), 60: (1, 127, 0.10041582448716004), 61: (1, 127, 0.10048195100059425), 62: (1, 127, 0.10039448563566827), 63: (1, 127, 0.10034284891018014), 64: (1, 127, 0.1003438306048395), 65: (1, 127, 0.10031171481117723), 66: (1, 127, 0.10030489730260034), 67: (1, 127, 0.10030153952538967), 68: (1, 127, 0.10031606838488438), 69: (1, 127, 0.1003394901283144), 70: (1, 127, 0.10024658159360172)}\n",
      "{'predict_runtime': 916.2428, 'predict_samples_per_second': 0.077, 'predict_steps_per_second': 0.077}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:16.24\n",
      "  predict_samples_per_second =      0.077\n",
      "  predict_steps_per_second   =      0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.21010807063430548), 2: (2, 0.19018327724188566), 3: (2, 0.19708330556750298), 4: (2, 0.19084504898637533), 5: (2, 0.18130044173449278), 6: (2, 0.19870746694505215), 7: (2, 0.1962753450497985), 8: (2, 0.19644655473530293), 9: (2, 0.1969536980614066), 10: (2, 0.19620978739112616), 11: (2, 0.18045330327004194), 12: (2, 0.1958945905789733), 13: (2, 0.19116093777120113), 14: (2, 0.18150816578418016), 15: (2, 0.18636527843773365), 16: (2, 0.19670426566153765), 17: (2, 0.19752348493784666), 18: (2, 0.18342042434960604), 19: (2, 0.19853263441473246), 20: (2, 0.1888241907581687), 21: (2, 0.1869518244639039), 22: (2, 0.19391516037285328), 23: (2, 0.18916994892060757), 24: (2, 0.1976939281448722), 25: (2, 0.18758156895637512), 26: (2, 0.18300772551447153), 27: (2, 0.18383485544472933), 28: (2, 0.19642051588743925), 29: (2, 0.1861435091122985), 30: (2, 0.1920901881530881), 31: (2, 0.18396293558180332), 32: (2, 0.20170909445732832), 33: (2, 0.1888322876766324), 34: (2, 0.18818161729723215), 35: (2, 0.1969859516248107), 36: (2, 0.19637188874185085), 37: (2, 0.20163032785058022), 38: (2, 0.19887322187423706), 39: (2, 0.1971448427066207), 40: (2, 0.1920353239402175), 41: (2, 0.18307455070316792), 42: (2, 0.18570152949541807), 43: (2, 0.20240251068025827), 44: (2, 0.1974144820123911), 45: (2, 0.19334189128130674), 46: (2, 0.19753524102270603), 47: (2, 0.18941487930715084), 48: (2, 0.19731295481324196), 49: (2, 0.18440870754420757), 50: (2, 0.19743149355053902), 51: (2, 0.19750969391316175), 52: (2, 0.19847717229276896), 53: (2, 0.1944349016994238), 54: (2, 0.20098846312612295), 55: (2, 0.1908733444288373), 56: (2, 0.1982139078900218), 57: (2, 0.202304869890213), 58: (2, 0.1963463705033064), 59: (2, 0.19865777343511581), 60: (2, 0.19824185874313116), 61: (2, 0.18096062634140253), 62: (2, 0.1917386967688799), 63: (2, 0.19793381355702877), 64: (2, 0.1964386934414506), 65: (2, 0.1931916307657957), 66: (2, 0.19239532109349966), 67: (2, 0.1971475537866354), 68: (2, 0.1976058604195714), 69: (2, 0.18986992351710796), 70: (2, 0.1974502131342888), 71: (1, 0.1835309285670519)}\n",
      "{1: (2, 127, 0.15409231647907748), 2: (2, 127, 0.15407369359887726), 3: (2, 127, 0.15409144012653453), 4: (2, 127, 0.15407315425310783), 5: (2, 127, 0.15400444455151482), 6: (2, 127, 0.1541349002138132), 7: (2, 127, 0.15401915421958748), 8: (2, 127, 0.15404311838875137), 9: (2, 127, 0.15405725841740453), 10: (2, 127, 0.15413773144910656), 11: (2, 127, 0.15401136061895315), 12: (2, 127, 0.15399053601885404), 13: (2, 127, 0.1541375599024216), 14: (2, 127, 0.15426932056031123), 15: (2, 127, 0.1541026192093928), 16: (2, 127, 0.15415112890567131), 17: (2, 127, 0.1541528678902491), 18: (2, 127, 0.15415360719904186), 19: (2, 127, 0.15414830388897283), 20: (2, 127, 0.15413673956123158), 21: (2, 127, 0.15415243686389501), 22: (2, 127, 0.15419471651081026), 23: (2, 127, 0.15413787175615237), 24: (2, 127, 0.15411109491214742), 25: (2, 127, 0.15411161127551568), 26: (2, 127, 0.1542400850687088), 27: (2, 127, 0.1541875676493945), 28: (2, 127, 0.15420940485379592), 29: (2, 127, 0.15413015120200754), 30: (2, 127, 0.15423344663806318), 31: (2, 127, 0.15421057152231848), 32: (2, 127, 0.1541420860788015), 33: (2, 127, 0.15411635610736965), 34: (2, 127, 0.154258068298965), 35: (2, 127, 0.15407420235033345), 36: (2, 127, 0.15410585166871782), 37: (2, 127, 0.15418075079347673), 38: (2, 127, 0.1541978875248451), 39: (2, 127, 0.15414011209293849), 40: (2, 127, 0.1542647304526699), 41: (2, 127, 0.1542085487776854), 42: (2, 127, 0.15416778295528233), 43: (2, 127, 0.15414904830170664), 44: (2, 127, 0.15423822603151788), 45: (2, 127, 0.15430509853433436), 46: (2, 127, 0.15411459023910246), 47: (2, 127, 0.15418436230108964), 48: (2, 127, 0.15423242942848076), 49: (2, 127, 0.15429413355300275), 50: (2, 127, 0.15411723791584958), 51: (2, 127, 0.1541382232974247), 52: (2, 127, 0.15418986311754374), 53: (2, 127, 0.15416805719678092), 54: (2, 127, 0.15411215246926377), 55: (2, 127, 0.1541026291459447), 56: (2, 127, 0.15420150885901113), 57: (2, 127, 0.15405671998095793), 58: (2, 127, 0.15407640693753255), 59: (2, 127, 0.15415457460853293), 60: (2, 127, 0.1542301959189491), 61: (2, 127, 0.15416442608739447), 62: (2, 127, 0.15407418710450957), 63: (2, 127, 0.15420796841705645), 64: (2, 127, 0.15417747658596734), 65: (2, 127, 0.15410642932337804), 66: (2, 127, 0.15421607281543373), 67: (2, 127, 0.1541025446375876), 68: (2, 127, 0.15420874634273643), 69: (2, 127, 0.15411266346469404), 70: (2, 127, 0.1541691044286832)}\n",
      "{'predict_runtime': 1396.8466, 'predict_samples_per_second': 0.101, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:16.84\n",
      "  predict_samples_per_second =      0.101\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.2675000103190541), 2: (4, 0.24263057671487331), 3: (4, 0.24252091813832521), 4: (4, 0.23575415834784508), 5: (4, 0.23904648050665855), 6: (4, 0.2370853340253234), 7: (4, 0.2390799606218934), 8: (4, 0.23887583427131176), 9: (4, 0.2380993841215968), 10: (4, 0.2386450869962573), 11: (4, 0.2405476365238428), 12: (4, 0.23740407265722752), 13: (4, 0.23769549932330847), 14: (4, 0.23749880958348513), 15: (4, 0.24107566941529512), 16: (4, 0.23960464727133512), 17: (4, 0.23960105702280998), 18: (4, 0.23579629324376583), 19: (4, 0.23643470648676157), 20: (4, 0.23825951479375362), 21: (4, 0.23871643003076315), 22: (4, 0.23715987894684076), 23: (4, 0.23821565695106983), 24: (4, 0.23850535415112972), 25: (4, 0.23745326697826385), 26: (4, 0.24033456295728683), 27: (4, 0.23938597366213799), 28: (4, 0.2405391512438655), 29: (4, 0.23893368151038885), 30: (4, 0.23880939278751612), 31: (4, 0.23866753466427326), 32: (4, 0.2412248943001032), 33: (4, 0.23803159315139055), 34: (4, 0.24213122483342886), 35: (4, 0.23676757887005806), 36: (4, 0.2389641534537077), 37: (4, 0.23806361388415098), 38: (4, 0.23602357879281044), 39: (4, 0.23754851147532463), 40: (4, 0.23790788743644953), 41: (4, 0.24110565055161715), 42: (4, 0.23941208980977535), 43: (4, 0.2396609978750348), 44: (4, 0.24100233241915703), 45: (4, 0.2366826143115759), 46: (4, 0.2366772349923849), 47: (4, 0.23992284666746855), 48: (4, 0.23725649900734425), 49: (4, 0.23713443707674742), 50: (4, 0.2393000116571784), 51: (4, 0.23978418670594692), 52: (4, 0.23789541888982058), 53: (4, 0.24120914097875357), 54: (4, 0.23724212776869535), 55: (4, 0.24042631033807993), 56: (4, 0.23705305997282267), 57: (4, 0.23666056524962187), 58: (4, 0.2386400531977415), 59: (4, 0.23798767011612654), 60: (4, 0.24054375104606152), 61: (4, 0.23968834150582552), 62: (4, 0.2388654099777341), 63: (4, 0.23598786536604166), 64: (4, 0.23861285392194986), 65: (4, 0.23863228410482407), 66: (4, 0.24064556043595076), 67: (4, 0.23937450628727674), 68: (4, 0.2423695707693696), 69: (4, 0.23935315664857626), 70: (4, 0.23837800789624453), 71: (1, 0.1702205017209053)}\n",
      "{1: (4, 127, 0.15489534334110933), 2: (4, 127, 0.15470208018636844), 3: (4, 127, 0.1547951693829941), 4: (4, 127, 0.15466403705251264), 5: (4, 127, 0.15460911192234575), 6: (4, 127, 0.1547737303299932), 7: (4, 127, 0.15464719156844645), 8: (4, 127, 0.1546133268023218), 9: (4, 127, 0.15468480088198044), 10: (4, 127, 0.1546015324525711), 11: (4, 127, 0.1547105224568426), 12: (4, 127, 0.15465917342203103), 13: (4, 127, 0.15465525643328043), 14: (4, 127, 0.15465119203156608), 15: (4, 127, 0.15470884710286312), 16: (4, 127, 0.15470678153939135), 17: (4, 127, 0.1547601809065173), 18: (4, 127, 0.154642698824347), 19: (4, 127, 0.15470795324585568), 20: (4, 127, 0.1545878407200725), 21: (4, 127, 0.1546351329797483), 22: (4, 127, 0.15468955058311148), 23: (4, 127, 0.15453077480930277), 24: (4, 127, 0.15450040192350628), 25: (4, 127, 0.15463086231575002), 26: (4, 127, 0.15454264475751345), 27: (4, 127, 0.15445794872059596), 28: (4, 127, 0.15455934488192552), 29: (4, 127, 0.15449670053959833), 30: (4, 127, 0.15446822919450173), 31: (4, 127, 0.1545421012611253), 32: (4, 127, 0.15463580452199058), 33: (4, 127, 0.15443984782103243), 34: (4, 127, 0.15450399731997194), 35: (4, 127, 0.1544988329236315), 36: (4, 127, 0.1545411810997551), 37: (4, 127, 0.1546941413654117), 38: (4, 127, 0.1546850362792611), 39: (4, 127, 0.15458275279484865), 40: (4, 127, 0.15459903812138584), 41: (4, 127, 0.15461757609723356), 42: (4, 127, 0.15462645490866478), 43: (4, 127, 0.15464350108174593), 44: (4, 127, 0.15450279543718953), 45: (4, 127, 0.15445323484238443), 46: (4, 127, 0.15450374549621437), 47: (4, 127, 0.1544984231196989), 48: (4, 127, 0.15457498501458272), 49: (4, 127, 0.15452574952468862), 50: (4, 127, 0.15451223709745202), 51: (4, 127, 0.15444699159317363), 52: (4, 127, 0.15453208358885032), 53: (4, 127, 0.15453723732264726), 54: (4, 127, 0.15455709198328454), 55: (4, 127, 0.1546318153667403), 56: (4, 127, 0.1545945032184401), 57: (4, 127, 0.15450389169185885), 58: (4, 127, 0.15442622040845747), 59: (4, 127, 0.15455522337620417), 60: (4, 127, 0.15458167598062145), 61: (4, 127, 0.1544159666862427), 62: (4, 127, 0.15432948840591382), 63: (4, 127, 0.15434248211580937), 64: (4, 127, 0.15439170090056312), 65: (4, 127, 0.15436490444745135), 66: (4, 127, 0.15448282334924213), 67: (4, 127, 0.15426506583879548), 68: (4, 127, 0.15441715411519205), 69: (4, 127, 0.15427033867188325), 70: (4, 127, 0.15440128798647892)}\n",
      "{'predict_runtime': 1403.718, 'predict_samples_per_second': 0.2, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:23.71\n",
      "  predict_samples_per_second =        0.2\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 19\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3074381733313203), 2: (1, 0.27840956673026085), 3: (1, 0.27737652882933617), 4: (1, 0.2802219558507204), 5: (1, 0.27732650004327297), 6: (1, 0.28219594340771437), 7: (1, 0.2786823147907853), 8: (1, 0.28006490878760815), 9: (1, 0.2810503775253892), 10: (1, 0.2778486851602793), 11: (1, 0.2790795909240842), 12: (1, 0.2779699945822358), 13: (1, 0.2804683046415448), 14: (1, 0.27717018499970436), 15: (1, 0.27779985684901476), 16: (1, 0.277678188867867), 17: (1, 0.2782502919435501), 18: (1, 0.27796976547688246), 19: (1, 0.2768449503928423), 20: (1, 0.27703923638910055), 21: (1, 0.2798719136044383), 22: (1, 0.2772672660648823), 23: (1, 0.2780228164047003), 24: (1, 0.2773802438750863), 25: (1, 0.2762337988242507), 26: (1, 0.28047757782042027), 27: (1, 0.28101399168372154), 28: (1, 0.28070626594126225), 29: (1, 0.28081414569169283), 30: (1, 0.2817734098061919), 31: (1, 0.27703473623842), 32: (1, 0.2811663867905736), 33: (1, 0.2803946966305375), 34: (1, 0.27932094782590866), 35: (1, 0.2810931075364351), 36: (1, 0.278592336922884), 37: (1, 0.2796211149543524), 38: (1, 0.27709979470819235), 39: (1, 0.28127435594797134), 40: (1, 0.28190141916275024), 41: (1, 0.27759829815477133), 42: (1, 0.2818430792540312), 43: (1, 0.28118110727518797), 44: (1, 0.27865438628941774), 45: (1, 0.27910276129841805), 46: (1, 0.2783285593613982), 47: (1, 0.2783933887258172), 48: (1, 0.2807484418153763), 49: (1, 0.28009628877043724), 50: (1, 0.28105712682008743), 51: (1, 0.2789830816909671), 52: (1, 0.2793643279001117), 53: (1, 0.28046221379190683), 54: (1, 0.28108905628323555), 55: (1, 0.28056897316128016), 56: (1, 0.2801133692264557), 57: (1, 0.2797696525231004), 58: (1, 0.277214421890676), 59: (1, 0.27744053956121206), 60: (1, 0.27805287204682827), 61: (1, 0.27793982345610857), 62: (1, 0.27779272478073835), 63: (1, 0.2765191597864032), 64: (1, 0.27627391275018454), 65: (1, 0.2807393195107579), 66: (1, 0.28217250388115644), 67: (1, 0.2818805268034339), 68: (1, 0.2815886000171304), 69: (1, 0.28068501129746437), 70: (1, 0.28120600432157516), 71: (1, 0.27738569863140583)}\n",
      "{1: (1, 127, 0.16678293742327474), 2: (1, 127, 0.16674345576270358), 3: (1, 127, 0.16652820043735148), 4: (1, 127, 0.1665530658114379), 5: (1, 127, 0.16635156535052173), 6: (1, 127, 0.16642021171484642), 7: (1, 127, 0.16631382469850498), 8: (1, 127, 0.1661913862129248), 9: (1, 127, 0.16633720417308995), 10: (1, 127, 0.16650227222620972), 11: (1, 127, 0.16649605687267668), 12: (1, 127, 0.16646820386710365), 13: (1, 127, 0.16636890401022406), 14: (1, 127, 0.16634838879255093), 15: (1, 127, 0.16640453285530327), 16: (1, 127, 0.16650812239862803), 17: (1, 127, 0.16652819939603017), 18: (1, 127, 0.1664594393956849), 19: (1, 127, 0.16646714086138356), 20: (1, 127, 0.16648607691529932), 21: (1, 127, 0.16641935878469954), 22: (1, 127, 0.1666145485011846), 23: (1, 127, 0.16639366005290682), 24: (1, 127, 0.1665411064782598), 25: (1, 127, 0.16628243910574067), 26: (1, 127, 0.16634055257107563), 27: (1, 127, 0.16625752532488014), 28: (1, 127, 0.1663595879318442), 29: (1, 127, 0.16621809537837826), 30: (1, 127, 0.16636240716994277), 31: (1, 127, 0.16630279916653953), 32: (1, 127, 0.16647222006004156), 33: (1, 127, 0.1663911143596482), 34: (1, 127, 0.16649682049118864), 35: (1, 127, 0.16656974321744572), 36: (1, 127, 0.16648732587020462), 37: (1, 127, 0.16640471766783496), 38: (1, 127, 0.16651369604157415), 39: (1, 127, 0.16692997247537994), 40: (1, 127, 0.16753077432219907), 41: (1, 127, 0.16696471043341743), 42: (1, 127, 0.16700896065623508), 43: (1, 127, 0.16696274092816932), 44: (1, 127, 0.16684326283105716), 45: (1, 127, 0.16671651704456864), 46: (1, 127, 0.16675313721286264), 47: (1, 127, 0.16667304850938752), 48: (1, 127, 0.16674556053705572), 49: (1, 127, 0.1666336178808935), 50: (1, 127, 0.16669728953801977), 51: (1, 127, 0.16663772194081639), 52: (1, 127, 0.1666306160009048), 53: (1, 127, 0.1669495399660013), 54: (1, 127, 0.16699304973603937), 55: (1, 127, 0.16654356299188194), 56: (1, 127, 0.16646085982394265), 57: (1, 127, 0.16641504835982726), 58: (1, 127, 0.16641978458244736), 59: (1, 127, 0.16666083385449226), 60: (1, 127, 0.16638687876324484), 61: (1, 127, 0.1663886507621079), 62: (1, 127, 0.16638474527189112), 63: (1, 127, 0.16647408710513997), 64: (1, 127, 0.16702278035392207), 65: (1, 127, 0.16668119927589584), 66: (1, 127, 0.16635740374574276), 67: (1, 127, 0.16625501238190987), 68: (1, 127, 0.1660648668698204), 69: (1, 127, 0.16602650618429962), 70: (1, 127, 0.16638030943380097)}\n",
      "{'predict_runtime': 1521.4173, 'predict_samples_per_second': 0.047, 'predict_steps_per_second': 0.047}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:21.41\n",
      "  predict_samples_per_second =      0.047\n",
      "  predict_steps_per_second   =      0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.32872863858938217), 2: (2, 0.32942493073642254), 3: (2, 0.3027508230879903), 4: (2, 0.32266929000616074), 5: (2, 0.298806918784976), 6: (2, 0.3239862946793437), 7: (2, 0.3041100865229964), 8: (2, 0.30308521911501884), 9: (2, 0.3260568007826805), 10: (2, 0.32209230680018663), 11: (2, 0.2993621714413166), 12: (2, 0.3226648988202214), 13: (2, 0.3049417156726122), 14: (2, 0.30097389314323664), 15: (2, 0.3070409009233117), 16: (2, 0.32336366083472967), 17: (2, 0.3252760889008641), 18: (2, 0.3236749777570367), 19: (2, 0.30263273138552904), 20: (2, 0.30232786759734154), 21: (2, 0.32263586949557066), 22: (2, 0.3242902597412467), 23: (2, 0.3236806560307741), 24: (2, 0.31796111445873976), 25: (2, 0.3177046366035938), 26: (2, 0.3030831776559353), 27: (2, 0.3063454497605562), 28: (2, 0.30161015409976244), 29: (2, 0.32902184408158064), 30: (2, 0.32598298974335194), 31: (2, 0.31637322157621384), 32: (2, 0.3205661131069064), 33: (2, 0.3228447958827019), 34: (2, 0.32695283833891153), 35: (2, 0.3229835145175457), 36: (2, 0.3257678607478738), 37: (2, 0.32258107885718346), 38: (2, 0.30863024573773146), 39: (2, 0.3235069625079632), 40: (2, 0.3266195273026824), 41: (2, 0.32287906017154455), 42: (2, 0.32739029731601477), 43: (2, 0.3224985236302018), 44: (2, 0.3089442802593112), 45: (2, 0.32325196359306574), 46: (2, 0.3276211228221655), 47: (2, 0.323282552883029), 48: (2, 0.3279539383947849), 49: (2, 0.30085950065404177), 50: (2, 0.3047248860821128), 51: (2, 0.3270006887614727), 52: (2, 0.3251286391168833), 53: (2, 0.3165511693805456), 54: (2, 0.32512941863387823), 55: (2, 0.32229889184236526), 56: (2, 0.3252318277955055), 57: (2, 0.3159493859857321), 58: (2, 0.3011993896216154), 59: (2, 0.3164965398609638), 60: (2, 0.32504414953291416), 61: (2, 0.30310836527496576), 62: (2, 0.3253642460331321), 63: (2, 0.32344308868050575), 64: (2, 0.3169932132586837), 65: (2, 0.31777065340429544), 66: (2, 0.30775241181254387), 67: (2, 0.3236501747742295), 68: (2, 0.32328633964061737), 69: (2, 0.323728415183723), 70: (2, 0.3034903407096863), 71: (1, 0.30231835413724184)}\n",
      "{1: (2, 127, 0.2573549170413707), 2: (2, 127, 0.2573600075552313), 3: (2, 127, 0.25726129477623644), 4: (2, 127, 0.25710067102377576), 5: (2, 127, 0.2573031823656808), 6: (2, 127, 0.2572034386712618), 7: (2, 127, 0.2570466907606937), 8: (2, 127, 0.2569676389492403), 9: (2, 127, 0.25715559756192635), 10: (2, 127, 0.2572012713882984), 11: (2, 127, 0.25740672414022403), 12: (2, 127, 0.2575292714805467), 13: (2, 127, 0.2576533384753142), 14: (2, 127, 0.2572750577219124), 15: (2, 127, 0.2572975905729443), 16: (2, 127, 0.2571155981446697), 17: (2, 127, 0.25738431425310493), 18: (2, 127, 0.2570774400034758), 19: (2, 127, 0.25728898913430887), 20: (2, 127, 0.2570150014981041), 21: (2, 127, 0.25720676267886255), 22: (2, 127, 0.25702583184099104), 23: (2, 127, 0.25706024548610834), 24: (2, 127, 0.2570421243174456), 25: (2, 127, 0.2571736371481982), 26: (2, 127, 0.2571766029706034), 27: (2, 127, 0.25723251440804307), 28: (2, 127, 0.25707252726222823), 29: (2, 127, 0.2572982218263187), 30: (2, 127, 0.25699101467653523), 31: (2, 127, 0.2573105080610537), 32: (2, 127, 0.2569376754567144), 33: (2, 127, 0.2571310376469779), 34: (2, 127, 0.25702361390727946), 35: (2, 127, 0.2572995320651827), 36: (2, 127, 0.2571079782833617), 37: (2, 127, 0.25724221174935186), 38: (2, 127, 0.2572514952241084), 39: (2, 127, 0.2572333440477923), 40: (2, 127, 0.2571251393464489), 41: (2, 127, 0.2572002132298557), 42: (2, 127, 0.2570896889706414), 43: (2, 127, 0.257282330962558), 44: (2, 127, 0.257104988114571), 45: (2, 127, 0.25713676433482274), 46: (2, 127, 0.2571711203919386), 47: (2, 127, 0.2572552990021668), 48: (2, 127, 0.2571950042766966), 49: (2, 127, 0.25731544642467197), 50: (2, 127, 0.2571733693379586), 51: (2, 127, 0.2569829972284868), 52: (2, 127, 0.25709353338956364), 53: (2, 127, 0.2570031714134329), 54: (2, 127, 0.2569758152501203), 55: (2, 127, 0.2570638188094957), 56: (2, 127, 0.25709435345942344), 57: (2, 127, 0.25713740904470833), 58: (2, 127, 0.2570686269712847), 59: (2, 127, 0.257021659699188), 60: (2, 127, 0.2571664368660431), 61: (2, 127, 0.25701287215736907), 62: (2, 127, 0.2571486921056988), 63: (2, 127, 0.25678912799541403), 64: (2, 127, 0.2568388730507549), 65: (2, 127, 0.25684115960167386), 66: (2, 127, 0.2569143447702325), 67: (2, 127, 0.2568926865704299), 68: (2, 127, 0.25700893627817), 69: (2, 127, 0.2568484502441184), 70: (2, 127, 0.2570166429651417)}\n",
      "{'predict_runtime': 2329.623, 'predict_samples_per_second': 0.061, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:49.62\n",
      "  predict_samples_per_second =      0.061\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.42324731405824423), 2: (4, 0.3935899203643203), 3: (4, 0.391702001914382), 4: (4, 0.4205540744587779), 5: (4, 0.39321782533079386), 6: (4, 0.3952034404501319), 7: (4, 0.3945047101005912), 8: (4, 0.39524916000664234), 9: (4, 0.3933878717944026), 10: (4, 0.39695653039962053), 11: (4, 0.39190019853413105), 12: (4, 0.393091406673193), 13: (4, 0.39101423881947994), 14: (4, 0.39300166722387075), 15: (4, 0.40751095674932003), 16: (4, 0.39767879247665405), 17: (4, 0.3950996920466423), 18: (4, 0.40970592107623816), 19: (4, 0.39379054587334394), 20: (4, 0.3937231069430709), 21: (4, 0.4142447682097554), 22: (4, 0.4001123830676079), 23: (4, 0.397336364723742), 24: (4, 0.3891590693965554), 25: (4, 0.3973309453576803), 26: (4, 0.3901119390502572), 27: (4, 0.3990820348262787), 28: (4, 0.3940319335088134), 29: (4, 0.39600239135324955), 30: (4, 0.4178751949220896), 31: (4, 0.3898301627486944), 32: (4, 0.3971547381952405), 33: (4, 0.39285427052527666), 34: (4, 0.3954945793375373), 35: (4, 0.3977244636043906), 36: (4, 0.39772527292370796), 37: (4, 0.3986858632415533), 38: (4, 0.39846689719706774), 39: (4, 0.39571363013237715), 40: (4, 0.39212771225720644), 41: (4, 0.3985391780734062), 42: (4, 0.39526898693293333), 43: (4, 0.3950638798996806), 44: (4, 0.3980385847389698), 45: (4, 0.3965505938977003), 46: (4, 0.39483949448913336), 47: (4, 0.39420752227306366), 48: (4, 0.4038053788244724), 49: (4, 0.3944923700764775), 50: (4, 0.3935949606820941), 51: (4, 0.3981423396617174), 52: (4, 0.39409614633768797), 53: (4, 0.40056509990245104), 54: (4, 0.4174286527559161), 55: (4, 0.39669245667755604), 56: (4, 0.39726133085787296), 57: (4, 0.41140938457101583), 58: (4, 0.39852159656584263), 59: (4, 0.3932844400405884), 60: (4, 0.42224225867539644), 61: (4, 0.3959832787513733), 62: (4, 0.4079095087945461), 63: (4, 0.39993993286043406), 64: (4, 0.3982643624767661), 65: (4, 0.4028903990983963), 66: (4, 0.40005094464868307), 67: (4, 0.40214397944509983), 68: (4, 0.3893563589081168), 69: (4, 0.40087286569178104), 70: (4, 0.3891571229323745), 71: (1, 0.29951989371329546)}\n",
      "{1: (4, 127, 0.2581829657690145), 2: (4, 127, 0.25819387229702134), 3: (4, 127, 0.25784330249683357), 4: (4, 127, 0.25798442121595144), 5: (4, 127, 0.25785575716895615), 6: (4, 127, 0.2579150040025317), 7: (4, 127, 0.25823487882597707), 8: (4, 127, 0.25783542039855495), 9: (4, 127, 0.2580229648660252), 10: (4, 127, 0.2580718790716308), 11: (4, 127, 0.25815282218656904), 12: (4, 127, 0.25811674226603404), 13: (4, 127, 0.25804840799743733), 14: (4, 127, 0.2579455820066253), 15: (4, 127, 0.25784914246870305), 16: (4, 127, 0.2575359696405023), 17: (4, 127, 0.2576061898226461), 18: (4, 127, 0.25757342286583945), 19: (4, 127, 0.25764800047164593), 20: (4, 127, 0.2575923593597501), 21: (4, 127, 0.2576832984332142), 22: (4, 127, 0.258565356624936), 23: (4, 127, 0.2579176554192356), 24: (4, 127, 0.25772826430043133), 25: (4, 127, 0.2580103879926477), 26: (4, 127, 0.25785466222693837), 27: (4, 127, 0.25788105197074845), 28: (4, 127, 0.2578135197468865), 29: (4, 127, 0.2578379368394848), 30: (4, 127, 0.2576984011854126), 31: (4, 127, 0.2578096845458577), 32: (4, 127, 0.25796992500407956), 33: (4, 127, 0.2578396147234351), 34: (4, 127, 0.25789619452048707), 35: (4, 127, 0.25768973039624493), 36: (4, 127, 0.2576979264968962), 37: (4, 127, 0.25770088745002434), 38: (4, 127, 0.2577199377999531), 39: (4, 127, 0.2577288167873823), 40: (4, 127, 0.2576384320415146), 41: (4, 127, 0.25771271228408954), 42: (4, 127, 0.25751806837396596), 43: (4, 127, 0.25758287611263475), 44: (4, 127, 0.25764715384809284), 45: (4, 127, 0.25773214213696755), 46: (4, 127, 0.25775398989391374), 47: (4, 127, 0.25759473111568476), 48: (4, 127, 0.25780829314259796), 49: (4, 127, 0.2576387513238262), 50: (4, 127, 0.25779251403021297), 51: (4, 127, 0.25805748528324246), 52: (4, 127, 0.25814981784994206), 53: (4, 127, 0.2579091850404195), 54: (4, 127, 0.25860138707537583), 55: (4, 127, 0.2586150903944073), 56: (4, 127, 0.2597287420374085), 57: (4, 127, 0.26102889093797743), 58: (4, 127, 0.258777966840178), 59: (4, 127, 0.2585706843767227), 60: (4, 127, 0.2581491460950356), 61: (4, 127, 0.25817551741772515), 62: (4, 127, 0.25792051802616656), 63: (4, 127, 0.26081573833366783), 64: (4, 127, 0.2589981226382528), 65: (4, 127, 0.25843849334513813), 66: (4, 127, 0.25825200768876966), 67: (4, 127, 0.25796386387609826), 68: (4, 127, 0.2575247707798725), 69: (4, 127, 0.25761325574502), 70: (4, 127, 0.25775897942160764)}\n",
      "{'predict_runtime': 2343.8349, 'predict_samples_per_second': 0.12, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:39:03.83\n",
      "  predict_samples_per_second =       0.12\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 32\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_len of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.2015764405950904), 2: (1, 0.16534615214914083), 3: (1, 0.16272660344839096), 4: (1, 0.1626243144273758), 5: (1, 0.16273227240890265), 6: (1, 0.16298199072480202), 7: (1, 0.15967645030468702), 8: (1, 0.1587105905637145), 9: (1, 0.15968403965234756), 10: (1, 0.16058147884905338), 11: (1, 0.15803883876651525), 12: (1, 0.1609545759856701), 13: (1, 0.16213009133934975), 14: (1, 0.16992560867220163), 15: (1, 0.16247552633285522), 16: (1, 0.15925574488937855), 17: (1, 0.15922416653484106), 18: (1, 0.15914809703826904), 19: (1, 0.15951878298074007), 20: (1, 0.1774852992966771), 21: (1, 0.16312512010335922), 22: (1, 0.161503529176116), 23: (1, 0.15936333499848843), 24: (1, 0.15998748783022165), 25: (1, 0.1616683378815651), 26: (1, 0.15955853275954723), 27: (1, 0.1615490186959505), 28: (1, 0.16100311744958162), 29: (1, 0.17044512275606394), 30: (1, 0.16318092122673988), 31: (1, 0.16068676114082336), 32: (1, 0.15972631238400936), 33: (1, 0.16077829897403717), 34: (1, 0.16039002407342196), 35: (1, 0.15940666664391756), 36: (1, 0.15828759875148535), 37: (1, 0.15878216363489628), 38: (1, 0.16181594785302877), 39: (1, 0.1609336081892252), 40: (1, 0.1593108968809247), 41: (1, 0.15953370463103056), 42: (1, 0.1584348175674677), 43: (1, 0.1586806047707796), 44: (1, 0.16102178860455751), 45: (1, 0.1606320310384035), 46: (1, 0.15834113024175167), 47: (1, 0.15890757273882627), 48: (1, 0.1595730846747756), 49: (1, 0.1603501858189702), 50: (1, 0.1616494795307517), 51: (1, 0.15992061141878366), 52: (1, 0.15910590067505836), 53: (1, 0.15821528248488903), 54: (1, 0.15938653703778982), 55: (1, 0.1613511350005865), 56: (1, 0.16070123203098774), 57: (1, 0.16460082679986954), 58: (1, 0.1615618821233511), 59: (1, 0.16250593215227127), 60: (1, 0.16086753085255623), 61: (1, 0.15960237476974726), 62: (1, 0.16029409784823656), 63: (1, 0.16072483360767365), 64: (1, 0.16245600208640099), 65: (1, 0.16243853140622377), 66: (1, 0.16290337778627872), 67: (1, 0.16161701176315546), 68: (1, 0.16215230710804462), 69: (1, 0.16050043608993292), 70: (1, 0.16184327006340027), 71: (1, 0.15867264848202467)}\n",
      "{1: (1, 127, 0.09731215678566084), 2: (1, 127, 0.09533771610723471), 3: (1, 127, 0.09591783036837193), 4: (1, 127, 0.09455596302877965), 5: (1, 127, 0.09614280326013255), 6: (1, 127, 0.09517317454469955), 7: (1, 127, 0.09491872016017831), 8: (1, 127, 0.09454422012176805), 9: (1, 127, 0.09460151114127063), 10: (1, 127, 0.0954228679862196), 11: (1, 127, 0.09522440913683317), 12: (1, 127, 0.09486552300004977), 13: (1, 127, 0.09836109068362027), 14: (1, 127, 0.09845365595629835), 15: (1, 127, 0.09493017652050012), 16: (1, 127, 0.09449952327477651), 17: (1, 127, 0.09462175519007632), 18: (1, 127, 0.09476748839988718), 19: (1, 127, 0.09784249944509718), 20: (1, 127, 0.09446178184543538), 21: (1, 127, 0.09459852208713378), 22: (1, 127, 0.09473502478290965), 23: (1, 127, 0.09462766823776829), 24: (1, 127, 0.09977488537267672), 25: (1, 127, 0.09439355020565311), 26: (1, 127, 0.09471753081966808), 27: (1, 127, 0.0960464986979844), 28: (1, 127, 0.09464241782071318), 29: (1, 127, 0.09440336669758549), 30: (1, 127, 0.09399514830135923), 31: (1, 127, 0.09400077002841657), 32: (1, 127, 0.09385740713722358), 33: (1, 127, 0.09387314969336423), 34: (1, 127, 0.09456874604710913), 35: (1, 127, 0.09401386946909071), 36: (1, 127, 0.09387421449573022), 37: (1, 127, 0.09943286787835866), 38: (1, 127, 0.09568393547234573), 39: (1, 127, 0.09402963353364956), 40: (1, 127, 0.0938508107627588), 41: (1, 127, 0.09426479100975699), 42: (1, 127, 0.09429847287732786), 43: (1, 127, 0.09452458157930083), 44: (1, 127, 0.09460992621272568), 45: (1, 127, 0.09403557072972923), 46: (1, 127, 0.09459734741803699), 47: (1, 127, 0.09419858165994638), 48: (1, 127, 0.09425428389446942), 49: (1, 127, 0.09423273010546063), 50: (1, 127, 0.09412998123109106), 51: (1, 127, 0.09439851147834007), 52: (1, 127, 0.0946898801164247), 53: (1, 127, 0.0943834999517545), 54: (1, 127, 0.09440417361893053), 55: (1, 127, 0.09457384386488538), 56: (1, 127, 0.09530727868151712), 57: (1, 127, 0.09645512274752452), 58: (1, 127, 0.09708855898068176), 59: (1, 127, 0.09460869288497319), 60: (1, 127, 0.09438612936137933), 61: (1, 127, 0.09391139087626549), 62: (1, 127, 0.09644253553426642), 63: (1, 127, 0.09451540066002626), 64: (1, 127, 0.09414475669307033), 65: (1, 127, 0.09434071757398017), 66: (1, 127, 0.09516994911795995), 67: (1, 127, 0.09432656209417216), 68: (1, 127, 0.09435307702386943), 69: (1, 127, 0.09938583974763164), 70: (1, 127, 0.09666133329536267)}\n",
      "{'predict_runtime': 868.9904, 'predict_samples_per_second': 0.082, 'predict_steps_per_second': 0.082}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:14:28.99\n",
      "  predict_samples_per_second =      0.082\n",
      "  predict_steps_per_second   =      0.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.20354886539280415), 2: (2, 0.19332242663949728), 3: (2, 0.17814698722213507), 4: (2, 0.17685303185135126), 5: (2, 0.18763692490756512), 6: (2, 0.17886817920953035), 7: (2, 0.20223874226212502), 8: (2, 0.20016589760780334), 9: (2, 0.18377807084470987), 10: (2, 0.1848067156970501), 11: (2, 0.1881481958553195), 12: (2, 0.18255657330155373), 13: (2, 0.18112648092210293), 14: (2, 0.18619155045598745), 15: (2, 0.18517159298062325), 16: (2, 0.21566724870353937), 17: (2, 0.17909437604248524), 18: (2, 0.19698175229132175), 19: (2, 0.17954001016914845), 20: (2, 0.19097333494573832), 21: (2, 0.18952116183936596), 22: (2, 0.1898603681474924), 23: (2, 0.1778142126277089), 24: (2, 0.17290299013257027), 25: (2, 0.19422585610300303), 26: (2, 0.17478465754538774), 27: (2, 0.181466119363904), 28: (2, 0.1832311488687992), 29: (2, 0.17816114891320467), 30: (2, 0.17824598774313927), 31: (2, 0.1762000322341919), 32: (2, 0.18261297512799501), 33: (2, 0.17336988635361195), 34: (2, 0.17921407520771027), 35: (2, 0.18004415649920702), 36: (2, 0.1922947997227311), 37: (2, 0.17502063605934381), 38: (2, 0.18980946112424135), 39: (2, 0.18167143687605858), 40: (2, 0.1858926573768258), 41: (2, 0.18766518589109182), 42: (2, 0.17770898435264826), 43: (2, 0.1787488628178835), 44: (2, 0.17777346447110176), 45: (2, 0.1779198832809925), 46: (2, 0.20104301813989878), 47: (2, 0.1744707329198718), 48: (2, 0.1867433488368988), 49: (2, 0.17352379485964775), 50: (2, 0.18779437616467476), 51: (2, 0.1788856415078044), 52: (2, 0.1890500420704484), 53: (2, 0.17437061574310064), 54: (2, 0.18621961493045092), 55: (2, 0.17696996498852968), 56: (2, 0.1764690214768052), 57: (2, 0.17566045187413692), 58: (2, 0.17575806006789207), 59: (2, 0.17915561888366938), 60: (2, 0.18740782141685486), 61: (2, 0.1750228190794587), 62: (2, 0.19091640040278435), 63: (2, 0.18061386328190565), 64: (2, 0.18920998089015484), 65: (2, 0.17689375672489405), 66: (2, 0.1863603051751852), 67: (2, 0.1761431684717536), 68: (2, 0.17597748059779406), 69: (2, 0.17723559588193893), 70: (2, 0.1875132229179144), 71: (1, 0.1613169852644205)}\n",
      "{1: (2, 127, 0.14695968187788105), 2: (2, 127, 0.1459650246602461), 3: (2, 127, 0.14598867962298195), 4: (2, 127, 0.14543801697895048), 5: (2, 127, 0.14958373424193755), 6: (2, 127, 0.14940215525488684), 7: (2, 127, 0.14931329116811903), 8: (2, 127, 0.1466996290420336), 9: (2, 127, 0.14699185190825012), 10: (2, 127, 0.14565428088265142), 11: (2, 127, 0.14597430260573316), 12: (2, 127, 0.145901730584758), 13: (2, 127, 0.14554146537923907), 14: (2, 127, 0.1471572395296782), 15: (2, 127, 0.15067591620095838), 16: (2, 127, 0.14992536470939324), 17: (2, 127, 0.14830286833127654), 18: (2, 127, 0.1497931968215413), 19: (2, 127, 0.1480318941395935), 20: (2, 127, 0.1483017414969605), 21: (2, 127, 0.14859123421671588), 22: (2, 127, 0.14855795133653588), 23: (2, 127, 0.14818100876900858), 24: (2, 127, 0.14888807020964115), 25: (2, 127, 0.14892704245876373), 26: (2, 127, 0.15015233497274674), 27: (2, 127, 0.14918179560716696), 28: (2, 127, 0.14767137724231547), 29: (2, 127, 0.14785350557035348), 30: (2, 127, 0.1478550617223767), 31: (2, 127, 0.14772524061341455), 32: (2, 127, 0.14808757215239635), 33: (2, 127, 0.14819572355568877), 34: (2, 127, 0.14787053178966514), 35: (2, 127, 0.1478320461235882), 36: (2, 127, 0.14805474657360024), 37: (2, 127, 0.14792451907066614), 38: (2, 127, 0.14792058827340837), 39: (2, 127, 0.14819886813336236), 40: (2, 127, 0.14801078834607612), 41: (2, 127, 0.147883877040833), 42: (2, 127, 0.14770940818831207), 43: (2, 127, 0.1480364320198382), 44: (2, 127, 0.14971556158839014), 45: (2, 127, 0.14742588806222742), 46: (2, 127, 0.14821433515735263), 47: (2, 127, 0.14773904452995051), 48: (2, 127, 0.14750235475687765), 49: (2, 127, 0.14764148429564133), 50: (2, 127, 0.147960109973517), 51: (2, 127, 0.14791347156095458), 52: (2, 127, 0.14821987343937393), 53: (2, 127, 0.14799930796936506), 54: (2, 127, 0.14796885212252694), 55: (2, 127, 0.14808965148037578), 56: (2, 127, 0.1479408958574801), 57: (2, 127, 0.14806685720636384), 58: (2, 127, 0.14814939836817465), 59: (2, 127, 0.14822173744117415), 60: (2, 127, 0.14816077888070597), 61: (2, 127, 0.14801959191104325), 62: (2, 127, 0.1478030938567139), 63: (2, 127, 0.1478931485403945), 64: (2, 127, 0.14776738918584398), 65: (2, 127, 0.1481377532133671), 66: (2, 127, 0.14795665357877888), 67: (2, 127, 0.1480567473551537), 68: (2, 127, 0.14783451022712266), 69: (2, 127, 0.14789611713476772), 70: (2, 127, 0.14781172797963846)}\n",
      "{'predict_runtime': 1340.6778, 'predict_samples_per_second': 0.105, 'predict_steps_per_second': 0.053}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:20.67\n",
      "  predict_samples_per_second =      0.105\n",
      "  predict_steps_per_second   =      0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.2636052407324314), 2: (4, 0.22519050724804401), 3: (4, 0.22766744811087847), 4: (4, 0.24279467854648829), 5: (4, 0.22881585359573364), 6: (4, 0.23088603001087904), 7: (4, 0.2375986399129033), 8: (4, 0.22986106108874083), 9: (4, 0.22647521179169416), 10: (4, 0.22812996245920658), 11: (4, 0.2293833876028657), 12: (4, 0.23029734753072262), 13: (4, 0.2249503806233406), 14: (4, 0.23138253390789032), 15: (4, 0.23357002902776003), 16: (4, 0.24062542617321014), 17: (4, 0.22447455674409866), 18: (4, 0.2401473317295313), 19: (4, 0.23034716863185167), 20: (4, 0.22944201808422804), 21: (4, 0.2339378846809268), 22: (4, 0.22629858553409576), 23: (4, 0.23060412425547838), 24: (4, 0.22628259751945734), 25: (4, 0.2412317991256714), 26: (4, 0.22745229303836823), 27: (4, 0.24017211236059666), 28: (4, 0.2251813393086195), 29: (4, 0.22660447284579277), 30: (4, 0.23236255533993244), 31: (4, 0.22845800034701824), 32: (4, 0.22518368158489466), 33: (4, 0.23462881799787283), 34: (4, 0.23120538890361786), 35: (4, 0.22796559799462557), 36: (4, 0.22982432506978512), 37: (4, 0.22672655247151852), 38: (4, 0.22570521477609873), 39: (4, 0.22615697048604488), 40: (4, 0.23114106990396976), 41: (4, 0.22866898868232965), 42: (4, 0.2401030333712697), 43: (4, 0.22528774105012417), 44: (4, 0.22680140286684036), 45: (4, 0.2321423189714551), 46: (4, 0.22931965347379446), 47: (4, 0.22616960015147924), 48: (4, 0.23967550974339247), 49: (4, 0.22723436821252108), 50: (4, 0.23437605425715446), 51: (4, 0.22535273991525173), 52: (4, 0.24329634755849838), 53: (4, 0.22963271755725145), 54: (4, 0.2409686241298914), 55: (4, 0.22715887613594532), 56: (4, 0.22731552366167307), 57: (4, 0.22722212597727776), 58: (4, 0.22831660229712725), 59: (4, 0.22537621669471264), 60: (4, 0.23004207201302052), 61: (4, 0.2265966832637787), 62: (4, 0.22828766331076622), 63: (4, 0.22624217718839645), 64: (4, 0.24214097950607538), 65: (4, 0.23046844638884068), 66: (4, 0.22948112804442644), 67: (4, 0.23040514811873436), 68: (4, 0.2267720913514495), 69: (4, 0.22869816794991493), 70: (4, 0.2244666963815689), 71: (1, 0.16101258248090744)}\n",
      "{1: (4, 127, 0.1475809185479687), 2: (4, 127, 0.1476617313584122), 3: (4, 127, 0.14768515934977006), 4: (4, 127, 0.14764936519860047), 5: (4, 127, 0.14767136547978468), 6: (4, 127, 0.14755046376445163), 7: (4, 127, 0.14775927680155893), 8: (4, 127, 0.1476545321249117), 9: (4, 127, 0.14758397396800554), 10: (4, 127, 0.1477344930538629), 11: (4, 127, 0.14783698803649878), 12: (4, 127, 0.14746837106746014), 13: (4, 127, 0.14746872813800188), 14: (4, 127, 0.14768363810401028), 15: (4, 127, 0.14759770327607008), 16: (4, 127, 0.14769736972204814), 17: (4, 127, 0.14771444077684184), 18: (4, 127, 0.14770718926461193), 19: (4, 127, 0.14787532104633924), 20: (4, 127, 0.14759260187233528), 21: (4, 127, 0.14811284364179128), 22: (4, 127, 0.14784067520857092), 23: (4, 127, 0.14815314494689383), 24: (4, 127, 0.14784903838262548), 25: (4, 127, 0.14796114105760583), 26: (4, 127, 0.14789578929455496), 27: (4, 127, 0.14801614100890836), 28: (4, 127, 0.1480264441058861), 29: (4, 127, 0.14796172328087992), 30: (4, 127, 0.1480299382081886), 31: (4, 127, 0.14805002409348808), 32: (4, 127, 0.14786747656029275), 33: (4, 127, 0.14794370279772076), 34: (4, 127, 0.14792830817489408), 35: (4, 127, 0.1479411602064263), 36: (4, 127, 0.14815616095071937), 37: (4, 127, 0.14811594849525708), 38: (4, 127, 0.14808209494166957), 39: (4, 127, 0.1482306253678334), 40: (4, 127, 0.14787616728123013), 41: (4, 127, 0.14791197912019538), 42: (4, 127, 0.14806468460679523), 43: (4, 127, 0.14797571753188382), 44: (4, 127, 0.14769850842889368), 45: (4, 127, 0.14813985161512622), 46: (4, 127, 0.14795833460869282), 47: (4, 127, 0.1480268600037483), 48: (4, 127, 0.1480099172661389), 49: (4, 127, 0.14813627047449585), 50: (4, 127, 0.14798658277370094), 51: (4, 127, 0.14816916005055267), 52: (4, 127, 0.1478720211137937), 53: (4, 127, 0.14774327778704757), 54: (4, 127, 0.1479502515647355), 55: (4, 127, 0.14799394701262863), 56: (4, 127, 0.14801573223896383), 57: (4, 127, 0.14827164873392798), 58: (4, 127, 0.14798427216972657), 59: (4, 127, 0.14782888088815324), 60: (4, 127, 0.1479420683559353), 61: (4, 127, 0.14812950817794782), 62: (4, 127, 0.14795727442627346), 63: (4, 127, 0.14783406049365133), 64: (4, 127, 0.14824320480784797), 65: (4, 127, 0.1480879062185372), 66: (4, 127, 0.14798014736404336), 67: (4, 127, 0.14801880342548523), 68: (4, 127, 0.14777796747764266), 69: (4, 127, 0.14790712729624406), 70: (4, 127, 0.14817458302457268)}\n",
      "{'predict_runtime': 1343.424, 'predict_samples_per_second': 0.209, 'predict_steps_per_second': 0.053}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:22:23.42\n",
      "  predict_samples_per_second =      0.209\n",
      "  predict_steps_per_second   =      0.053\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 18\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/71 00:13 < 14:58, 0.08 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.1981162168085575), 2: (1, 0.1684387344866991), 3: (1, 0.16854922380298376), 4: (1, 0.17016290500760078), 5: (1, 0.1699726665392518), 6: (1, 0.17135155014693737), 7: (1, 0.16978340782225132), 8: (1, 0.16917612496763468), 9: (1, 0.1687385505065322), 10: (1, 0.1700468948110938), 11: (1, 0.170724056661129), 12: (1, 0.17057255003601313), 13: (1, 0.17017295397818089), 14: (1, 0.17156655807048082), 15: (1, 0.16880027018487453), 16: (1, 0.16819870751351118), 17: (1, 0.16922860592603683), 18: (1, 0.16887348983436823), 19: (1, 0.16910272557288408), 20: (1, 0.16843615379184484), 21: (1, 0.17546188179403543), 22: (1, 0.1685964521020651), 23: (1, 0.16925676353275776), 24: (1, 0.17120004165917635), 25: (1, 0.17207160126417875), 26: (1, 0.17068500723689795), 27: (1, 0.16844137385487556), 28: (1, 0.16920679528266191), 29: (1, 0.1691464064642787), 30: (1, 0.16950339078903198), 31: (1, 0.16831253468990326), 32: (1, 0.17045800015330315), 33: (1, 0.1699399771168828), 34: (1, 0.16889629792422056), 35: (1, 0.16868478152900934), 36: (1, 0.17013402376323938), 37: (1, 0.1683947341516614), 38: (1, 0.16902986727654934), 39: (1, 0.16930969338864088), 40: (1, 0.17095028422772884), 41: (1, 0.1686530914157629), 42: (1, 0.169306012801826), 43: (1, 0.16933755204081535), 44: (1, 0.16918508429080248), 45: (1, 0.16842391341924667), 46: (1, 0.1680111875757575), 47: (1, 0.16982558742165565), 48: (1, 0.16885139793157578), 49: (1, 0.16906588524580002), 50: (1, 0.16922498401254416), 51: (1, 0.16872128937393427), 52: (1, 0.1698157573118806), 53: (1, 0.17002221383154392), 54: (1, 0.16809090599417686), 55: (1, 0.16947400104254484), 56: (1, 0.16917376406490803), 57: (1, 0.16938486136496067), 58: (1, 0.16901737544685602), 59: (1, 0.16953324060887098), 60: (1, 0.17025701235979795), 61: (1, 0.16905159503221512), 62: (1, 0.17001538444310427), 63: (1, 0.16969472914934158), 64: (1, 0.17009471356868744), 65: (1, 0.17133810929954052), 66: (1, 0.17127796914428473), 67: (1, 0.16839147359132767), 68: (1, 0.1691881539300084), 69: (1, 0.16981241665780544), 70: (1, 0.17074320558458567), 71: (1, 0.1676201205700636)}\n",
      "{1: (1, 127, 0.10124797769272187), 2: (1, 127, 0.10116973663790255), 3: (1, 127, 0.10202223568509414), 4: (1, 127, 0.101892338919006), 5: (1, 127, 0.10187001816019065), 6: (1, 127, 0.10209934136236277), 7: (1, 127, 0.1017962677448284), 8: (1, 127, 0.1013554196042104), 9: (1, 127, 0.10134280233196621), 10: (1, 127, 0.10122112548492086), 11: (1, 127, 0.10138754375044286), 12: (1, 127, 0.10115300207655495), 13: (1, 127, 0.10122917062331607), 14: (1, 127, 0.10091533870472917), 15: (1, 127, 0.10134175061944901), 16: (1, 127, 0.1009902656738331), 17: (1, 127, 0.10120151814542652), 18: (1, 127, 0.10121906557538378), 19: (1, 127, 0.10107310909015221), 20: (1, 127, 0.10098572695759807), 21: (1, 127, 0.10116993178298155), 22: (1, 127, 0.10110509735128777), 23: (1, 127, 0.10109302983802604), 24: (1, 127, 0.10083812431204976), 25: (1, 127, 0.10080021671862818), 26: (1, 127, 0.10098992133381095), 27: (1, 127, 0.10083753538618642), 28: (1, 127, 0.10094422643168235), 29: (1, 127, 0.1008718888326658), 30: (1, 127, 0.10086958639059715), 31: (1, 127, 0.10090084308685046), 32: (1, 127, 0.10089413020906486), 33: (1, 127, 0.1007553655800857), 34: (1, 127, 0.10077641641823795), 35: (1, 127, 0.10086472740206193), 36: (1, 127, 0.10085903783512162), 37: (1, 127, 0.10086348901436788), 38: (1, 127, 0.10085664827405937), 39: (1, 127, 0.10080976383833903), 40: (1, 127, 0.10078581495899853), 41: (1, 127, 0.10081849210550935), 42: (1, 127, 0.100884389271593), 43: (1, 127, 0.10082336916316917), 44: (1, 127, 0.10088991631174415), 45: (1, 127, 0.1009416088285878), 46: (1, 127, 0.1008993050406181), 47: (1, 127, 0.10085932320115838), 48: (1, 127, 0.10074348287202242), 49: (1, 127, 0.10086236342670411), 50: (1, 127, 0.10090462259185595), 51: (1, 127, 0.10098693128235227), 52: (1, 127, 0.10101159750740593), 53: (1, 127, 0.10088410298890016), 54: (1, 127, 0.10104717766704756), 55: (1, 127, 0.10099939504770312), 56: (1, 127, 0.10093937707170257), 57: (1, 127, 0.10089711579457512), 58: (1, 127, 0.10100932785229186), 59: (1, 127, 0.10102669831629343), 60: (1, 127, 0.10129302960094505), 61: (1, 127, 0.10098866753162831), 62: (1, 127, 0.10098900773569824), 63: (1, 127, 0.1010301669208905), 64: (1, 127, 0.10098395884535678), 65: (1, 127, 0.10091358547164934), 66: (1, 127, 0.10105123714815209), 67: (1, 127, 0.101152254444525), 68: (1, 127, 0.10112612472304444), 69: (1, 127, 0.10104332268091402), 70: (1, 127, 0.10097344606146803)}\n",
      "{'predict_runtime': 923.3435, 'predict_samples_per_second': 0.077, 'predict_steps_per_second': 0.077}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:15:23.34\n",
      "  predict_samples_per_second =      0.077\n",
      "  predict_steps_per_second   =      0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.20956648234277964), 2: (2, 0.1889392714947462), 3: (2, 0.19117377698421478), 4: (2, 0.1905756527557969), 5: (2, 0.18576059862971306), 6: (2, 0.18688320647925138), 7: (2, 0.1816402282565832), 8: (2, 0.19736746419221163), 9: (2, 0.19743413291871548), 10: (2, 0.19171182997524738), 11: (2, 0.19888715632259846), 12: (2, 0.18793951347470284), 13: (2, 0.19797654636204243), 14: (2, 0.1903958348557353), 15: (2, 0.18341405596584082), 16: (2, 0.19146488141268492), 17: (2, 0.18111823312938213), 18: (2, 0.19070762116461992), 19: (2, 0.19706871639937162), 20: (2, 0.19405629020184278), 21: (2, 0.18583887815475464), 22: (2, 0.1978727662935853), 23: (2, 0.19118088576942682), 24: (2, 0.18190211337059736), 25: (2, 0.1842532055452466), 26: (2, 0.1826642733067274), 27: (2, 0.19914654176682234), 28: (2, 0.19098425656557083), 29: (2, 0.19206641428172588), 30: (2, 0.18408010806888342), 31: (2, 0.19736242201179266), 32: (2, 0.1975722797214985), 33: (2, 0.19715459365397692), 34: (2, 0.1907984772697091), 35: (2, 0.1973413722589612), 36: (2, 0.19264815747737885), 37: (2, 0.19817614182829857), 38: (2, 0.191671178676188), 39: (2, 0.19753029011189938), 40: (2, 0.19788652565330267), 41: (2, 0.18358613178133965), 42: (2, 0.18622309248894453), 43: (2, 0.192378468811512), 44: (2, 0.19907773099839687), 45: (2, 0.1978043857961893), 46: (2, 0.19090461637824774), 47: (2, 0.19816264137625694), 48: (2, 0.19339382834732533), 49: (2, 0.1991255898028612), 50: (2, 0.1912758918479085), 51: (2, 0.19701834488660097), 52: (2, 0.19115146435797215), 53: (2, 0.1984545085579157), 54: (2, 0.19111462403088808), 55: (2, 0.18347305338829756), 56: (2, 0.19250935688614845), 57: (2, 0.19821447134017944), 58: (2, 0.19144561979919672), 59: (2, 0.19732560962438583), 60: (2, 0.1937452331185341), 61: (2, 0.1994387460872531), 62: (2, 0.1912691816687584), 63: (2, 0.1975938966497779), 64: (2, 0.19285925291478634), 65: (2, 0.19968582224100828), 66: (2, 0.18957020062953234), 67: (2, 0.18738972675055265), 68: (2, 0.1993999257683754), 69: (2, 0.19964786246418953), 70: (2, 0.19026542268693447), 71: (1, 0.1840950846672058)}\n",
      "{1: (2, 127, 0.15484885654346212), 2: (2, 127, 0.15480437913660225), 3: (2, 127, 0.15483946197732226), 4: (2, 127, 0.15480060465487205), 5: (2, 127, 0.15474243472352273), 6: (2, 127, 0.15495609547796213), 7: (2, 127, 0.1548614706917424), 8: (2, 127, 0.15480752732956737), 9: (2, 127, 0.1548846722837156), 10: (2, 127, 0.1549213221883328), 11: (2, 127, 0.1556883303331226), 12: (2, 127, 0.1562295143499853), 13: (2, 127, 0.15542174050745766), 14: (2, 127, 0.15537421337116186), 15: (2, 127, 0.15505252691264462), 16: (2, 127, 0.1549321547238611), 17: (2, 127, 0.154847901167832), 18: (2, 127, 0.15479401748363428), 19: (2, 127, 0.15503514604276325), 20: (2, 127, 0.1551204250656127), 21: (2, 127, 0.15502323834298867), 22: (2, 127, 0.15491447453277082), 23: (2, 127, 0.1550209583406608), 24: (2, 127, 0.15497052755324156), 25: (2, 127, 0.15485451712207063), 26: (2, 127, 0.15490715991793655), 27: (2, 127, 0.15485479291821794), 28: (2, 127, 0.15495492004620748), 29: (2, 127, 0.15490044550016874), 30: (2, 127, 0.15542962085308992), 31: (2, 127, 0.1555558739626032), 32: (2, 127, 0.1553325362899524), 33: (2, 127, 0.1550610577687621), 34: (2, 127, 0.15484712682811058), 35: (2, 127, 0.15476755290402203), 36: (2, 127, 0.15470268888267005), 37: (2, 127, 0.15487872000314354), 38: (2, 127, 0.1549752480387101), 39: (2, 127, 0.15483672480560898), 40: (2, 127, 0.15490865809329618), 41: (2, 127, 0.1549506919590507), 42: (2, 127, 0.15488871917363226), 43: (2, 127, 0.15489434394398777), 44: (2, 127, 0.15485934643294869), 45: (2, 127, 0.15478177713303584), 46: (2, 127, 0.15488203717615662), 47: (2, 127, 0.15489982376535108), 48: (2, 127, 0.15528436899038517), 49: (2, 127, 0.15542173000624565), 50: (2, 127, 0.15542640849419936), 51: (2, 127, 0.15515381123459948), 52: (2, 127, 0.1549486121690766), 53: (2, 127, 0.15497978947558036), 54: (2, 127, 0.15495871448904042), 55: (2, 127, 0.15495874231138568), 56: (2, 127, 0.15491438065985524), 57: (2, 127, 0.15500753889901667), 58: (2, 127, 0.15487094431030235), 59: (2, 127, 0.15498703558320606), 60: (2, 127, 0.15493935933263284), 61: (2, 127, 0.15488592266127116), 62: (2, 127, 0.1549003390653983), 63: (2, 127, 0.15492405638274714), 64: (2, 127, 0.15494498979358926), 65: (2, 127, 0.15489456672808083), 66: (2, 127, 0.1552489238651836), 67: (2, 127, 0.15542484129830372), 68: (2, 127, 0.15555082048164812), 69: (2, 127, 0.15523300125578962), 70: (2, 127, 0.15489315179975952)}\n",
      "{'predict_runtime': 1404.7196, 'predict_samples_per_second': 0.1, 'predict_steps_per_second': 0.051}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:24.71\n",
      "  predict_samples_per_second =        0.1\n",
      "  predict_steps_per_second   =      0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.2769411485642195), 2: (4, 0.2455880744382739), 3: (4, 0.25513265281915665), 4: (4, 0.24493790231645107), 5: (4, 0.24001068994402885), 6: (4, 0.24174044001847506), 7: (4, 0.24093570932745934), 8: (4, 0.25451787281781435), 9: (4, 0.2407463015988469), 10: (4, 0.24512176122516394), 11: (4, 0.24336266983300447), 12: (4, 0.24074444081634283), 13: (4, 0.2386571653187275), 14: (4, 0.24252760969102383), 15: (4, 0.25290315970778465), 16: (4, 0.25330917444080114), 17: (4, 0.25390416756272316), 18: (4, 0.25629056990146637), 19: (4, 0.2507811039686203), 20: (4, 0.24172514863312244), 21: (4, 0.23788473196327686), 22: (4, 0.25651294831186533), 23: (4, 0.24004276748746634), 24: (4, 0.2462289361283183), 25: (4, 0.2397433202713728), 26: (4, 0.23859882354736328), 27: (4, 0.24069764837622643), 28: (4, 0.25308650452643633), 29: (4, 0.25061513390392065), 30: (4, 0.2361378101631999), 31: (4, 0.23939949367195368), 32: (4, 0.23970984853804111), 33: (4, 0.2417419059202075), 34: (4, 0.24135730974376202), 35: (4, 0.25214520655572414), 36: (4, 0.2366140242666006), 37: (4, 0.24104716442525387), 38: (4, 0.240344881080091), 39: (4, 0.23610728979110718), 40: (4, 0.25209515634924173), 41: (4, 0.23800903744995594), 42: (4, 0.23804767709225416), 43: (4, 0.2529838653281331), 44: (4, 0.24648748990148306), 45: (4, 0.24591993633657694), 46: (4, 0.23857659008353949), 47: (4, 0.23807423561811447), 48: (4, 0.2512869741767645), 49: (4, 0.2386482795700431), 50: (4, 0.23968377709388733), 51: (4, 0.24068744480609894), 52: (4, 0.23749593272805214), 53: (4, 0.2413504784926772), 54: (4, 0.23817290551960468), 55: (4, 0.23751436173915863), 56: (4, 0.24238587729632854), 57: (4, 0.23832139559090137), 58: (4, 0.2367075551301241), 59: (4, 0.2379856901243329), 60: (4, 0.23984018806368113), 61: (4, 0.24166408739984035), 62: (4, 0.24035505205392838), 63: (4, 0.238605591468513), 64: (4, 0.24031913094222546), 65: (4, 0.2383261127397418), 66: (4, 0.25263551995158195), 67: (4, 0.2522041341289878), 68: (4, 0.2503305058926344), 69: (4, 0.23919670283794403), 70: (4, 0.2514125322923064), 71: (1, 0.180671451613307)}\n",
      "{1: (4, 127, 0.15526667152949442), 2: (4, 127, 0.1554335321365731), 3: (4, 127, 0.1553618653684737), 4: (4, 127, 0.15516573582284562), 5: (4, 127, 0.15515783931473343), 6: (4, 127, 0.1553555562153576), 7: (4, 127, 0.15522812158016003), 8: (4, 127, 0.15511298327758086), 9: (4, 127, 0.15519893296268278), 10: (4, 127, 0.15512278326970386), 11: (4, 127, 0.15522865650398054), 12: (4, 127, 0.1551412122881436), 13: (4, 127, 0.15523067130670537), 14: (4, 127, 0.15577506523315363), 15: (4, 127, 0.1558658425864859), 16: (4, 127, 0.15572620133363355), 17: (4, 127, 0.15517948573733878), 18: (4, 127, 0.15501614679824413), 19: (4, 127, 0.15503084306847156), 20: (4, 127, 0.15513086440701654), 21: (4, 127, 0.15499783970239595), 22: (4, 127, 0.1552425206264877), 23: (4, 127, 0.1550846803845383), 24: (4, 127, 0.15517005827424563), 25: (4, 127, 0.15521336593995178), 26: (4, 127, 0.1552160063714493), 27: (4, 127, 0.1550857276164406), 28: (4, 127, 0.15515693283720514), 29: (4, 127, 0.15512562972148808), 30: (4, 127, 0.15517902892728255), 31: (4, 127, 0.15531379529311667), 32: (4, 127, 0.15571760014432856), 33: (4, 127, 0.15578186693857973), 34: (4, 127, 0.1556474164230969), 35: (4, 127, 0.1552327952208364), 36: (4, 127, 0.15530775441223477), 37: (4, 127, 0.15520731578984365), 38: (4, 127, 0.15534472325450088), 39: (4, 127, 0.15511896568313827), 40: (4, 127, 0.15534473896231943), 41: (4, 127, 0.15519520179111893), 42: (4, 127, 0.1551815369643095), 43: (4, 127, 0.1551825641837763), 44: (4, 127, 0.15515367403685107), 45: (4, 127, 0.15520604350054124), 46: (4, 127, 0.15529264272813956), 47: (4, 127, 0.1551484728789353), 48: (4, 127, 0.15528511066048398), 49: (4, 127, 0.15538013317277583), 50: (4, 127, 0.15581216652122304), 51: (4, 127, 0.15586098766790366), 52: (4, 127, 0.1557993246682399), 53: (4, 127, 0.15532710012341813), 54: (4, 127, 0.15516355460670989), 55: (4, 127, 0.15521022863686085), 56: (4, 127, 0.15522151188851577), 57: (4, 127, 0.15536424608563815), 58: (4, 127, 0.15528646561016482), 59: (4, 127, 0.15518199723565906), 60: (4, 127, 0.15523605374986027), 61: (4, 127, 0.15524048218136932), 62: (4, 127, 0.15522680907532221), 63: (4, 127, 0.15527383859936647), 64: (4, 127, 0.1551974111009301), 65: (4, 127, 0.15513283929486912), 66: (4, 127, 0.15510864458303517), 67: (4, 127, 0.1552433893964516), 68: (4, 127, 0.1558478391457965), 69: (4, 127, 0.1557012363886974), 70: (4, 127, 0.15572197094383672)}\n",
      "{'predict_runtime': 1410.7933, 'predict_samples_per_second': 0.199, 'predict_steps_per_second': 0.05}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:23:30.79\n",
      "  predict_samples_per_second =      0.199\n",
      "  predict_steps_per_second   =       0.05\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 19\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3178816121071577), 2: (1, 0.2793082119897008), 3: (1, 0.2772633358836174), 4: (1, 0.2786848386749625), 5: (1, 0.27847186103463173), 6: (1, 0.27890070527791977), 7: (1, 0.2808327628299594), 8: (1, 0.2792979199439287), 9: (1, 0.2769640376791358), 10: (1, 0.27708093635737896), 11: (1, 0.28078852314502), 12: (1, 0.2783872792497277), 13: (1, 0.279964130371809), 14: (1, 0.27807664312422276), 15: (1, 0.28061730321496725), 16: (1, 0.2790996301919222), 17: (1, 0.27835622895509005), 18: (1, 0.2790129715576768), 19: (1, 0.2800273587927222), 20: (1, 0.2774102594703436), 21: (1, 0.278693363070488), 22: (1, 0.2787345126271248), 23: (1, 0.27940670493990183), 24: (1, 0.27912545669823885), 25: (1, 0.27716015186160803), 26: (1, 0.28014298621565104), 27: (1, 0.27823782712221146), 28: (1, 0.28107628505676985), 29: (1, 0.2772464081645012), 30: (1, 0.2810199949890375), 31: (1, 0.28098865505307913), 32: (1, 0.27814555633813143), 33: (1, 0.2789244083687663), 34: (1, 0.277197876945138), 35: (1, 0.27831479348242283), 36: (1, 0.27891732938587666), 37: (1, 0.28044823091477156), 38: (1, 0.2803978305310011), 39: (1, 0.2780347689986229), 40: (1, 0.28031533025205135), 41: (1, 0.279379703104496), 42: (1, 0.2778655793517828), 43: (1, 0.27832799311727285), 44: (1, 0.2787519795820117), 45: (1, 0.27935947198420763), 46: (1, 0.2825768440961838), 47: (1, 0.2794494992122054), 48: (1, 0.2793477503582835), 49: (1, 0.27997332252562046), 50: (1, 0.27724328450858593), 51: (1, 0.2770910235121846), 52: (1, 0.27956167701631784), 53: (1, 0.2785968268290162), 54: (1, 0.2782607898116112), 55: (1, 0.2798946127295494), 56: (1, 0.2793668480589986), 57: (1, 0.2801282284781337), 58: (1, 0.2772429808974266), 59: (1, 0.28126475494354963), 60: (1, 0.27771035581827164), 61: (1, 0.2793554263189435), 62: (1, 0.2829846842214465), 63: (1, 0.27768409438431263), 64: (1, 0.27864892315119505), 65: (1, 0.2806537300348282), 66: (1, 0.28204383328557014), 67: (1, 0.2837485345080495), 68: (1, 0.2776156133040786), 69: (1, 0.2816887265071273), 70: (1, 0.2788703991100192), 71: (1, 0.27740645594894886)}\n",
      "{1: (1, 127, 0.1679347423308595), 2: (1, 127, 0.1677631390405687), 3: (1, 127, 0.16760363515583784), 4: (1, 127, 0.16769528445443066), 5: (1, 127, 0.16766445625456064), 6: (1, 127, 0.16756076307043316), 7: (1, 127, 0.16764242933901746), 8: (1, 127, 0.16748344056366934), 9: (1, 127, 0.16759708409351626), 10: (1, 127, 0.16752191531053912), 11: (1, 127, 0.16757546867588607), 12: (1, 127, 0.16752407553891732), 13: (1, 127, 0.16763273779097504), 14: (1, 127, 0.16807368159382127), 15: (1, 127, 0.16821217816323042), 16: (1, 127, 0.16823333119020217), 17: (1, 127, 0.1675366563062499), 18: (1, 127, 0.16751360228857187), 19: (1, 127, 0.16746946103049545), 20: (1, 127, 0.16734794208295936), 21: (1, 127, 0.16748163445786698), 22: (1, 127, 0.16727128810447267), 23: (1, 127, 0.16752671830238788), 24: (1, 127, 0.16725476265070946), 25: (1, 127, 0.16726967606576174), 26: (1, 127, 0.16766590449783042), 27: (1, 127, 0.16743009583657886), 28: (1, 127, 0.1675110742611092), 29: (1, 127, 0.16739874277410544), 30: (1, 127, 0.16770068526737333), 31: (1, 127, 0.16801360205519855), 32: (1, 127, 0.1680759211606163), 33: (1, 127, 0.16761966440533324), 34: (1, 127, 0.16743388346682384), 35: (1, 127, 0.167311891884081), 36: (1, 127, 0.16733917791220382), 37: (1, 127, 0.16740747307991888), 38: (1, 127, 0.1673272187403572), 39: (1, 127, 0.16723769192591192), 40: (1, 127, 0.1674766571766983), 41: (1, 127, 0.16736940213105106), 42: (1, 127, 0.16758935524546725), 43: (1, 127, 0.1675675579632713), 44: (1, 127, 0.16753070227303138), 45: (1, 127, 0.167474532015915), 46: (1, 127, 0.16744179731073577), 47: (1, 127, 0.16771776183677), 48: (1, 127, 0.1679905732345628), 49: (1, 127, 0.1679749384111776), 50: (1, 127, 0.1678411984948192), 51: (1, 127, 0.16745230842997708), 52: (1, 127, 0.16765311576690026), 53: (1, 127, 0.16740833083534334), 54: (1, 127, 0.16762435958376082), 55: (1, 127, 0.1675282776517075), 56: (1, 127, 0.1676673274487257), 57: (1, 127, 0.16745571834658543), 58: (1, 127, 0.1675973585036796), 59: (1, 127, 0.16758534563045333), 60: (1, 127, 0.16761049483792753), 61: (1, 127, 0.16746531143843188), 62: (1, 127, 0.1675101380692575), 63: (1, 127, 0.16738526372781654), 64: (1, 127, 0.17012233867889315), 65: (1, 127, 0.1683868747937867), 66: (1, 127, 0.1681597930357212), 67: (1, 127, 0.16776403614620525), 68: (1, 127, 0.16781746724429797), 69: (1, 127, 0.16756549066915286), 70: (1, 127, 0.16757453283603033)}\n",
      "{'predict_runtime': 1531.5006, 'predict_samples_per_second': 0.046, 'predict_steps_per_second': 0.046}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:25:31.50\n",
      "  predict_samples_per_second =      0.046\n",
      "  predict_steps_per_second   =      0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.3340828036889434), 2: (2, 0.32261288445442915), 3: (2, 0.3014016589149833), 4: (2, 0.3020944809541106), 5: (2, 0.3233356261625886), 6: (2, 0.32311747781932354), 7: (2, 0.3012352390214801), 8: (2, 0.3241503741592169), 9: (2, 0.3233155235648155), 10: (2, 0.3240918256342411), 11: (2, 0.32137720473110676), 12: (2, 0.31474888045340776), 13: (2, 0.3256329447031021), 14: (2, 0.3232440920546651), 15: (2, 0.3030442241579294), 16: (2, 0.29779123421758413), 17: (2, 0.30010524671524763), 18: (2, 0.29830392822623253), 19: (2, 0.3037974638864398), 20: (2, 0.3251720080152154), 21: (2, 0.3210582537576556), 22: (2, 0.3216942762956023), 23: (2, 0.3020620821043849), 24: (2, 0.30185232404619455), 25: (2, 0.30113418214023113), 26: (2, 0.30061776749789715), 27: (2, 0.30001778434962034), 28: (2, 0.32651241961866617), 29: (2, 0.29955269768834114), 30: (2, 0.32253065425902605), 31: (2, 0.30464852042496204), 32: (2, 0.30597268231213093), 33: (2, 0.30205680802464485), 34: (2, 0.3200907800346613), 35: (2, 0.3001792598515749), 36: (2, 0.3253211686387658), 37: (2, 0.30182362999767065), 38: (2, 0.3264827746897936), 39: (2, 0.30368398781865835), 40: (2, 0.31890123151242733), 41: (2, 0.32151384092867374), 42: (2, 0.32529956940561533), 43: (2, 0.29937732219696045), 44: (2, 0.3164030695334077), 45: (2, 0.29958391841501), 46: (2, 0.32567999325692654), 47: (2, 0.30124182999134064), 48: (2, 0.3262719651684165), 49: (2, 0.3024326451122761), 50: (2, 0.3273595916107297), 51: (2, 0.30008490942418575), 52: (2, 0.30781757179647684), 53: (2, 0.30106745939701796), 54: (2, 0.31959096621721983), 55: (2, 0.3004067549481988), 56: (2, 0.32779255229979753), 57: (2, 0.2983756558969617), 58: (2, 0.3199390210211277), 59: (2, 0.3034806167706847), 60: (2, 0.3280441090464592), 61: (2, 0.3072920925915241), 62: (2, 0.328321423381567), 63: (2, 0.3078827653080225), 64: (2, 0.3284452222287655), 65: (2, 0.30258896481245756), 66: (2, 0.3269788958132267), 67: (2, 0.3082401491701603), 68: (2, 0.31688722036778927), 69: (2, 0.3002697890624404), 70: (2, 0.32659670896828175), 71: (1, 0.27743428852409124)}\n",
      "{1: (2, 127, 0.25812966925803366), 2: (2, 127, 0.25810090721562856), 3: (2, 127, 0.25810426235286976), 4: (2, 127, 0.25807355616359023), 5: (2, 127, 0.2580330482955406), 6: (2, 127, 0.2583820128549389), 7: (2, 127, 0.2587125911194039), 8: (2, 127, 0.25864244633772243), 9: (2, 127, 0.25813460376436315), 10: (2, 127, 0.25805688947145866), 11: (2, 127, 0.2580381603324859), 12: (2, 127, 0.25809381680753757), 13: (2, 127, 0.25814712156842307), 14: (2, 127, 0.25806121462882736), 15: (2, 127, 0.2586317117157297), 16: (2, 127, 0.25814106959966926), 17: (2, 127, 0.2583990527287595), 18: (2, 127, 0.2579982879197621), 19: (2, 127, 0.2582081833516988), 20: (2, 127, 0.2579779006819439), 21: (2, 127, 0.2580111053970268), 22: (2, 127, 0.2581029691858085), 23: (2, 127, 0.2581109680440717), 24: (2, 127, 0.2580219355859156), 25: (2, 127, 0.25826217617663577), 26: (2, 127, 0.2581948984311674), 27: (2, 127, 0.25812640124711933), 28: (2, 127, 0.25812832318158363), 29: (2, 127, 0.2581225064707788), 30: (2, 127, 0.2582931627526762), 31: (2, 127, 0.2582335893475399), 32: (2, 127, 0.25816317284699736), 33: (2, 127, 0.25836904463541555), 34: (2, 127, 0.2581614187559274), 35: (2, 127, 0.25809013306009254), 36: (2, 127, 0.25830687913955663), 37: (2, 127, 0.258117556293297), 38: (2, 127, 0.25820721661686663), 39: (2, 127, 0.25820766434836107), 40: (2, 127, 0.2580885954905213), 41: (2, 127, 0.25808065063430097), 42: (2, 127, 0.2581155112335884), 43: (2, 127, 0.25828163097722556), 44: (2, 127, 0.2584288644083724), 45: (2, 127, 0.25821690703558875), 46: (2, 127, 0.2581985381644542), 47: (2, 127, 0.25819402679390324), 48: (2, 127, 0.2581873369351851), 49: (2, 127, 0.2581453714299742), 50: (2, 127, 0.2581576755578358), 51: (2, 127, 0.25820314599655747), 52: (2, 127, 0.2582677336057692), 53: (2, 127, 0.2581844225995184), 54: (2, 127, 0.25815747293284325), 55: (2, 127, 0.25824137002699016), 56: (2, 127, 0.25826122267098406), 57: (2, 127, 0.258074323639391), 58: (2, 127, 0.25817726517286826), 59: (2, 127, 0.25815982509433755), 60: (2, 127, 0.2580691108069434), 61: (2, 127, 0.25804595726241514), 62: (2, 127, 0.25884694175604056), 63: (2, 127, 0.2584933362915877), 64: (2, 127, 0.25899919807382926), 65: (2, 127, 0.2583686633284871), 66: (2, 127, 0.25989433377981186), 67: (2, 127, 0.2587289531297219), 68: (2, 127, 0.2586484101828276), 69: (2, 127, 0.25875881914870713), 70: (2, 127, 0.2585500417438548)}\n",
      "{'predict_runtime': 2339.5134, 'predict_samples_per_second': 0.06, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:38:59.51\n",
      "  predict_samples_per_second =       0.06\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.41952582262456417), 2: (4, 0.3905878206714988), 3: (4, 0.3956852909177542), 4: (4, 0.41648742463439703), 5: (4, 0.3926830356940627), 6: (4, 0.3943660268560052), 7: (4, 0.41562212351709604), 8: (4, 0.39674178790301085), 9: (4, 0.40131568536162376), 10: (4, 0.39168680366128683), 11: (4, 0.39897560980170965), 12: (4, 0.4013189636170864), 13: (4, 0.3930252678692341), 14: (4, 0.40331193059682846), 15: (4, 0.41809660103172064), 16: (4, 0.416367300786078), 17: (4, 0.39853586349636316), 18: (4, 0.40298266243189573), 19: (4, 0.41259901132434607), 20: (4, 0.40018908120691776), 21: (4, 0.40655740909278393), 22: (4, 0.3976289005950093), 23: (4, 0.41141417250037193), 24: (4, 0.3899840172380209), 25: (4, 0.4119188664481044), 26: (4, 0.41579957120120525), 27: (4, 0.4087485810741782), 28: (4, 0.41117942426353693), 29: (4, 0.393993329256773), 30: (4, 0.395960895344615), 31: (4, 0.41338879615068436), 32: (4, 0.41855813656002283), 33: (4, 0.4059011209756136), 34: (4, 0.41670625656843185), 35: (4, 0.41631227266043425), 36: (4, 0.41690654400736094), 37: (4, 0.39663790445774794), 38: (4, 0.3969678897410631), 39: (4, 0.40803294349461794), 40: (4, 0.3949621021747589), 41: (4, 0.39331527054309845), 42: (4, 0.3900312976911664), 43: (4, 0.41794174909591675), 44: (4, 0.4102603765204549), 45: (4, 0.4076735945418477), 46: (4, 0.4162323661148548), 47: (4, 0.41599858924746513), 48: (4, 0.39880323503166437), 49: (4, 0.40996747836470604), 50: (4, 0.3940687598660588), 51: (4, 0.4122991422191262), 52: (4, 0.40874185133725405), 53: (4, 0.4187125572934747), 54: (4, 0.39157750736922026), 55: (4, 0.40727532748132944), 56: (4, 0.39069267734885216), 57: (4, 0.41475939098745584), 58: (4, 0.396178743802011), 59: (4, 0.4095989689230919), 60: (4, 0.3923843055963516), 61: (4, 0.4172047423198819), 62: (4, 0.39611954241991043), 63: (4, 0.4114966867491603), 64: (4, 0.39587121549993753), 65: (4, 0.4001832064241171), 66: (4, 0.4190742298960686), 67: (4, 0.39745626598596573), 68: (4, 0.4130932465195656), 69: (4, 0.396873832680285), 70: (4, 0.3977017421275377), 71: (1, 0.3087491123005748)}\n",
      "{1: (4, 127, 0.25845987163484097), 2: (4, 127, 0.25852067583775895), 3: (4, 127, 0.25827698262159043), 4: (4, 127, 0.2582784508039632), 5: (4, 127, 0.2582790667161815), 6: (4, 127, 0.25807652902591416), 7: (4, 127, 0.25830955718328635), 8: (4, 127, 0.25827170370190633), 9: (4, 127, 0.25834872725412367), 10: (4, 127, 0.2581677288770324), 11: (4, 127, 0.25823936966343186), 12: (4, 127, 0.25828763827916207), 13: (4, 127, 0.2584441269887245), 14: (4, 127, 0.2581821937245999), 15: (4, 127, 0.2580905250368977), 16: (4, 127, 0.2582645895634228), 17: (4, 127, 0.2580582228980548), 18: (4, 127, 0.2579722600717714), 19: (4, 127, 0.25803525910866776), 20: (4, 127, 0.258030267637663), 21: (4, 127, 0.2581392953494989), 22: (4, 127, 0.2581952829647252), 23: (4, 127, 0.2584003684015607), 24: (4, 127, 0.2582078679120095), 25: (4, 127, 0.25809556949062373), 26: (4, 127, 0.2581983540632476), 27: (4, 127, 0.25848161791429275), 28: (4, 127, 0.258338839373016), 29: (4, 127, 0.25874319359454817), 30: (4, 127, 0.25881039582955556), 31: (4, 127, 0.25881320200713837), 32: (4, 127, 0.2587730891005261), 33: (4, 127, 0.25878762641525643), 34: (4, 127, 0.2587535811485503), 35: (4, 127, 0.25872947016774905), 36: (4, 127, 0.258944002867449), 37: (4, 127, 0.2589854865048931), 38: (4, 127, 0.25877642127736583), 39: (4, 127, 0.25898913052079714), 40: (4, 127, 0.25884335056152635), 41: (4, 127, 0.2588957767552278), 42: (4, 127, 0.2587079597255728), 43: (4, 127, 0.25888044542566996), 44: (4, 127, 0.2587431119828243), 45: (4, 127, 0.2587554552922333), 46: (4, 127, 0.258914876406587), 47: (4, 127, 0.2586760924043735), 48: (4, 127, 0.258245008520958), 49: (4, 127, 0.25841288018502356), 50: (4, 127, 0.2582479322431829), 51: (4, 127, 0.2582956202269539), 52: (4, 127, 0.25844131921249347), 53: (4, 127, 0.25821427088670845), 54: (4, 127, 0.258117087544712), 55: (4, 127, 0.25827949523456456), 56: (4, 127, 0.2581679474078412), 57: (4, 127, 0.2582894501415646), 58: (4, 127, 0.25822228763809824), 59: (4, 127, 0.25815114889323243), 60: (4, 127, 0.2581522766222048), 61: (4, 127, 0.25826318617763483), 62: (4, 127, 0.2582346137877055), 63: (4, 127, 0.25850848037397534), 64: (4, 127, 0.2582377619440044), 65: (4, 127, 0.25851744822571127), 66: (4, 127, 0.258266339415875), 67: (4, 127, 0.258268052213422), 68: (4, 127, 0.2581958493848485), 69: (4, 127, 0.25838489647896035), 70: (4, 127, 0.25841342132010564)}\n",
      "{'predict_runtime': 2347.1781, 'predict_samples_per_second': 0.12, 'predict_steps_per_second': 0.03}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:39:07.17\n",
      "  predict_samples_per_second =       0.12\n",
      "  predict_steps_per_second   =       0.03\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 32\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
