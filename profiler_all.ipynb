{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb65e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "# os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7bb842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsanyal7/miniconda3/envs/amoeballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3daad3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using compute dtype: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"512\",\n",
    "    \"--max_new_tokens\", \"32\", # TODO: hkolisetty6\n",
    "    # \"--bf16\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6186fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with num_layers: 16\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.2154464554041624), 2: (1, 0.19507850240916014), 3: (1, 0.1941644735634327), 4: (1, 0.19450733251869678), 5: (1, 0.1942154634743929), 6: (1, 0.19414843432605267), 7: (1, 0.19376584608107805), 8: (1, 0.19385494571179152), 9: (1, 0.1935255266726017), 10: (1, 0.19397968333214521), 11: (1, 0.1936962753534317), 12: (1, 0.19496701192110777), 13: (1, 0.19417630415409803), 14: (1, 0.19409166555851698), 15: (1, 0.19429887365549803), 16: (1, 0.1945168236270547), 17: (1, 0.194290554150939), 18: (1, 0.19475911278277636), 19: (1, 0.1944847833365202), 20: (1, 0.19499493204057217), 21: (1, 0.19442474283277988), 22: (1, 0.19405509438365698), 23: (1, 0.19418378453701735), 24: (1, 0.1960844285786152), 25: (1, 0.19446810334920883), 26: (1, 0.1944258138537407), 27: (1, 0.1942357448861003), 28: (1, 0.19435006380081177), 29: (1, 0.1943665537983179), 30: (1, 0.1943148747086525), 31: (1, 0.1941770650446415), 32: (1, 0.19398080557584763), 33: (1, 0.19463392347097397), 34: (1, 0.19416782446205616), 35: (1, 0.19435710366815329), 36: (1, 0.19421829376369715), 37: (1, 0.19445852376520634), 38: (1, 0.19459746312350035), 39: (1, 0.19425630383193493), 40: (1, 0.19429271388798952), 41: (1, 0.19419060368090868), 42: (1, 0.1941918944939971), 43: (1, 0.19420864339917898), 44: (1, 0.19428080413490534), 45: (1, 0.19423214346170425), 46: (1, 0.19411282520741224), 47: (1, 0.1944787735119462), 48: (1, 0.19404121581465006), 49: (1, 0.19433975405991077), 50: (1, 0.19422642420977354), 51: (1, 0.19423929415643215), 52: (1, 0.19446927309036255), 53: (1, 0.1941215144470334), 54: (1, 0.1945933224633336), 55: (1, 0.19414640497416258), 56: (1, 0.19447707291692495), 57: (1, 0.19442197401076555), 58: (1, 0.1946917325258255), 59: (1, 0.19455259293317795), 60: (1, 0.19453992322087288), 61: (1, 0.1942819943651557), 62: (1, 0.19450147449970245), 63: (1, 0.1943594040349126), 64: (1, 0.19494194258004427), 65: (1, 0.1941480441018939), 66: (1, 0.19432221353054047), 67: (1, 0.19412057474255562), 68: (1, 0.19467476289719343), 69: (1, 0.1941152447834611), 70: (1, 0.19417989440262318), 71: (1, 0.1936728162690997)}\n",
      "{1: (1, 31, 0.07370286537033896), 2: (1, 31, 0.07434827945525607), 3: (1, 31, 0.07371895507939401), 4: (1, 31, 0.07422484601697614), 5: (1, 31, 0.07367318300830741), 6: (1, 31, 0.07287923655202312), 7: (1, 31, 0.0759310133214439), 8: (1, 31, 0.07538803768975119), 9: (1, 31, 0.07604386528292971), 10: (1, 31, 0.07351933242452721), 11: (1, 31, 0.0745525324356652), 12: (1, 31, 0.07528289434530082), 13: (1, 31, 0.07289919043861089), 14: (1, 31, 0.07337400215047021), 15: (1, 31, 0.07455293641936395), 16: (1, 31, 0.07456611060807782), 17: (1, 31, 0.07600062914312847), 18: (1, 31, 0.07368209621598644), 19: (1, 31, 0.07475522785417495), 20: (1, 31, 0.07358665442875316), 21: (1, 31, 0.07511212610669675), 22: (1, 31, 0.0742913646202895), 23: (1, 31, 0.07327454296811935), 24: (1, 31, 0.07295878462853932), 25: (1, 31, 0.07310325811587033), 26: (1, 31, 0.0728788472892296), 27: (1, 31, 0.07300570904607734), 28: (1, 31, 0.07301656769648675), 29: (1, 31, 0.0729417098505843), 30: (1, 31, 0.07317750606565707), 31: (1, 31, 0.07320693174316999), 32: (1, 31, 0.07299659551391678), 33: (1, 31, 0.07302877096639525), 34: (1, 31, 0.07297331587441507), 35: (1, 31, 0.07301524158326848), 36: (1, 31, 0.07304407824431697), 37: (1, 31, 0.07292814315446923), 38: (1, 31, 0.07294452499838606), 39: (1, 31, 0.07278098619633144), 40: (1, 31, 0.07281950347486042), 41: (1, 31, 0.07284587017831302), 42: (1, 31, 0.07279204649309959), 43: (1, 31, 0.07444047399105565), 44: (1, 31, 0.0729830390022647), 45: (1, 31, 0.07286447926514572), 46: (1, 31, 0.0730179550666963), 47: (1, 31, 0.07283123771870328), 48: (1, 31, 0.07277151846116589), 49: (1, 31, 0.07280225033361104), 50: (1, 31, 0.07289726124896158), 51: (1, 31, 0.07280397258939282), 52: (1, 31, 0.07289746863346908), 53: (1, 31, 0.07297071243726438), 54: (1, 31, 0.0728660881399147), 55: (1, 31, 0.07294543721382657), 56: (1, 31, 0.07294275686745683), 57: (1, 31, 0.073084051991182), 58: (1, 31, 0.07299656438971719), 59: (1, 31, 0.07287024793725821), 60: (1, 31, 0.07299420456852644), 61: (1, 31, 0.07284455458002706), 62: (1, 31, 0.07302111035753642), 63: (1, 31, 0.07294669594135016), 64: (1, 31, 0.07317029886067875), 65: (1, 31, 0.07285628464793967), 66: (1, 31, 0.07278521617333736), 67: (1, 31, 0.07295521015241262), 68: (1, 31, 0.07283302525719328), 69: (1, 31, 0.07299936103123811), 70: (1, 31, 0.07294117827569285)}\n",
      "{'predict_runtime': 175.5424, 'predict_samples_per_second': 0.404, 'predict_steps_per_second': 0.404}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:02:55.54\n",
      "  predict_samples_per_second =      0.404\n",
      "  predict_steps_per_second   =      0.404\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.32418809924274683), 2: (2, 0.30336253717541695), 3: (2, 0.3025214998051524), 4: (2, 0.30370423570275307), 5: (2, 0.3027303786948323), 6: (2, 0.3036179067566991), 7: (2, 0.3030100194737315), 8: (2, 0.3030607383698225), 9: (2, 0.3037814563140273), 10: (2, 0.3030804777517915), 11: (2, 0.3046946134418249), 12: (2, 0.3022612202912569), 13: (2, 0.3035259572789073), 14: (2, 0.3032721569761634), 15: (2, 0.3023851700127125), 16: (2, 0.30359999649226665), 17: (2, 0.30303522758185863), 18: (2, 0.30279869865626097), 19: (2, 0.3035506969317794), 20: (2, 0.303690736182034), 21: (2, 0.30394260585308075), 22: (2, 0.3032279182225466), 23: (2, 0.30301069747656584), 24: (2, 0.3033811869099736), 25: (2, 0.30390753597021103), 26: (2, 0.30328442715108395), 27: (2, 0.30310252867639065), 28: (2, 0.3035471374168992), 29: (2, 0.30360604729503393), 30: (2, 0.30369577649980783), 31: (2, 0.30330115742981434), 32: (2, 0.3037834856659174), 33: (2, 0.3033529482781887), 34: (2, 0.30342039838433266), 35: (2, 0.3032092582434416), 36: (2, 0.3028553584590554), 37: (2, 0.3030762681737542), 38: (2, 0.30338721722364426), 39: (2, 0.3031441178172827), 40: (2, 0.30305281933397055), 41: (2, 0.3031558971852064), 42: (2, 0.30321544874459505), 43: (2, 0.30354514718055725), 44: (2, 0.30321780778467655), 45: (2, 0.3033389877527952), 46: (2, 0.3032272970303893), 47: (2, 0.30342827644199133), 48: (2, 0.30378580652177334), 49: (2, 0.3037609653547406), 50: (2, 0.30308243818581104), 51: (2, 0.30348354764282703), 52: (2, 0.3032891070470214), 53: (2, 0.30353008676320314), 54: (2, 0.3034011572599411), 55: (2, 0.3031382877379656), 56: (2, 0.30347343627363443), 57: (2, 0.3032068181782961), 58: (2, 0.30339829716831446), 59: (2, 0.3036172166466713), 60: (2, 0.3036653157323599), 61: (2, 0.303169378079474), 62: (2, 0.3033716669306159), 63: (2, 0.3038217257708311), 64: (2, 0.303420296870172), 65: (2, 0.30340765696018934), 66: (2, 0.30321467760950327), 67: (2, 0.30403315648436546), 68: (2, 0.30305886920541525), 69: (2, 0.30512223299592733), 70: (2, 0.3025788189843297), 71: (1, 0.19369312282651663)}\n",
      "{1: (2, 31, 0.1201340111212865), 2: (2, 31, 0.1200597994029522), 3: (2, 31, 0.12028863956971515), 4: (2, 31, 0.1201470656200282), 5: (2, 31, 0.12013160629618552), 6: (2, 31, 0.12005295069707979), 7: (2, 31, 0.12002956299411674), 8: (2, 31, 0.12107792187241777), 9: (2, 31, 0.12129961999673997), 10: (2, 31, 0.12265738646589941), 11: (2, 31, 0.12084689261692186), 12: (2, 31, 0.12084581937280393), 13: (2, 31, 0.121385843883599), 14: (2, 31, 0.12196119811626212), 15: (2, 31, 0.12019670673555904), 16: (2, 31, 0.1202754795010532), 17: (2, 31, 0.12007632196670578), 18: (2, 31, 0.1200742292247953), 19: (2, 31, 0.12003895808612147), 20: (2, 31, 0.12012249201295837), 21: (2, 31, 0.12013137364579786), 22: (2, 31, 0.12002746424367351), 23: (2, 31, 0.12004068938474502), 24: (2, 31, 0.12003600852744233), 25: (2, 31, 0.12004913774228865), 26: (2, 31, 0.12002918646941262), 27: (2, 31, 0.12014799237611794), 28: (2, 31, 0.12006731523621467), 29: (2, 31, 0.12008134188551095), 30: (2, 31, 0.12015186580679109), 31: (2, 31, 0.1201176403330699), 32: (2, 31, 0.1200101378884527), 33: (2, 31, 0.1200519877395803), 34: (2, 31, 0.12007972547003339), 35: (2, 31, 0.12017509888016409), 36: (2, 31, 0.12006274181147737), 37: (2, 31, 0.1201990338703317), 38: (2, 31, 0.12008493426706522), 39: (2, 31, 0.12013264240757111), 40: (2, 31, 0.12004278416955663), 41: (2, 31, 0.12000297764015774), 42: (2, 31, 0.11998218457184491), 43: (2, 31, 0.12006829252406474), 44: (2, 31, 0.12011029373013205), 45: (2, 31, 0.1200736798045616), 46: (2, 31, 0.12004461890507129), 47: (2, 31, 0.12006014495367004), 48: (2, 31, 0.12007890891043409), 49: (2, 31, 0.12008681433695939), 50: (2, 31, 0.12009975464353638), 51: (2, 31, 0.12006561833644105), 52: (2, 31, 0.12012979862911086), 53: (2, 31, 0.12015103218295882), 54: (2, 31, 0.12021252353705707), 55: (2, 31, 0.12008308811533835), 56: (2, 31, 0.12009257808207505), 57: (2, 31, 0.12007508874540368), 58: (2, 31, 0.12017221015787893), 59: (2, 31, 0.12006464074816435), 60: (2, 31, 0.1201060511952927), 61: (2, 31, 0.12011834255029116), 62: (2, 31, 0.12001818751976374), 63: (2, 31, 0.12008263429086055), 64: (2, 31, 0.11999446421020454), 65: (2, 31, 0.12013455390209152), 66: (2, 31, 0.12005074328232196), 67: (2, 31, 0.12005803037074304), 68: (2, 31, 0.12005512515503552), 69: (2, 31, 0.12023253276223136), 70: (2, 31, 0.1199362653818342)}\n",
      "{'predict_runtime': 284.7601, 'predict_samples_per_second': 0.495, 'predict_steps_per_second': 0.249}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:44.76\n",
      "  predict_samples_per_second =      0.495\n",
      "  predict_steps_per_second   =      0.249\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.5306851174682379), 2: (4, 0.5118727283552289), 3: (4, 0.5126386154443026), 4: (4, 0.5119033986702561), 5: (4, 0.5118636693805456), 6: (4, 0.5135332746431231), 7: (4, 0.5125452568754554), 8: (4, 0.5127576272934675), 9: (4, 0.5130177959799767), 10: (4, 0.5137245925143361), 11: (4, 0.5132101662456989), 12: (4, 0.5136367734521627), 13: (4, 0.5131777748465538), 14: (4, 0.5129288760945201), 15: (4, 0.5129942065104842), 16: (4, 0.5131893744692206), 17: (4, 0.5127526363357902), 18: (4, 0.5124373380094767), 19: (4, 0.514436331577599), 20: (4, 0.512881807051599), 21: (4, 0.512678206898272), 22: (4, 0.5129269864410162), 23: (4, 0.5139569826424122), 24: (4, 0.5122425565496087), 25: (4, 0.5127257956191897), 26: (4, 0.5129443863406777), 27: (4, 0.5128410160541534), 28: (4, 0.5135106649249792), 29: (4, 0.5123666366562247), 30: (4, 0.5126238064840436), 31: (4, 0.5131109161302447), 32: (4, 0.5125136664137244), 33: (4, 0.5129943443462253), 34: (4, 0.5125618865713477), 35: (4, 0.5125719672068954), 36: (4, 0.5123767582699656), 37: (4, 0.5125177670270205), 38: (4, 0.5120152793824673), 39: (4, 0.5125532569363713), 40: (4, 0.5121440477669239), 41: (4, 0.5124550275504589), 42: (4, 0.5122270183637738), 43: (4, 0.5127416858449578), 44: (4, 0.5123704876750708), 45: (4, 0.5123156569898129), 46: (4, 0.5127044059336185), 47: (4, 0.512561846524477), 48: (4, 0.5127799566835165), 49: (4, 0.5121822273358703), 50: (4, 0.5121651478111744), 51: (4, 0.5123289879411459), 52: (4, 0.5123048480600119), 53: (4, 0.5124774165451527), 54: (4, 0.5122608579695225), 55: (4, 0.5123771773651242), 56: (4, 0.5125630972906947), 57: (4, 0.5122515885159373), 58: (4, 0.5128455758094788), 59: (4, 0.5130982464179397), 60: (4, 0.5125474072992802), 61: (4, 0.5126533675938845), 62: (4, 0.5125893969088793), 63: (4, 0.5129496855661273), 64: (4, 0.5136124240234494), 65: (4, 0.5127151058986783), 66: (4, 0.5126907872036099), 67: (4, 0.5130331544205546), 68: (4, 0.5122804269194603), 69: (4, 0.5128504857420921), 70: (4, 0.5108077507466078), 71: (1, 0.19386501144617796)}\n",
      "{1: (4, 31, 0.12409042792334672), 2: (4, 31, 0.12414182347035216), 3: (4, 31, 0.12408541734780996), 4: (4, 31, 0.1240376471091182), 5: (4, 31, 0.12574386870067927), 6: (4, 31, 0.12492355716324621), 7: (4, 31, 0.12536760344500503), 8: (4, 31, 0.12539097336271116), 9: (4, 31, 0.12533643009561685), 10: (4, 31, 0.12606697322259988), 11: (4, 31, 0.12496702024532903), 12: (4, 31, 0.12498777068310207), 13: (4, 31, 0.12501546217789572), 14: (4, 31, 0.12483630308340635), 15: (4, 31, 0.12505671442035707), 16: (4, 31, 0.1247040421491669), 17: (4, 31, 0.12479293836100448), 18: (4, 31, 0.12497721387133483), 19: (4, 31, 0.12484950899717308), 20: (4, 31, 0.12519778716828553), 21: (4, 31, 0.12478244250580188), 22: (4, 31, 0.12518890604617133), 23: (4, 31, 0.12472220465180374), 24: (4, 31, 0.12431962538750903), 25: (4, 31, 0.12422720279784934), 26: (4, 31, 0.12409903064009643), 27: (4, 31, 0.12407315804833366), 28: (4, 31, 0.12398277944134127), 29: (4, 31, 0.12423472614177773), 30: (4, 31, 0.12405465687474897), 31: (4, 31, 0.12421037758430166), 32: (4, 31, 0.1241251022645062), 33: (4, 31, 0.12415166788043515), 34: (4, 31, 0.12400706752293533), 35: (4, 31, 0.12407833307741149), 36: (4, 31, 0.12408906242419634), 37: (4, 31, 0.12413224136276592), 38: (4, 31, 0.12413754665683355), 39: (4, 31, 0.12412691933493461), 40: (4, 31, 0.12413234972665387), 41: (4, 31, 0.12415196641438431), 42: (4, 31, 0.12410248822021869), 43: (4, 31, 0.1241567262838925), 44: (4, 31, 0.12411729787145892), 45: (4, 31, 0.12412447578484012), 46: (4, 31, 0.12407890211550458), 47: (4, 31, 0.12407443924776969), 48: (4, 31, 0.12424852314495272), 49: (4, 31, 0.12424049433320761), 50: (4, 31, 0.1241877015019136), 51: (4, 31, 0.12419794385711994), 52: (4, 31, 0.12411282767331408), 53: (4, 31, 0.12417554801269885), 54: (4, 31, 0.12415988226571391), 55: (4, 31, 0.1240696691937985), 56: (4, 31, 0.12420156841436701), 57: (4, 31, 0.12424211303192761), 58: (4, 31, 0.1241656829633059), 59: (4, 31, 0.12421511332955092), 60: (4, 31, 0.12507652875877195), 61: (4, 31, 0.12675836447986863), 62: (4, 31, 0.12699024917017068), 63: (4, 31, 0.12526312188035058), 64: (4, 31, 0.1243170025427976), 65: (4, 31, 0.12617422586246843), 66: (4, 31, 0.12433012142296761), 67: (4, 31, 0.12713191700318166), 68: (4, 31, 0.12551027485319682), 69: (4, 31, 0.1246424407788342), 70: (4, 31, 0.12437352129528599)}\n",
      "{'predict_runtime': 308.9403, 'predict_samples_per_second': 0.91, 'predict_steps_per_second': 0.23}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:08.94\n",
      "  predict_samples_per_second =       0.91\n",
      "  predict_steps_per_second   =       0.23\n",
      "Evaluating with num_layers: 17\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.22555291559547186), 2: (1, 0.2052050605416298), 3: (1, 0.20562755968421698), 4: (1, 0.20776396431028843), 5: (1, 0.2054717792198062), 6: (1, 0.20575285889208317), 7: (1, 0.2054868098348379), 8: (1, 0.2055043699219823), 9: (1, 0.20524345058947802), 10: (1, 0.20580639876425266), 11: (1, 0.2053157603368163), 12: (1, 0.20546347927302122), 13: (1, 0.20535563956946135), 14: (1, 0.20556671917438507), 15: (1, 0.20535598043352365), 16: (1, 0.20545264892280102), 17: (1, 0.20526948012411594), 18: (1, 0.2055917987599969), 19: (1, 0.20635422691702843), 20: (1, 0.20599001832306385), 21: (1, 0.2056388696655631), 22: (1, 0.20601198822259903), 23: (1, 0.20617028791457415), 24: (1, 0.20599541906267405), 25: (1, 0.20573408901691437), 26: (1, 0.2061774069443345), 27: (1, 0.2065860154107213), 28: (1, 0.20607763808220625), 29: (1, 0.20623945724219084), 30: (1, 0.20588107965886593), 31: (1, 0.2079560523852706), 32: (1, 0.2061814172193408), 33: (1, 0.20586353726685047), 34: (1, 0.20577167812734842), 35: (1, 0.20602991804480553), 36: (1, 0.20590909849852324), 37: (1, 0.20590276923030615), 38: (1, 0.2060391576960683), 39: (1, 0.2070094244554639), 40: (1, 0.20588729809969664), 41: (1, 0.20599153731018305), 42: (1, 0.20622774865478277), 43: (1, 0.20604956801980734), 44: (1, 0.20589336846023798), 45: (1, 0.20650254748761654), 46: (1, 0.20617665816098452), 47: (1, 0.2061446886509657), 48: (1, 0.20588604733347893), 49: (1, 0.20592408813536167), 50: (1, 0.20718736480921507), 51: (1, 0.20597998797893524), 52: (1, 0.20616723783314228), 53: (1, 0.20583851914852858), 54: (1, 0.2060993378981948), 55: (1, 0.206144567579031), 56: (1, 0.2061759065836668), 57: (1, 0.20590811874717474), 58: (1, 0.20590516831725836), 59: (1, 0.20628844760358334), 60: (1, 0.2059270478785038), 61: (1, 0.20591073855757713), 62: (1, 0.206318236887455), 63: (1, 0.20589372888207436), 64: (1, 0.20587585773319006), 65: (1, 0.20592079777270555), 66: (1, 0.20594858843833208), 67: (1, 0.20562690030783415), 68: (1, 0.20604803878813982), 69: (1, 0.20598438754677773), 70: (1, 0.20599650871008635), 71: (1, 0.20510783046483994)}\n",
      "{1: (1, 31, 0.07992691702900394), 2: (1, 31, 0.07915550446318041), 3: (1, 31, 0.07809451889366872), 4: (1, 31, 0.07971563818113457), 5: (1, 31, 0.07724670834478832), 6: (1, 31, 0.0771463246595475), 7: (1, 31, 0.07769371283751342), 8: (1, 31, 0.07746801017633369), 9: (1, 31, 0.07737700088370231), 10: (1, 31, 0.07738413099920557), 11: (1, 31, 0.0772270594513224), 12: (1, 31, 0.0771657355550316), 13: (1, 31, 0.07716231042098615), 14: (1, 31, 0.07707184592201825), 15: (1, 31, 0.07722018370705266), 16: (1, 31, 0.07715929392725229), 17: (1, 31, 0.07710292923354334), 18: (1, 31, 0.07753372450749721), 19: (1, 31, 0.07727104797959328), 20: (1, 31, 0.0771203888580203), 21: (1, 31, 0.07714356346836974), 22: (1, 31, 0.07725035471300926), 23: (1, 31, 0.07714024489565242), 24: (1, 31, 0.07710244452520724), 25: (1, 31, 0.07724966916946634), 26: (1, 31, 0.07728584525325606), 27: (1, 31, 0.0773497482821826), 28: (1, 31, 0.07725451784508844), 29: (1, 31, 0.07716812998537094), 30: (1, 31, 0.07741585325810217), 31: (1, 31, 0.07742011399879571), 32: (1, 31, 0.0771303101472797), 33: (1, 31, 0.077323965007259), 34: (1, 31, 0.07715079110235937), 35: (1, 31, 0.07704357748791095), 36: (1, 31, 0.07714377283569306), 37: (1, 31, 0.0771611655251153), 38: (1, 31, 0.07736583324449678), 39: (1, 31, 0.07701940495040148), 40: (1, 31, 0.07706739540181813), 41: (1, 31, 0.07722350405228715), 42: (1, 31, 0.0771436088628346), 43: (1, 31, 0.07726419638962514), 44: (1, 31, 0.08085578983469356), 45: (1, 31, 0.07839833779801283), 46: (1, 31, 0.08004530396072133), 47: (1, 31, 0.08004399524220536), 48: (1, 31, 0.07771658095260782), 49: (1, 31, 0.07861823934100327), 50: (1, 31, 0.0799948807144838), 51: (1, 31, 0.07761220603940948), 52: (1, 31, 0.07853032185906364), 53: (1, 31, 0.07987620435174435), 54: (1, 31, 0.08092237807690136), 55: (1, 31, 0.0772288175179593), 56: (1, 31, 0.0776318144654074), 57: (1, 31, 0.07723141016979371), 58: (1, 31, 0.07720956473701424), 59: (1, 31, 0.07976199250908629), 60: (1, 31, 0.0771896849656778), 61: (1, 31, 0.07725302436419072), 62: (1, 31, 0.07937481563778655), 63: (1, 31, 0.07718271819213705), 64: (1, 31, 0.07713873185698063), 65: (1, 31, 0.07754638953314673), 66: (1, 31, 0.07712040072487246), 67: (1, 31, 0.08128997650478155), 68: (1, 31, 0.07713167002845195), 69: (1, 31, 0.07704557905033711), 70: (1, 31, 0.08116856385623256)}\n",
      "{'predict_runtime': 186.2006, 'predict_samples_per_second': 0.381, 'predict_steps_per_second': 0.381}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:06.20\n",
      "  predict_samples_per_second =      0.381\n",
      "  predict_steps_per_second   =      0.381\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.3411046676337719), 2: (2, 0.32094331085681915), 3: (2, 0.32108019944280386), 4: (2, 0.32100246008485556), 5: (2, 0.32079282123595476), 6: (2, 0.3212030502036214), 7: (2, 0.3215858479961753), 8: (2, 0.32132989913225174), 9: (2, 0.3217159975320101), 10: (2, 0.3211044892668724), 11: (2, 0.3223761059343815), 12: (2, 0.3213661387562752), 13: (2, 0.32216372713446617), 14: (2, 0.32191324792802334), 15: (2, 0.3228788059204817), 16: (2, 0.321806687861681), 17: (2, 0.3221217868849635), 18: (2, 0.32395942229777575), 19: (2, 0.3218144178390503), 20: (2, 0.3222337272018194), 21: (2, 0.3223971053957939), 22: (2, 0.3227067459374666), 23: (2, 0.3228963455185294), 24: (2, 0.3228744650259614), 25: (2, 0.32256592623889446), 26: (2, 0.32241140585392714), 27: (2, 0.32277457509189844), 28: (2, 0.32210029661655426), 29: (2, 0.3237312426790595), 30: (2, 0.32249043602496386), 31: (2, 0.32252428587526083), 32: (2, 0.32237404584884644), 33: (2, 0.32244225684553385), 34: (2, 0.3225857950747013), 35: (2, 0.32221299689263105), 36: (2, 0.3224587272852659), 37: (2, 0.3227608846500516), 38: (2, 0.321947337128222), 39: (2, 0.3228109562769532), 40: (2, 0.32230291701853275), 41: (2, 0.3226078161969781), 42: (2, 0.3226108755916357), 43: (2, 0.32235892675817013), 44: (2, 0.3223971361294389), 45: (2, 0.3225014256313443), 46: (2, 0.32239216659218073), 47: (2, 0.3223171764984727), 48: (2, 0.3223651172593236), 49: (2, 0.3227751860395074), 50: (2, 0.32237190660089254), 51: (2, 0.3223185772076249), 52: (2, 0.3222373565658927), 53: (2, 0.3229428045451641), 54: (2, 0.322330666705966), 55: (2, 0.3222913360223174), 56: (2, 0.32206672709435225), 57: (2, 0.3218721682205796), 58: (2, 0.32237345539033413), 59: (2, 0.32239527627825737), 60: (2, 0.3226204663515091), 61: (2, 0.3222783450037241), 62: (2, 0.3220810452476144), 63: (2, 0.32253421377390623), 64: (2, 0.32149527687579393), 65: (2, 0.322057674638927), 66: (2, 0.3217966966331005), 67: (2, 0.322110285051167), 68: (2, 0.3214548071846366), 69: (2, 0.3231080425903201), 70: (2, 0.3208806272596121), 71: (1, 0.20526754669845104)}\n",
      "{1: (2, 31, 0.12732797924188838), 2: (2, 31, 0.12844602538332825), 3: (2, 31, 0.1273269372421407), 4: (2, 31, 0.12843676887813113), 5: (2, 31, 0.12731891795391997), 6: (2, 31, 0.12731371162038657), 7: (2, 31, 0.1283963396544418), 8: (2, 31, 0.13041147397410485), 9: (2, 31, 0.1289581415213404), 10: (2, 31, 0.12995305501164928), 11: (2, 31, 0.1298154212774769), 12: (2, 31, 0.12796723914723243), 13: (2, 31, 0.12978299214474617), 14: (2, 31, 0.12815368920564651), 15: (2, 31, 0.1294986873023933), 16: (2, 31, 0.12845613449932106), 17: (2, 31, 0.12851078904444171), 18: (2, 31, 0.12752582156850445), 19: (2, 31, 0.12750747778843488), 20: (2, 31, 0.12742935355392196), 21: (2, 31, 0.12776500942005264), 22: (2, 31, 0.1288761109293949), 23: (2, 31, 0.1282121787268308), 24: (2, 31, 0.12873718361820904), 25: (2, 31, 0.12833782964416088), 26: (2, 31, 0.12826178352078121), 27: (2, 31, 0.12837720674372488), 28: (2, 31, 0.12862181669521716), 29: (2, 31, 0.12855231746911042), 30: (2, 31, 0.1282965835003603), 31: (2, 31, 0.12853747630311596), 32: (2, 31, 0.12812666147346458), 33: (2, 31, 0.12822766653111867), 34: (2, 31, 0.1282589726390377), 35: (2, 31, 0.12814199467820506), 36: (2, 31, 0.1283577510546292), 37: (2, 31, 0.12863970890400872), 38: (2, 31, 0.12834370890331845), 39: (2, 31, 0.1286660310241484), 40: (2, 31, 0.1284916166576647), 41: (2, 31, 0.12893463767343952), 42: (2, 31, 0.1281959759371896), 43: (2, 31, 0.12838253267710248), 44: (2, 31, 0.12831698814707418), 45: (2, 31, 0.12821581761442846), 46: (2, 31, 0.12867233499644265), 47: (2, 31, 0.12814189511681756), 48: (2, 31, 0.1281943405047059), 49: (2, 31, 0.12818720591284574), 50: (2, 31, 0.1281990316966849), 51: (2, 31, 0.12812733941621357), 52: (2, 31, 0.12864357707721571), 53: (2, 31, 0.12829371776071288), 54: (2, 31, 0.1282506958251038), 55: (2, 31, 0.12827497985093825), 56: (2, 31, 0.12837627160573198), 57: (2, 31, 0.12819663612472434), 58: (2, 31, 0.12939929676752898), 59: (2, 31, 0.12819142810880177), 60: (2, 31, 0.12825648711934204), 61: (2, 31, 0.12825107228972257), 62: (2, 31, 0.12889717963914718), 63: (2, 31, 0.1273523301426922), 64: (2, 31, 0.12719493239156662), 65: (2, 31, 0.12783088174558455), 66: (2, 31, 0.12745442544861185), 67: (2, 31, 0.12733129958712286), 68: (2, 31, 0.12781220344045469), 69: (2, 31, 0.1278068350567933), 70: (2, 31, 0.1272837554495181)}\n",
      "{'predict_runtime': 303.8335, 'predict_samples_per_second': 0.464, 'predict_steps_per_second': 0.234}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:03.83\n",
      "  predict_samples_per_second =      0.464\n",
      "  predict_steps_per_second   =      0.234\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.5641478002071381), 2: (4, 0.5426825694739819), 3: (4, 0.5447722328826785), 4: (4, 0.543488166294992), 5: (4, 0.543095207773149), 6: (4, 0.5435528075322509), 7: (4, 0.5439651552587748), 8: (4, 0.5434102369472384), 9: (4, 0.5436047166585922), 10: (4, 0.5440118154510856), 11: (4, 0.5451193228363991), 12: (4, 0.5443064542487264), 13: (4, 0.5432405676692724), 14: (4, 0.5439849952235818), 15: (4, 0.5432749381288886), 16: (4, 0.543599097058177), 17: (4, 0.5429814578965306), 18: (4, 0.5432347180321813), 19: (4, 0.5430051777511835), 20: (4, 0.5432209372520447), 21: (4, 0.543006768450141), 22: (4, 0.5443143453449011), 23: (4, 0.5433168979361653), 24: (4, 0.5435800775885582), 25: (4, 0.5431530382484198), 26: (4, 0.5436157956719398), 27: (4, 0.5432390077039599), 28: (4, 0.5430186679586768), 29: (4, 0.5430190088227391), 30: (4, 0.542969879694283), 31: (4, 0.5434758868068457), 32: (4, 0.5428743595257401), 33: (4, 0.5442415159195662), 34: (4, 0.5437919059768319), 35: (4, 0.5429164590314031), 36: (4, 0.5427195904776454), 37: (4, 0.5431068381294608), 38: (4, 0.543232218362391), 39: (4, 0.5431289179250598), 40: (4, 0.5429924689233303), 41: (4, 0.5433909269049764), 42: (4, 0.5434863474220037), 43: (4, 0.5432548178359866), 44: (4, 0.5429743677377701), 45: (4, 0.5438260156661272), 46: (4, 0.5430159475654364), 47: (4, 0.5432049576193094), 48: (4, 0.5432389779016376), 49: (4, 0.5429065087810159), 50: (4, 0.5432150587439537), 51: (4, 0.5434512281790376), 52: (4, 0.5433819778263569), 53: (4, 0.5432109981775284), 54: (4, 0.5431476682424545), 55: (4, 0.5425084196031094), 56: (4, 0.5432414775714278), 57: (4, 0.5434453375637531), 58: (4, 0.5434942273423076), 59: (4, 0.5434209788218141), 60: (4, 0.5429319078102708), 61: (4, 0.5431973580271006), 62: (4, 0.5430729277431965), 63: (4, 0.5429929494857788), 64: (4, 0.5435551563277841), 65: (4, 0.5429446492344141), 66: (4, 0.5431574378162622), 67: (4, 0.5432401467114687), 68: (4, 0.5429593380540609), 69: (4, 0.5431232592090964), 70: (4, 0.5415937015786767), 71: (1, 0.20535207632929087)}\n",
      "{1: (4, 31, 0.13251164756835468), 2: (4, 31, 0.13257400496231933), 3: (4, 31, 0.13324472248073546), 4: (4, 31, 0.1324979174401491), 5: (4, 31, 0.13271883436508716), 6: (4, 31, 0.1324620270020058), 7: (4, 31, 0.13289578039679797), 8: (4, 31, 0.1326473684560868), 9: (4, 31, 0.13242111748625193), 10: (4, 31, 0.13257923187507736), 11: (4, 31, 0.13249900504466025), 12: (4, 31, 0.13296889153219038), 13: (4, 31, 0.13245753541348443), 14: (4, 31, 0.13234422022416706), 15: (4, 31, 0.13254566854166408), 16: (4, 31, 0.13267381690562732), 17: (4, 31, 0.13151759179609437), 18: (4, 31, 0.13433723647387757), 19: (4, 31, 0.1314776917438834), 20: (4, 31, 0.13143649997730408), 21: (4, 31, 0.131588238681997), 22: (4, 31, 0.13240658621033352), 23: (4, 31, 0.13154482874538628), 24: (4, 31, 0.1325813769813507), 25: (4, 31, 0.13195350979484857), 26: (4, 31, 0.13140505083626317), 27: (4, 31, 0.1320963529869914), 28: (4, 31, 0.1314124116193383), 29: (4, 31, 0.1314938755766038), 30: (4, 31, 0.13141014880590862), 31: (4, 31, 0.13145181443542242), 32: (4, 31, 0.1316277877758107), 33: (4, 31, 0.1319516189696808), 34: (4, 31, 0.13151328716306918), 35: (4, 31, 0.13210301125241863), 36: (4, 31, 0.1320084960410191), 37: (4, 31, 0.13148755435982057), 38: (4, 31, 0.13141804479903751), 39: (4, 31, 0.13159309925451393), 40: (4, 31, 0.1325278456412977), 41: (4, 31, 0.13152050515336375), 42: (4, 31, 0.13207679854766016), 43: (4, 31, 0.13153403615879436), 44: (4, 31, 0.1318760061816823), 45: (4, 31, 0.13172542312813382), 46: (4, 31, 0.1316768998700765), 47: (4, 31, 0.13160550534244506), 48: (4, 31, 0.1314223631014747), 49: (4, 31, 0.13288093463427597), 50: (4, 31, 0.13233048123337568), 51: (4, 31, 0.13159336909771926), 52: (4, 31, 0.1313903278581077), 53: (4, 31, 0.13153751383745863), 54: (4, 31, 0.13147248997683486), 55: (4, 31, 0.13140968338496262), 56: (4, 31, 0.13150686704583706), 57: (4, 31, 0.1326711951424518), 58: (4, 31, 0.1314232920206362), 59: (4, 31, 0.1323039083771648), 60: (4, 31, 0.13147045753055042), 61: (4, 31, 0.1324762802330717), 62: (4, 31, 0.13137455768282374), 63: (4, 31, 0.13481002913848047), 64: (4, 31, 0.13154249322871048), 65: (4, 31, 0.13219890391994868), 66: (4, 31, 0.1315220859081995), 67: (4, 31, 0.1319149794477609), 68: (4, 31, 0.13191612638653286), 69: (4, 31, 0.13180840387940407), 70: (4, 31, 0.13152539787153084)}\n",
      "{'predict_runtime': 327.3362, 'predict_samples_per_second': 0.858, 'predict_steps_per_second': 0.217}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:27.33\n",
      "  predict_samples_per_second =      0.858\n",
      "  predict_steps_per_second   =      0.217\n",
      "Evaluating with num_layers: 18\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.2388932341709733), 2: (1, 0.21729127317667007), 3: (1, 0.2172405943274498), 4: (1, 0.2177976006641984), 5: (1, 0.2220388799905777), 6: (1, 0.22294319793581963), 7: (1, 0.2219837699085474), 8: (1, 0.22174035105854273), 9: (1, 0.22305669635534286), 10: (1, 0.22051658481359482), 11: (1, 0.2196470471099019), 12: (1, 0.22025743499398232), 13: (1, 0.21805529110133648), 14: (1, 0.21989924646914005), 15: (1, 0.2204720936715603), 16: (1, 0.21996983606368303), 17: (1, 0.21760942321270704), 18: (1, 0.21971533633768559), 19: (1, 0.21867765858769417), 20: (1, 0.2183242402970791), 21: (1, 0.21977417636662722), 22: (1, 0.21960651688277721), 23: (1, 0.21812552120536566), 24: (1, 0.22067458368837833), 25: (1, 0.21843626908957958), 26: (1, 0.21803920064121485), 27: (1, 0.21813479159027338), 28: (1, 0.21774201188236475), 29: (1, 0.21768853161484003), 30: (1, 0.21775888185948133), 31: (1, 0.21753115206956863), 32: (1, 0.217628282494843), 33: (1, 0.21759510319679976), 34: (1, 0.21756239235401154), 35: (1, 0.21754311304539442), 36: (1, 0.21749786287546158), 37: (1, 0.21739565301686525), 38: (1, 0.217638841830194), 39: (1, 0.21824469976127148), 40: (1, 0.21779751125723124), 41: (1, 0.21745724324136972), 42: (1, 0.21795629058033228), 43: (1, 0.2176855718716979), 44: (1, 0.2173898033797741), 45: (1, 0.21760490164160728), 46: (1, 0.21757655125111341), 47: (1, 0.2175254812464118), 48: (1, 0.21752424258738756), 49: (1, 0.21748670283704996), 50: (1, 0.21767668146640062), 51: (1, 0.21757097262889147), 52: (1, 0.21759704314172268), 53: (1, 0.21768507175147533), 54: (1, 0.21766557171940804), 55: (1, 0.21737351268529892), 56: (1, 0.2174064526334405), 57: (1, 0.2183729400858283), 58: (1, 0.21768468152731657), 59: (1, 0.21766266226768494), 60: (1, 0.2176267122849822), 61: (1, 0.21727041341364384), 62: (1, 0.21746594365686178), 63: (1, 0.21847476996481419), 64: (1, 0.21772448252886534), 65: (1, 0.21746586170047522), 66: (1, 0.2181152207776904), 67: (1, 0.21739466302096844), 68: (1, 0.21759114228188992), 69: (1, 0.2181039210408926), 70: (1, 0.2176577616482973), 71: (1, 0.21672136429697275)}\n",
      "{1: (1, 31, 0.08202837620891872), 2: (1, 31, 0.08231555577367544), 3: (1, 31, 0.08211130708936722), 4: (1, 31, 0.08273187904588637), 5: (1, 31, 0.08226407316303061), 6: (1, 31, 0.08256881155313985), 7: (1, 31, 0.08231671848484585), 8: (1, 31, 0.08277810854657043), 9: (1, 31, 0.08236213016413874), 10: (1, 31, 0.08325321539755791), 11: (1, 31, 0.08241112244826171), 12: (1, 31, 0.08249027549379295), 13: (1, 31, 0.08247912440809511), 14: (1, 31, 0.08232823999658707), 15: (1, 31, 0.08238817784454554), 16: (1, 31, 0.08220993454057363), 17: (1, 31, 0.08186967163196494), 18: (1, 31, 0.0823109408299769), 19: (1, 31, 0.08200397859177282), 20: (1, 31, 0.0822885652042685), 21: (1, 31, 0.0820917773751482), 22: (1, 31, 0.08216457819986728), 23: (1, 31, 0.08196160116142803), 24: (1, 31, 0.08255076750872596), 25: (1, 31, 0.08204754577168534), 26: (1, 31, 0.08239079371935898), 27: (1, 31, 0.08211113203076585), 28: (1, 31, 0.08235432294708106), 29: (1, 31, 0.08214513098280277), 30: (1, 31, 0.0823701888082489), 31: (1, 31, 0.08217670194684498), 32: (1, 31, 0.08219884903801064), 33: (1, 31, 0.08196537977745456), 34: (1, 31, 0.08217871231177161), 35: (1, 31, 0.0822106758132577), 36: (1, 31, 0.08206806578222782), 37: (1, 31, 0.08174972867052402), 38: (1, 31, 0.08206221392197956), 39: (1, 31, 0.0818722989229906), 40: (1, 31, 0.08189705681175954), 41: (1, 31, 0.08202080077101145), 42: (1, 31, 0.0818905958365048), 43: (1, 31, 0.08190467301756144), 44: (1, 31, 0.08191106183033797), 45: (1, 31, 0.08217419515694341), 46: (1, 31, 0.08229997904310303), 47: (1, 31, 0.08204541100008834), 48: (1, 31, 0.0819624864285992), 49: (1, 31, 0.08175656890436526), 50: (1, 31, 0.08238106686621904), 51: (1, 31, 0.08211972567463113), 52: (1, 31, 0.08220472312983006), 53: (1, 31, 0.08211914840484819), 54: (1, 31, 0.08233412403252817), 55: (1, 31, 0.08201166527766374), 56: (1, 31, 0.08201767660437091), 57: (1, 31, 0.08281588602450586), 58: (1, 31, 0.08210438871455769), 59: (1, 31, 0.08222171871532355), 60: (1, 31, 0.08191665219924142), 61: (1, 31, 0.08218753995794442), 62: (1, 31, 0.08224579349400536), 63: (1, 31, 0.08179844960930847), 64: (1, 31, 0.08226172568937463), 65: (1, 31, 0.08173911375624518), 66: (1, 31, 0.08213525544852018), 67: (1, 31, 0.08202498060681167), 68: (1, 31, 0.0818908279761672), 69: (1, 31, 0.08190485844088177), 70: (1, 31, 0.08223739239357171)}\n",
      "{'predict_runtime': 196.5586, 'predict_samples_per_second': 0.361, 'predict_steps_per_second': 0.361}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:16.55\n",
      "  predict_samples_per_second =      0.361\n",
      "  predict_steps_per_second   =      0.361\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.36044652946293354), 2: (2, 0.3456463795155287), 3: (2, 0.343353777192533), 4: (2, 0.3434353172779083), 5: (2, 0.34299938660115004), 6: (2, 0.34372793789952993), 7: (2, 0.34283658023923635), 8: (2, 0.34414708614349365), 9: (2, 0.3431643098592758), 10: (2, 0.3425934100523591), 11: (2, 0.34195633232593536), 12: (2, 0.3423635410144925), 13: (2, 0.3412677850574255), 14: (2, 0.3434188598766923), 15: (2, 0.34151178412139416), 16: (2, 0.3413498243317008), 17: (2, 0.34114063531160355), 18: (2, 0.34164885338395834), 19: (2, 0.3409069748595357), 20: (2, 0.3411482749506831), 21: (2, 0.3404069561511278), 22: (2, 0.33976191841065884), 23: (2, 0.34017577674239874), 24: (2, 0.34025206696242094), 25: (2, 0.3403633562847972), 26: (2, 0.3401328781619668), 27: (2, 0.34026740677654743), 28: (2, 0.33994762785732746), 29: (2, 0.33983889874070883), 30: (2, 0.340549586340785), 31: (2, 0.3394233901053667), 32: (2, 0.34035474713891745), 33: (2, 0.33997755870223045), 34: (2, 0.3401707364246249), 35: (2, 0.3402395863085985), 36: (2, 0.33984832745045424), 37: (2, 0.33993687853217125), 38: (2, 0.33998290821909904), 39: (2, 0.33988417871296406), 40: (2, 0.3401920571923256), 41: (2, 0.339996637776494), 42: (2, 0.33970940858125687), 43: (2, 0.33965753950178623), 44: (2, 0.33994109742343426), 45: (2, 0.33977438788861036), 46: (2, 0.3400992564857006), 47: (2, 0.34002481680363417), 48: (2, 0.33997535798698664), 49: (2, 0.34014606662094593), 50: (2, 0.3401199271902442), 51: (2, 0.3399221682921052), 52: (2, 0.3398624276742339), 53: (2, 0.3400087282061577), 54: (2, 0.34014384634792805), 55: (2, 0.33990173786878586), 56: (2, 0.34020096715539694), 57: (2, 0.33994520734995604), 58: (2, 0.340125166811049), 59: (2, 0.34056669659912586), 60: (2, 0.339977378025651), 61: (2, 0.3401563875377178), 62: (2, 0.34002222772687674), 63: (2, 0.3402770170941949), 64: (2, 0.3392004994675517), 65: (2, 0.3403688659891486), 66: (2, 0.339934098534286), 67: (2, 0.34017977863550186), 68: (2, 0.33983183838427067), 69: (2, 0.34080964606255293), 70: (2, 0.3387202313169837), 71: (1, 0.21680188551545143)}\n",
      "{1: (2, 31, 0.13640016978306155), 2: (2, 31, 0.13568451267576986), 3: (2, 31, 0.13528838161859782), 4: (2, 31, 0.13631138905522325), 5: (2, 31, 0.1352949369578592), 6: (2, 31, 0.13568200558544166), 7: (2, 31, 0.13600457204325545), 8: (2, 31, 0.13578282780344447), 9: (2, 31, 0.13592618733884826), 10: (2, 31, 0.13597365105224232), 11: (2, 31, 0.13574663847084006), 12: (2, 31, 0.1362667577341199), 13: (2, 31, 0.13549482275641733), 14: (2, 31, 0.13621558840837208), 15: (2, 31, 0.13476676830360967), 16: (2, 31, 0.13488785465878825), 17: (2, 31, 0.1347423960725146), 18: (2, 31, 0.13464953314753308), 19: (2, 31, 0.13599115580080018), 20: (2, 31, 0.13489616013342334), 21: (2, 31, 0.13516407072423928), 22: (2, 31, 0.1344861519793349), 23: (2, 31, 0.13458122487270063), 24: (2, 31, 0.13530588456459583), 25: (2, 31, 0.13570414375393622), 26: (2, 31, 0.13494550833298313), 27: (2, 31, 0.1352344598440874), 28: (2, 31, 0.1349537119629883), 29: (2, 31, 0.13489854795437667), 30: (2, 31, 0.13495116254254694), 31: (2, 31, 0.13467096735633188), 32: (2, 31, 0.1349751479142616), 33: (2, 31, 0.13488144118098483), 34: (2, 31, 0.1346203343522164), 35: (2, 31, 0.13453158279580454), 36: (2, 31, 0.13453489914536476), 37: (2, 31, 0.13469432294368744), 38: (2, 31, 0.134536586521614), 39: (2, 31, 0.13462952572491863), 40: (2, 31, 0.1347347322791334), 41: (2, 31, 0.13456543559028256), 42: (2, 31, 0.13461286640695988), 43: (2, 31, 0.13472838741877385), 44: (2, 31, 0.13485685411480167), 45: (2, 31, 0.13477786984895507), 46: (2, 31, 0.13471250151914935), 47: (2, 31, 0.13473267964417895), 48: (2, 31, 0.1347174922364854), 49: (2, 31, 0.13463611173773965), 50: (2, 31, 0.1345979437652615), 51: (2, 31, 0.13475513761682856), 52: (2, 31, 0.1345811416545222), 53: (2, 31, 0.1345575133398656), 54: (2, 31, 0.1345582419946309), 55: (2, 31, 0.13460445842675625), 56: (2, 31, 0.13462463604106056), 57: (2, 31, 0.1345682729396128), 58: (2, 31, 0.13470495534279653), 59: (2, 31, 0.13458088004300672), 60: (2, 31, 0.1347802507901384), 61: (2, 31, 0.1345860090166811), 62: (2, 31, 0.1345489548759595), 63: (2, 31, 0.13472616999980905), 64: (2, 31, 0.13440959068435815), 65: (2, 31, 0.1345601124508727), 66: (2, 31, 0.134532522530325), 67: (2, 31, 0.13495844082846756), 68: (2, 31, 0.13445749479315935), 69: (2, 31, 0.13454359084848436), 70: (2, 31, 0.1344581286633207)}\n",
      "{'predict_runtime': 319.6615, 'predict_samples_per_second': 0.441, 'predict_steps_per_second': 0.222}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:19.66\n",
      "  predict_samples_per_second =      0.441\n",
      "  predict_steps_per_second   =      0.222\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.5927644157782197), 2: (4, 0.5783491339534521), 3: (4, 0.5798245100304484), 4: (4, 0.57796261459589), 5: (4, 0.5779103748500347), 6: (4, 0.5749932015314698), 7: (4, 0.5771682364866138), 8: (4, 0.5762227308005095), 9: (4, 0.574884464032948), 10: (4, 0.5742839649319649), 11: (4, 0.5745169250294566), 12: (4, 0.5740108573809266), 13: (4, 0.5767399091273546), 14: (4, 0.5735698072239757), 15: (4, 0.5752183832228184), 16: (4, 0.5742671452462673), 17: (4, 0.5745764849707484), 18: (4, 0.574103825725615), 19: (4, 0.5747637944296002), 20: (4, 0.574064495973289), 21: (4, 0.5746646346524358), 22: (4, 0.57430415507406), 23: (4, 0.5748641444370151), 24: (4, 0.5738862659782171), 25: (4, 0.575942081399262), 26: (4, 0.5742750959470868), 27: (4, 0.5742570664733648), 28: (4, 0.5740062072873116), 29: (4, 0.5741628063842654), 30: (4, 0.5740292659029365), 31: (4, 0.5739102363586426), 32: (4, 0.5741045661270618), 33: (4, 0.574845083989203), 34: (4, 0.5739504471421242), 35: (4, 0.5737778265029192), 36: (4, 0.5739518674090505), 37: (4, 0.5741904163733125), 38: (4, 0.5739705758169293), 39: (4, 0.574362974613905), 40: (4, 0.5739600453525782), 41: (4, 0.5739746959879994), 42: (4, 0.5745423249900341), 43: (4, 0.5741837564855814), 44: (4, 0.5739726172760129), 45: (4, 0.5745341153815389), 46: (4, 0.5744438748806715), 47: (4, 0.5741045763716102), 48: (4, 0.5741234561428428), 49: (4, 0.5741360858082771), 50: (4, 0.5737364776432514), 51: (4, 0.5742236552760005), 52: (4, 0.5737936170771718), 53: (4, 0.5738692069426179), 54: (4, 0.5742500955238938), 55: (4, 0.5739124668762088), 56: (4, 0.5746196648105979), 57: (4, 0.5738955270498991), 58: (4, 0.5744708348065615), 59: (4, 0.5738025261089206), 60: (4, 0.5738025372847915), 61: (4, 0.5742559749633074), 62: (4, 0.5740534160286188), 63: (4, 0.5735497074201703), 64: (4, 0.5745977442711592), 65: (4, 0.5735424170270562), 66: (4, 0.5741770965978503), 67: (4, 0.5745108546689153), 68: (4, 0.5739500652998686), 69: (4, 0.5745163140818477), 70: (4, 0.5724491998553276), 71: (1, 0.2170365648344159)}\n",
      "{1: (4, 31, 0.13991775498875686), 2: (4, 31, 0.13948507805264765), 3: (4, 31, 0.1394034564915684), 4: (4, 31, 0.1393313796349591), 5: (4, 31, 0.13923442477901135), 6: (4, 31, 0.13925992096624068), 7: (4, 31, 0.13918060268605909), 8: (4, 31, 0.13925374067959287), 9: (4, 31, 0.13921790473884152), 10: (4, 31, 0.13909479852525458), 11: (4, 31, 0.13915666300923593), 12: (4, 31, 0.1393120213441791), 13: (4, 31, 0.1390905979600164), 14: (4, 31, 0.1392532926833918), 15: (4, 31, 0.13913405656574235), 16: (4, 31, 0.1391925840007682), 17: (4, 31, 0.1390509357856166), 18: (4, 31, 0.13915555131050847), 19: (4, 31, 0.13909846634393738), 20: (4, 31, 0.1390188938427356), 21: (4, 31, 0.1390430984658099), 22: (4, 31, 0.13909736440907564), 23: (4, 31, 0.13902423272450123), 24: (4, 31, 0.13903760456389958), 25: (4, 31, 0.13919726233448712), 26: (4, 31, 0.1391603840034335), 27: (4, 31, 0.1412694065441047), 28: (4, 31, 0.13892300264729607), 29: (4, 31, 0.13937963668497338), 30: (4, 31, 0.1398118555005039), 31: (4, 31, 0.14089500372328104), 32: (4, 31, 0.1388650894345295), 33: (4, 31, 0.13914715865206334), 34: (4, 31, 0.13960963499642187), 35: (4, 31, 0.1405092289130534), 36: (4, 31, 0.13896709055669845), 37: (4, 31, 0.13924945569446973), 38: (4, 31, 0.13917391720197855), 39: (4, 31, 0.13898236953443097), 40: (4, 31, 0.13926411381051426), 41: (4, 31, 0.1392060483114854), 42: (4, 31, 0.14079686930222857), 43: (4, 31, 0.1397314345944793), 44: (4, 31, 0.13996226950398377), 45: (4, 31, 0.139219788443898), 46: (4, 31, 0.13961175597843625), 47: (4, 31, 0.13929367401907522), 48: (4, 31, 0.13895167620672333), 49: (4, 31, 0.14113459889326366), 50: (4, 31, 0.13959033946476637), 51: (4, 31, 0.13905886392439565), 52: (4, 31, 0.13900840778144136), 53: (4, 31, 0.13900396984911734), 54: (4, 31, 0.13897026600616594), 55: (4, 31, 0.13887921603576792), 56: (4, 31, 0.13903564635303714), 57: (4, 31, 0.1392198331473816), 58: (4, 31, 0.13894602310873808), 59: (4, 31, 0.13949032524420368), 60: (4, 31, 0.13908963629435148), 61: (4, 31, 0.13975525938815647), 62: (4, 31, 0.13961436449279707), 63: (4, 31, 0.13936857500624272), 64: (4, 31, 0.13916094198582635), 65: (4, 31, 0.13928184261725796), 66: (4, 31, 0.13911365828807315), 67: (4, 31, 0.13913946048987488), 68: (4, 31, 0.13904602924782422), 69: (4, 31, 0.13915776260076992), 70: (4, 31, 0.1392359451480931)}\n",
      "{'predict_runtime': 345.5294, 'predict_samples_per_second': 0.813, 'predict_steps_per_second': 0.205}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:45.52\n",
      "  predict_samples_per_second =      0.813\n",
      "  predict_steps_per_second   =      0.205\n",
      "Evaluating with num_layers: 19\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.24949820525944233), 2: (1, 0.23055278789252043), 3: (1, 0.23273732047528028), 4: (1, 0.2325651627033949), 5: (1, 0.22922839038074017), 6: (1, 0.23193116392940283), 7: (1, 0.22999450843781233), 8: (1, 0.22945443075150251), 9: (1, 0.22930629085749388), 10: (1, 0.23141711577773094), 11: (1, 0.22921988181769848), 12: (1, 0.2297851499170065), 13: (1, 0.22954048961400986), 14: (1, 0.22938582114875317), 15: (1, 0.2293202606961131), 16: (1, 0.22985164914280176), 17: (1, 0.22947508096694946), 18: (1, 0.22963375970721245), 19: (1, 0.22939415089786053), 20: (1, 0.22942034155130386), 21: (1, 0.22922866232693195), 22: (1, 0.22946914099156857), 23: (1, 0.22967303078621626), 24: (1, 0.2294117109850049), 25: (1, 0.22923474106937647), 26: (1, 0.22950598131865263), 27: (1, 0.22937999106943607), 28: (1, 0.2291597118601203), 29: (1, 0.22939242143183947), 30: (1, 0.22960252035409212), 31: (1, 0.22922028042376041), 32: (1, 0.22925908118486404), 33: (1, 0.22911265213042498), 34: (1, 0.22921902127563953), 35: (1, 0.22957156039774418), 36: (1, 0.2293877713382244), 37: (1, 0.22907000128179789), 38: (1, 0.22914389241486788), 39: (1, 0.2293412908911705), 40: (1, 0.22955719102174044), 41: (1, 0.22965695150196552), 42: (1, 0.2292781714349985), 43: (1, 0.2298368802294135), 44: (1, 0.22938216105103493), 45: (1, 0.2293063411489129), 46: (1, 0.22918547131121159), 47: (1, 0.22951731085777283), 48: (1, 0.22960165049880743), 49: (1, 0.22936563100665808), 50: (1, 0.2296835808083415), 51: (1, 0.22931787092238665), 52: (1, 0.22951240092515945), 53: (1, 0.22923751268535852), 54: (1, 0.22946580965071917), 55: (1, 0.22921645175665617), 56: (1, 0.22941192146390676), 57: (1, 0.22929324209690094), 58: (1, 0.22947271075099707), 59: (1, 0.22922181151807308), 60: (1, 0.22947509121149778), 61: (1, 0.22942740097641945), 62: (1, 0.22933285031467676), 63: (1, 0.2294066809117794), 64: (1, 0.23018368892371655), 65: (1, 0.23012605961412191), 66: (1, 0.22954633086919785), 67: (1, 0.22942689154297113), 68: (1, 0.2294108411297202), 69: (1, 0.22933499049395323), 70: (1, 0.22924955189228058), 71: (1, 0.22864541318267584)}\n",
      "{1: (1, 31, 0.08626107384841289), 2: (1, 31, 0.08640815681146999), 3: (1, 31, 0.08649487754390124), 4: (1, 31, 0.08603849992035859), 5: (1, 31, 0.08609768688198059), 6: (1, 31, 0.08630419077892457), 7: (1, 31, 0.0860971794914334), 8: (1, 31, 0.08600858737143778), 9: (1, 31, 0.08610245720633576), 10: (1, 31, 0.0864283702666721), 11: (1, 31, 0.08614638901405758), 12: (1, 31, 0.08589541094918404), 13: (1, 31, 0.0860157745379594), 14: (1, 31, 0.08604671878199424), 15: (1, 31, 0.08601899000425492), 16: (1, 31, 0.08601101403755526), 17: (1, 31, 0.08601565136303825), 18: (1, 31, 0.08623884209702092), 19: (1, 31, 0.08592239160451197), 20: (1, 31, 0.08587292026007368), 21: (1, 31, 0.08598492670083238), 22: (1, 31, 0.08599139743995282), 23: (1, 31, 0.08594317106349815), 24: (1, 31, 0.08599997837577135), 25: (1, 31, 0.08596514988570444), 26: (1, 31, 0.08600834324475258), 27: (1, 31, 0.08593905032161743), 28: (1, 31, 0.08601392387983299), 29: (1, 31, 0.08603006345970977), 30: (1, 31, 0.08606681912656754), 31: (1, 31, 0.08607768510738688), 32: (1, 31, 0.08605348267742703), 33: (1, 31, 0.08602955438677341), 34: (1, 31, 0.08600605135002444), 35: (1, 31, 0.0859927549777973), 36: (1, 31, 0.08585711090915626), 37: (1, 31, 0.08587456031912757), 38: (1, 31, 0.08592930240857025), 39: (1, 31, 0.0859937080813031), 40: (1, 31, 0.08597151048841976), 41: (1, 31, 0.08589404361743119), 42: (1, 31, 0.08610883298059625), 43: (1, 31, 0.08594664252333102), 44: (1, 31, 0.08597231034429804), 45: (1, 31, 0.0859484042551729), 46: (1, 31, 0.08595767361863006), 47: (1, 31, 0.08598641780835967), 48: (1, 31, 0.08608691202056024), 49: (1, 31, 0.08590663284544021), 50: (1, 31, 0.08602172758189901), 51: (1, 31, 0.08616448503227965), 52: (1, 31, 0.08597810512348529), 53: (1, 31, 0.08603627273752805), 54: (1, 31, 0.08607101404378491), 55: (1, 31, 0.08614763175888408), 56: (1, 31, 0.08594841792458488), 57: (1, 31, 0.08610194323644522), 58: (1, 31, 0.08612013893622544), 59: (1, 31, 0.08600223905617191), 60: (1, 31, 0.08612484956580785), 61: (1, 31, 0.08611788642742942), 62: (1, 31, 0.08598219531197701), 63: (1, 31, 0.08589832601888527), 64: (1, 31, 0.08612377593113531), 65: (1, 31, 0.08597461668954741), 66: (1, 31, 0.08600184609813075), 67: (1, 31, 0.08590179880059534), 68: (1, 31, 0.08614655932591807), 69: (1, 31, 0.0859168088664451), 70: (1, 31, 0.08595040590772705)}\n",
      "{'predict_runtime': 205.8391, 'predict_samples_per_second': 0.345, 'predict_steps_per_second': 0.345}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:25.83\n",
      "  predict_samples_per_second =      0.345\n",
      "  predict_steps_per_second   =      0.345\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.3824319913983345), 2: (2, 0.35849308781325817), 3: (2, 0.3613242581486702), 4: (2, 0.3620994184166193), 5: (2, 0.36149151902645826), 6: (2, 0.36038657184690237), 7: (2, 0.3583260178565979), 8: (2, 0.3594906246289611), 9: (2, 0.3586805472150445), 10: (2, 0.35795355774462223), 11: (2, 0.3582256780937314), 12: (2, 0.36004520300775766), 13: (2, 0.3588341660797596), 14: (2, 0.35815045796334743), 15: (2, 0.3585732374340296), 16: (2, 0.3576340489089489), 17: (2, 0.35894313640892506), 18: (2, 0.3578089093789458), 19: (2, 0.3584572374820709), 20: (2, 0.35833546705543995), 21: (2, 0.3586299456655979), 22: (2, 0.35828309785574675), 23: (2, 0.35849314741790295), 24: (2, 0.3585680155083537), 25: (2, 0.35848367772996426), 26: (2, 0.3583307582885027), 27: (2, 0.3581933779641986), 28: (2, 0.358069677837193), 29: (2, 0.35840658843517303), 30: (2, 0.3579051783308387), 31: (2, 0.3581730080768466), 32: (2, 0.3584592370316386), 33: (2, 0.35901158582419157), 34: (2, 0.3579631485044956), 35: (2, 0.3579228986054659), 36: (2, 0.35839145723730326), 37: (2, 0.35726540070027113), 38: (2, 0.3577821683138609), 39: (2, 0.35793989803642035), 40: (2, 0.35828076861798763), 41: (2, 0.35797840636223555), 42: (2, 0.3583430368453264), 43: (2, 0.3586471062153578), 44: (2, 0.35800021793693304), 45: (2, 0.3585090357810259), 46: (2, 0.35824892669916153), 47: (2, 0.35823447722941637), 48: (2, 0.3583127064630389), 49: (2, 0.35881143528968096), 50: (2, 0.35842505749315023), 51: (2, 0.3583022076636553), 52: (2, 0.35804908722639084), 53: (2, 0.3581559872254729), 54: (2, 0.35886439494788647), 55: (2, 0.3582653971388936), 56: (2, 0.3582528056576848), 57: (2, 0.3583407960832119), 58: (2, 0.35808032657951117), 59: (2, 0.35872857458889484), 60: (2, 0.35795974638313055), 61: (2, 0.35851726680994034), 62: (2, 0.3581404872238636), 63: (2, 0.35813543666154146), 64: (2, 0.35828669648617506), 65: (2, 0.3583534760400653), 66: (2, 0.35825076699256897), 67: (2, 0.3585360962897539), 68: (2, 0.3578442372381687), 69: (2, 0.3599793715402484), 70: (2, 0.3577521173283458), 71: (1, 0.22882782481610775)}\n",
      "{1: (2, 31, 0.14214190723554743), 2: (2, 31, 0.1422302546880899), 3: (2, 31, 0.14219538609106694), 4: (2, 31, 0.1421105179394926), 5: (2, 31, 0.14213755678746007), 6: (2, 31, 0.1421819740245419), 7: (2, 31, 0.14202879810886038), 8: (2, 31, 0.14251183216730434), 9: (2, 31, 0.14231818977503047), 10: (2, 31, 0.14206208168498932), 11: (2, 31, 0.14218344169879152), 12: (2, 31, 0.14200964609100933), 13: (2, 31, 0.14199982123870042), 14: (2, 31, 0.1419863858290257), 15: (2, 31, 0.14190833102310857), 16: (2, 31, 0.14191720676758596), 17: (2, 31, 0.14209434792639747), 18: (2, 31, 0.14198072546071583), 19: (2, 31, 0.14191735839290964), 20: (2, 31, 0.1419725857014137), 21: (2, 31, 0.14191112321831525), 22: (2, 31, 0.14264640894027486), 23: (2, 31, 0.141803118640617), 24: (2, 31, 0.1419994953659273), 25: (2, 31, 0.14239353990002024), 26: (2, 31, 0.1418853004372889), 27: (2, 31, 0.14240163675839862), 28: (2, 31, 0.14215335210845356), 29: (2, 31, 0.14214775323747628), 30: (2, 31, 0.14206403196458856), 31: (2, 31, 0.14197338147148972), 32: (2, 31, 0.14196435467249924), 33: (2, 31, 0.14216991474912052), 34: (2, 31, 0.14182026678275678), 35: (2, 31, 0.14189839522324263), 36: (2, 31, 0.14195989721244381), 37: (2, 31, 0.14191382561600016), 38: (2, 31, 0.1419013096620479), 39: (2, 31, 0.14189928703971447), 40: (2, 31, 0.14199056593520987), 41: (2, 31, 0.1418330135845369), 42: (2, 31, 0.14213373557093642), 43: (2, 31, 0.1419814111845147), 44: (2, 31, 0.1421496346592903), 45: (2, 31, 0.14196802068862222), 46: (2, 31, 0.14218536734340653), 47: (2, 31, 0.14200492632845718), 48: (2, 31, 0.14203693882952775), 49: (2, 31, 0.1418568522579247), 50: (2, 31, 0.14196101603128256), 51: (2, 31, 0.14185722574831977), 52: (2, 31, 0.14190318327276938), 53: (2, 31, 0.1418033505399381), 54: (2, 31, 0.14192102215583285), 55: (2, 31, 0.14181755777568586), 56: (2, 31, 0.1419371828857449), 57: (2, 31, 0.14183949570982687), 58: (2, 31, 0.1418651735350009), 59: (2, 31, 0.14210606756950578), 60: (2, 31, 0.14225117462657152), 61: (2, 31, 0.14187293887258537), 62: (2, 31, 0.14197600356513454), 63: (2, 31, 0.14186978117833215), 64: (2, 31, 0.1417665066678197), 65: (2, 31, 0.1417835116867096), 66: (2, 31, 0.14174062743662827), 67: (2, 31, 0.14181378297507763), 68: (2, 31, 0.14216062991369155), 69: (2, 31, 0.14247019339593187), 70: (2, 31, 0.14241462987997838)}\n",
      "{'predict_runtime': 336.3925, 'predict_samples_per_second': 0.419, 'predict_steps_per_second': 0.211}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:36.39\n",
      "  predict_samples_per_second =      0.419\n",
      "  predict_steps_per_second   =      0.211\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.6240146905183792), 2: (4, 0.6051463317126036), 3: (4, 0.6108517460525036), 4: (4, 0.6091776117682457), 5: (4, 0.608564181253314), 6: (4, 0.6057254513725638), 7: (4, 0.6074479464441538), 8: (4, 0.6057773707434535), 9: (4, 0.6050205016508698), 10: (4, 0.6052750824019313), 11: (4, 0.6074127163738012), 12: (4, 0.605615240521729), 13: (4, 0.6063356194645166), 14: (4, 0.6053044721484184), 15: (4, 0.605077532120049), 16: (4, 0.6051617320626974), 17: (4, 0.6055299611762166), 18: (4, 0.6045364132151008), 19: (4, 0.6050161737948656), 20: (4, 0.6052906718105078), 21: (4, 0.6050588227808475), 22: (4, 0.6053767716512084), 23: (4, 0.6046305429190397), 24: (4, 0.604854472912848), 25: (4, 0.6045428328216076), 26: (4, 0.6050634132698178), 27: (4, 0.6048369035124779), 28: (4, 0.6048957034945488), 29: (4, 0.605032772757113), 30: (4, 0.6046538734808564), 31: (4, 0.6046646237373352), 32: (4, 0.604889303445816), 33: (4, 0.6048323325812817), 34: (4, 0.6049107136204839), 35: (4, 0.604817682877183), 36: (4, 0.6046555936336517), 37: (4, 0.6049338113516569), 38: (4, 0.6046540439128876), 39: (4, 0.6045169541612267), 40: (4, 0.6046766927465796), 41: (4, 0.6044661840423942), 42: (4, 0.6046844031661749), 43: (4, 0.6047965036705136), 44: (4, 0.6045778235420585), 45: (4, 0.6048549339175224), 46: (4, 0.6049914518371224), 47: (4, 0.6050685336813331), 48: (4, 0.6046714736148715), 49: (4, 0.6042673150077462), 50: (4, 0.6047710236161947), 51: (4, 0.6048434926196933), 52: (4, 0.6049264324828982), 53: (4, 0.6048630429431796), 54: (4, 0.6043110946193337), 55: (4, 0.6053787004202604), 56: (4, 0.6048007933422923), 57: (4, 0.6048784125596285), 58: (4, 0.6045579835772514), 59: (4, 0.6051489524543285), 60: (4, 0.6046392042189837), 61: (4, 0.6054466515779495), 62: (4, 0.6045546727254987), 63: (4, 0.6048229932785034), 64: (4, 0.6049896012991667), 65: (4, 0.6050923317670822), 66: (4, 0.6048275828361511), 67: (4, 0.6052820524200797), 68: (4, 0.6044363845139742), 69: (4, 0.6050486415624619), 70: (4, 0.603212277404964), 71: (1, 0.22847283724695444)}\n",
      "{1: (4, 31, 0.14666583208787826), 2: (4, 31, 0.14713890493036277), 3: (4, 31, 0.14690938366637116), 4: (4, 31, 0.1467271954001438), 5: (4, 31, 0.146746234487622), 6: (4, 31, 0.14669817550888947), 7: (4, 31, 0.14680902608820506), 8: (4, 31, 0.146732808931941), 9: (4, 31, 0.1466368793720199), 10: (4, 31, 0.1469238266168583), 11: (4, 31, 0.1466748784146001), 12: (4, 31, 0.1467311395512473), 13: (4, 31, 0.14655400389024326), 14: (4, 31, 0.1465695419559075), 15: (4, 31, 0.14655905111782974), 16: (4, 31, 0.1471251152876404), 17: (4, 31, 0.14721089177915164), 18: (4, 31, 0.14767811570556894), 19: (4, 31, 0.14731382215095143), 20: (4, 31, 0.14670522324740887), 21: (4, 31, 0.14779742287411804), 22: (4, 31, 0.14815341948621696), 23: (4, 31, 0.14646081079638773), 24: (4, 31, 0.14644838208633085), 25: (4, 31, 0.14660644155716704), 26: (4, 31, 0.14734700045758678), 27: (4, 31, 0.14648408256471157), 28: (4, 31, 0.14634548605329567), 29: (4, 31, 0.14647763330609567), 30: (4, 31, 0.14633460177649413), 31: (4, 31, 0.1470204200896044), 32: (4, 31, 0.14633073955173453), 33: (4, 31, 0.14673611819143256), 34: (4, 31, 0.14643542793008588), 35: (4, 31, 0.14689198103282722), 36: (4, 31, 0.1464368721710578), 37: (4, 31, 0.14647002542211163), 38: (4, 31, 0.1469894485067456), 39: (4, 31, 0.14644179889752018), 40: (4, 31, 0.14640789331808204), 41: (4, 31, 0.14640422766247102), 42: (4, 31, 0.14699054115842428), 43: (4, 31, 0.14645027940071398), 44: (4, 31, 0.1463903663980384), 45: (4, 31, 0.14699965535152343), 46: (4, 31, 0.14819845130607004), 47: (4, 31, 0.14641676308406937), 48: (4, 31, 0.1464144679146909), 49: (4, 31, 0.14647410755916948), 50: (4, 31, 0.14885493292803725), 51: (4, 31, 0.14700756702692278), 52: (4, 31, 0.14638687514009013), 53: (4, 31, 0.14853325777597004), 54: (4, 31, 0.1464963799883281), 55: (4, 31, 0.14937016911684506), 56: (4, 31, 0.14691114155275206), 57: (4, 31, 0.14770396534473665), 58: (4, 31, 0.14777095213292107), 59: (4, 31, 0.14645291612513603), 60: (4, 31, 0.14644682524545538), 61: (4, 31, 0.14673748086657254), 62: (4, 31, 0.1467260078737332), 63: (4, 31, 0.14655537702023022), 64: (4, 31, 0.14649122842257062), 65: (4, 31, 0.1465324778109789), 66: (4, 31, 0.14653075576549576), 67: (4, 31, 0.14726599101578036), 68: (4, 31, 0.14649957060934074), 69: (4, 31, 0.14714732303494407), 70: (4, 31, 0.14648018792391784)}\n",
      "{'predict_runtime': 364.1841, 'predict_samples_per_second': 0.772, 'predict_steps_per_second': 0.195}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:04.18\n",
      "  predict_samples_per_second =      0.772\n",
      "  predict_steps_per_second   =      0.195\n",
      "Evaluating with num_layers: 20\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.26111028622835875), 2: (1, 0.2406782815232873), 3: (1, 0.24418479297310114), 4: (1, 0.24412448331713676), 5: (1, 0.24143618065863848), 6: (1, 0.2410819921642542), 7: (1, 0.24056060332804918), 8: (1, 0.2402923535555601), 9: (1, 0.2403876530006528), 10: (1, 0.2404098128899932), 11: (1, 0.24026105366647243), 12: (1, 0.24018021393567324), 13: (1, 0.2406201520934701), 14: (1, 0.2409376623108983), 15: (1, 0.24066911358386278), 16: (1, 0.2407430913299322), 17: (1, 0.24059201311320066), 18: (1, 0.24066114332526922), 19: (1, 0.2407571030780673), 20: (1, 0.24082466308027506), 21: (1, 0.24081565253436565), 22: (1, 0.24067581351846457), 23: (1, 0.2408709516748786), 24: (1, 0.24069042317569256), 25: (1, 0.24082403350621462), 26: (1, 0.24084160383790731), 27: (1, 0.2409654026851058), 28: (1, 0.24108966253697872), 29: (1, 0.24097394198179245), 30: (1, 0.24077744223177433), 31: (1, 0.2408751528710127), 32: (1, 0.24083208292722702), 33: (1, 0.24067717231810093), 34: (1, 0.24082382209599018), 35: (1, 0.2409522021189332), 36: (1, 0.24040196277201176), 37: (1, 0.24050562363117933), 38: (1, 0.24077032320201397), 39: (1, 0.24082535319030285), 40: (1, 0.24100540205836296), 41: (1, 0.24079165142029524), 42: (1, 0.24073489289730787), 43: (1, 0.24078824184834957), 44: (1, 0.24066949170082808), 45: (1, 0.24051579274237156), 46: (1, 0.24100545141845942), 47: (1, 0.24068904295563698), 48: (1, 0.24096326250582933), 49: (1, 0.24122375063598156), 50: (1, 0.24077617190778255), 51: (1, 0.24091686215251684), 52: (1, 0.24098160210996866), 53: (1, 0.24107118230313063), 54: (1, 0.24069366231560707), 55: (1, 0.24077250249683857), 56: (1, 0.2409464018419385), 57: (1, 0.24066500272601843), 58: (1, 0.24119422119110823), 59: (1, 0.24077549297362566), 60: (1, 0.24103145208209753), 61: (1, 0.24085428286343813), 62: (1, 0.24072671309113503), 63: (1, 0.24110311176627874), 64: (1, 0.2405031230300665), 65: (1, 0.24075287207961082), 66: (1, 0.24068978242576122), 67: (1, 0.24038451351225376), 68: (1, 0.2406096225604415), 69: (1, 0.24086402263492346), 70: (1, 0.24070687126368284), 71: (1, 0.24027782399207354)}\n",
      "{1: (1, 31, 0.09061035973530623), 2: (1, 31, 0.09066224308504213), 3: (1, 31, 0.09059771474811339), 4: (1, 31, 0.09064908265586823), 5: (1, 31, 0.09027721068911976), 6: (1, 31, 0.09018330131807635), 7: (1, 31, 0.09010461943163987), 8: (1, 31, 0.09028713251914709), 9: (1, 31, 0.09006858322649233), 10: (1, 31, 0.09018345507642915), 11: (1, 31, 0.09024997686426486), 12: (1, 31, 0.0902037599514569), 13: (1, 31, 0.09027741999635773), 14: (1, 31, 0.09013858416508283), 15: (1, 31, 0.0903458169871761), 16: (1, 31, 0.09010519814347068), 17: (1, 31, 0.09008851166694395), 18: (1, 31, 0.09021537654822873), 19: (1, 31, 0.0900332425690947), 20: (1, 31, 0.09028738298483434), 21: (1, 31, 0.09055449377985732), 22: (1, 31, 0.09026111578268389), 23: (1, 31, 0.0902671484396823), 24: (1, 31, 0.09040744521565014), 25: (1, 31, 0.09007028457258016), 26: (1, 31, 0.09013979112909686), 27: (1, 31, 0.09004105939980477), 28: (1, 31, 0.09014140240727894), 29: (1, 31, 0.09059970720761246), 30: (1, 31, 0.09042987419712928), 31: (1, 31, 0.09023218908377233), 32: (1, 31, 0.09017412334440215), 33: (1, 31, 0.09033803864111824), 34: (1, 31, 0.09009316365324682), 35: (1, 31, 0.09017215017229319), 36: (1, 31, 0.09004467635625793), 37: (1, 31, 0.09023820879238267), 38: (1, 31, 0.0903192717702158), 39: (1, 31, 0.09028088716008971), 40: (1, 31, 0.09014833105667945), 41: (1, 31, 0.09004128138504681), 42: (1, 31, 0.0901847570353458), 43: (1, 31, 0.09023567601557701), 44: (1, 31, 0.09020848629335242), 45: (1, 31, 0.09024316556150874), 46: (1, 31, 0.0902727909025646), 47: (1, 31, 0.09021961007026895), 48: (1, 31, 0.09023829910062975), 49: (1, 31, 0.09021901255173068), 50: (1, 31, 0.09015770127335863), 51: (1, 31, 0.09013434866022679), 52: (1, 31, 0.09028663672506809), 53: (1, 31, 0.09032144565736094), 54: (1, 31, 0.0901158461647649), 55: (1, 31, 0.09005044148333612), 56: (1, 31, 0.09023348317151109), 57: (1, 31, 0.0902196457008681), 58: (1, 31, 0.09043870737115221), 59: (1, 31, 0.09043082333500346), 60: (1, 31, 0.09024990211811758), 61: (1, 31, 0.09040875648779254), 62: (1, 31, 0.09034159680407855), 63: (1, 31, 0.09041317642456101), 64: (1, 31, 0.0903078440817133), 65: (1, 31, 0.09025779787090517), 66: (1, 31, 0.09035905294360654), 67: (1, 31, 0.09016384707102852), 68: (1, 31, 0.09015206001218289), 69: (1, 31, 0.09023678008346789), 70: (1, 31, 0.09030783852382053)}\n",
      "{'predict_runtime': 215.9315, 'predict_samples_per_second': 0.329, 'predict_steps_per_second': 0.329}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:35.93\n",
      "  predict_samples_per_second =      0.329\n",
      "  predict_steps_per_second   =      0.329\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.3992555532604456), 2: (2, 0.38049847446382046), 3: (2, 0.3791016386821866), 4: (2, 0.3782331505790353), 5: (2, 0.3763898769393563), 6: (2, 0.37755494471639395), 7: (2, 0.3763886373490095), 8: (2, 0.3756258497014642), 9: (2, 0.3765958659350872), 10: (2, 0.3776668030768633), 11: (2, 0.3758287774398923), 12: (2, 0.37622361723333597), 13: (2, 0.3761598067358136), 14: (2, 0.37638521660119295), 15: (2, 0.3758670575916767), 16: (2, 0.37641414627432823), 17: (2, 0.3755187187343836), 18: (2, 0.3758744578808546), 19: (2, 0.3762416560202837), 20: (2, 0.3764124559238553), 21: (2, 0.3762078871950507), 22: (2, 0.37662321608513594), 23: (2, 0.37637981586158276), 24: (2, 0.37676412519067526), 25: (2, 0.3770650941878557), 26: (2, 0.37620085664093494), 27: (2, 0.37621874641627073), 28: (2, 0.37639909517019987), 29: (2, 0.37678879499435425), 30: (2, 0.37606549728661776), 31: (2, 0.3761138981208205), 32: (2, 0.3767686150968075), 33: (2, 0.3766498165205121), 34: (2, 0.37614367716014385), 35: (2, 0.37592035811394453), 36: (2, 0.37650239653885365), 37: (2, 0.3763510175049305), 38: (2, 0.37620009668171406), 39: (2, 0.37635976634919643), 40: (2, 0.3766652559861541), 41: (2, 0.37571278866380453), 42: (2, 0.3759421482682228), 43: (2, 0.3760370472446084), 44: (2, 0.37599001731723547), 45: (2, 0.3762724753469229), 46: (2, 0.3760027075186372), 47: (2, 0.3759519373998046), 48: (2, 0.3764325762167573), 49: (2, 0.37617745622992516), 50: (2, 0.3768926151096821), 51: (2, 0.37662813626229763), 52: (2, 0.37607514671981335), 53: (2, 0.3761245673522353), 54: (2, 0.3761262185871601), 55: (2, 0.3761089062318206), 56: (2, 0.37637949641793966), 57: (2, 0.37600309774279594), 58: (2, 0.37618212681263685), 59: (2, 0.37677341513335705), 60: (2, 0.37635048665106297), 61: (2, 0.37642696406692266), 62: (2, 0.3761378042399883), 63: (2, 0.3761334540322423), 64: (2, 0.37612583488225937), 65: (2, 0.3764031734317541), 66: (2, 0.376306664198637), 67: (2, 0.3762693051248789), 68: (2, 0.3762629544362426), 69: (2, 0.37666462268680334), 70: (2, 0.37505839858204126), 71: (1, 0.23976936377584934)}\n",
      "{1: (2, 31, 0.15362142540153959), 2: (2, 31, 0.14960291458954733), 3: (2, 31, 0.14910927051377873), 4: (2, 31, 0.14895324300854437), 5: (2, 31, 0.14901006600308803), 6: (2, 31, 0.14905524770579032), 7: (2, 31, 0.14896286474240403), 8: (2, 31, 0.1489258053442163), 9: (2, 31, 0.14895693393003556), 10: (2, 31, 0.14890193581701286), 11: (2, 31, 0.14911557794097932), 12: (2, 31, 0.14889225009227952), 13: (2, 31, 0.14903031902447825), 14: (2, 31, 0.14894630666822195), 15: (2, 31, 0.14903508922866276), 16: (2, 31, 0.14894168024822588), 17: (2, 31, 0.1489082785443433), 18: (2, 31, 0.14881911954932636), 19: (2, 31, 0.14899800904095173), 20: (2, 31, 0.14888743323183828), 21: (2, 31, 0.1488852368126954), 22: (2, 31, 0.1488242747802888), 23: (2, 31, 0.14898342362815334), 24: (2, 31, 0.14893638961497815), 25: (2, 31, 0.14900279141241504), 26: (2, 31, 0.1489655750112668), 27: (2, 31, 0.14898119812771196), 28: (2, 31, 0.148955054430952), 29: (2, 31, 0.1490184417475135), 30: (2, 31, 0.14898683283958705), 31: (2, 31, 0.14902714657927713), 32: (2, 31, 0.1489680001752511), 33: (2, 31, 0.14897937922468107), 34: (2, 31, 0.14890802961083188), 35: (2, 31, 0.14917642845501822), 36: (2, 31, 0.1490288134664297), 37: (2, 31, 0.14899496947445215), 38: (2, 31, 0.1489874882202956), 39: (2, 31, 0.14908971667530074), 40: (2, 31, 0.14895141425151978), 41: (2, 31, 0.14898206242510387), 42: (2, 31, 0.149017954485551), 43: (2, 31, 0.14921910940639435), 44: (2, 31, 0.14909159226883803), 45: (2, 31, 0.14905559136382035), 46: (2, 31, 0.14901432205712603), 47: (2, 31, 0.14903549862004095), 48: (2, 31, 0.14905071498886233), 49: (2, 31, 0.14904669666242215), 50: (2, 31, 0.14904827300098636), 51: (2, 31, 0.14911528646705613), 52: (2, 31, 0.14886276823498548), 53: (2, 31, 0.15008675466261565), 54: (2, 31, 0.15101055617654516), 55: (2, 31, 0.14926348521464294), 56: (2, 31, 0.1518887689998073), 57: (2, 31, 0.14889826475372236), 58: (2, 31, 0.14893804250224943), 59: (2, 31, 0.14894301282061684), 60: (2, 31, 0.14885100262660172), 61: (2, 31, 0.1499844363199607), 62: (2, 31, 0.14883677793606634), 63: (2, 31, 0.14922222239716398), 64: (2, 31, 0.15039700401886816), 65: (2, 31, 0.14893052002955828), 66: (2, 31, 0.14880899117598612), 67: (2, 31, 0.14932578675929578), 68: (2, 31, 0.1488376794262759), 69: (2, 31, 0.14887314274786942), 70: (2, 31, 0.1497863756132222)}\n",
      "{'predict_runtime': 353.307, 'predict_samples_per_second': 0.399, 'predict_steps_per_second': 0.201}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:53.30\n",
      "  predict_samples_per_second =      0.399\n",
      "  predict_steps_per_second   =      0.201\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.6562377475202084), 2: (4, 0.6402340810745955), 3: (4, 0.6411976078525186), 4: (4, 0.6400851113721728), 5: (4, 0.6387923751026392), 6: (4, 0.6405354896560311), 7: (4, 0.6373280277475715), 8: (4, 0.6362581104040146), 9: (4, 0.6366172814741731), 10: (4, 0.6384176854044199), 11: (4, 0.6358075328171253), 12: (4, 0.6363282818347216), 13: (4, 0.6361478706821799), 14: (4, 0.6360993823036551), 15: (4, 0.6357265030965209), 16: (4, 0.636495791375637), 17: (4, 0.6360902823507786), 18: (4, 0.6359605919569731), 19: (4, 0.6364310011267662), 20: (4, 0.6359203727915883), 21: (4, 0.6357857529073954), 22: (4, 0.6358133032917976), 23: (4, 0.6363483825698495), 24: (4, 0.636244541965425), 25: (4, 0.6363132111728191), 26: (4, 0.6362935118377209), 27: (4, 0.6365263713523746), 28: (4, 0.636160422116518), 29: (4, 0.6364039108157158), 30: (4, 0.6364074712619185), 31: (4, 0.6366784702986479), 32: (4, 0.6361860316246748), 33: (4, 0.6364735513925552), 34: (4, 0.6385213062167168), 35: (4, 0.6367754098027945), 36: (4, 0.6359778521582484), 37: (4, 0.6365081705152988), 38: (4, 0.6358349313959479), 39: (4, 0.6363853309303522), 40: (4, 0.6360557312145829), 41: (4, 0.6363443415611982), 42: (4, 0.6363956509158015), 43: (4, 0.6363598313182592), 44: (4, 0.6361792022362351), 45: (4, 0.6369982995092869), 46: (4, 0.6362868323922157), 47: (4, 0.636590070091188), 48: (4, 0.6361122820526361), 49: (4, 0.6365533107891679), 50: (4, 0.6360602527856827), 51: (4, 0.63621811196208), 52: (4, 0.6362513219937682), 53: (4, 0.6363879311829805), 54: (4, 0.6363313421607018), 55: (4, 0.6363480621948838), 56: (4, 0.6364158717915416), 57: (4, 0.6363558704033494), 58: (4, 0.6361701814457774), 59: (4, 0.6368753099814057), 60: (4, 0.6362243220210075), 61: (4, 0.6366005809977651), 62: (4, 0.6362073216587305), 63: (4, 0.6371332695707679), 64: (4, 0.6364182708784938), 65: (4, 0.6366253411397338), 66: (4, 0.6364508308470249), 67: (4, 0.6365054100751877), 68: (4, 0.6364499414339662), 69: (4, 0.6362847806885839), 70: (4, 0.634841425344348), 71: (1, 0.24089136999100447)}\n",
      "{1: (4, 31, 0.15492625976161611), 2: (4, 31, 0.1544854931773678), 3: (4, 31, 0.15438143539452745), 4: (4, 31, 0.15411740183950431), 5: (4, 31, 0.15408727899193764), 6: (4, 31, 0.15416512385972084), 7: (4, 31, 0.15417147833373276), 8: (4, 31, 0.15408728764422477), 9: (4, 31, 0.1542425921427146), 10: (4, 31, 0.15404290411501162), 11: (4, 31, 0.15425310938829376), 12: (4, 31, 0.15411849389032972), 13: (4, 31, 0.15416797776255878), 14: (4, 31, 0.15418049404698034), 15: (4, 31, 0.1541867931223204), 16: (4, 31, 0.15405142274234565), 17: (4, 31, 0.15409419856845372), 18: (4, 31, 0.15405117095478119), 19: (4, 31, 0.15412195546612625), 20: (4, 31, 0.1540804453674824), 21: (4, 31, 0.15409979437507929), 22: (4, 31, 0.1541607937805595), 23: (4, 31, 0.15482126756180678), 24: (4, 31, 0.15587304646690045), 25: (4, 31, 0.1549167190828631), 26: (4, 31, 0.1548707488203241), 27: (4, 31, 0.1549806273692558), 28: (4, 31, 0.15484964114523703), 29: (4, 31, 0.15493491225905956), 30: (4, 31, 0.1548072678908225), 31: (4, 31, 0.1549242973748234), 32: (4, 31, 0.1548105926823712), 33: (4, 31, 0.15499183166051103), 34: (4, 31, 0.15497596859331092), 35: (4, 31, 0.1549741694883954), 36: (4, 31, 0.15669807199869426), 37: (4, 31, 0.15673717751257843), 38: (4, 31, 0.15702612839278676), 39: (4, 31, 0.15731235668664018), 40: (4, 31, 0.15563417102901206), 41: (4, 31, 0.15822689256240283), 42: (4, 31, 0.1564702015790728), 43: (4, 31, 0.1555042819630715), 44: (4, 31, 0.15648288276767539), 45: (4, 31, 0.1548698790551674), 46: (4, 31, 0.15760872293744357), 47: (4, 31, 0.1557349158571132), 48: (4, 31, 0.1548631774081338), 49: (4, 31, 0.15480569750070572), 50: (4, 31, 0.15495335016279452), 51: (4, 31, 0.1550070989216047), 52: (4, 31, 0.15485521324820095), 53: (4, 31, 0.15491890039054618), 54: (4, 31, 0.15494746363331233), 55: (4, 31, 0.15539943841436216), 56: (4, 31, 0.15490506625463885), 57: (4, 31, 0.15641288474322326), 58: (4, 31, 0.1550430524793844), 59: (4, 31, 0.15494788642371854), 60: (4, 31, 0.15489564637743658), 61: (4, 31, 0.1554475152985223), 62: (4, 31, 0.15487127570856002), 63: (4, 31, 0.15564940115737338), 64: (4, 31, 0.1558382187579428), 65: (4, 31, 0.15493859648103675), 66: (4, 31, 0.1576202801098266), 67: (4, 31, 0.15518186680011212), 68: (4, 31, 0.15509603427903307), 69: (4, 31, 0.1550548823490258), 70: (4, 31, 0.1554730882748)}\n",
      "{'predict_runtime': 384.3746, 'predict_samples_per_second': 0.731, 'predict_steps_per_second': 0.185}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:24.37\n",
      "  predict_samples_per_second =      0.731\n",
      "  predict_steps_per_second   =      0.185\n",
      "Evaluating with num_layers: 21\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.27171663381159306), 2: (1, 0.25201456900686026), 3: (1, 0.2565692067146301), 4: (1, 0.2556515000760555), 5: (1, 0.25274099688977003), 6: (1, 0.25281345658004284), 7: (1, 0.25251357816159725), 8: (1, 0.2522771079093218), 9: (1, 0.2522147595882416), 10: (1, 0.2524627596139908), 11: (1, 0.2519471189007163), 12: (1, 0.2525677178055048), 13: (1, 0.25239618867635727), 14: (1, 0.2528049862012267), 15: (1, 0.2523525897413492), 16: (1, 0.25297222658991814), 17: (1, 0.25244705844670534), 18: (1, 0.2522049695253372), 19: (1, 0.25237866770476103), 20: (1, 0.2530819671228528), 21: (1, 0.25228511821478605), 22: (1, 0.2522109290584922), 23: (1, 0.2526897471398115), 24: (1, 0.2526189284399152), 25: (1, 0.2525040488690138), 26: (1, 0.25281664729118347), 27: (1, 0.2524664280936122), 28: (1, 0.2524432083591819), 29: (1, 0.25225479900836945), 30: (1, 0.2518887594342232), 31: (1, 0.25283671729266644), 32: (1, 0.2523201182484627), 33: (1, 0.2525828182697296), 34: (1, 0.25510817114263773), 35: (1, 0.25239399913698435), 36: (1, 0.2535325866192579), 37: (1, 0.25205805990844965), 38: (1, 0.2528655072674155), 39: (1, 0.2524193683639169), 40: (1, 0.25310078728944063), 41: (1, 0.2524514691904187), 42: (1, 0.2521709492430091), 43: (1, 0.25217901915311813), 44: (1, 0.25238243862986565), 45: (1, 0.25235663913190365), 46: (1, 0.2522497894242406), 47: (1, 0.2525803782045841), 48: (1, 0.25230130832642317), 49: (1, 0.2522832378745079), 50: (1, 0.2525279987603426), 51: (1, 0.2520127100870013), 52: (1, 0.2522684894502163), 53: (1, 0.2523039374500513), 54: (1, 0.2521532094106078), 55: (1, 0.25202921871095896), 56: (1, 0.25246393866837025), 57: (1, 0.2523450180888176), 58: (1, 0.2526297578588128), 59: (1, 0.2522590886801481), 60: (1, 0.25236653722822666), 61: (1, 0.252488037571311), 62: (1, 0.25215893890708685), 63: (1, 0.25216720905154943), 64: (1, 0.2523268386721611), 65: (1, 0.2523355297744274), 66: (1, 0.252300669439137), 67: (1, 0.2523446287959814), 68: (1, 0.25224153883755207), 69: (1, 0.252136099152267), 70: (1, 0.2522997483611107), 71: (1, 0.25155481044203043)}\n",
      "{1: (1, 31, 0.09454506419358714), 2: (1, 31, 0.0952198252442383), 3: (1, 31, 0.09489535576393528), 4: (1, 31, 0.09477475240466095), 5: (1, 31, 0.09459048215179675), 6: (1, 31, 0.09459420482838346), 7: (1, 31, 0.09461561094729169), 8: (1, 31, 0.09464182130872242), 9: (1, 31, 0.09476967855927444), 10: (1, 31, 0.09484977933067468), 11: (1, 31, 0.09479773104671509), 12: (1, 31, 0.09443738428695549), 13: (1, 31, 0.09450362084974204), 14: (1, 31, 0.09481224913390414), 15: (1, 31, 0.09449795759733647), 16: (1, 31, 0.09474646279047574), 17: (1, 31, 0.09444496251883046), 18: (1, 31, 0.09453548725333906), 19: (1, 31, 0.09461820462057667), 20: (1, 31, 0.09483130567616993), 21: (1, 31, 0.09432327642195648), 22: (1, 31, 0.09448526147753), 23: (1, 31, 0.09468639338569294), 24: (1, 31, 0.09459671705600715), 25: (1, 31, 0.09461645700878674), 26: (1, 31, 0.09471321541575654), 27: (1, 31, 0.09468811630241332), 28: (1, 31, 0.09466629042740791), 29: (1, 31, 0.09480144567186793), 30: (1, 31, 0.09490328038772268), 31: (1, 31, 0.09464274160563946), 32: (1, 31, 0.09460298521744628), 33: (1, 31, 0.09769023411096103), 34: (1, 31, 0.09521771177288986), 35: (1, 31, 0.09675173031827135), 36: (1, 31, 0.09464511894170315), 37: (1, 31, 0.09804444943344401), 38: (1, 31, 0.09648870211094618), 39: (1, 31, 0.09867184221624367), 40: (1, 31, 0.09694008589271576), 41: (1, 31, 0.0948656118444858), 42: (1, 31, 0.09596567489807645), 43: (1, 31, 0.09446896008786655), 44: (1, 31, 0.09463909172242688), 45: (1, 31, 0.09667220786814729), 46: (1, 31, 0.09468925281638099), 47: (1, 31, 0.09591715311210963), 48: (1, 31, 0.09652186434475644), 49: (1, 31, 0.09506689964403067), 50: (1, 31, 0.09434473941162709), 51: (1, 31, 0.09465308373253192), 52: (1, 31, 0.09463298819478481), 53: (1, 31, 0.09461190284139687), 54: (1, 31, 0.09459594541019009), 55: (1, 31, 0.09448026225812012), 56: (1, 31, 0.09452033090975977), 57: (1, 31, 0.0946469536772178), 58: (1, 31, 0.09732843902442724), 59: (1, 31, 0.09696392823130853), 60: (1, 31, 0.09526175981567751), 61: (1, 31, 0.09465787169193068), 62: (1, 31, 0.09460631406475459), 63: (1, 31, 0.09605071979064134), 64: (1, 31, 0.09475631609318717), 65: (1, 31, 0.0960438989042755), 66: (1, 31, 0.09476645669389155), 67: (1, 31, 0.0948049596120273), 68: (1, 31, 0.09434460647284024), 69: (1, 31, 0.09472853008417352), 70: (1, 31, 0.09460291149274956)}\n",
      "{'predict_runtime': 227.445, 'predict_samples_per_second': 0.312, 'predict_steps_per_second': 0.312}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:47.44\n",
      "  predict_samples_per_second =      0.312\n",
      "  predict_steps_per_second   =      0.312\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.4152612257748842), 2: (2, 0.3982682731002569), 3: (2, 0.3974319053813815), 4: (2, 0.39661681838333607), 5: (2, 0.3942465139552951), 6: (2, 0.39622119814157486), 7: (2, 0.3948324229568243), 8: (2, 0.3947526328265667), 9: (2, 0.3949305322021246), 10: (2, 0.3959460500627756), 11: (2, 0.3940391344949603), 12: (2, 0.3950636116787791), 13: (2, 0.3945518145337701), 14: (2, 0.3944962341338396), 15: (2, 0.39470050297677517), 16: (2, 0.39521950110793114), 17: (2, 0.3949763420969248), 18: (2, 0.3940602745860815), 19: (2, 0.39397372491657734), 20: (2, 0.39483277313411236), 21: (2, 0.3940507750958204), 22: (2, 0.39434145390987396), 23: (2, 0.39409950375556946), 24: (2, 0.3945926930755377), 25: (2, 0.3948228033259511), 26: (2, 0.3946412429213524), 27: (2, 0.3941685240715742), 28: (2, 0.394822352565825), 29: (2, 0.39475460164248943), 30: (2, 0.3949399320408702), 31: (2, 0.395004921592772), 32: (2, 0.3952076220884919), 33: (2, 0.39508695155382156), 34: (2, 0.3944371435791254), 35: (2, 0.39467123337090015), 36: (2, 0.3942702244967222), 37: (2, 0.3948719520121813), 38: (2, 0.3947462718933821), 39: (2, 0.3945964025333524), 40: (2, 0.3946885336190462), 41: (2, 0.39503581263124943), 42: (2, 0.39509197138249874), 43: (2, 0.3943494837731123), 44: (2, 0.394522943533957), 45: (2, 0.39491003286093473), 46: (2, 0.39490672294050455), 47: (2, 0.39473382383584976), 48: (2, 0.3947718031704426), 49: (2, 0.3946400322020054), 50: (2, 0.39482638239860535), 51: (2, 0.3947566030547023), 52: (2, 0.3946248535066843), 53: (2, 0.39509664196521044), 54: (2, 0.39503797329962254), 55: (2, 0.39464137237519026), 56: (2, 0.39486965257674456), 57: (2, 0.3952872510999441), 58: (2, 0.3944936441257596), 59: (2, 0.39519115164875984), 60: (2, 0.39460139255970716), 61: (2, 0.39457011222839355), 62: (2, 0.39501165226101875), 63: (2, 0.3947763526812196), 64: (2, 0.3946763938292861), 65: (2, 0.39500214252620935), 66: (2, 0.3952596811577678), 67: (2, 0.39448858331888914), 68: (2, 0.3943450339138508), 69: (2, 0.3958982992917299), 70: (2, 0.39401594549417496), 71: (1, 0.25158100109547377)}\n",
      "{1: (2, 31, 0.15900567071812768), 2: (2, 31, 0.1580291646382501), 3: (2, 31, 0.1588380769075405), 4: (2, 31, 0.1587876140049869), 5: (2, 31, 0.15754702443917912), 6: (2, 31, 0.15663117632990883), 7: (2, 31, 0.15712125250889408), 8: (2, 31, 0.15675578104151833), 9: (2, 31, 0.15832907487187656), 10: (2, 31, 0.1564317648148825), 11: (2, 31, 0.15662639567087736), 12: (2, 31, 0.15645387546429712), 13: (2, 31, 0.1565618824754511), 14: (2, 31, 0.15647813088951573), 15: (2, 31, 0.15678799810308602), 16: (2, 31, 0.15675220887867675), 17: (2, 31, 0.15697000346957676), 18: (2, 31, 0.15650770885329093), 19: (2, 31, 0.15666146717605092), 20: (2, 31, 0.15708293339177484), 21: (2, 31, 0.1564906101613756), 22: (2, 31, 0.15749037461054902), 23: (2, 31, 0.15664170369986566), 24: (2, 31, 0.1575728943871875), 25: (2, 31, 0.1564541212733715), 26: (2, 31, 0.15677640854471153), 27: (2, 31, 0.15663615475979545), 28: (2, 31, 0.15650852802660195), 29: (2, 31, 0.15661092775483285), 30: (2, 31, 0.15655078189147095), 31: (2, 31, 0.15649426497158506), 32: (2, 31, 0.15679014344970066), 33: (2, 31, 0.15644006031535326), 34: (2, 31, 0.15643662752042856), 35: (2, 31, 0.15719668374907586), 36: (2, 31, 0.1564686786864073), 37: (2, 31, 0.1564379792900816), 38: (2, 31, 0.15976311329511866), 39: (2, 31, 0.16015642418736412), 40: (2, 31, 0.1584083027236404), 41: (2, 31, 0.157674812381306), 42: (2, 31, 0.15645789895807544), 43: (2, 31, 0.15704090157223324), 44: (2, 31, 0.15673302937178843), 45: (2, 31, 0.1569561589389078), 46: (2, 31, 0.1567829516866515), 47: (2, 31, 0.15642121265972814), 48: (2, 31, 0.1570401683209404), 49: (2, 31, 0.15661044752285366), 50: (2, 31, 0.1566635275620126), 51: (2, 31, 0.1567062850620958), 52: (2, 31, 0.15651400864965492), 53: (2, 31, 0.15651742498119992), 54: (2, 31, 0.15664562946485897), 55: (2, 31, 0.1564614600652168), 56: (2, 31, 0.15655756594553108), 57: (2, 31, 0.15648799662988994), 58: (2, 31, 0.1566220905872122), 59: (2, 31, 0.15679209964770463), 60: (2, 31, 0.15654831860334642), 61: (2, 31, 0.1566804593368884), 62: (2, 31, 0.15681483067812457), 63: (2, 31, 0.15678161683101807), 64: (2, 31, 0.15639471049390494), 65: (2, 31, 0.156504882109021), 66: (2, 31, 0.156488191817076), 67: (2, 31, 0.15649552003390366), 68: (2, 31, 0.15656389238973778), 69: (2, 31, 0.15655385435468727), 70: (2, 31, 0.15691930121712147)}\n",
      "{'predict_runtime': 371.593, 'predict_samples_per_second': 0.379, 'predict_steps_per_second': 0.191}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:11.59\n",
      "  predict_samples_per_second =      0.379\n",
      "  predict_steps_per_second   =      0.191\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.6856563147157431), 2: (4, 0.6706745279952884), 3: (4, 0.6713831862434745), 4: (4, 0.6704992186278105), 5: (4, 0.6676232665777206), 6: (4, 0.6706864377483726), 7: (4, 0.6680392762646079), 8: (4, 0.6677443068474531), 9: (4, 0.6677456172183156), 10: (4, 0.670275098644197), 11: (4, 0.6671724887564778), 12: (4, 0.6682112151756883), 13: (4, 0.6674921363592148), 14: (4, 0.6667290404438972), 15: (4, 0.6677562464028597), 16: (4, 0.6673201080411673), 17: (4, 0.6678572557866573), 18: (4, 0.667685367166996), 19: (4, 0.6678171455860138), 20: (4, 0.6668757190927863), 21: (4, 0.6666180286556482), 22: (4, 0.6681728763505816), 23: (4, 0.6671377290040255), 24: (4, 0.6672164984047413), 25: (4, 0.6669641090556979), 26: (4, 0.6665896996855736), 27: (4, 0.6669424185529351), 28: (4, 0.6670388877391815), 29: (4, 0.6672021094709635), 30: (4, 0.6673482079058886), 31: (4, 0.667111768387258), 32: (4, 0.6667052684351802), 33: (4, 0.6671233791857958), 34: (4, 0.6681923251599073), 35: (4, 0.6667233500629663), 36: (4, 0.667113658040762), 37: (4, 0.6670739278197289), 38: (4, 0.6668746890500188), 39: (4, 0.6668569091707468), 40: (4, 0.6666912082582712), 41: (4, 0.6672265185043216), 42: (4, 0.6670249588787556), 43: (4, 0.6673222668468952), 44: (4, 0.6671689888462424), 45: (4, 0.667154947295785), 46: (4, 0.6671101683750749), 47: (4, 0.6671428987756371), 48: (4, 0.6670222776010633), 49: (4, 0.6669200891628861), 50: (4, 0.6669949078932405), 51: (4, 0.6670528091490269), 52: (4, 0.6670153085142374), 53: (4, 0.6669936887919903), 54: (4, 0.6669436991214752), 55: (4, 0.667102038860321), 56: (4, 0.6672692280262709), 57: (4, 0.6669909888878465), 58: (4, 0.6673199981451035), 59: (4, 0.66725704818964), 60: (4, 0.6666634185239673), 61: (4, 0.6673770062625408), 62: (4, 0.6668152883648872), 63: (4, 0.6667893892154098), 64: (4, 0.666889788582921), 65: (4, 0.6671359576284885), 66: (4, 0.6666575903072953), 67: (4, 0.6671590581536293), 68: (4, 0.666973939165473), 69: (4, 0.6671475972980261), 70: (4, 0.6656944826245308), 71: (1, 0.25171606335788965)}\n",
      "{1: (4, 31, 0.1626268935900542), 2: (4, 31, 0.1620282933656727), 3: (4, 31, 0.1619881145475853), 4: (4, 31, 0.16183682446998934), 5: (4, 31, 0.16179089200112126), 6: (4, 31, 0.16183547062739248), 7: (4, 31, 0.16251430783661142), 8: (4, 31, 0.1616287807964029), 9: (4, 31, 0.16205640188268117), 10: (4, 31, 0.16171397376925714), 11: (4, 31, 0.16183455228324858), 12: (4, 31, 0.16159987572820916), 13: (4, 31, 0.1618962297816911), 14: (4, 31, 0.16166176887289171), 15: (4, 31, 0.16272980539548781), 16: (4, 31, 0.16170315841032612), 17: (4, 31, 0.16152451295525797), 18: (4, 31, 0.16647524999514704), 19: (4, 31, 0.16160294545754308), 20: (4, 31, 0.16152248198106403), 21: (4, 31, 0.16178424836647126), 22: (4, 31, 0.16140475343432156), 23: (4, 31, 0.16139367616344844), 24: (4, 31, 0.16142641398454866), 25: (4, 31, 0.1615450041248433), 26: (4, 31, 0.1613180145861641), 27: (4, 31, 0.16145585624561196), 28: (4, 31, 0.16131837377625127), 29: (4, 31, 0.1614192111958419), 30: (4, 31, 0.16130615755795472), 31: (4, 31, 0.16142872150146192), 32: (4, 31, 0.16129535968385397), 33: (4, 31, 0.16135465765311832), 34: (4, 31, 0.1613978937027916), 35: (4, 31, 0.1615117213298236), 36: (4, 31, 0.16134793134105782), 37: (4, 31, 0.1613793045642876), 38: (4, 31, 0.1613737056933103), 39: (4, 31, 0.16140823898416373), 40: (4, 31, 0.16133784583859867), 41: (4, 31, 0.16137585927161477), 42: (4, 31, 0.1613548191324357), 43: (4, 31, 0.16146781445751268), 44: (4, 31, 0.16139905067581323), 45: (4, 31, 0.16135443416574308), 46: (4, 31, 0.16139728473799844), 47: (4, 31, 0.161320828472174), 48: (4, 31, 0.16141523928531715), 49: (4, 31, 0.16143845745752897), 50: (4, 31, 0.16150332689886132), 51: (4, 31, 0.16148185192216788), 52: (4, 31, 0.1614334266031942), 53: (4, 31, 0.1614543677517964), 54: (4, 31, 0.16141551024010103), 55: (4, 31, 0.1613782618134733), 56: (4, 31, 0.1615164748302871), 57: (4, 31, 0.16145445643773965), 58: (4, 31, 0.16138020668539307), 59: (4, 31, 0.1614128007523475), 60: (4, 31, 0.16148399678809988), 61: (4, 31, 0.16147489202839713), 62: (4, 31, 0.16140241193915567), 63: (4, 31, 0.16150610758772782), 64: (4, 31, 0.16153671532388655), 65: (4, 31, 0.1614637930066355), 66: (4, 31, 0.16146369819198886), 67: (4, 31, 0.16148578790166684), 68: (4, 31, 0.16153213486916596), 69: (4, 31, 0.16146395812111516), 70: (4, 31, 0.16142918112417382)}\n",
      "{'predict_runtime': 400.8024, 'predict_samples_per_second': 0.701, 'predict_steps_per_second': 0.177}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:40.80\n",
      "  predict_samples_per_second =      0.701\n",
      "  predict_steps_per_second   =      0.177\n",
      "Evaluating with num_layers: 22\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.28379679191857576), 2: (1, 0.26440286729484797), 3: (1, 0.2656351123005152), 4: (1, 0.26612413115799427), 5: (1, 0.2637344980612397), 6: (1, 0.2638201480731368), 7: (1, 0.26372492872178555), 8: (1, 0.26370739843696356), 9: (1, 0.26391732785850763), 10: (1, 0.26432117633521557), 11: (1, 0.2637759381905198), 12: (1, 0.26336250826716423), 13: (1, 0.26347890868782997), 14: (1, 0.2637417381629348), 15: (1, 0.26497778482735157), 16: (1, 0.26440055575221777), 17: (1, 0.26386108808219433), 18: (1, 0.2639924082905054), 19: (1, 0.2639438770711422), 20: (1, 0.26409322675317526), 21: (1, 0.2638150481507182), 22: (1, 0.2636582786217332), 23: (1, 0.2640174385160208), 24: (1, 0.2660443913191557), 25: (1, 0.264705965295434), 26: (1, 0.2644364358857274), 27: (1, 0.2640953678637743), 28: (1, 0.2636442678049207), 29: (1, 0.2637149589136243), 30: (1, 0.2638683579862118), 31: (1, 0.26351819932460785), 32: (1, 0.2639990383759141), 33: (1, 0.26460697688162327), 34: (1, 0.26409212686121464), 35: (1, 0.2639744868502021), 36: (1, 0.2642500763759017), 37: (1, 0.2637433586642146), 38: (1, 0.2642020471394062), 39: (1, 0.264505535364151), 40: (1, 0.26414009649306536), 41: (1, 0.2637134585529566), 42: (1, 0.26724623795598745), 43: (1, 0.2649961235001683), 44: (1, 0.263723268173635), 45: (1, 0.2641870565712452), 46: (1, 0.26395484805107117), 47: (1, 0.26406992692500353), 48: (1, 0.26378458738327026), 49: (1, 0.26394807640463114), 50: (1, 0.2641434967517853), 51: (1, 0.2638127878308296), 52: (1, 0.2638888480141759), 53: (1, 0.263673497363925), 54: (1, 0.2637421675026417), 55: (1, 0.26375674828886986), 56: (1, 0.2638020580634475), 57: (1, 0.26394641771912575), 58: (1, 0.26367271784693), 59: (1, 0.26692291907966137), 60: (1, 0.2639705380424857), 61: (1, 0.2633806290104985), 62: (1, 0.264722085557878), 63: (1, 0.2650901237502694), 64: (1, 0.2639203770086169), 65: (1, 0.2642399473115802), 66: (1, 0.2637825980782509), 67: (1, 0.26401133835315704), 68: (1, 0.264119116589427), 69: (1, 0.2636026097461581), 70: (1, 0.26364660914987326), 71: (1, 0.2641505775973201)}\n",
      "{1: (1, 31, 0.09917998839650423), 2: (1, 31, 0.09892499164467858), 3: (1, 31, 0.09999450233073966), 4: (1, 31, 0.10169190105291144), 5: (1, 31, 0.09920250179786835), 6: (1, 31, 0.09900989383459091), 7: (1, 31, 0.09891501877216562), 8: (1, 31, 0.10194675588319378), 9: (1, 31, 0.10294580087065697), 10: (1, 31, 0.09907812751348942), 11: (1, 31, 0.09998014824645172), 12: (1, 31, 0.09946376878407694), 13: (1, 31, 0.09891114215697011), 14: (1, 31, 0.09895740981183705), 15: (1, 31, 0.09936025194943912), 16: (1, 31, 0.09972646210582987), 17: (1, 31, 0.09875476940144454), 18: (1, 31, 0.09986106159105416), 19: (1, 31, 0.09893646938425879), 20: (1, 31, 0.09892734001961447), 21: (1, 31, 0.09939288071567012), 22: (1, 31, 0.09978260859967239), 23: (1, 31, 0.09940987017246024), 24: (1, 31, 0.09927312735347979), 25: (1, 31, 0.09887416123021994), 26: (1, 31, 0.09892466820536121), 27: (1, 31, 0.09865174538666202), 28: (1, 31, 0.09886866913086945), 29: (1, 31, 0.09862732583837162), 30: (1, 31, 0.0987530869221495), 31: (1, 31, 0.0986781123604986), 32: (1, 31, 0.09887616195145153), 33: (1, 31, 0.0986776344418045), 34: (1, 31, 0.09866782064519582), 35: (1, 31, 0.09860520079852111), 36: (1, 31, 0.09865760280480308), 37: (1, 31, 0.09868345217358682), 38: (1, 31, 0.09863210454462998), 39: (1, 31, 0.09898897699050364), 40: (1, 31, 0.09859646577388048), 41: (1, 31, 0.09890529161859904), 42: (1, 31, 0.09872475491776582), 43: (1, 31, 0.09862885104432222), 44: (1, 31, 0.09852073038177143), 45: (1, 31, 0.0984656982904961), 46: (1, 31, 0.09877922334858487), 47: (1, 31, 0.09864758102283362), 48: (1, 31, 0.09875176231106443), 49: (1, 31, 0.09872036490349038), 50: (1, 31, 0.09858399091829215), 51: (1, 31, 0.09902744905482377), 52: (1, 31, 0.10301971387478613), 53: (1, 31, 0.10186385997240582), 54: (1, 31, 0.10476922553272978), 55: (1, 31, 0.10386362266276152), 56: (1, 31, 0.10409082478332904), 57: (1, 31, 0.10166422593136949), 58: (1, 31, 0.10453945773863985), 59: (1, 31, 0.10283701680600643), 60: (1, 31, 0.10020626624745707), 61: (1, 31, 0.10055340132525852), 62: (1, 31, 0.10134104435001651), 63: (1, 31, 0.10007401393546213), 64: (1, 31, 0.09961106018313477), 65: (1, 31, 0.09960984318487105), 66: (1, 31, 0.10156072309661296), 67: (1, 31, 0.09996779124823309), 68: (1, 31, 0.0999757602149921), 69: (1, 31, 0.10026659843541923), 70: (1, 31, 0.10134857604580541)}\n",
      "{'predict_runtime': 238.6628, 'predict_samples_per_second': 0.297, 'predict_steps_per_second': 0.297}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:03:58.66\n",
      "  predict_samples_per_second =      0.297\n",
      "  predict_steps_per_second   =      0.297\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.4350968496873975), 2: (2, 0.4134570211172104), 3: (2, 0.4134613713249564), 4: (2, 0.4116556057706475), 5: (2, 0.41200023610144854), 6: (2, 0.41221665497869253), 7: (2, 0.41137534752488136), 8: (2, 0.41208518482744694), 9: (2, 0.4121304051950574), 10: (2, 0.41290088277310133), 11: (2, 0.41248735412955284), 12: (2, 0.4121975852176547), 13: (2, 0.4131304416805506), 14: (2, 0.412869312800467), 15: (2, 0.4126484040170908), 16: (2, 0.41396375000476837), 17: (2, 0.4129618126899004), 18: (2, 0.4132149023935199), 19: (2, 0.4128237022086978), 20: (2, 0.41322385240346193), 21: (2, 0.41279861330986023), 22: (2, 0.4123867340385914), 23: (2, 0.4127986831590533), 24: (2, 0.413285662420094), 25: (2, 0.41303244326263666), 26: (2, 0.4126341938972473), 27: (2, 0.41439006850123405), 28: (2, 0.4128381432965398), 29: (2, 0.4129686113446951), 30: (2, 0.412923033349216), 31: (2, 0.41312144324183464), 32: (2, 0.41368770133703947), 33: (2, 0.4128568647429347), 34: (2, 0.4128557927906513), 35: (2, 0.4126321142539382), 36: (2, 0.4130801623687148), 37: (2, 0.4131807517260313), 38: (2, 0.41319015249609947), 39: (2, 0.4128996226936579), 40: (2, 0.41340785194188356), 41: (2, 0.412855782546103), 42: (2, 0.4131940519437194), 43: (2, 0.4126065541058779), 44: (2, 0.4133891109377146), 45: (2, 0.4128201939165592), 46: (2, 0.4133012518286705), 47: (2, 0.41280435398221016), 48: (2, 0.4125561835244298), 49: (2, 0.41316736210137606), 50: (2, 0.4126487448811531), 51: (2, 0.4129925034940243), 52: (2, 0.4129862831905484), 53: (2, 0.41310390271246433), 54: (2, 0.4125933339819312), 55: (2, 0.41315227188169956), 56: (2, 0.4135261010378599), 57: (2, 0.41273177322000265), 58: (2, 0.41288895439356565), 59: (2, 0.41314017307013273), 60: (2, 0.4131276123225689), 61: (2, 0.41348241083323956), 62: (2, 0.4124074140563607), 63: (2, 0.41283120308071375), 64: (2, 0.4130531223490834), 65: (2, 0.4128946829587221), 66: (2, 0.4125861134380102), 67: (2, 0.41228503454476595), 68: (2, 0.41222522500902414), 69: (2, 0.41337249148637056), 70: (2, 0.41099443938583136), 71: (1, 0.2630722504109144)}\n",
      "{1: (2, 31, 0.16386475960814184), 2: (2, 31, 0.16399469493978447), 3: (2, 31, 0.16586736394392868), 4: (2, 31, 0.1652804272429597), 5: (2, 31, 0.16406148326613249), 6: (2, 31, 0.16496424572241883), 7: (2, 31, 0.16380687505607644), 8: (2, 31, 0.1639596942752119), 9: (2, 31, 0.16421753600720437), 10: (2, 31, 0.16493129120358535), 11: (2, 31, 0.16419203393161297), 12: (2, 31, 0.1645636230767254), 13: (2, 31, 0.16537835836530693), 14: (2, 31, 0.16482689919611138), 15: (2, 31, 0.1642463739300447), 16: (2, 31, 0.16519729300372063), 17: (2, 31, 0.16384868128525634), 18: (2, 31, 0.16407508376024424), 19: (2, 31, 0.16376632668318286), 20: (2, 31, 0.16390427463357488), 21: (2, 31, 0.16387182519200347), 22: (2, 31, 0.1654751691967249), 23: (2, 31, 0.16795631876635936), 24: (2, 31, 0.16437492988282634), 25: (2, 31, 0.16392232228310838), 26: (2, 31, 0.16613613513688888), 27: (2, 31, 0.16524275909027747), 28: (2, 31, 0.16524190876272418), 29: (2, 31, 0.16526553644648484), 30: (2, 31, 0.16478884562609658), 31: (2, 31, 0.16558144965599622), 32: (2, 31, 0.16568996949541953), 33: (2, 31, 0.165753472145767), 34: (2, 31, 0.16484506311075342), 35: (2, 31, 0.16627541166399756), 36: (2, 31, 0.16644821072658222), 37: (2, 31, 0.16582124331785786), 38: (2, 31, 0.1651860502878985), 39: (2, 31, 0.16532213766608508), 40: (2, 31, 0.16612791747695976), 41: (2, 31, 0.1656829000060116), 42: (2, 31, 0.1649694415710626), 43: (2, 31, 0.16535964980721474), 44: (2, 31, 0.16629875910979125), 45: (2, 31, 0.16585995175785595), 46: (2, 31, 0.16557305014782375), 47: (2, 31, 0.16586331100833993), 48: (2, 31, 0.1648871752042924), 49: (2, 31, 0.1666315027602738), 50: (2, 31, 0.16471471484269826), 51: (2, 31, 0.1646826078274077), 52: (2, 31, 0.16462990557474474), 53: (2, 31, 0.16461479279302782), 54: (2, 31, 0.16482916444299683), 55: (2, 31, 0.16464381541816459), 56: (2, 31, 0.16459395015431988), 57: (2, 31, 0.16473202882034163), 58: (2, 31, 0.16467228492782002), 59: (2, 31, 0.16474279884489312), 60: (2, 31, 0.16457366132207454), 61: (2, 31, 0.1647422948792096), 62: (2, 31, 0.1646119320104199), 63: (2, 31, 0.16464969906355104), 64: (2, 31, 0.16366609417262576), 65: (2, 31, 0.1636047006674832), 66: (2, 31, 0.1634629669509107), 67: (2, 31, 0.1640442151636366), 68: (2, 31, 0.16356940663629962), 69: (2, 31, 0.16363173359704594), 70: (2, 31, 0.16347641792268522)}\n",
      "{'predict_runtime': 390.1632, 'predict_samples_per_second': 0.361, 'predict_steps_per_second': 0.182}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:30.16\n",
      "  predict_samples_per_second =      0.361\n",
      "  predict_steps_per_second   =      0.182\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.71663320902735), 2: (4, 0.6961661465466022), 3: (4, 0.6975503815338016), 4: (4, 0.6974805919453502), 5: (4, 0.6974923424422741), 6: (4, 0.6977316914126277), 7: (4, 0.6980427093803883), 8: (4, 0.6981330206617713), 9: (4, 0.6999285658821464), 10: (4, 0.698471199721098), 11: (4, 0.6983255594968796), 12: (4, 0.6978937815874815), 13: (4, 0.6987213594838977), 14: (4, 0.6991058671846986), 15: (4, 0.697918251156807), 16: (4, 0.6986814690753818), 17: (4, 0.697937791235745), 18: (4, 0.6981444414705038), 19: (4, 0.6986422501504421), 20: (4, 0.6984184803441167), 21: (4, 0.698127681389451), 22: (4, 0.6980324508622289), 23: (4, 0.6994484076276422), 24: (4, 0.6996124759316444), 25: (4, 0.6986779188737273), 26: (4, 0.6982376212254167), 27: (4, 0.6983149703592062), 28: (4, 0.6982778599485755), 29: (4, 0.6981252506375313), 30: (4, 0.6981761800125241), 31: (4, 0.6986393295228481), 32: (4, 0.6981493607163429), 33: (4, 0.6984422905370593), 34: (4, 0.6979551911354065), 35: (4, 0.6980798216536641), 36: (4, 0.6978210117667913), 37: (4, 0.6979904714971781), 38: (4, 0.6982850795611739), 39: (4, 0.6983698401600122), 40: (4, 0.6979216719046235), 41: (4, 0.6981364293023944), 42: (4, 0.6979460613802075), 43: (4, 0.6985114198178053), 44: (4, 0.6979607604444027), 45: (4, 0.6989048384130001), 46: (4, 0.6984895784407854), 47: (4, 0.6983094196766615), 48: (4, 0.6982343094423413), 49: (4, 0.6990404585376382), 50: (4, 0.6981152007356286), 51: (4, 0.6983398105949163), 52: (4, 0.6986634284257889), 53: (4, 0.6982221510261297), 54: (4, 0.6985535388812423), 55: (4, 0.6984175993129611), 56: (4, 0.6977140521630645), 57: (4, 0.6980375703424215), 58: (4, 0.6984409308061004), 59: (4, 0.6986489184200764), 60: (4, 0.6981847900897264), 61: (4, 0.698146641254425), 62: (4, 0.6979962810873985), 63: (4, 0.6984184794127941), 64: (4, 0.6982349902391434), 65: (4, 0.6986096985638142), 66: (4, 0.6981094516813755), 67: (4, 0.6989203579723835), 68: (4, 0.6981758307665586), 69: (4, 0.6985143097117543), 70: (4, 0.696608304977417), 71: (1, 0.2630341360345483)}\n",
      "{1: (4, 31, 0.17253960903373458), 2: (4, 31, 0.172912968562976), 3: (4, 31, 0.17372471610865287), 4: (4, 31, 0.16920019436867967), 5: (4, 31, 0.1737239166433292), 6: (4, 31, 0.17320573861680685), 7: (4, 31, 0.17380632562262396), 8: (4, 31, 0.17191892952447937), 9: (4, 31, 0.17342036133331637), 10: (4, 31, 0.1741045883466159), 11: (4, 31, 0.17318744347580978), 12: (4, 31, 0.17333352130146756), 13: (4, 31, 0.17400048991605158), 14: (4, 31, 0.1737886018330051), 15: (4, 31, 0.16904583666473627), 16: (4, 31, 0.17238535831171659), 17: (4, 31, 0.1736294090928089), 18: (4, 31, 0.17017278237448585), 19: (4, 31, 0.17188738040145365), 20: (4, 31, 0.1715876731060205), 21: (4, 31, 0.17234206235697191), 22: (4, 31, 0.17362875419278298), 23: (4, 31, 0.16975999896925303), 24: (4, 31, 0.1736137613714222), 25: (4, 31, 0.17034766570694984), 26: (4, 31, 0.1697840970309992), 27: (4, 31, 0.16996484276868642), 28: (4, 31, 0.16890589772693573), 29: (4, 31, 0.17104001009776706), 30: (4, 31, 0.16972332027169965), 31: (4, 31, 0.17015828501673474), 32: (4, 31, 0.1706360049185253), 33: (4, 31, 0.16881595431796967), 34: (4, 31, 0.16957047680813458), 35: (4, 31, 0.16905464024673547), 36: (4, 31, 0.17066009820348793), 37: (4, 31, 0.16897375740471385), 38: (4, 31, 0.16893388306902302), 39: (4, 31, 0.16898991624193807), 40: (4, 31, 0.1690239409104951), 41: (4, 31, 0.1714635553259042), 42: (4, 31, 0.16889075138756343), 43: (4, 31, 0.16897528285100574), 44: (4, 31, 0.1688920841101677), 45: (4, 31, 0.17120372329748446), 46: (4, 31, 0.16896141825183744), 47: (4, 31, 0.1714878995572367), 48: (4, 31, 0.17009400912830908), 49: (4, 31, 0.1710738490726198), 50: (4, 31, 0.16940585857317333), 51: (4, 31, 0.17025375693675973), 52: (4, 31, 0.17019546698899038), 53: (4, 31, 0.17106462221953175), 54: (4, 31, 0.17078508821225935), 55: (4, 31, 0.16928073835949745), 56: (4, 31, 0.1701388833443484), 57: (4, 31, 0.16905208244439093), 58: (4, 31, 0.1694327722333612), 59: (4, 31, 0.1692980192301254), 60: (4, 31, 0.16939655976790574), 61: (4, 31, 0.16940094617706153), 62: (4, 31, 0.16915509792705696), 63: (4, 31, 0.16918401128702587), 64: (4, 31, 0.16904150937954265), 65: (4, 31, 0.17020619946021226), 66: (4, 31, 0.16911265091790306), 67: (4, 31, 0.16915723405057384), 68: (4, 31, 0.16907298652034614), 69: (4, 31, 0.16907837145751523), 70: (4, 31, 0.16901882049897987)}\n",
      "{'predict_runtime': 422.8048, 'predict_samples_per_second': 0.665, 'predict_steps_per_second': 0.168}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:02.80\n",
      "  predict_samples_per_second =      0.665\n",
      "  predict_steps_per_second   =      0.168\n",
      "Evaluating with num_layers: 23\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.297503269277513), 2: (1, 0.27664067782461643), 3: (1, 0.27712608594447374), 4: (1, 0.2763045188039541), 5: (1, 0.2762121595442295), 6: (1, 0.2765340181067586), 7: (1, 0.2764414679259062), 8: (1, 0.27617654856294394), 9: (1, 0.27610986959189177), 10: (1, 0.27640571910887957), 11: (1, 0.2760632187128067), 12: (1, 0.2763037784025073), 13: (1, 0.2762157181277871), 14: (1, 0.27756488509476185), 15: (1, 0.27622963953763247), 16: (1, 0.2762510096654296), 17: (1, 0.27615946903824806), 18: (1, 0.27635499835014343), 19: (1, 0.2762133590877056), 20: (1, 0.27662128675729036), 21: (1, 0.2759511088952422), 22: (1, 0.27631372958421707), 23: (1, 0.27763730473816395), 24: (1, 0.27643138729035854), 25: (1, 0.27612730860710144), 26: (1, 0.2770273359492421), 27: (1, 0.27660178672522306), 28: (1, 0.27603920828551054), 29: (1, 0.2762440387159586), 30: (1, 0.2763771079480648), 31: (1, 0.27618519961833954), 32: (1, 0.27723069582134485), 33: (1, 0.2760954387485981), 34: (1, 0.2760733189061284), 35: (1, 0.2765023484826088), 36: (1, 0.2762376992031932), 37: (1, 0.2760221492499113), 38: (1, 0.27615134883672), 39: (1, 0.27645573765039444), 40: (1, 0.27653269842267036), 41: (1, 0.27623315900564194), 42: (1, 0.2761356784030795), 43: (1, 0.277944253757596), 44: (1, 0.2761774091050029), 45: (1, 0.27603611908853054), 46: (1, 0.27646284829825163), 47: (1, 0.27619154937565327), 48: (1, 0.2760698888450861), 49: (1, 0.2761750090867281), 50: (1, 0.27641227748245), 51: (1, 0.275909879244864), 52: (1, 0.27657401841133833), 53: (1, 0.2760790688917041), 54: (1, 0.27612104918807745), 55: (1, 0.27629667799919844), 56: (1, 0.27591526973992586), 57: (1, 0.27614867873489857), 58: (1, 0.2763237673789263), 59: (1, 0.276391108520329), 60: (1, 0.2774032447487116), 61: (1, 0.27636079769581556), 62: (1, 0.2764034578576684), 63: (1, 0.27678140718489885), 64: (1, 0.27636080887168646), 65: (1, 0.2758878106251359), 66: (1, 0.2765824282541871), 67: (1, 0.2766449963673949), 68: (1, 0.2763818381354213), 69: (1, 0.2760138204321265), 70: (1, 0.2763059986755252), 71: (1, 0.2754716416820884)}\n",
      "{1: (1, 31, 0.10437952660985532), 2: (1, 31, 0.10467956034887221), 3: (1, 31, 0.1042513768939722), 4: (1, 31, 0.10443228149726506), 5: (1, 31, 0.10427724362741556), 6: (1, 31, 0.10393506102263927), 7: (1, 31, 0.10400720965117216), 8: (1, 31, 0.10463955334477848), 9: (1, 31, 0.10473602006752644), 10: (1, 31, 0.10408905542065058), 11: (1, 31, 0.10432698003827565), 12: (1, 31, 0.10397932735542136), 13: (1, 31, 0.1046016428379282), 14: (1, 31, 0.10415870269700404), 15: (1, 31, 0.10404003910239666), 16: (1, 31, 0.10575235037193183), 17: (1, 31, 0.1039429440072948), 18: (1, 31, 0.10432380999648763), 19: (1, 31, 0.1041400414260645), 20: (1, 31, 0.10384207164808627), 21: (1, 31, 0.10379368210992505), 22: (1, 31, 0.10422389683944563), 23: (1, 31, 0.10451944385685268), 24: (1, 31, 0.10481776465331355), 25: (1, 31, 0.105178774004021), 26: (1, 31, 0.10389974956671076), 27: (1, 31, 0.1038683979441562), 28: (1, 31, 0.10425046645104885), 29: (1, 31, 0.10400624308855302), 30: (1, 31, 0.10421333897618516), 31: (1, 31, 0.1049253340930708), 32: (1, 31, 0.10387593570856317), 33: (1, 31, 0.10471973442021877), 34: (1, 31, 0.10396262618803209), 35: (1, 31, 0.10386654070668644), 36: (1, 31, 0.10405935680553798), 37: (1, 31, 0.104019382517905), 38: (1, 31, 0.10401932498620402), 39: (1, 31, 0.10418313933957007), 40: (1, 31, 0.10452665172276958), 41: (1, 31, 0.10384791743971648), 42: (1, 31, 0.10432081651543418), 43: (1, 31, 0.10410551849993006), 44: (1, 31, 0.10486928857262096), 45: (1, 31, 0.10428627162811256), 46: (1, 31, 0.10408010505019658), 47: (1, 31, 0.10428077745581826), 48: (1, 31, 0.10414213179460456), 49: (1, 31, 0.10390795436837981), 50: (1, 31, 0.10501173487113367), 51: (1, 31, 0.10427674768312324), 52: (1, 31, 0.1050270144196768), 53: (1, 31, 0.10457493737339973), 54: (1, 31, 0.10396730250889255), 55: (1, 31, 0.10435829921475341), 56: (1, 31, 0.10554381943638286), 57: (1, 31, 0.10487590766241474), 58: (1, 31, 0.1047298880594392), 59: (1, 31, 0.1045012557278237), 60: (1, 31, 0.1049903019842121), 61: (1, 31, 0.10473361449135889), 62: (1, 31, 0.104256009322501), 63: (1, 31, 0.10397140774875879), 64: (1, 31, 0.10455628796931236), 65: (1, 31, 0.10391816121315764), 66: (1, 31, 0.10412581706599842), 67: (1, 31, 0.10408617583133521), 68: (1, 31, 0.10400780152168966), 69: (1, 31, 0.10404463130379876), 70: (1, 31, 0.1043722057835229)}\n",
      "{'predict_runtime': 249.423, 'predict_samples_per_second': 0.285, 'predict_steps_per_second': 0.285}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:09.42\n",
      "  predict_samples_per_second =      0.285\n",
      "  predict_steps_per_second   =      0.285\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.45261815655976534), 2: (2, 0.4320287127047777), 3: (2, 0.4331715414300561), 4: (2, 0.43040688801556826), 5: (2, 0.43056717701256275), 6: (2, 0.4302710685878992), 7: (2, 0.4298738595098257), 8: (2, 0.4305643383413553), 9: (2, 0.4336910890415311), 10: (2, 0.43158138543367386), 11: (2, 0.4314544452354312), 12: (2, 0.4312465852126479), 13: (2, 0.43206889368593693), 14: (2, 0.4318196140229702), 15: (2, 0.433053120970726), 16: (2, 0.4305695975199342), 17: (2, 0.43114860635250807), 18: (2, 0.43021721858531237), 19: (2, 0.43033197801560163), 20: (2, 0.43170755356550217), 21: (2, 0.4303394388407469), 22: (2, 0.4317602850496769), 23: (2, 0.43117130640894175), 24: (2, 0.43239220324903727), 25: (2, 0.4329442912712693), 26: (2, 0.431864763610065), 27: (2, 0.43091927748173475), 28: (2, 0.4309359975159168), 29: (2, 0.4315321845933795), 30: (2, 0.4312174767255783), 31: (2, 0.43132700584828854), 32: (2, 0.4313854146748781), 33: (2, 0.4311256455257535), 34: (2, 0.4311761260032654), 35: (2, 0.4313942454755306), 36: (2, 0.4314450044184923), 37: (2, 0.4315115148201585), 38: (2, 0.43126662634313107), 39: (2, 0.431056447327137), 40: (2, 0.4315977552905679), 41: (2, 0.4312794841825962), 42: (2, 0.430939145386219), 43: (2, 0.43062586709856987), 44: (2, 0.4303865972906351), 45: (2, 0.4308342766016722), 46: (2, 0.430529547855258), 47: (2, 0.4301355592906475), 48: (2, 0.4305807473137975), 49: (2, 0.4307349668815732), 50: (2, 0.43041260819882154), 51: (2, 0.43050492741167545), 52: (2, 0.43039686791598797), 53: (2, 0.4309319267049432), 54: (2, 0.43016414903104305), 55: (2, 0.43064984772354364), 56: (2, 0.4307172270491719), 57: (2, 0.43070145789533854), 58: (2, 0.43097663577646017), 59: (2, 0.4306420786306262), 60: (2, 0.43057842645794153), 61: (2, 0.4304905775934458), 62: (2, 0.4311096938326955), 63: (2, 0.4304923051968217), 64: (2, 0.4304235363379121), 65: (2, 0.4311496848240495), 66: (2, 0.4305758448317647), 67: (2, 0.4305963646620512), 68: (2, 0.43001417722553015), 69: (2, 0.4306147648021579), 70: (2, 0.42953962832689285), 71: (1, 0.27428811229765415)}\n",
      "{1: (2, 31, 0.17208835233243241), 2: (2, 31, 0.17208801726660422), 3: (2, 31, 0.17210738180625823), 4: (2, 31, 0.17219652791297244), 5: (2, 31, 0.17207049914906103), 6: (2, 31, 0.1720295711270263), 7: (2, 31, 0.1720610275984772), 8: (2, 31, 0.17219823400580114), 9: (2, 31, 0.17199721436707244), 10: (2, 31, 0.17208440731009167), 11: (2, 31, 0.17205597992025076), 12: (2, 31, 0.17209532838915625), 13: (2, 31, 0.17214211476065458), 14: (2, 31, 0.17236319085162494), 15: (2, 31, 0.17211271615158166), 16: (2, 31, 0.1721730143312485), 17: (2, 31, 0.17200508389261462), 18: (2, 31, 0.17266728650898702), 19: (2, 31, 0.17249276023358107), 20: (2, 31, 0.17203558605885313), 21: (2, 31, 0.17116173263639212), 22: (2, 31, 0.17112162435847905), 23: (2, 31, 0.17135371150629175), 24: (2, 31, 0.1729092030155082), 25: (2, 31, 0.17213978023538667), 26: (2, 31, 0.17201420139040677), 27: (2, 31, 0.17202874363189744), 28: (2, 31, 0.17200459392681236), 29: (2, 31, 0.17240397154443687), 30: (2, 31, 0.1720829973778417), 31: (2, 31, 0.172091607725428), 32: (2, 31, 0.1721972812628073), 33: (2, 31, 0.17204846486809752), 34: (2, 31, 0.17220818293431112), 35: (2, 31, 0.1724125235191276), 36: (2, 31, 0.1722484253527176), 37: (2, 31, 0.17202421602222226), 38: (2, 31, 0.1724247665955655), 39: (2, 31, 0.17207166687735626), 40: (2, 31, 0.17215155867198784), 41: (2, 31, 0.1720138288012916), 42: (2, 31, 0.17089306608202956), 43: (2, 31, 0.17252779730986204), 44: (2, 31, 0.17204586245239742), 45: (2, 31, 0.17105778234620247), 46: (2, 31, 0.1709757349303653), 47: (2, 31, 0.1711353252251302), 48: (2, 31, 0.17097308486700058), 49: (2, 31, 0.17316699601830013), 50: (2, 31, 0.17108155913170306), 51: (2, 31, 0.1710687144509246), 52: (2, 31, 0.17157272189374892), 53: (2, 31, 0.17291317459556363), 54: (2, 31, 0.1709387417161657), 55: (2, 31, 0.17285437443323673), 56: (2, 31, 0.1710672272789863), 57: (2, 31, 0.1710242799092685), 58: (2, 31, 0.17320652366165193), 59: (2, 31, 0.1721253544392605), 60: (2, 31, 0.17133324139661366), 61: (2, 31, 0.17227330665674903), 62: (2, 31, 0.1711213155799816), 63: (2, 31, 0.17315015890785762), 64: (2, 31, 0.17124764513104193), 65: (2, 31, 0.1713681207789529), 66: (2, 31, 0.17260918318624457), 67: (2, 31, 0.17109048141226654), 68: (2, 31, 0.17211653316213238), 69: (2, 31, 0.1732243623945021), 70: (2, 31, 0.1717960474291636)}\n",
      "{'predict_runtime': 407.0004, 'predict_samples_per_second': 0.346, 'predict_steps_per_second': 0.174}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:06:47.00\n",
      "  predict_samples_per_second =      0.346\n",
      "  predict_steps_per_second   =      0.174\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.7483320264145732), 2: (4, 0.7271965956315398), 3: (4, 0.7283421019092202), 4: (4, 0.7280225232243538), 5: (4, 0.7277797125279903), 6: (4, 0.7277753241360188), 7: (4, 0.7280363934114575), 8: (4, 0.729725987650454), 9: (4, 0.7305448660627007), 10: (4, 0.7296506194397807), 11: (4, 0.7297319695353508), 12: (4, 0.7304232772439718), 13: (4, 0.7299887482076883), 14: (4, 0.7302424572408199), 15: (4, 0.7292317906394601), 16: (4, 0.7309189550578594), 17: (4, 0.7295190589502454), 18: (4, 0.7290909308940172), 19: (4, 0.7304782569408417), 20: (4, 0.7296000495553017), 21: (4, 0.7295244885608554), 22: (4, 0.7301024785265326), 23: (4, 0.7292396295815706), 24: (4, 0.7302943272516131), 25: (4, 0.7296491786837578), 26: (4, 0.7296363990753889), 27: (4, 0.7292644688859582), 28: (4, 0.7292088996618986), 29: (4, 0.7292788801714778), 30: (4, 0.7293361499905586), 31: (4, 0.7294769892469049), 32: (4, 0.7290142606943846), 33: (4, 0.7289540404453874), 34: (4, 0.7292829602956772), 35: (4, 0.7296759579330683), 36: (4, 0.7286897515878081), 37: (4, 0.7292323792353272), 38: (4, 0.7292298804968596), 39: (4, 0.7288590809330344), 40: (4, 0.7291316101327538), 41: (4, 0.7290620496496558), 42: (4, 0.7291074693202972), 43: (4, 0.7293341187760234), 44: (4, 0.7298126174136996), 45: (4, 0.7295701680704951), 46: (4, 0.729561829008162), 47: (4, 0.7288359310477972), 48: (4, 0.729642178863287), 49: (4, 0.7290937704965472), 50: (4, 0.7288242308422923), 51: (4, 0.729266588576138), 52: (4, 0.729000760242343), 53: (4, 0.7290274100378156), 54: (4, 0.7291493397206068), 55: (4, 0.7290883408859372), 56: (4, 0.7295214589685202), 57: (4, 0.7297291476279497), 58: (4, 0.7299834080040455), 59: (4, 0.7293918086215854), 60: (4, 0.729161529801786), 61: (4, 0.729670949280262), 62: (4, 0.7295084092766047), 63: (4, 0.728752551600337), 64: (4, 0.7295512296259403), 65: (4, 0.7298069978132844), 66: (4, 0.7295281793922186), 67: (4, 0.7296129185706377), 68: (4, 0.7291104504838586), 69: (4, 0.7290940806269646), 70: (4, 0.7278340738266706), 71: (1, 0.27513178158551455)}\n",
      "{1: (4, 31, 0.1769337588320336), 2: (4, 31, 0.17716102106797119), 3: (4, 31, 0.17799759677220736), 4: (4, 31, 0.17792326037681871), 5: (4, 31, 0.1788073674505276), 6: (4, 31, 0.17804058346777193), 7: (4, 31, 0.1768811453554419), 8: (4, 31, 0.17712874839743298), 9: (4, 31, 0.17896653705787274), 10: (4, 31, 0.17691387314229243), 11: (4, 31, 0.17781703768958967), 12: (4, 31, 0.1774127027320285), 13: (4, 31, 0.17745170760298928), 14: (4, 31, 0.1773098063084387), 15: (4, 31, 0.1770975000014709), 16: (4, 31, 0.17690223830962373), 17: (4, 31, 0.17694356803211472), 18: (4, 31, 0.1768728698333425), 19: (4, 31, 0.1772565785194597), 20: (4, 31, 0.17691093893541443), 21: (4, 31, 0.17711269251641729), 22: (4, 31, 0.17705003983311116), 23: (4, 31, 0.17684482641878627), 24: (4, 31, 0.17714008259316605), 25: (4, 31, 0.17712605777647225), 26: (4, 31, 0.17717097450288072), 27: (4, 31, 0.18103038005891345), 28: (4, 31, 0.17821848719951608), 29: (4, 31, 0.17951237893993816), 30: (4, 31, 0.17825620089687647), 31: (4, 31, 0.17995460046034667), 32: (4, 31, 0.17731795880583026), 33: (4, 31, 0.17842176490493358), 34: (4, 31, 0.1767653823499718), 35: (4, 31, 0.17760742032119342), 36: (4, 31, 0.17676455518531223), 37: (4, 31, 0.17710470997037425), 38: (4, 31, 0.1768761352906304), 39: (4, 31, 0.17679114952202765), 40: (4, 31, 0.17815786822428625), 41: (4, 31, 0.17681044000651566), 42: (4, 31, 0.17748343424811477), 43: (4, 31, 0.17677637057438975), 44: (4, 31, 0.1779673712989015), 45: (4, 31, 0.1801632397597836), 46: (4, 31, 0.1767396431175932), 47: (4, 31, 0.17764313930585499), 48: (4, 31, 0.17670636681178886), 49: (4, 31, 0.17679573123854014), 50: (4, 31, 0.17719043779277033), 51: (4, 31, 0.1777133161742841), 52: (4, 31, 0.17683926840583164), 53: (4, 31, 0.17792783500326256), 54: (4, 31, 0.17681623238228983), 55: (4, 31, 0.17679700255393982), 56: (4, 31, 0.17697080483119335), 57: (4, 31, 0.17761946370404574), 58: (4, 31, 0.17960728494630707), 59: (4, 31, 0.17685475804272197), 60: (4, 31, 0.17717924596922052), 61: (4, 31, 0.17692890592039592), 62: (4, 31, 0.17722888417061297), 63: (4, 31, 0.17781315954221832), 64: (4, 31, 0.17691117798488948), 65: (4, 31, 0.17809308073934046), 66: (4, 31, 0.1768208463045378), 67: (4, 31, 0.17745791667050892), 68: (4, 31, 0.1795446541340601), 69: (4, 31, 0.17782538050725574), 70: (4, 31, 0.17689089083503332)}\n",
      "{'predict_runtime': 439.9754, 'predict_samples_per_second': 0.639, 'predict_steps_per_second': 0.161}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:19.97\n",
      "  predict_samples_per_second =      0.639\n",
      "  predict_steps_per_second   =      0.161\n",
      "Evaluating with num_layers: 24\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.30753619968891144), 2: (1, 0.28707311674952507), 3: (1, 0.28680670727044344), 4: (1, 0.2882209038361907), 5: (1, 0.2869695369154215), 6: (1, 0.2872391054406762), 7: (1, 0.28710143733769655), 8: (1, 0.28698661737143993), 9: (1, 0.2871046094223857), 10: (1, 0.2871118374168873), 11: (1, 0.28695131838321686), 12: (1, 0.28702488634735346), 13: (1, 0.28706199675798416), 14: (1, 0.2869895473122597), 15: (1, 0.2881288044154644), 16: (1, 0.28702358715236187), 17: (1, 0.2868717070668936), 18: (1, 0.287167745642364), 19: (1, 0.2870785864070058), 20: (1, 0.28755096439272165), 21: (1, 0.2869727062061429), 22: (1, 0.2868297081440687), 23: (1, 0.28819161374121904), 24: (1, 0.28761213459074497), 25: (1, 0.28680391795933247), 26: (1, 0.287155507132411), 27: (1, 0.28739513643085957), 28: (1, 0.28726012632250786), 29: (1, 0.2869704971089959), 30: (1, 0.28697024658322334), 31: (1, 0.28962663002312183), 32: (1, 0.28787439316511154), 33: (1, 0.28700385708361864), 34: (1, 0.2870979066938162), 35: (1, 0.28715803660452366), 36: (1, 0.2869622865691781), 37: (1, 0.28687063697725534), 38: (1, 0.28715562634170055), 39: (1, 0.28699948638677597), 40: (1, 0.2875228552147746), 41: (1, 0.28715082723647356), 42: (1, 0.2870886866003275), 43: (1, 0.28821088280528784), 44: (1, 0.28689064737409353), 45: (1, 0.2871701158583164), 46: (1, 0.2871425272896886), 47: (1, 0.28675670735538006), 48: (1, 0.28728378657251596), 49: (1, 0.28730731550604105), 50: (1, 0.28718503657728434), 51: (1, 0.28702183719724417), 52: (1, 0.2874546954408288), 53: (1, 0.2870191168040037), 54: (1, 0.2869341569021344), 55: (1, 0.2870967863127589), 56: (1, 0.28700604662299156), 57: (1, 0.2867140378803015), 58: (1, 0.2870840569958091), 59: (1, 0.2867716681212187), 60: (1, 0.2869189381599426), 61: (1, 0.2871891474351287), 62: (1, 0.2867577485740185), 63: (1, 0.28687920700758696), 64: (1, 0.28710829745978117), 65: (1, 0.28718897607177496), 66: (1, 0.2869731467217207), 67: (1, 0.2872206773608923), 68: (1, 0.2870188169181347), 69: (1, 0.2869113078340888), 70: (1, 0.286854256875813), 71: (1, 0.28622047882527113)}\n",
      "{1: (1, 31, 0.1122515240023213), 2: (1, 31, 0.1075106276079051), 3: (1, 31, 0.10905056726187468), 4: (1, 31, 0.11157780723466028), 5: (1, 31, 0.10907563615229822), 6: (1, 31, 0.10714203753178159), 7: (1, 31, 0.10883825731974456), 8: (1, 31, 0.10910437871972399), 9: (1, 31, 0.1083913589677503), 10: (1, 31, 0.10806453603530122), 11: (1, 31, 0.1071773326745437), 12: (1, 31, 0.10719830506751614), 13: (1, 31, 0.11307564675207099), 14: (1, 31, 0.10921424480095025), 15: (1, 31, 0.10777695332804034), 16: (1, 31, 0.11155144044107967), 17: (1, 31, 0.107919440634789), 18: (1, 31, 0.10798628571172876), 19: (1, 31, 0.10775304321319826), 20: (1, 31, 0.10793253671257727), 21: (1, 31, 0.10792515075374995), 22: (1, 31, 0.10746462273621751), 23: (1, 31, 0.10762115006124781), 24: (1, 31, 0.10715945314375623), 25: (1, 31, 0.1070721086655413), 26: (1, 31, 0.10707072267729428), 27: (1, 31, 0.10704521462321281), 28: (1, 31, 0.10712235811496934), 29: (1, 31, 0.10710709145472895), 30: (1, 31, 0.10751592833548784), 31: (1, 31, 0.1071409445496336), 32: (1, 31, 0.10741469750721608), 33: (1, 31, 0.10708099462452435), 34: (1, 31, 0.10719589279183457), 35: (1, 31, 0.10704178759647955), 36: (1, 31, 0.10752901810431673), 37: (1, 31, 0.10716826973422881), 38: (1, 31, 0.10717091955725223), 39: (1, 31, 0.10723944383883668), 40: (1, 31, 0.10727543831472436), 41: (1, 31, 0.10701273808315877), 42: (1, 31, 0.10764907255408264), 43: (1, 31, 0.10762697917919967), 44: (1, 31, 0.10706226990347908), 45: (1, 31, 0.10699864350739986), 46: (1, 31, 0.10735892843935758), 47: (1, 31, 0.10701711887433644), 48: (1, 31, 0.10702921723526332), 49: (1, 31, 0.10699408267053866), 50: (1, 31, 0.10709244496519527), 51: (1, 31, 0.107034795076376), 52: (1, 31, 0.10702663732151832), 53: (1, 31, 0.10697490130100519), 54: (1, 31, 0.10706133137066517), 55: (1, 31, 0.1069808944819435), 56: (1, 31, 0.10712794241525474), 57: (1, 31, 0.10719530705002046), 58: (1, 31, 0.10712486172034856), 59: (1, 31, 0.10700345447947902), 60: (1, 31, 0.10754696502079887), 61: (1, 31, 0.10777762943818685), 62: (1, 31, 0.10719661808182154), 63: (1, 31, 0.1070466895077017), 64: (1, 31, 0.10704225076422576), 65: (1, 31, 0.1069892947111399), 66: (1, 31, 0.10707602959366576), 67: (1, 31, 0.10708559908333325), 68: (1, 31, 0.1070814081918328), 69: (1, 31, 0.10723909825807618), 70: (1, 31, 0.10704756567194577)}\n",
      "{'predict_runtime': 257.5728, 'predict_samples_per_second': 0.276, 'predict_steps_per_second': 0.276}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:17.57\n",
      "  predict_samples_per_second =      0.276\n",
      "  predict_steps_per_second   =      0.276\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.47253453731536865), 2: (2, 0.45326599199324846), 3: (2, 0.45175684709101915), 4: (2, 0.4508938193321228), 5: (2, 0.44976662192493677), 6: (2, 0.4499141117557883), 7: (2, 0.450585950165987), 8: (2, 0.45304836332798004), 9: (2, 0.4506396288052201), 10: (2, 0.4517555059865117), 11: (2, 0.4503744402900338), 12: (2, 0.45193943474441767), 13: (2, 0.4549385067075491), 14: (2, 0.4517587162554264), 15: (2, 0.449740681797266), 16: (2, 0.4500274211168289), 17: (2, 0.4516411665827036), 18: (2, 0.4507099287584424), 19: (2, 0.4504433600232005), 20: (2, 0.4519151048734784), 21: (2, 0.45102951768785715), 22: (2, 0.45176292583346367), 23: (2, 0.4500697208568454), 24: (2, 0.45008804090321064), 25: (2, 0.4511743178591132), 26: (2, 0.4507340183481574), 27: (2, 0.45218498539179564), 28: (2, 0.4515058370307088), 29: (2, 0.4509872877970338), 30: (2, 0.4509865092113614), 31: (2, 0.4521509651094675), 32: (2, 0.45142716728150845), 33: (2, 0.45110365748405457), 34: (2, 0.4505375800654292), 35: (2, 0.45054248906672), 36: (2, 0.4508841186761856), 37: (2, 0.45131844747811556), 38: (2, 0.45022907946258783), 39: (2, 0.45128180738538504), 40: (2, 0.4512004069983959), 41: (2, 0.450714779086411), 42: (2, 0.4512006174772978), 43: (2, 0.4513003882020712), 44: (2, 0.4509221576154232), 45: (2, 0.4505374087020755), 46: (2, 0.450643259100616), 47: (2, 0.4511522613465786), 48: (2, 0.4509341921657324), 49: (2, 0.45153575018048286), 50: (2, 0.4511332903057337), 51: (2, 0.4509512819349766), 52: (2, 0.4509562822058797), 53: (2, 0.4519122587516904), 54: (2, 0.4501186739653349), 55: (2, 0.45095080230385065), 56: (2, 0.4512178609147668), 57: (2, 0.4506416730582714), 58: (2, 0.4513095607981086), 59: (2, 0.4503422426059842), 60: (2, 0.4510793723165989), 61: (2, 0.45088285207748413), 62: (2, 0.45166891999542713), 63: (2, 0.4514063512906432), 64: (2, 0.45052498299628496), 65: (2, 0.45137695129960775), 66: (2, 0.4509505219757557), 67: (2, 0.45102679170668125), 68: (2, 0.45173870865255594), 69: (2, 0.4513900997117162), 70: (2, 0.45059522334486246), 71: (1, 0.2860422981902957)}\n",
      "{1: (2, 31, 0.1782999160369077), 2: (2, 31, 0.17825409226239688), 3: (2, 31, 0.17820577035027166), 4: (2, 31, 0.17808709636090264), 5: (2, 31, 0.17815722335851), 6: (2, 31, 0.17822240022641997), 7: (2, 31, 0.178771342060739), 8: (2, 31, 0.17800993868900883), 9: (2, 31, 0.17825487367207965), 10: (2, 31, 0.17792668031348335), 11: (2, 31, 0.178508133477261), 12: (2, 31, 0.17803788128038567), 13: (2, 31, 0.17834242060780525), 14: (2, 31, 0.17816949566645968), 15: (2, 31, 0.17841687621248345), 16: (2, 31, 0.17819254205472046), 17: (2, 31, 0.17819426833621918), 18: (2, 31, 0.17812145032709645), 19: (2, 31, 0.17802331824937173), 20: (2, 31, 0.1781108462582192), 21: (2, 31, 0.17815397015862888), 22: (2, 31, 0.17822857375346846), 23: (2, 31, 0.17977644527150738), 24: (2, 31, 0.18075025406095288), 25: (2, 31, 0.18083762650888774), 26: (2, 31, 0.17825716292305338), 27: (2, 31, 0.17799875975376175), 28: (2, 31, 0.17897169313002978), 29: (2, 31, 0.17802149844506093), 30: (2, 31, 0.17985575592085237), 31: (2, 31, 0.17836493791471567), 32: (2, 31, 0.17868282847226627), 33: (2, 31, 0.1779664343283061), 34: (2, 31, 0.17803036977326678), 35: (2, 31, 0.17816151372126995), 36: (2, 31, 0.17927453138174548), 37: (2, 31, 0.17817758726737193), 38: (2, 31, 0.17898566113604653), 39: (2, 31, 0.17807720472375232), 40: (2, 31, 0.1782005488151504), 41: (2, 31, 0.17914092606834828), 42: (2, 31, 0.17942340116226865), 43: (2, 31, 0.178489918640304), 44: (2, 31, 0.17804891249585536), 45: (2, 31, 0.17813788417486415), 46: (2, 31, 0.17797299973185984), 47: (2, 31, 0.1783250138584164), 48: (2, 31, 0.17824736673144564), 49: (2, 31, 0.17802659842756488), 50: (2, 31, 0.17940497371338068), 51: (2, 31, 0.17807856280236475), 52: (2, 31, 0.17804808842559014), 53: (2, 31, 0.17820206753188564), 54: (2, 31, 0.17803640246030786), 55: (2, 31, 0.17911840034949203), 56: (2, 31, 0.17835262423801806), 57: (2, 31, 0.17853136333606898), 58: (2, 31, 0.1780683426486869), 59: (2, 31, 0.17823170077416203), 60: (2, 31, 0.17843540902099303), 61: (2, 31, 0.17809304219460295), 62: (2, 31, 0.17898108614909072), 63: (2, 31, 0.17827186108596862), 64: (2, 31, 0.1792989623462481), 65: (2, 31, 0.17799228495888172), 66: (2, 31, 0.18048120052703925), 67: (2, 31, 0.1783338216463885), 68: (2, 31, 0.1780543517501604), 69: (2, 31, 0.1779749016728132), 70: (2, 31, 0.17917468549022753)}\n",
      "{'predict_runtime': 422.6814, 'predict_samples_per_second': 0.334, 'predict_steps_per_second': 0.168}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:02.68\n",
      "  predict_samples_per_second =      0.334\n",
      "  predict_steps_per_second   =      0.168\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.7800294887274504), 2: (4, 0.7588497288525105), 3: (4, 0.7605716045945883), 4: (4, 0.7584619605913758), 5: (4, 0.7585407104343176), 6: (4, 0.7583647100254893), 7: (4, 0.7585514103993773), 8: (4, 0.7585825994610786), 9: (4, 0.7595648169517517), 10: (4, 0.7587047293782234), 11: (4, 0.7592761181294918), 12: (4, 0.758791540749371), 13: (4, 0.7582085216417909), 14: (4, 0.7597547061741352), 15: (4, 0.7588186487555504), 16: (4, 0.7590231783688068), 17: (4, 0.759467457421124), 18: (4, 0.758736539632082), 19: (4, 0.7588914288207889), 20: (4, 0.7589327488094568), 21: (4, 0.7594542074948549), 22: (4, 0.7587879104539752), 23: (4, 0.7595784571021795), 24: (4, 0.7586246998980641), 25: (4, 0.7588926292955875), 26: (4, 0.7590798884630203), 27: (4, 0.7585744401440024), 28: (4, 0.7583477506414056), 29: (4, 0.7588869398459792), 30: (4, 0.7589859776198864), 31: (4, 0.7589194187894464), 32: (4, 0.7585279094055295), 33: (4, 0.7589823585003614), 34: (4, 0.7590491594746709), 35: (4, 0.758964697830379), 36: (4, 0.7583139315247536), 37: (4, 0.7590224985033274), 38: (4, 0.7582390615716577), 39: (4, 0.7591439979150891), 40: (4, 0.7581466808915138), 41: (4, 0.7590150982141495), 42: (4, 0.7585601797327399), 43: (4, 0.7589975595474243), 44: (4, 0.7591072283685207), 45: (4, 0.7587940488010645), 46: (4, 0.7589121181517839), 47: (4, 0.7596927555277944), 48: (4, 0.7589651681482792), 49: (4, 0.7592556374147534), 50: (4, 0.7591067086905241), 51: (4, 0.7591668674722314), 52: (4, 0.7593810986727476), 53: (4, 0.7594922864809632), 54: (4, 0.7594709470868111), 55: (4, 0.7597223864868283), 56: (4, 0.7587966285645962), 57: (4, 0.7591503076255322), 58: (4, 0.7589946389198303), 59: (4, 0.7591269677504897), 60: (4, 0.7585009997710586), 61: (4, 0.7596162464469671), 62: (4, 0.7589572984725237), 63: (4, 0.759184387512505), 64: (4, 0.7588215488940477), 65: (4, 0.7593930577859282), 66: (4, 0.7591114183887839), 67: (4, 0.759153057821095), 68: (4, 0.7586427992209792), 69: (4, 0.758904398418963), 70: (4, 0.7579762814566493), 71: (1, 0.2864354979246855)}\n",
      "{1: (4, 31, 0.18606778835096666), 2: (4, 31, 0.18419574119991833), 3: (4, 31, 0.18624424877306145), 4: (4, 31, 0.18460165610116336), 5: (4, 31, 0.18437256603952376), 6: (4, 31, 0.18508758855563018), 7: (4, 31, 0.18505172067952733), 8: (4, 31, 0.1844401349944453), 9: (4, 31, 0.18414212486916973), 10: (4, 31, 0.1841874917848937), 11: (4, 31, 0.1847278962752992), 12: (4, 31, 0.18657546006743947), 13: (4, 31, 0.18465244466619146), 14: (4, 31, 0.1841119378504734), 15: (4, 31, 0.1841069410344766), 16: (4, 31, 0.18463674974778005), 17: (4, 31, 0.1849663574548979), 18: (4, 31, 0.18417300884762117), 19: (4, 31, 0.18548741480035166), 20: (4, 31, 0.18560946783832005), 21: (4, 31, 0.18512102390729612), 22: (4, 31, 0.18481298121473483), 23: (4, 31, 0.185453851767365), 24: (4, 31, 0.18397034211985527), 25: (4, 31, 0.18424456007778645), 26: (4, 31, 0.18415919219654414), 27: (4, 31, 0.18433084822590312), 28: (4, 31, 0.1839061223210827), 29: (4, 31, 0.1845318412468318), 30: (4, 31, 0.18474975657919723), 31: (4, 31, 0.18422559528581559), 32: (4, 31, 0.1851774596519047), 33: (4, 31, 0.1858717541420652), 34: (4, 31, 0.18406073776103796), 35: (4, 31, 0.18737213953488296), 36: (4, 31, 0.18407465027825487), 37: (4, 31, 0.18403269143234338), 38: (4, 31, 0.1839539688380976), 39: (4, 31, 0.1855190886304744), 40: (4, 31, 0.1841005117241894), 41: (4, 31, 0.18404819308629922), 42: (4, 31, 0.1842164048143933), 43: (4, 31, 0.1855845610581098), 44: (4, 31, 0.18577628071990707), 45: (4, 31, 0.18460917821334255), 46: (4, 31, 0.18520365237829187), 47: (4, 31, 0.18818448691238318), 48: (4, 31, 0.1870418269968321), 49: (4, 31, 0.18840931334923353), 50: (4, 31, 0.18846637350056442), 51: (4, 31, 0.18891198641710705), 52: (4, 31, 0.1888557706749247), 53: (4, 31, 0.18924697446486644), 54: (4, 31, 0.18758584090298222), 55: (4, 31, 0.1886688864699775), 56: (4, 31, 0.1887831423251379), 57: (4, 31, 0.1843494761194433), 58: (4, 31, 0.1856652009150674), 59: (4, 31, 0.1853238102349062), 60: (4, 31, 0.18685014590981505), 61: (4, 31, 0.1845831093829005), 62: (4, 31, 0.18417118012063927), 63: (4, 31, 0.18432769059173523), 64: (4, 31, 0.1843629258594686), 65: (4, 31, 0.18448255673771904), 66: (4, 31, 0.1858807468125897), 67: (4, 31, 0.1851468806064898), 68: (4, 31, 0.18631889577955008), 69: (4, 31, 0.18554144626062724), 70: (4, 31, 0.1849263255754786)}\n",
      "{'predict_runtime': 459.2258, 'predict_samples_per_second': 0.612, 'predict_steps_per_second': 0.155}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:39.22\n",
      "  predict_samples_per_second =      0.612\n",
      "  predict_steps_per_second   =      0.155\n",
      "Evaluating with num_layers: 25\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.31937194522470236), 2: (1, 0.3017980754375458), 3: (1, 0.29910406190901995), 4: (1, 0.29960001073777676), 5: (1, 0.29904086235910654), 6: (1, 0.30131559632718563), 7: (1, 0.29937396105378866), 8: (1, 0.299221302382648), 9: (1, 0.2989536924287677), 10: (1, 0.2988572921603918), 11: (1, 0.29887397307902575), 12: (1, 0.29981140047311783), 13: (1, 0.29898969270288944), 14: (1, 0.30002149008214474), 15: (1, 0.2991550527513027), 16: (1, 0.2991147618740797), 17: (1, 0.29965694062411785), 18: (1, 0.2990525923669338), 19: (1, 0.299198841676116), 20: (1, 0.2998053692281246), 21: (1, 0.2985362038016319), 22: (1, 0.2989853732287884), 23: (1, 0.298815181478858), 24: (1, 0.29917342122644186), 25: (1, 0.30004344042390585), 26: (1, 0.29912171233445406), 27: (1, 0.2987346639856696), 28: (1, 0.2994078919291496), 29: (1, 0.2993368115276098), 30: (1, 0.2998209102079272), 31: (1, 0.2987314136698842), 32: (1, 0.2991159837692976), 33: (1, 0.2992595713585615), 34: (1, 0.2991187423467636), 35: (1, 0.299093771725893), 36: (1, 0.29922069143503904), 37: (1, 0.29899275209754705), 38: (1, 0.2989644631743431), 39: (1, 0.29908787179738283), 40: (1, 0.29899629298597574), 41: (1, 0.29881821293383837), 42: (1, 0.2993593020364642), 43: (1, 0.2987026032060385), 44: (1, 0.29855444375425577), 45: (1, 0.2988326223567128), 46: (1, 0.29887142311781645), 47: (1, 0.29858657345175743), 48: (1, 0.2991653820499778), 49: (1, 0.299011611379683), 50: (1, 0.2990891020745039), 51: (1, 0.2994633913040161), 52: (1, 0.29898830130696297), 53: (1, 0.2990900129079819), 54: (1, 0.2988499328494072), 55: (1, 0.29923312086611986), 56: (1, 0.2993058115243912), 57: (1, 0.2985123135149479), 58: (1, 0.2984957033768296), 59: (1, 0.29866818338632584), 60: (1, 0.2983267242088914), 61: (1, 0.2985807228833437), 62: (1, 0.29860425367951393), 63: (1, 0.2986399633809924), 64: (1, 0.29880147241055965), 65: (1, 0.29892223235219717), 66: (1, 0.2986593022942543), 67: (1, 0.2982728835195303), 68: (1, 0.29841411393135786), 69: (1, 0.2988109737634659), 70: (1, 0.29864893294870853), 71: (1, 0.2977988161146641)}\n",
      "{1: (1, 31, 0.11554084760287116), 2: (1, 31, 0.11848881786629077), 3: (1, 31, 0.11506490418387036), 4: (1, 31, 0.11857918676950278), 5: (1, 31, 0.11482582049023721), 6: (1, 31, 0.11298277358254118), 7: (1, 31, 0.1175669215980076), 8: (1, 31, 0.11207363505156771), 9: (1, 31, 0.11299209332754535), 10: (1, 31, 0.11538451964095715), 11: (1, 31, 0.114142321951447), 12: (1, 31, 0.11261594277476111), 13: (1, 31, 0.11554827583172629), 14: (1, 31, 0.11217382451098773), 15: (1, 31, 0.1119792785555605), 16: (1, 31, 0.11196989457934134), 17: (1, 31, 0.11205557649654727), 18: (1, 31, 0.11229191687438757), 19: (1, 31, 0.11269771379809226), 20: (1, 31, 0.11247383343476441), 21: (1, 31, 0.1124546277006307), 22: (1, 31, 0.11206323310973183), 23: (1, 31, 0.11216487368989375), 24: (1, 31, 0.11215381138026714), 25: (1, 31, 0.11334808909844968), 26: (1, 31, 0.11312161133654657), 27: (1, 31, 0.11215413758350957), 28: (1, 31, 0.11306733815299888), 29: (1, 31, 0.11213157217829459), 30: (1, 31, 0.11313355482754207), 31: (1, 31, 0.11209491700414688), 32: (1, 31, 0.11199374295650952), 33: (1, 31, 0.11207022571996335), 34: (1, 31, 0.11200034684471545), 35: (1, 31, 0.11182965972130338), 36: (1, 31, 0.11178659428391725), 37: (1, 31, 0.11179865539194114), 38: (1, 31, 0.11236684414888581), 39: (1, 31, 0.11241085067271225), 40: (1, 31, 0.11261938629491676), 41: (1, 31, 0.11273381147052973), 42: (1, 31, 0.11336592708023326), 43: (1, 31, 0.1119183398062183), 44: (1, 31, 0.11194889899343252), 45: (1, 31, 0.11266718351192051), 46: (1, 31, 0.1122475873017984), 47: (1, 31, 0.11189141415900761), 48: (1, 31, 0.11204676732661263), 49: (1, 31, 0.11291371481192689), 50: (1, 31, 0.11213430296629667), 51: (1, 31, 0.11221209372724256), 52: (1, 31, 0.11186404964856562), 53: (1, 31, 0.11162372645471365), 54: (1, 31, 0.11207526360428141), 55: (1, 31, 0.11155944578950444), 56: (1, 31, 0.11300920604938461), 57: (1, 31, 0.11154532630837732), 58: (1, 31, 0.11165561088390889), 59: (1, 31, 0.11174087346561494), 60: (1, 31, 0.11167193627766063), 61: (1, 31, 0.11179927988879142), 62: (1, 31, 0.11165371417037902), 63: (1, 31, 0.11151524897544615), 64: (1, 31, 0.1116645625762401), 65: (1, 31, 0.11167169794920952), 66: (1, 31, 0.11187597433285366), 67: (1, 31, 0.11160106647519334), 68: (1, 31, 0.11163242912340549), 69: (1, 31, 0.11160210982686089), 70: (1, 31, 0.1116665830655444)}\n",
      "{'predict_runtime': 269.3857, 'predict_samples_per_second': 0.264, 'predict_steps_per_second': 0.264}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:29.38\n",
      "  predict_samples_per_second =      0.264\n",
      "  predict_steps_per_second   =      0.264\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.48891365341842175), 2: (2, 0.4692553896456957), 3: (2, 0.46763531398028135), 4: (2, 0.46817444264888763), 5: (2, 0.4670662358403206), 6: (2, 0.4684659615159035), 7: (2, 0.46810367330908775), 8: (2, 0.46855037193745375), 9: (2, 0.46872692182660103), 10: (2, 0.468419311568141), 11: (2, 0.4682671930640936), 12: (2, 0.46836387272924185), 13: (2, 0.4692714996635914), 14: (2, 0.46864918153733015), 15: (2, 0.4684957917779684), 16: (2, 0.4695023484528065), 17: (2, 0.4680447932332754), 18: (2, 0.46853266283869743), 19: (2, 0.4689275408163667), 20: (2, 0.4689918998628855), 21: (2, 0.4690430602058768), 22: (2, 0.46924979891628027), 23: (2, 0.4690584512427449), 24: (2, 0.46879428066313267), 25: (2, 0.46897474117577076), 26: (2, 0.46947554871439934), 27: (2, 0.4695787848904729), 28: (2, 0.46872951835393906), 29: (2, 0.46900800708681345), 30: (2, 0.46935578621923923), 31: (2, 0.4684290178120136), 32: (2, 0.46938355546444654), 33: (2, 0.46930770576000214), 34: (2, 0.46899623703211546), 35: (2, 0.46850276831537485), 36: (2, 0.4688042374327779), 37: (2, 0.4694239152595401), 38: (2, 0.46910983603447676), 39: (2, 0.46923992596566677), 40: (2, 0.4691003356128931), 41: (2, 0.46862963773310184), 42: (2, 0.46937513444572687), 43: (2, 0.4685194678604603), 44: (2, 0.46859785821288824), 45: (2, 0.46867944765836), 46: (2, 0.4695624653249979), 47: (2, 0.46951549500226974), 48: (2, 0.46845074836164713), 49: (2, 0.4690008256584406), 50: (2, 0.4693928752094507), 51: (2, 0.4690875867381692), 52: (2, 0.4691769666969776), 53: (2, 0.46905782725661993), 54: (2, 0.4689408568665385), 55: (2, 0.468870316632092), 56: (2, 0.4692908562719822), 57: (2, 0.4691237770020962), 58: (2, 0.4691761555150151), 59: (2, 0.469058645889163), 60: (2, 0.4695704448968172), 61: (2, 0.4688367173075676), 62: (2, 0.46891086734831333), 63: (2, 0.4695015652105212), 64: (2, 0.468836716376245), 65: (2, 0.46957913506776094), 66: (2, 0.46894422732293606), 67: (2, 0.46947036497294903), 68: (2, 0.46849445812404156), 69: (2, 0.46933825593441725), 70: (2, 0.4693098859861493), 71: (1, 0.2986254869028926)}\n",
      "{1: (2, 31, 0.1857219226057491), 2: (2, 31, 0.18545054677393166), 3: (2, 31, 0.18566602934151888), 4: (2, 31, 0.1892091453435921), 5: (2, 31, 0.18559063048732857), 6: (2, 31, 0.18544606669175048), 7: (2, 31, 0.1857113761887435), 8: (2, 31, 0.1853673412734943), 9: (2, 31, 0.18609646407346572), 10: (2, 31, 0.18561855298016341), 11: (2, 31, 0.18691107141034258), 12: (2, 31, 0.18564433760700688), 13: (2, 31, 0.19188697642136004), 14: (2, 31, 0.18549354782988947), 15: (2, 31, 0.18565213139499387), 16: (2, 31, 0.1883651720840604), 17: (2, 31, 0.1854817746207118), 18: (2, 31, 0.18709987281791626), 19: (2, 31, 0.18678881486337032), 20: (2, 31, 0.18660487516993476), 21: (2, 31, 0.18624813494182402), 22: (2, 31, 0.1861345285790101), 23: (2, 31, 0.18629502520085342), 24: (2, 31, 0.18631490476189122), 25: (2, 31, 0.1861514854695528), 26: (2, 31, 0.18615662489807414), 27: (2, 31, 0.18620411907472917), 28: (2, 31, 0.18622213857428682), 29: (2, 31, 0.1861939987528228), 30: (2, 31, 0.186217297379288), 31: (2, 31, 0.19152964666605957), 32: (2, 31, 0.18617766846211686), 33: (2, 31, 0.18616147017887524), 34: (2, 31, 0.18617830419492337), 35: (2, 31, 0.18623097871820773), 36: (2, 31, 0.18623057954133518), 37: (2, 31, 0.186192398169829), 38: (2, 31, 0.18621753228287544), 39: (2, 31, 0.18627336801540467), 40: (2, 31, 0.18623554484257776), 41: (2, 31, 0.1861755844025362), 42: (2, 31, 0.18619325558745092), 43: (2, 31, 0.18616795864316724), 44: (2, 31, 0.18632797914887628), 45: (2, 31, 0.18628801477532234), 46: (2, 31, 0.18614495076960133), 47: (2, 31, 0.18618611537761265), 48: (2, 31, 0.18622093719820823), 49: (2, 31, 0.18622409357058425), 50: (2, 31, 0.1861305813034696), 51: (2, 31, 0.18617942517683392), 52: (2, 31, 0.18621239111187957), 53: (2, 31, 0.1861110986661046), 54: (2, 31, 0.18614505072154344), 55: (2, 31, 0.18617524795474544), 56: (2, 31, 0.18614382651304046), 57: (2, 31, 0.18614247657598987), 58: (2, 31, 0.18613757024849614), 59: (2, 31, 0.18613419282220064), 60: (2, 31, 0.18623310528815754), 61: (2, 31, 0.18618219153534982), 62: (2, 31, 0.1861906634463418), 63: (2, 31, 0.1861870556228584), 64: (2, 31, 0.18605428831952234), 65: (2, 31, 0.18614476135060673), 66: (2, 31, 0.18607296551307362), 67: (2, 31, 0.18619226303792769), 68: (2, 31, 0.1860379437885938), 69: (2, 31, 0.18613537289803067), 70: (2, 31, 0.1860419001971041)}\n",
      "{'predict_runtime': 441.1577, 'predict_samples_per_second': 0.32, 'predict_steps_per_second': 0.161}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:21.15\n",
      "  predict_samples_per_second =       0.32\n",
      "  predict_steps_per_second   =      0.161\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.811465029604733), 2: (4, 0.7899020416662097), 3: (4, 0.7903881696984172), 4: (4, 0.7907660696655512), 5: (4, 0.7908521294593811), 6: (4, 0.7905340204015374), 7: (4, 0.790560320019722), 8: (4, 0.7907843692228198), 9: (4, 0.7909026192501187), 10: (4, 0.790727449581027), 11: (4, 0.7907745987176895), 12: (4, 0.7912089386954904), 13: (4, 0.7914523966610432), 14: (4, 0.7906323606148362), 15: (4, 0.7901217304170132), 16: (4, 0.791114117950201), 17: (4, 0.7905839495360851), 18: (4, 0.7906349990516901), 19: (4, 0.7907893285155296), 20: (4, 0.7906406689435244), 21: (4, 0.7903391001746058), 22: (4, 0.7903158497065306), 23: (4, 0.7899235310032964), 24: (4, 0.7895199721679091), 25: (4, 0.789955161511898), 26: (4, 0.7899488508701324), 27: (4, 0.7899632202461362), 28: (4, 0.7895646514371037), 29: (4, 0.790270010009408), 30: (4, 0.7897488223388791), 31: (4, 0.7904226388782263), 32: (4, 0.7894172733649611), 33: (4, 0.7896180916577578), 34: (4, 0.7906516985967755), 35: (4, 0.7895402321591973), 36: (4, 0.7899404307827353), 37: (4, 0.7898939503356814), 38: (4, 0.7901731012389064), 39: (4, 0.7898120218887925), 40: (4, 0.7895155437290668), 41: (4, 0.7901773797348142), 42: (4, 0.7896369723603129), 43: (4, 0.7908190488815308), 44: (4, 0.7901566103100777), 45: (4, 0.7901251101866364), 46: (4, 0.7903473516926169), 47: (4, 0.7898925114423037), 48: (4, 0.7904479596763849), 49: (4, 0.7902950197458267), 50: (4, 0.7900301916524768), 51: (4, 0.7899751411750913), 52: (4, 0.7902696216478944), 53: (4, 0.7901029512286186), 54: (4, 0.7902565794065595), 55: (4, 0.7900393698364496), 56: (4, 0.7900990610942245), 57: (4, 0.7898984923958778), 58: (4, 0.7905659088864923), 59: (4, 0.7905214400961995), 60: (4, 0.7908474486321211), 61: (4, 0.7903832700103521), 62: (4, 0.7900897599756718), 63: (4, 0.7898987913504243), 64: (4, 0.7906443690881133), 65: (4, 0.790282960049808), 66: (4, 0.790799168869853), 67: (4, 0.7905214391648769), 68: (4, 0.7903346503153443), 69: (4, 0.7902237111702561), 70: (4, 0.7882680548354983), 71: (1, 0.29854278825223446)}\n",
      "{1: (4, 31, 0.19177843149631255), 2: (4, 31, 0.1917684788725549), 3: (4, 31, 0.19185467749353377), 4: (4, 31, 0.19283642649890914), 5: (4, 31, 0.19270290353245312), 6: (4, 31, 0.1930130147224953), 7: (4, 31, 0.1919711512483416), 8: (4, 31, 0.19187952190517418), 9: (4, 31, 0.19170764824675937), 10: (4, 31, 0.19293472780695847), 11: (4, 31, 0.19228091805932984), 12: (4, 31, 0.19206885320525016), 13: (4, 31, 0.19404577734249254), 14: (4, 31, 0.19408788324724283), 15: (4, 31, 0.1958152771056179), 16: (4, 31, 0.19160564553232923), 17: (4, 31, 0.19188255254900263), 18: (4, 31, 0.191696775746682), 19: (4, 31, 0.19175437230977319), 20: (4, 31, 0.19216790786313434), 21: (4, 31, 0.1932490940295881), 22: (4, 31, 0.19177327473317424), 23: (4, 31, 0.1936280223871431), 24: (4, 31, 0.19283871550954157), 25: (4, 31, 0.19428440679105058), 26: (4, 31, 0.1938870826796178), 27: (4, 31, 0.19170742067358187), 28: (4, 31, 0.19194299198927417), 29: (4, 31, 0.19169037098125105), 30: (4, 31, 0.19288182021268913), 31: (4, 31, 0.19637892551479802), 32: (4, 31, 0.19661976949822518), 33: (4, 31, 0.1932931339007712), 34: (4, 31, 0.19452138338238), 35: (4, 31, 0.19596664877908845), 36: (4, 31, 0.19282184814613673), 37: (4, 31, 0.19426613874853618), 38: (4, 31, 0.19451892919718258), 39: (4, 31, 0.1943429432689182), 40: (4, 31, 0.19360521309558423), 41: (4, 31, 0.19572302876340766), 42: (4, 31, 0.19298512377445737), 43: (4, 31, 0.19404600575686462), 44: (4, 31, 0.19285198418243277), 45: (4, 31, 0.19335141765975183), 46: (4, 31, 0.192534186276457), 47: (4, 31, 0.19263781159515342), 48: (4, 31, 0.19250474620850816), 49: (4, 31, 0.19276695488201034), 50: (4, 31, 0.19374147718471865), 51: (4, 31, 0.1939136665314436), 52: (4, 31, 0.1938452581544557), 53: (4, 31, 0.19324046793964603), 54: (4, 31, 0.19272911870071002), 55: (4, 31, 0.19260117207323352), 56: (4, 31, 0.19274600688368082), 57: (4, 31, 0.19267786660742375), 58: (4, 31, 0.1925733054297105), 59: (4, 31, 0.1926341475918889), 60: (4, 31, 0.1926250632311548), 61: (4, 31, 0.1930762507141598), 62: (4, 31, 0.1925726514910498), 63: (4, 31, 0.19419392369567387), 64: (4, 31, 0.19264300416914687), 65: (4, 31, 0.19274232903074834), 66: (4, 31, 0.19282478307403864), 67: (4, 31, 0.19286644614992604), 68: (4, 31, 0.1933606874137636), 69: (4, 31, 0.1935413026761624), 70: (4, 31, 0.19267940791624208)}\n",
      "{'predict_runtime': 478.3254, 'predict_samples_per_second': 0.587, 'predict_steps_per_second': 0.148}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:58.32\n",
      "  predict_samples_per_second =      0.587\n",
      "  predict_steps_per_second   =      0.148\n",
      "Evaluating with num_layers: 26\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.3301606886088848), 2: (1, 0.31246533896774054), 3: (1, 0.3109439527615905), 4: (1, 0.3108133524656296), 5: (1, 0.3104047840461135), 6: (1, 0.31066328287124634), 7: (1, 0.31071533262729645), 8: (1, 0.31048247404396534), 9: (1, 0.31063125375658274), 10: (1, 0.3106098845601082), 11: (1, 0.31072257459163666), 12: (1, 0.31142604164779186), 13: (1, 0.31061831302940845), 14: (1, 0.31155197136104107), 15: (1, 0.3106337431818247), 16: (1, 0.31099215243011713), 17: (1, 0.3099910253658891), 18: (1, 0.31047022342681885), 19: (1, 0.31055978406220675), 20: (1, 0.31168255023658276), 21: (1, 0.31068406347185373), 22: (1, 0.31079750321805477), 23: (1, 0.3110643122345209), 24: (1, 0.3111018715426326), 25: (1, 0.3118823105469346), 26: (1, 0.311507691629231), 27: (1, 0.311146623454988), 28: (1, 0.3110100431367755), 29: (1, 0.3114077812060714), 30: (1, 0.3116719610989094), 31: (1, 0.3114574709907174), 32: (1, 0.31123753171414137), 33: (1, 0.3112261425703764), 34: (1, 0.31134847085922956), 35: (1, 0.3113019112497568), 36: (1, 0.3109361529350281), 37: (1, 0.3106858329847455), 38: (1, 0.31101129204034805), 39: (1, 0.31132461223751307), 40: (1, 0.31140307057648897), 41: (1, 0.31144637055695057), 42: (1, 0.3114189812913537), 43: (1, 0.3114935513585806), 44: (1, 0.3114240812137723), 45: (1, 0.3110097935423255), 46: (1, 0.3113767709583044), 47: (1, 0.31170231103897095), 48: (1, 0.3113917112350464), 49: (1, 0.311100653372705), 50: (1, 0.31122863199561834), 51: (1, 0.3112504016608), 52: (1, 0.31163728050887585), 53: (1, 0.31108766235411167), 54: (1, 0.31125221215188503), 55: (1, 0.311468280851841), 56: (1, 0.31134658120572567), 57: (1, 0.3114600423723459), 58: (1, 0.31210697907954454), 59: (1, 0.31093286257237196), 60: (1, 0.3113476624712348), 61: (1, 0.31112026143819094), 62: (1, 0.3111076131463051), 63: (1, 0.31130035128444433), 64: (1, 0.31133218202739954), 65: (1, 0.3114953115582466), 66: (1, 0.31167872063815594), 67: (1, 0.3109724121168256), 68: (1, 0.31124257389456034), 69: (1, 0.31094826478511095), 70: (1, 0.3112249244004488), 71: (1, 0.3104054471477866)}\n",
      "{1: (1, 31, 0.11806179814401173), 2: (1, 31, 0.11742276653286911), 3: (1, 31, 0.11719548870478907), 4: (1, 31, 0.11772060226048192), 5: (1, 31, 0.11695536036765383), 6: (1, 31, 0.11706998190211673), 7: (1, 31, 0.11969435957050131), 8: (1, 31, 0.11730396906815228), 9: (1, 31, 0.11972195868410411), 10: (1, 31, 0.11796677361933454), 11: (1, 31, 0.11729353356866105), 12: (1, 31, 0.1170452076100534), 13: (1, 31, 0.1171603831913202), 14: (1, 31, 0.11702502437777096), 15: (1, 31, 0.11700332702528085), 16: (1, 31, 0.11728339185637812), 17: (1, 31, 0.11691552649943097), 18: (1, 31, 0.11710905478966813), 19: (1, 31, 0.12017829740239729), 20: (1, 31, 0.11767182144666871), 21: (1, 31, 0.11763433258860342), 22: (1, 31, 0.11689108315735094), 23: (1, 31, 0.11688393546688941), 24: (1, 31, 0.11728094587282788), 25: (1, 31, 0.1168990133690738), 26: (1, 31, 0.11761150776498741), 27: (1, 31, 0.11718127813430564), 28: (1, 31, 0.1177995475609937), 29: (1, 31, 0.11742675097118463), 30: (1, 31, 0.11762928109495871), 31: (1, 31, 0.1183394091804662), 32: (1, 31, 0.11738190688793698), 33: (1, 31, 0.1176535792408451), 34: (1, 31, 0.11732122881878768), 35: (1, 31, 0.11739454805971153), 36: (1, 31, 0.11708031588744733), 37: (1, 31, 0.11698558665211162), 38: (1, 31, 0.11734186115884973), 39: (1, 31, 0.11720709430594597), 40: (1, 31, 0.11720284423039805), 41: (1, 31, 0.11718454524394005), 42: (1, 31, 0.11709228221086725), 43: (1, 31, 0.1174732191908744), 44: (1, 31, 0.11705756974556754), 45: (1, 31, 0.11698399388021039), 46: (1, 31, 0.11698608578092629), 47: (1, 31, 0.11703033694216321), 48: (1, 31, 0.11704839132125339), 49: (1, 31, 0.11709955797320412), 50: (1, 31, 0.11783512155976027), 51: (1, 31, 0.11829223615988609), 52: (1, 31, 0.11733329208988336), 53: (1, 31, 0.11741093410960128), 54: (1, 31, 0.11727738434508923), 55: (1, 31, 0.11849299785230429), 56: (1, 31, 0.11711970990103099), 57: (1, 31, 0.11765284178357932), 58: (1, 31, 0.11835182374042849), 59: (1, 31, 0.11703410597458001), 60: (1, 31, 0.11708853111392067), 61: (1, 31, 0.11712904953427854), 62: (1, 31, 0.11813304732523618), 63: (1, 31, 0.11809060752632157), 64: (1, 31, 0.11710199981086677), 65: (1, 31, 0.1172227407955835), 66: (1, 31, 0.11710613482301274), 67: (1, 31, 0.11722735378650888), 68: (1, 31, 0.11767702237252266), 69: (1, 31, 0.11883703760442234), 70: (1, 31, 0.11781583522115985)}\n",
      "{'predict_runtime': 280.8758, 'predict_samples_per_second': 0.253, 'predict_steps_per_second': 0.253}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:40.87\n",
      "  predict_samples_per_second =      0.253\n",
      "  predict_steps_per_second   =      0.253\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5071679828688502), 2: (2, 0.48655747156590223), 3: (2, 0.4883355461061001), 4: (2, 0.4867393709719181), 5: (2, 0.48584120254963636), 6: (2, 0.4860218819230795), 7: (2, 0.48675979021936655), 8: (2, 0.48687796015292406), 9: (2, 0.4883861457929015), 10: (2, 0.4874472189694643), 11: (2, 0.48749241791665554), 12: (2, 0.48850385565310717), 13: (2, 0.48861975595355034), 14: (2, 0.4890653947368264), 15: (2, 0.4884573854506016), 16: (2, 0.48856080509722233), 17: (2, 0.4880336057394743), 18: (2, 0.4889515545219183), 19: (2, 0.488245977088809), 20: (2, 0.48914613388478756), 21: (2, 0.48765443824231625), 22: (2, 0.4887229446321726), 23: (2, 0.48859897535294294), 24: (2, 0.4877161467447877), 25: (2, 0.48749223724007607), 26: (2, 0.48772886767983437), 27: (2, 0.4868479697033763), 28: (2, 0.48762019723653793), 29: (2, 0.48747049923986197), 30: (2, 0.4873325191438198), 31: (2, 0.4871908985078335), 32: (2, 0.48773345816880465), 33: (2, 0.487662848085165), 34: (2, 0.48784307669848204), 35: (2, 0.4873719494789839), 36: (2, 0.48791408631950617), 37: (2, 0.48687334917485714), 38: (2, 0.48746901750564575), 39: (2, 0.4866502517834306), 40: (2, 0.48658988159149885), 41: (2, 0.4864538311958313), 42: (2, 0.4877820070832968), 43: (2, 0.48674590047448874), 44: (2, 0.48727387841790915), 45: (2, 0.486704439856112), 46: (2, 0.4873715788125992), 47: (2, 0.4866500999778509), 48: (2, 0.48685143049806356), 49: (2, 0.48685124050825834), 50: (2, 0.4871469996869564), 51: (2, 0.48722303938120604), 52: (2, 0.48659819085150957), 53: (2, 0.4868952101096511), 54: (2, 0.4869728498160839), 55: (2, 0.4869285002350807), 56: (2, 0.48698834888637066), 57: (2, 0.4870656095445156), 58: (2, 0.4868053998798132), 59: (2, 0.48672736156731844), 60: (2, 0.4866616502404213), 61: (2, 0.4865244207903743), 62: (2, 0.4873926090076566), 63: (2, 0.48688438069075346), 64: (2, 0.487589037977159), 65: (2, 0.48703642934560776), 66: (2, 0.48645942099392414), 67: (2, 0.48715163860470057), 68: (2, 0.48691711015999317), 69: (2, 0.4872001791372895), 70: (2, 0.4860644321888685), 71: (1, 0.30939192045480013)}\n",
      "{1: (2, 31, 0.1938238975201403), 2: (2, 31, 0.1937651521255893), 3: (2, 31, 0.19373793473407144), 4: (2, 31, 0.1937694502393565), 5: (2, 31, 0.19379719569077414), 6: (2, 31, 0.1939040132227444), 7: (2, 31, 0.1938865725551882), 8: (2, 31, 0.19404853691136645), 9: (2, 31, 0.19480707400268124), 10: (2, 31, 0.19417455044364737), 11: (2, 31, 0.19437186507087562), 12: (2, 31, 0.1943356815365053), 13: (2, 31, 0.19432852185902097), 14: (2, 31, 0.1953516179215043), 15: (2, 31, 0.19465659970357532), 16: (2, 31, 0.19444582641365066), 17: (2, 31, 0.19439589139074087), 18: (2, 31, 0.19445812257547532), 19: (2, 31, 0.19394485156742797), 20: (2, 31, 0.19422185192665747), 21: (2, 31, 0.19410441431307024), 22: (2, 31, 0.19429220382364526), 23: (2, 31, 0.19391468696055875), 24: (2, 31, 0.19425078685725888), 25: (2, 31, 0.1938707661784945), 26: (2, 31, 0.19388343276636255), 27: (2, 31, 0.1937862245305892), 28: (2, 31, 0.1938870763706584), 29: (2, 31, 0.19391359160504035), 30: (2, 31, 0.1939521340593215), 31: (2, 31, 0.19392874942071014), 32: (2, 31, 0.19385307282209396), 33: (2, 31, 0.1938345299192494), 34: (2, 31, 0.19377042100794853), 35: (2, 31, 0.19381548208935606), 36: (2, 31, 0.1938102549662994), 37: (2, 31, 0.19256372966112628), 38: (2, 31, 0.19245336640385852), 39: (2, 31, 0.19267389923334122), 40: (2, 31, 0.19263582376222457), 41: (2, 31, 0.19281798823466223), 42: (2, 31, 0.19283724939751049), 43: (2, 31, 0.19284378989569603), 44: (2, 31, 0.19273237817950786), 45: (2, 31, 0.1929044765870898), 46: (2, 31, 0.19276617539505805), 47: (2, 31, 0.19727689583575533), 48: (2, 31, 0.19672570353554142), 49: (2, 31, 0.19610496763620647), 50: (2, 31, 0.1928673533482417), 51: (2, 31, 0.19258372410531005), 52: (2, 31, 0.1928182280051612), 53: (2, 31, 0.19294022927962004), 54: (2, 31, 0.19284778067301359), 55: (2, 31, 0.19324840782510658), 56: (2, 31, 0.19297122657899896), 57: (2, 31, 0.19291534833610058), 58: (2, 31, 0.19295939163214737), 59: (2, 31, 0.19304158430426352), 60: (2, 31, 0.19271537397176988), 61: (2, 31, 0.19459605802811922), 62: (2, 31, 0.1977716973652282), 63: (2, 31, 0.1929362312019352), 64: (2, 31, 0.1950091839197182), 65: (2, 31, 0.19707876383777587), 66: (2, 31, 0.19309780097776844), 67: (2, 31, 0.1929758016861254), 68: (2, 31, 0.19435635695774708), 69: (2, 31, 0.1931235453173999), 70: (2, 31, 0.1927397070272315)}\n",
      "{'predict_runtime': 458.8927, 'predict_samples_per_second': 0.307, 'predict_steps_per_second': 0.155}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:38.89\n",
      "  predict_samples_per_second =      0.307\n",
      "  predict_steps_per_second   =      0.155\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.8431490771472454), 2: (4, 0.8223717473447323), 3: (4, 0.8215415282174945), 4: (4, 0.8213259782642126), 5: (4, 0.8215463478118181), 6: (4, 0.8218778977170587), 7: (4, 0.8230374343693256), 8: (4, 0.8216881072148681), 9: (4, 0.8217097176238894), 10: (4, 0.8220484470948577), 11: (4, 0.8218601867556572), 12: (4, 0.8216635687276721), 13: (4, 0.8226549252867699), 14: (4, 0.8220775770023465), 15: (4, 0.8213445385918021), 16: (4, 0.8227947652339935), 17: (4, 0.8220436563715339), 18: (4, 0.8210597196593881), 19: (4, 0.8223313353955746), 20: (4, 0.8217229582369328), 21: (4, 0.8218027483671904), 22: (4, 0.8211007788777351), 23: (4, 0.8217485276982188), 24: (4, 0.8218564465641975), 25: (4, 0.8215278685092926), 26: (4, 0.8209134796634316), 27: (4, 0.8210100699216127), 28: (4, 0.8212429992854595), 29: (4, 0.8208270007744431), 30: (4, 0.8211432006210089), 31: (4, 0.8221146762371063), 32: (4, 0.8213827591389418), 33: (4, 0.8218289176002145), 34: (4, 0.821854617446661), 35: (4, 0.8214706787839532), 36: (4, 0.8220176165923476), 37: (4, 0.8221022170037031), 38: (4, 0.8214906677603722), 39: (4, 0.8220450673252344), 40: (4, 0.8211408592760563), 41: (4, 0.8227177951484919), 42: (4, 0.8215379184111953), 43: (4, 0.8218838479369879), 44: (4, 0.8217770680785179), 45: (4, 0.8219607872888446), 46: (4, 0.8226046664640307), 47: (4, 0.822372485883534), 48: (4, 0.821588758379221), 49: (4, 0.8217688584700227), 50: (4, 0.8218360776081681), 51: (4, 0.8225271357223392), 52: (4, 0.8222076473757625), 53: (4, 0.8218106580898166), 54: (4, 0.82191451638937), 55: (4, 0.821871617808938), 56: (4, 0.8220815369859338), 57: (4, 0.8214382193982601), 58: (4, 0.8222341164946556), 59: (4, 0.8216663682833314), 60: (4, 0.8212974993512034), 61: (4, 0.8217788273468614), 62: (4, 0.8211501203477383), 63: (4, 0.8222164558246732), 64: (4, 0.8211629493162036), 65: (4, 0.8210877794772387), 66: (4, 0.821137030608952), 67: (4, 0.8219403773546219), 68: (4, 0.8217102978378534), 69: (4, 0.821420787833631), 70: (4, 0.8199165128171444), 71: (1, 0.30930543038994074)}\n",
      "{1: (4, 31, 0.20192630255534763), 2: (4, 31, 0.2006867765298774), 3: (4, 31, 0.2023552700937275), 4: (4, 31, 0.20098916251933382), 5: (4, 31, 0.20251466228716797), 6: (4, 31, 0.2017966192215681), 7: (4, 31, 0.20236335848007472), 8: (4, 31, 0.20061264514562585), 9: (4, 31, 0.20218164657032298), 10: (4, 31, 0.20108444625211339), 11: (4, 31, 0.200908491147622), 12: (4, 31, 0.2014525569975376), 13: (4, 31, 0.20059542174661352), 14: (4, 31, 0.20075360210912843), 15: (4, 31, 0.20002668489131234), 16: (4, 31, 0.1989670530141842), 17: (4, 31, 0.20039326063687762), 18: (4, 31, 0.20225872829436295), 19: (4, 31, 0.2009485263016916), 20: (4, 31, 0.19901113641718704), 21: (4, 31, 0.20110237120740837), 22: (4, 31, 0.2007276490330696), 23: (4, 31, 0.19930916715172992), 24: (4, 31, 0.20058341074975267), 25: (4, 31, 0.20038434673821734), 26: (4, 31, 0.19923495125746535), 27: (4, 31, 0.20022748251475633), 28: (4, 31, 0.19922313544779055), 29: (4, 31, 0.2005926073198357), 30: (4, 31, 0.20146379073060328), 31: (4, 31, 0.2011906027553543), 32: (4, 31, 0.20052179441817344), 33: (4, 31, 0.20050606648287467), 34: (4, 31, 0.2000482421849043), 35: (4, 31, 0.20079532698277505), 36: (4, 31, 0.20028296945196006), 37: (4, 31, 0.20129571236189334), 38: (4, 31, 0.2000533968150135), 39: (4, 31, 0.20119812174309645), 40: (4, 31, 0.2000553817037613), 41: (4, 31, 0.2003093184903264), 42: (4, 31, 0.2009162862574862), 43: (4, 31, 0.20022403953536863), 44: (4, 31, 0.20006283799246435), 45: (4, 31, 0.20000953545733804), 46: (4, 31, 0.2002622699965873), 47: (4, 31, 0.1999896549649777), 48: (4, 31, 0.20143817788771085), 49: (4, 31, 0.20096086353183754), 50: (4, 31, 0.20062688726090616), 51: (4, 31, 0.19940073995460425), 52: (4, 31, 0.20006285794079304), 53: (4, 31, 0.20216329311651568), 54: (4, 31, 0.20044585650846844), 55: (4, 31, 0.20101216856029727), 56: (4, 31, 0.20030392411976092), 57: (4, 31, 0.19899194780737162), 58: (4, 31, 0.20118567155253503), 59: (4, 31, 0.19998944944311534), 60: (4, 31, 0.1990398753494505), 61: (4, 31, 0.1990545022812101), 62: (4, 31, 0.19890130446442672), 63: (4, 31, 0.1990698538420181), 64: (4, 31, 0.1992447528267099), 65: (4, 31, 0.19940020315228932), 66: (4, 31, 0.1993138782019096), 67: (4, 31, 0.20162607158624357), 68: (4, 31, 0.19925771572537), 69: (4, 31, 0.19961675577947208), 70: (4, 31, 0.20042030693542573)}\n",
      "{'predict_runtime': 496.7542, 'predict_samples_per_second': 0.566, 'predict_steps_per_second': 0.143}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:16.75\n",
      "  predict_samples_per_second =      0.566\n",
      "  predict_steps_per_second   =      0.143\n",
      "Evaluating with num_layers: 27\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.3411063505336642), 2: (1, 0.3216005153954029), 3: (1, 0.322536732070148), 4: (1, 0.32103879656642675), 5: (1, 0.3209926765412092), 6: (1, 0.3214928647503257), 7: (1, 0.3211500458419323), 8: (1, 0.32125375512987375), 9: (1, 0.32131517585366964), 10: (1, 0.321490035392344), 11: (1, 0.3209631573408842), 12: (1, 0.32154723443090916), 13: (1, 0.32214699406176805), 14: (1, 0.3211001558229327), 15: (1, 0.3213856974616647), 16: (1, 0.3214662866666913), 17: (1, 0.32145150657743216), 18: (1, 0.3222977640107274), 19: (1, 0.32193982508033514), 20: (1, 0.32244429364800453), 21: (1, 0.3219310352578759), 22: (1, 0.3226997833698988), 23: (1, 0.32190327532589436), 24: (1, 0.3218239462003112), 25: (1, 0.32278807274997234), 26: (1, 0.3220366155728698), 27: (1, 0.32215456385165453), 28: (1, 0.3221130333840847), 29: (1, 0.32211681362241507), 30: (1, 0.3222885448485613), 31: (1, 0.32171574607491493), 32: (1, 0.32166311610490084), 33: (1, 0.3214631471782923), 34: (1, 0.32167722564190626), 35: (1, 0.3220822839066386), 36: (1, 0.3216324858367443), 37: (1, 0.3217818159610033), 38: (1, 0.3219251660630107), 39: (1, 0.3215809157118201), 40: (1, 0.3219747059047222), 41: (1, 0.32180183567106724), 42: (1, 0.3219815753400326), 43: (1, 0.3222318831831217), 44: (1, 0.32214441429823637), 45: (1, 0.3219933658838272), 46: (1, 0.32181204576045275), 47: (1, 0.321642866358161), 48: (1, 0.32173161674290895), 49: (1, 0.3219258449971676), 50: (1, 0.3222356541082263), 51: (1, 0.32191887497901917), 52: (1, 0.32239710446447134), 53: (1, 0.32216588500887156), 54: (1, 0.3220260953530669), 55: (1, 0.3221025438979268), 56: (1, 0.3219101456925273), 57: (1, 0.3255412243306637), 58: (1, 0.3243053276091814), 59: (1, 0.3217375362291932), 60: (1, 0.32200502417981625), 61: (1, 0.3219831557944417), 62: (1, 0.3217971855774522), 63: (1, 0.32182582560926676), 64: (1, 0.3217581259086728), 65: (1, 0.32182801607996225), 66: (1, 0.32277093175798655), 67: (1, 0.32531215623021126), 68: (1, 0.3221239149570465), 69: (1, 0.32142854668200016), 70: (1, 0.32122329715639353), 71: (1, 0.3206206988543272)}\n",
      "{1: (1, 31, 0.1214142060808597), 2: (1, 31, 0.1207631568935129), 3: (1, 31, 0.12062676100721283), 4: (1, 31, 0.12156064138417283), 5: (1, 31, 0.12007326722866105), 6: (1, 31, 0.12064373433109253), 7: (1, 31, 0.12033850729705826), 8: (1, 31, 0.1207304073858165), 9: (1, 31, 0.12048052491680268), 10: (1, 31, 0.12062430255595714), 11: (1, 31, 0.12053475979595416), 12: (1, 31, 0.12035257363271329), 13: (1, 31, 0.12042946822100109), 14: (1, 31, 0.12056830300078276), 15: (1, 31, 0.12068172565270815), 16: (1, 31, 0.1206827130649359), 17: (1, 31, 0.12043898011888227), 18: (1, 31, 0.12055896541043636), 19: (1, 31, 0.12073296684050752), 20: (1, 31, 0.1209372588463368), 21: (1, 31, 0.12120763104288809), 22: (1, 31, 0.12050769652330107), 23: (1, 31, 0.12037679955603615), 24: (1, 31, 0.12049948871736565), 25: (1, 31, 0.12161789702311639), 26: (1, 31, 0.12191589936734207), 27: (1, 31, 0.12048952173321478), 28: (1, 31, 0.12056455178366553), 29: (1, 31, 0.12068532088831548), 30: (1, 31, 0.120731279133789), 31: (1, 31, 0.1206551962982743), 32: (1, 31, 0.12034346082157665), 33: (1, 31, 0.12049230629758488), 34: (1, 31, 0.12066389797555824), 35: (1, 31, 0.1229015813779927), 36: (1, 31, 0.1203803446203951), 37: (1, 31, 0.12050528148369442), 38: (1, 31, 0.12013773659184095), 39: (1, 31, 0.12042607862742678), 40: (1, 31, 0.12048798036431113), 41: (1, 31, 0.12064493417499526), 42: (1, 31, 0.12060455719549809), 43: (1, 31, 0.12054074711857303), 44: (1, 31, 0.12054567023991578), 45: (1, 31, 0.12055228881898426), 46: (1, 31, 0.12060661562868664), 47: (1, 31, 0.12017609713779341), 48: (1, 31, 0.12390589957395869), 49: (1, 31, 0.12041815998212944), 50: (1, 31, 0.12500612329571478), 51: (1, 31, 0.12059876812441696), 52: (1, 31, 0.12484668561768147), 53: (1, 31, 0.12577384653230828), 54: (1, 31, 0.12061218628960271), 55: (1, 31, 0.12058134800604274), 56: (1, 31, 0.12627248853565223), 57: (1, 31, 0.12769127973625738), 58: (1, 31, 0.12057459186161718), 59: (1, 31, 0.120428673171949), 60: (1, 31, 0.12061584106976947), 61: (1, 31, 0.12044801620105582), 62: (1, 31, 0.1203805468676071), 63: (1, 31, 0.12041209605071813), 64: (1, 31, 0.1271914318203926), 65: (1, 31, 0.12046150043005904), 66: (1, 31, 0.12194896940021746), 67: (1, 31, 0.12685015007492997), 68: (1, 31, 0.12157459797397736), 69: (1, 31, 0.12663943545832748), 70: (1, 31, 0.12100478036389235)}\n",
      "{'predict_runtime': 290.1416, 'predict_samples_per_second': 0.245, 'predict_steps_per_second': 0.245}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:04:50.14\n",
      "  predict_samples_per_second =      0.245\n",
      "  predict_steps_per_second   =      0.245\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5249655023217201), 2: (2, 0.5038671959191561), 3: (2, 0.5040277345106006), 4: (2, 0.5027033984661102), 5: (2, 0.504197284579277), 6: (2, 0.5039410553872585), 7: (2, 0.5037579862400889), 8: (2, 0.5037462264299393), 9: (2, 0.5046523530036211), 10: (2, 0.5057177413254976), 11: (2, 0.5048371832817793), 12: (2, 0.5051375525072217), 13: (2, 0.5052160117775202), 14: (2, 0.5051436722278595), 15: (2, 0.508511302061379), 16: (2, 0.5041075646877289), 17: (2, 0.5040667550638318), 18: (2, 0.5048938924446702), 19: (2, 0.5039095748215914), 20: (2, 0.5046298028901219), 21: (2, 0.5046988530084491), 22: (2, 0.5046579036861658), 23: (2, 0.5044676242396235), 24: (2, 0.5043185651302338), 25: (2, 0.5042315851897001), 26: (2, 0.5043417848646641), 27: (2, 0.5037395460531116), 28: (2, 0.5042957253754139), 29: (2, 0.504505424760282), 30: (2, 0.5041538449004292), 31: (2, 0.503630037419498), 32: (2, 0.5045524947345257), 33: (2, 0.5039717648178339), 34: (2, 0.506837316788733), 35: (2, 0.5037608556449413), 36: (2, 0.5041638249531388), 37: (2, 0.5049934023991227), 38: (2, 0.5045864041894674), 39: (2, 0.5047216033563018), 40: (2, 0.5041801249608397), 41: (2, 0.504193264991045), 42: (2, 0.5042516756802797), 43: (2, 0.5043113641440868), 44: (2, 0.504001815803349), 45: (2, 0.5045780027285218), 46: (2, 0.5050605926662683), 47: (2, 0.5042112153023481), 48: (2, 0.5043208841234446), 49: (2, 0.505382850766182), 50: (2, 0.5043987045064569), 51: (2, 0.5047425236552954), 52: (2, 0.5040826350450516), 53: (2, 0.5049969730898738), 54: (2, 0.5045046238228679), 55: (2, 0.5045631937682629), 56: (2, 0.5042527848854661), 57: (2, 0.5039824256673455), 58: (2, 0.5046376641839743), 59: (2, 0.5043584443628788), 60: (2, 0.5047728223726153), 61: (2, 0.5048970822244883), 62: (2, 0.5045444834977388), 63: (2, 0.5046012941747904), 64: (2, 0.5040963049978018), 65: (2, 0.5042797848582268), 66: (2, 0.5044695837423205), 67: (2, 0.505235081538558), 68: (2, 0.5042408248409629), 69: (2, 0.5047703227028251), 70: (2, 0.5042656352743506), 71: (1, 0.32132378686219454)}\n",
      "{1: (2, 31, 0.20324877658558468), 2: (2, 31, 0.2008511546638704), 3: (2, 31, 0.20492090579242475), 4: (2, 31, 0.20633315279959671), 5: (2, 31, 0.20448985100994188), 6: (2, 31, 0.20233324040929157), 7: (2, 31, 0.20278904259565375), 8: (2, 31, 0.2013112774659549), 9: (2, 31, 0.20262450012829034), 10: (2, 31, 0.20296591499279584), 11: (2, 31, 0.20281306786402578), 12: (2, 31, 0.20270892527074583), 13: (2, 31, 0.2042516759867149), 14: (2, 31, 0.20325562222710541), 15: (2, 31, 0.20128676766950276), 16: (2, 31, 0.20304096742503105), 17: (2, 31, 0.20220938225787494), 18: (2, 31, 0.20230728898557923), 19: (2, 31, 0.20033754807926954), 20: (2, 31, 0.2010907352030758), 21: (2, 31, 0.20131978032089048), 22: (2, 31, 0.20212813782235306), 23: (2, 31, 0.20254387069613702), 24: (2, 31, 0.2038894278267699), 25: (2, 31, 0.203388704197301), 26: (2, 31, 0.2035712627393584), 27: (2, 31, 0.20278900543287878), 28: (2, 31, 0.20313443853369645), 29: (2, 31, 0.20317773319660656), 30: (2, 31, 0.20203259875697474), 31: (2, 31, 0.20196498789253733), 32: (2, 31, 0.20444965729069325), 33: (2, 31, 0.20121640633911855), 34: (2, 31, 0.19977231491957942), 35: (2, 31, 0.19956374222472792), 36: (2, 31, 0.2054501236266186), 37: (2, 31, 0.2007569415014117), 38: (2, 31, 0.2010016416409804), 39: (2, 31, 0.20196793850270972), 40: (2, 31, 0.2005202008952056), 41: (2, 31, 0.20048394342583994), 42: (2, 31, 0.20063615467159018), 43: (2, 31, 0.20075298677529058), 44: (2, 31, 0.2011991249577653), 45: (2, 31, 0.20276410003463108), 46: (2, 31, 0.2014905318858162), 47: (2, 31, 0.20081179952549358), 48: (2, 31, 0.20080172913449426), 49: (2, 31, 0.20204658593021094), 50: (2, 31, 0.20156044029300252), 51: (2, 31, 0.20039933589437314), 52: (2, 31, 0.2013720361395709), 53: (2, 31, 0.20061489606216068), 54: (2, 31, 0.20052802048984072), 55: (2, 31, 0.2005399648520735), 56: (2, 31, 0.20049974415451288), 57: (2, 31, 0.2048788801316292), 58: (2, 31, 0.20091741676292113), 59: (2, 31, 0.20339227557903336), 60: (2, 31, 0.20088181921070622), 61: (2, 31, 0.20172610145903402), 62: (2, 31, 0.20118304774645837), 63: (2, 31, 0.20050909162889566), 64: (2, 31, 0.2003310112162463), 65: (2, 31, 0.2004954572166166), 66: (2, 31, 0.2010397808626294), 67: (2, 31, 0.20111953334942942), 68: (2, 31, 0.2026954916936736), 69: (2, 31, 0.20396810073044994), 70: (2, 31, 0.19970763871265995)}\n",
      "{'predict_runtime': 477.8544, 'predict_samples_per_second': 0.295, 'predict_steps_per_second': 0.149}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:07:57.85\n",
      "  predict_samples_per_second =      0.295\n",
      "  predict_steps_per_second   =      0.149\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.8710270067676902), 2: (4, 0.8526005521416664), 3: (4, 0.8525262018665671), 4: (4, 0.8518119938671589), 5: (4, 0.8524243626743555), 6: (4, 0.8521801326423883), 7: (4, 0.8515064353123307), 8: (4, 0.8533308189362288), 9: (4, 0.85219363309443), 10: (4, 0.8527040611952543), 11: (4, 0.8523293221369386), 12: (4, 0.8551008440554142), 13: (4, 0.8529873909428716), 14: (4, 0.8533272193744779), 15: (4, 0.8535880278795958), 16: (4, 0.8534068390727043), 17: (4, 0.8535147290676832), 18: (4, 0.852979370392859), 19: (4, 0.85331900883466), 20: (4, 0.8535572793334723), 21: (4, 0.8523827828466892), 22: (4, 0.8534978991374373), 23: (4, 0.8532393490895629), 24: (4, 0.8526454409584403), 25: (4, 0.8528221910819411), 26: (4, 0.8527686223387718), 27: (4, 0.8526844419538975), 28: (4, 0.8527609007433057), 29: (4, 0.8527832105755806), 30: (4, 0.8530729003250599), 31: (4, 0.852791840210557), 32: (4, 0.8528979606926441), 33: (4, 0.8532349206507206), 34: (4, 0.85318792052567), 35: (4, 0.8528293017297983), 36: (4, 0.8530556606128812), 37: (4, 0.8525996124371886), 38: (4, 0.8522559832781553), 39: (4, 0.8528107712045312), 40: (4, 0.8528179004788399), 41: (4, 0.8525785515084863), 42: (4, 0.8529513198882341), 43: (4, 0.8529976913705468), 44: (4, 0.8528731008991599), 45: (4, 0.8532017897814512), 46: (4, 0.8530717510730028), 47: (4, 0.8537502381950617), 48: (4, 0.853217089548707), 49: (4, 0.8529412094503641), 50: (4, 0.8529285406693816), 51: (4, 0.8533564889803529), 52: (4, 0.852734750136733), 53: (4, 0.8527526818215847), 54: (4, 0.8532765600830317), 55: (4, 0.8532605189830065), 56: (4, 0.8523877924308181), 57: (4, 0.85270229075104), 58: (4, 0.8529590303078294), 59: (4, 0.8530673002824187), 60: (4, 0.8523556515574455), 61: (4, 0.8530904091894627), 62: (4, 0.8526786817237735), 63: (4, 0.8525355216115713), 64: (4, 0.8527074120938778), 65: (4, 0.8525528414174914), 66: (4, 0.8532196804881096), 67: (4, 0.8531959699466825), 68: (4, 0.8527855314314365), 69: (4, 0.8529782313853502), 70: (4, 0.8513216841965914), 71: (1, 0.32204073667526245)}\n",
      "{1: (4, 31, 0.20889663585131207), 2: (4, 31, 0.2088461699144494), 3: (4, 31, 0.21065471324348642), 4: (4, 31, 0.21045457295352413), 5: (4, 31, 0.20915267147844838), 6: (4, 31, 0.20905314433959224), 7: (4, 31, 0.2093847336007222), 8: (4, 31, 0.20763254297837133), 9: (4, 31, 0.2107744571422377), 10: (4, 31, 0.2107548021200684), 11: (4, 31, 0.20941005073367588), 12: (4, 31, 0.20770663662903732), 13: (4, 31, 0.20777013462277188), 14: (4, 31, 0.20779484991104372), 15: (4, 31, 0.20772975391798443), 16: (4, 31, 0.2076207349197038), 17: (4, 31, 0.2080178189301683), 18: (4, 31, 0.20997912517838901), 19: (4, 31, 0.20777497281350435), 20: (4, 31, 0.2075337523654584), 21: (4, 31, 0.207694124610674), 22: (4, 31, 0.20985170730179356), 23: (4, 31, 0.20757882134808647), 24: (4, 31, 0.20764467291413777), 25: (4, 31, 0.2076750929737764), 26: (4, 31, 0.2135872670239018), 27: (4, 31, 0.21186528420977055), 28: (4, 31, 0.20755339359804506), 29: (4, 31, 0.20797998506215312), 30: (4, 31, 0.2076828824656625), 31: (4, 31, 0.21174512710422277), 32: (4, 31, 0.20741734389335878), 33: (4, 31, 0.2076922408154895), 34: (4, 31, 0.2077825277322723), 35: (4, 31, 0.20776287607488134), 36: (4, 31, 0.2076024898598271), 37: (4, 31, 0.20774027807337622), 38: (4, 31, 0.2075921185615082), 39: (4, 31, 0.2075783488070292), 40: (4, 31, 0.2075801107491697), 41: (4, 31, 0.2094533465382072), 42: (4, 31, 0.212147272882923), 43: (4, 31, 0.21325061677564536), 44: (4, 31, 0.20760753985133865), 45: (4, 31, 0.2083595569636072), 46: (4, 31, 0.20770884022837685), 47: (4, 31, 0.20767678828128883), 48: (4, 31, 0.20756356066633616), 49: (4, 31, 0.20761000521240697), 50: (4, 31, 0.20769847632055322), 51: (4, 31, 0.21191293995587096), 52: (4, 31, 0.2129753432687252), 53: (4, 31, 0.21106611339435463), 54: (4, 31, 0.20785368278983138), 55: (4, 31, 0.20749051445313998), 56: (4, 31, 0.20992801753022977), 57: (4, 31, 0.2076452496131101), 58: (4, 31, 0.2076920259203161), 59: (4, 31, 0.20779479105746554), 60: (4, 31, 0.2078509039335674), 61: (4, 31, 0.20777677041628667), 62: (4, 31, 0.20756957427628578), 63: (4, 31, 0.2077502817095768), 64: (4, 31, 0.2077549733221531), 65: (4, 31, 0.20796303760500684), 66: (4, 31, 0.20778455768501566), 67: (4, 31, 0.2118720037922744), 68: (4, 31, 0.20924314541081268), 69: (4, 31, 0.20772566475094326), 70: (4, 31, 0.20966644951653096)}\n",
      "{'predict_runtime': 517.1625, 'predict_samples_per_second': 0.543, 'predict_steps_per_second': 0.137}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:37.16\n",
      "  predict_samples_per_second =      0.543\n",
      "  predict_steps_per_second   =      0.137\n",
      "Evaluating with num_layers: 28\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.3554245177656412), 2: (1, 0.33392291236668825), 3: (1, 0.3329710038378835), 4: (1, 0.3329025749117136), 5: (1, 0.332957174628973), 6: (1, 0.3329884046688676), 7: (1, 0.3332314835861325), 8: (1, 0.33283217437565327), 9: (1, 0.33272465504705906), 10: (1, 0.3338528014719486), 11: (1, 0.3345480803400278), 12: (1, 0.33373625203967094), 13: (1, 0.3343070102855563), 14: (1, 0.33354692347347736), 15: (1, 0.334044030867517), 16: (1, 0.33369910158216953), 17: (1, 0.33410489093512297), 18: (1, 0.33469978906214237), 19: (1, 0.3335701311007142), 20: (1, 0.3347032889723778), 21: (1, 0.333560261875391), 22: (1, 0.3333575539290905), 23: (1, 0.3344698706641793), 24: (1, 0.33354690205305815), 25: (1, 0.33364823274314404), 26: (1, 0.3338471921160817), 27: (1, 0.33396910037845373), 28: (1, 0.33386061154305935), 29: (1, 0.33372112177312374), 30: (1, 0.33370397239923477), 31: (1, 0.33388402219861746), 32: (1, 0.33356295246630907), 33: (1, 0.33341555297374725), 34: (1, 0.33337210305035114), 35: (1, 0.3335252432152629), 36: (1, 0.3335784235969186), 37: (1, 0.3333951523527503), 38: (1, 0.3332085842266679), 39: (1, 0.3336309716105461), 40: (1, 0.3334448030218482), 41: (1, 0.33354270178824663), 42: (1, 0.3338215323165059), 43: (1, 0.33356691244989634), 44: (1, 0.33367483224719763), 45: (1, 0.33357208129018545), 46: (1, 0.33377620205283165), 47: (1, 0.3338797325268388), 48: (1, 0.33348432276397943), 49: (1, 0.3337763324379921), 50: (1, 0.3337585721164942), 51: (1, 0.33351148199290037), 52: (1, 0.3337043933570385), 53: (1, 0.33322430308908224), 54: (1, 0.3339998107403517), 55: (1, 0.3341258307918906), 56: (1, 0.3345327600836754), 57: (1, 0.33407350070774555), 58: (1, 0.3337740022689104), 59: (1, 0.33414985053241253), 60: (1, 0.33335049357265234), 61: (1, 0.33369153179228306), 62: (1, 0.3330377843230963), 63: (1, 0.33441659063100815), 64: (1, 0.33493202924728394), 65: (1, 0.33345195185393095), 66: (1, 0.3339389907196164), 67: (1, 0.334215079434216), 68: (1, 0.33332307264208794), 69: (1, 0.33335420303046703), 70: (1, 0.33336628321558237), 71: (1, 0.33357507176697254)}\n",
      "{1: (1, 31, 0.1259130160474489), 2: (1, 31, 0.1300000775785696), 3: (1, 31, 0.12524479642630584), 4: (1, 31, 0.12431279873295177), 5: (1, 31, 0.1242868757295993), 6: (1, 31, 0.12660447126554866), 7: (1, 31, 0.12755224228866638), 8: (1, 31, 0.12991772426833068), 9: (1, 31, 0.12668457197686356), 10: (1, 31, 0.12614151450895494), 11: (1, 31, 0.1252615252629884), 12: (1, 31, 0.126177231751142), 13: (1, 31, 0.1247889372490106), 14: (1, 31, 0.12482026718076199), 15: (1, 31, 0.12493385470682575), 16: (1, 31, 0.12485249824221095), 17: (1, 31, 0.12489936179331233), 18: (1, 31, 0.1251543678884064), 19: (1, 31, 0.12479261828646544), 20: (1, 31, 0.12468367451501469), 21: (1, 31, 0.12465382481534634), 22: (1, 31, 0.12542259642073222), 23: (1, 31, 0.12464334812736319), 24: (1, 31, 0.12474799543739326), 25: (1, 31, 0.12484109407711413), 26: (1, 31, 0.12487110964232875), 27: (1, 31, 0.12485808476565345), 28: (1, 31, 0.12499005467660966), 29: (1, 31, 0.12499632860624021), 30: (1, 31, 0.1252828640262446), 31: (1, 31, 0.12471436213461622), 32: (1, 31, 0.12459903219414334), 33: (1, 31, 0.12460451747380918), 34: (1, 31, 0.12474166607904819), 35: (1, 31, 0.12495803253184404), 36: (1, 31, 0.12462336443845302), 37: (1, 31, 0.12487355523532437), 38: (1, 31, 0.12482166236206409), 39: (1, 31, 0.12464824667380701), 40: (1, 31, 0.12472930226114488), 41: (1, 31, 0.12472695298492908), 42: (1, 31, 0.12473952436759587), 43: (1, 31, 0.12467343636578129), 44: (1, 31, 0.12473133158299231), 45: (1, 31, 0.12500673871968063), 46: (1, 31, 0.12477415070057876), 47: (1, 31, 0.12463297289345533), 48: (1, 31, 0.1263046788892919), 49: (1, 31, 0.12830427481282142), 50: (1, 31, 0.1271740433069006), 51: (1, 31, 0.12840624898672104), 52: (1, 31, 0.12845039058236346), 53: (1, 31, 0.12749595958138665), 54: (1, 31, 0.12766168864383812), 55: (1, 31, 0.12839834482198761), 56: (1, 31, 0.12754077260052005), 57: (1, 31, 0.12850144544556255), 58: (1, 31, 0.12750409898017684), 59: (1, 31, 0.12748018411859388), 60: (1, 31, 0.12831545720297483), 61: (1, 31, 0.1281549368474272), 62: (1, 31, 0.12935518921022454), 63: (1, 31, 0.12773283706196853), 64: (1, 31, 0.12746531654509805), 65: (1, 31, 0.12797606862600772), 66: (1, 31, 0.12757522486630948), 67: (1, 31, 0.12697062881723528), 68: (1, 31, 0.1276222425362756), 69: (1, 31, 0.1284027069867138), 70: (1, 31, 0.12776068856398906)}\n",
      "{'predict_runtime': 301.4718, 'predict_samples_per_second': 0.236, 'predict_steps_per_second': 0.236}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:01.47\n",
      "  predict_samples_per_second =      0.236\n",
      "  predict_steps_per_second   =      0.236\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5446514738723636), 2: (2, 0.5216513704508543), 3: (2, 0.5213848724961281), 4: (2, 0.5224354891106486), 5: (2, 0.5218468997627497), 6: (2, 0.5217655012384057), 7: (2, 0.5215257508680224), 8: (2, 0.5216732313856483), 9: (2, 0.5224079685285687), 10: (2, 0.5229222178459167), 11: (2, 0.5225129285827279), 12: (2, 0.5223163897171617), 13: (2, 0.5230539469048381), 14: (2, 0.5237462650984526), 15: (2, 0.5226751081645489), 16: (2, 0.523446585983038), 17: (2, 0.5223510498180985), 18: (2, 0.522426319308579), 19: (2, 0.5232108263298869), 20: (2, 0.5230290871113539), 21: (2, 0.5227766875177622), 22: (2, 0.5232829470187426), 23: (2, 0.5233075059950352), 24: (2, 0.5233087269589305), 25: (2, 0.5233281860128045), 26: (2, 0.5231754975393414), 27: (2, 0.5225670579820871), 28: (2, 0.5226845182478428), 29: (2, 0.5230999970808625), 30: (2, 0.5228045871481299), 31: (2, 0.5227668778970838), 32: (2, 0.5230666473507881), 33: (2, 0.5225672284141183), 34: (2, 0.5222389400005341), 35: (2, 0.5230668168514967), 36: (2, 0.5224727289751172), 37: (2, 0.5224286997690797), 38: (2, 0.5223085889592767), 39: (2, 0.5226144185289741), 40: (2, 0.5231252666562796), 41: (2, 0.5228676870465279), 42: (2, 0.522362588904798), 43: (2, 0.5221388097852468), 44: (2, 0.5237566353753209), 45: (2, 0.5229534786194563), 46: (2, 0.5229872474446893), 47: (2, 0.5230272663757205), 48: (2, 0.5225274385884404), 49: (2, 0.5227074986323714), 50: (2, 0.5223286002874374), 51: (2, 0.5226077381521463), 52: (2, 0.5223054988309741), 53: (2, 0.5224414989352226), 54: (2, 0.5228984775021672), 55: (2, 0.5225456189364195), 56: (2, 0.5224877391010523), 57: (2, 0.5231088567525148), 58: (2, 0.5228096581995487), 59: (2, 0.522681588307023), 60: (2, 0.5225513884797692), 61: (2, 0.5227989479899406), 62: (2, 0.5222019990906119), 63: (2, 0.5229252874851227), 64: (2, 0.5223598089069128), 65: (2, 0.522761438973248), 66: (2, 0.5218335911631584), 67: (2, 0.5239349836483598), 68: (2, 0.5228370381519198), 69: (2, 0.522902337834239), 70: (2, 0.5216714823618531), 71: (1, 0.3326239651069045)}\n",
      "{1: (2, 31, 0.20994936683846097), 2: (2, 31, 0.20856193828606798), 3: (2, 31, 0.20694569519330416), 4: (2, 31, 0.20678719604808476), 5: (2, 31, 0.2069730927506762), 6: (2, 31, 0.20814587776699373), 7: (2, 31, 0.20731620334329143), 8: (2, 31, 0.20733081979016144), 9: (2, 31, 0.2072970639133165), 10: (2, 31, 0.20705133099709788), 11: (2, 31, 0.20711285590885148), 12: (2, 31, 0.20726342306983087), 13: (2, 31, 0.2074533785362878), 14: (2, 31, 0.20726007069911687), 15: (2, 31, 0.2074306388836234), 16: (2, 31, 0.20735747508344152), 17: (2, 31, 0.2072592558519494), 18: (2, 31, 0.20727172896506324), 19: (2, 31, 0.20730674308874913), 20: (2, 31, 0.20741200146655883), 21: (2, 31, 0.2071375865789671), 22: (2, 31, 0.20733320848235198), 23: (2, 31, 0.2074253386667659), 24: (2, 31, 0.20710413632613997), 25: (2, 31, 0.2071452598057447), 26: (2, 31, 0.20709916841118567), 27: (2, 31, 0.20714188225927851), 28: (2, 31, 0.20718470885748824), 29: (2, 31, 0.20742661151434144), 30: (2, 31, 0.20707661868824112), 31: (2, 31, 0.20727982092648745), 32: (2, 31, 0.20714722814098482), 33: (2, 31, 0.20709747965297393), 34: (2, 31, 0.20707379729156533), 35: (2, 31, 0.20719754416495562), 36: (2, 31, 0.20732959633272502), 37: (2, 31, 0.20755360624001873), 38: (2, 31, 0.2071721707020075), 39: (2, 31, 0.20782368404850846), 40: (2, 31, 0.20705200782826833), 41: (2, 31, 0.20709194894880056), 42: (2, 31, 0.20720436213718307), 43: (2, 31, 0.20726505408604298), 44: (2, 31, 0.20723858983406135), 45: (2, 31, 0.2071574677923514), 46: (2, 31, 0.20715545592529158), 47: (2, 31, 0.2071166469324981), 48: (2, 31, 0.20720361560703285), 49: (2, 31, 0.20723433687441772), 50: (2, 31, 0.20713376890747778), 51: (2, 31, 0.2071896010949727), 52: (2, 31, 0.20714407098749954), 53: (2, 31, 0.20700765476231614), 54: (2, 31, 0.20718757354564243), 55: (2, 31, 0.2071440213570191), 56: (2, 31, 0.2074272745859719), 57: (2, 31, 0.20728254035836266), 58: (2, 31, 0.2070464561543157), 59: (2, 31, 0.20713963548863126), 60: (2, 31, 0.20707140769809484), 61: (2, 31, 0.207229842011246), 62: (2, 31, 0.2070908632369772), 63: (2, 31, 0.20707195880071771), 64: (2, 31, 0.2068872601094265), 65: (2, 31, 0.20717251204675244), 66: (2, 31, 0.20687762473619753), 67: (2, 31, 0.20712296550552692), 68: (2, 31, 0.20691725341302733), 69: (2, 31, 0.20717847860989072), 70: (2, 31, 0.20693661633037752)}\n",
      "{'predict_runtime': 490.7243, 'predict_samples_per_second': 0.287, 'predict_steps_per_second': 0.145}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:10.72\n",
      "  predict_samples_per_second =      0.287\n",
      "  predict_steps_per_second   =      0.145\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.9028174243867397), 2: (4, 0.8842463484033942), 3: (4, 0.8833118723705411), 4: (4, 0.8835255913436413), 5: (4, 0.8828702131286263), 6: (4, 0.8839996894821525), 7: (4, 0.8841519067063928), 8: (4, 0.883550338447094), 9: (4, 0.8831512294709682), 10: (4, 0.8838765369728208), 11: (4, 0.8840722870081663), 12: (4, 0.8838193770498037), 13: (4, 0.8834602190181613), 14: (4, 0.8840801874175668), 15: (4, 0.8837542282417417), 16: (4, 0.8839465575292706), 17: (4, 0.8838573582470417), 18: (4, 0.8837614879012108), 19: (4, 0.8833682294934988), 20: (4, 0.884087516926229), 21: (4, 0.8838957771658897), 22: (4, 0.8841406861320138), 23: (4, 0.8837236184626818), 24: (4, 0.8836746076121926), 25: (4, 0.8837626380845904), 26: (4, 0.884108486585319), 27: (4, 0.8841864066198468), 28: (4, 0.8836540691554546), 29: (4, 0.8840075768530369), 30: (4, 0.8836546279489994), 31: (4, 0.884385815821588), 32: (4, 0.8839615071192384), 33: (4, 0.8841948360204697), 34: (4, 0.8846412552520633), 35: (4, 0.8838964868336916), 36: (4, 0.8838076265528798), 37: (4, 0.88439323566854), 38: (4, 0.8834155285730958), 39: (4, 0.8848756439983845), 40: (4, 0.8836306286975741), 41: (4, 0.8832493498921394), 42: (4, 0.8835458988323808), 43: (4, 0.8837942574173212), 44: (4, 0.8834253689274192), 45: (4, 0.8849170235916972), 46: (4, 0.884101577103138), 47: (4, 0.884765905328095), 48: (4, 0.8841366562992334), 49: (4, 0.8848026152700186), 50: (4, 0.8846866553649306), 51: (4, 0.8840665873140097), 52: (4, 0.884188937023282), 53: (4, 0.883862697519362), 54: (4, 0.8848209837451577), 55: (4, 0.8844563867896795), 56: (4, 0.8841993175446987), 57: (4, 0.8841152070090175), 58: (4, 0.8836587984114885), 59: (4, 0.884068856947124), 60: (4, 0.8834806680679321), 61: (4, 0.883742768317461), 62: (4, 0.8837641179561615), 63: (4, 0.8831963492557406), 64: (4, 0.8835553787648678), 65: (4, 0.8839378170669079), 66: (4, 0.8837556187063456), 67: (4, 0.8837633477523923), 68: (4, 0.8834997983649373), 69: (4, 0.883610618300736), 70: (4, 0.882005862891674), 71: (1, 0.3335003713145852)}\n",
      "{1: (4, 31, 0.2165787031032866), 2: (4, 31, 0.215351237675115), 3: (4, 31, 0.2155362850115184), 4: (4, 31, 0.21536424683947716), 5: (4, 31, 0.21521411968335027), 6: (4, 31, 0.21530918335361826), 7: (4, 31, 0.21544688426318667), 8: (4, 31, 0.2153438849735164), 9: (4, 31, 0.215395599153013), 10: (4, 31, 0.21534257541380583), 11: (4, 31, 0.2181680530850445), 12: (4, 31, 0.22105777134457905), 13: (4, 31, 0.21531485673040152), 14: (4, 31, 0.21532252779410732), 15: (4, 31, 0.215387144306254), 16: (4, 31, 0.2152193782310332), 17: (4, 31, 0.2210218020144009), 18: (4, 31, 0.22126875775715998), 19: (4, 31, 0.2155035980526478), 20: (4, 31, 0.2150996585166262), 21: (4, 31, 0.21524522690883569), 22: (4, 31, 0.21566704684688198), 23: (4, 31, 0.21907564622139739), 24: (4, 31, 0.21525436618755903), 25: (4, 31, 0.21534321631395048), 26: (4, 31, 0.21518036008121505), 27: (4, 31, 0.21526587907705577), 28: (4, 31, 0.2151458154642774), 29: (4, 31, 0.21546048803194875), 30: (4, 31, 0.21508126955239043), 31: (4, 31, 0.21537132843607856), 32: (4, 31, 0.2154796604187258), 33: (4, 31, 0.21514950335145958), 34: (4, 31, 0.21520866513732942), 35: (4, 31, 0.2153561683371663), 36: (4, 31, 0.21514393524416991), 37: (4, 31, 0.2152521087818088), 38: (4, 31, 0.21515894212549733), 39: (4, 31, 0.21522677161039844), 40: (4, 31, 0.21537703975674607), 41: (4, 31, 0.2151005954872216), 42: (4, 31, 0.21508177474982315), 43: (4, 31, 0.21522947325701675), 44: (4, 31, 0.21534748889145353), 45: (4, 31, 0.21518939030506917), 46: (4, 31, 0.21515126325069897), 47: (4, 31, 0.21523809246718884), 48: (4, 31, 0.2151970809565917), 49: (4, 31, 0.21540150481967196), 50: (4, 31, 0.2155712945687194), 51: (4, 31, 0.21531857655293518), 52: (4, 31, 0.21510764403689292), 53: (4, 31, 0.21742444058820123), 54: (4, 31, 0.21723215747624636), 55: (4, 31, 0.21801368883180042), 56: (4, 31, 0.2177659668509037), 57: (4, 31, 0.21729118680401194), 58: (4, 31, 0.2184447936052757), 59: (4, 31, 0.2199954239110793), 60: (4, 31, 0.21551620374403654), 61: (4, 31, 0.21737208286480558), 62: (4, 31, 0.21770843412847288), 63: (4, 31, 0.2174692418005678), 64: (4, 31, 0.21527372354701643), 65: (4, 31, 0.21822632185273594), 66: (4, 31, 0.21783696700848879), 67: (4, 31, 0.21640627491738526), 68: (4, 31, 0.21714539074849698), 69: (4, 31, 0.21595666353260318), 70: (4, 31, 0.21586690311350168)}\n",
      "{'predict_runtime': 535.3592, 'predict_samples_per_second': 0.525, 'predict_steps_per_second': 0.133}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:55.35\n",
      "  predict_samples_per_second =      0.525\n",
      "  predict_steps_per_second   =      0.133\n",
      "Evaluating with num_layers: 29\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.36508968193084), 2: (1, 0.34984369575977325), 3: (1, 0.34569300804287195), 4: (1, 0.34879757929593325), 5: (1, 0.34455252066254616), 6: (1, 0.3485725484788418), 7: (1, 0.34424509201198816), 8: (1, 0.3447687802836299), 9: (1, 0.344962059520185), 10: (1, 0.3447556383907795), 11: (1, 0.34552278742194176), 12: (1, 0.34530518762767315), 13: (1, 0.34723192267119884), 14: (1, 0.34515833854675293), 15: (1, 0.3453610986471176), 16: (1, 0.3448701687157154), 17: (1, 0.3448418704792857), 18: (1, 0.34580409713089466), 19: (1, 0.3463015854358673), 20: (1, 0.3450444592162967), 21: (1, 0.34780922159552574), 22: (1, 0.3477734010666609), 23: (1, 0.3448597099632025), 24: (1, 0.3452886277809739), 25: (1, 0.34776585176587105), 26: (1, 0.34613488614559174), 27: (1, 0.34498671907931566), 28: (1, 0.3452021488919854), 29: (1, 0.34520452935248613), 30: (1, 0.34497988875955343), 31: (1, 0.34507569018751383), 32: (1, 0.34519198909401894), 33: (1, 0.3446681499481201), 34: (1, 0.3447146397083998), 35: (1, 0.3451254488900304), 36: (1, 0.3452382693067193), 37: (1, 0.3449474088847637), 38: (1, 0.3445519609376788), 39: (1, 0.34515947941690683), 40: (1, 0.3450507801026106), 41: (1, 0.3453102884814143), 42: (1, 0.34493364952504635), 43: (1, 0.34503898955881596), 44: (1, 0.3448000606149435), 45: (1, 0.34494034945964813), 46: (1, 0.34516629949212074), 47: (1, 0.3452222375199199), 48: (1, 0.3451357875019312), 49: (1, 0.34470087941735983), 50: (1, 0.34536608774214983), 51: (1, 0.3455623174086213), 52: (1, 0.34501605946570635), 53: (1, 0.3448560405522585), 54: (1, 0.3451905995607376), 55: (1, 0.34498921036720276), 56: (1, 0.3449746984988451), 57: (1, 0.34482289012521505), 58: (1, 0.34493886958807707), 59: (1, 0.3449546294286847), 60: (1, 0.3451793286949396), 61: (1, 0.3451578486710787), 62: (1, 0.3445995897054672), 63: (1, 0.3448606291785836), 64: (1, 0.34531876910477877), 65: (1, 0.34476209059357643), 66: (1, 0.3451366489753127), 67: (1, 0.3454135078936815), 68: (1, 0.34503511898219585), 69: (1, 0.34492432978004217), 70: (1, 0.3449288383126259), 71: (1, 0.3444837098941207)}\n",
      "{1: (1, 31, 0.13625846067143063), 2: (1, 31, 0.1360271836540872), 3: (1, 31, 0.135667793963465), 4: (1, 31, 0.1355810322227978), 5: (1, 31, 0.13556836347185797), 6: (1, 31, 0.13603206005908788), 7: (1, 31, 0.13438487785958475), 8: (1, 31, 0.1356492817942654), 9: (1, 31, 0.13576752938810857), 10: (1, 31, 0.1354120651019677), 11: (1, 31, 0.13404814814848284), 12: (1, 31, 0.13288977973523639), 13: (1, 31, 0.1346028299942132), 14: (1, 31, 0.1324216458465784), 15: (1, 31, 0.13287480869480678), 16: (1, 31, 0.13537398254078242), 17: (1, 31, 0.13511420392821874), 18: (1, 31, 0.13592754968351894), 19: (1, 31, 0.13615040739457454), 20: (1, 31, 0.13561334379858547), 21: (1, 31, 0.13447105295715794), 22: (1, 31, 0.13219811181507765), 23: (1, 31, 0.136082740530612), 24: (1, 31, 0.13403582494826086), 25: (1, 31, 0.13263145083140943), 26: (1, 31, 0.12997123770295613), 27: (1, 31, 0.13031318065740408), 28: (1, 31, 0.13032968925131905), 29: (1, 31, 0.12883019976077542), 30: (1, 31, 0.13169435964476678), 31: (1, 31, 0.13380423957301724), 32: (1, 31, 0.12999387677278249), 33: (1, 31, 0.1343955990948504), 34: (1, 31, 0.12874390392173682), 35: (1, 31, 0.12853118506891112), 36: (1, 31, 0.12872089634859754), 37: (1, 31, 0.12873195138789953), 38: (1, 31, 0.1286910239667181), 39: (1, 31, 0.128566570369707), 40: (1, 31, 0.13083930244489062), 41: (1, 31, 0.13128089433115336), 42: (1, 31, 0.13437784430120261), 43: (1, 31, 0.1295668971274168), 44: (1, 31, 0.1345914992233438), 45: (1, 31, 0.13265762889697666), 46: (1, 31, 0.1358893450289484), 47: (1, 31, 0.12990162900138286), 48: (1, 31, 0.1290201020817603), 49: (1, 31, 0.12939588503251154), 50: (1, 31, 0.13172232515869603), 51: (1, 31, 0.12855541730119335), 52: (1, 31, 0.12891637488839128), 53: (1, 31, 0.1288673927586886), 54: (1, 31, 0.1295914514170539), 55: (1, 31, 0.13093262009562984), 56: (1, 31, 0.1318255541846156), 57: (1, 31, 0.13461879214211817), 58: (1, 31, 0.1317440079705369), 59: (1, 31, 0.13337218452004657), 60: (1, 31, 0.12992366508490616), 61: (1, 31, 0.12874212689817913), 62: (1, 31, 0.1285926629939387), 63: (1, 31, 0.12865601071426946), 64: (1, 31, 0.1285712424245092), 65: (1, 31, 0.13094355484410639), 66: (1, 31, 0.12939894241431066), 67: (1, 31, 0.12927142620807694), 68: (1, 31, 0.1295766213067597), 69: (1, 31, 0.13041761577610048), 70: (1, 31, 0.1350589371436546)}\n",
      "{'predict_runtime': 315.4896, 'predict_samples_per_second': 0.225, 'predict_steps_per_second': 0.225}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:15.48\n",
      "  predict_samples_per_second =      0.225\n",
      "  predict_steps_per_second   =      0.225\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5621928824111819), 2: (2, 0.5403897641226649), 3: (2, 0.5399761348962784), 4: (2, 0.5408575125038624), 5: (2, 0.5410784324631095), 6: (2, 0.5405742740258574), 7: (2, 0.5406164927408099), 8: (2, 0.5407031131908298), 9: (2, 0.542006098665297), 10: (2, 0.5418366901576519), 11: (2, 0.5407661031931639), 12: (2, 0.5409757615998387), 13: (2, 0.5416881097480655), 14: (2, 0.5415671104565263), 15: (2, 0.5416609598323703), 16: (2, 0.540814402513206), 17: (2, 0.542363727465272), 18: (2, 0.5438953237608075), 19: (2, 0.5434055859223008), 20: (2, 0.5416189692914486), 21: (2, 0.5411471519619226), 22: (2, 0.5417169602587819), 23: (2, 0.5412312317639589), 24: (2, 0.5407274533063173), 25: (2, 0.5420828284695745), 26: (2, 0.5424293093383312), 27: (2, 0.5415684999898076), 28: (2, 0.5408211527392268), 29: (2, 0.5419327598065138), 30: (2, 0.5413550715893507), 31: (2, 0.5406446931883693), 32: (2, 0.541569403372705), 33: (2, 0.5416269423440099), 34: (2, 0.5409722849726677), 35: (2, 0.5412421450018883), 36: (2, 0.5415933933109045), 37: (2, 0.5421062419191003), 38: (2, 0.5414322232827544), 39: (2, 0.5410863952711225), 40: (2, 0.5421431614086032), 41: (2, 0.5410980954766273), 42: (2, 0.5425400715321302), 43: (2, 0.5411727046594024), 44: (2, 0.5411782152950764), 45: (2, 0.5422780914232135), 46: (2, 0.5417457027360797), 47: (2, 0.5415847226977348), 48: (2, 0.5415108539164066), 49: (2, 0.5413778536021709), 50: (2, 0.5412610350176692), 51: (2, 0.5412365142256021), 52: (2, 0.5408607553690672), 53: (2, 0.5416828030720353), 54: (2, 0.5408819457516074), 55: (2, 0.5409478852525353), 56: (2, 0.5422169528901577), 57: (2, 0.5416712323203683), 58: (2, 0.5425381613895297), 59: (2, 0.5426089512184262), 60: (2, 0.5424456810578704), 61: (2, 0.5412339745089412), 62: (2, 0.5424035005271435), 63: (2, 0.541901052929461), 64: (2, 0.5411267448216677), 65: (2, 0.5419590016826987), 66: (2, 0.5416090022772551), 67: (2, 0.5424296613782644), 68: (2, 0.5404109973460436), 69: (2, 0.5425339406356215), 70: (2, 0.5411512339487672), 71: (1, 0.3440615003928542)}\n",
      "{1: (2, 31, 0.22046077699070016), 2: (2, 31, 0.21515286218134627), 3: (2, 31, 0.21517633184069587), 4: (2, 31, 0.21485567955119955), 5: (2, 31, 0.21825701229634784), 6: (2, 31, 0.2149132482647415), 7: (2, 31, 0.220222273511031), 8: (2, 31, 0.2169625499856568), 9: (2, 31, 0.21806492115701398), 10: (2, 31, 0.2176165971904993), 11: (2, 31, 0.21717964767688705), 12: (2, 31, 0.21478361717515415), 13: (2, 31, 0.21441669248405001), 14: (2, 31, 0.21664205391801172), 15: (2, 31, 0.21536883122978673), 16: (2, 31, 0.21783213716961683), 17: (2, 31, 0.22001158647359378), 18: (2, 31, 0.21858842046030105), 19: (2, 31, 0.22006687789314217), 20: (2, 31, 0.21435426232675392), 21: (2, 31, 0.2145715949215716), 22: (2, 31, 0.21457531044800435), 23: (2, 31, 0.21492189592531613), 24: (2, 31, 0.2144829588191163), 25: (2, 31, 0.21483035680026777), 26: (2, 31, 0.2151343530464557), 27: (2, 31, 0.2151319598178229), 28: (2, 31, 0.21495349906505115), 29: (2, 31, 0.2149825780802677), 30: (2, 31, 0.21476498741896882), 31: (2, 31, 0.21593345305131328), 32: (2, 31, 0.2154344124419074), 33: (2, 31, 0.21457187209518686), 34: (2, 31, 0.21479185189931624), 35: (2, 31, 0.2181637622716446), 36: (2, 31, 0.2142886238833589), 37: (2, 31, 0.21494933205746836), 38: (2, 31, 0.21429159831736358), 39: (2, 31, 0.21432406623517314), 40: (2, 31, 0.2187542895816507), 41: (2, 31, 0.21840260069697134), 42: (2, 31, 0.2176655401445685), 43: (2, 31, 0.21738035159726296), 44: (2, 31, 0.21450238668870542), 45: (2, 31, 0.21540514130385652), 46: (2, 31, 0.21474832071051483), 47: (2, 31, 0.21547496556154183), 48: (2, 31, 0.214390795617815), 49: (2, 31, 0.21952676265350274), 50: (2, 31, 0.21905497731941362), 51: (2, 31, 0.21699974214237544), 52: (2, 31, 0.21589061855188302), 53: (2, 31, 0.2151956488828986), 54: (2, 31, 0.2201257141066655), 55: (2, 31, 0.21468612131091855), 56: (2, 31, 0.2197269089219551), 57: (2, 31, 0.21997356916507405), 58: (2, 31, 0.22075985059622796), 59: (2, 31, 0.21816515345727244), 60: (2, 31, 0.21931965667153558), 61: (2, 31, 0.21855572076334107), 62: (2, 31, 0.21762936811653838), 63: (2, 31, 0.21960817526785598), 64: (2, 31, 0.21446874725722498), 65: (2, 31, 0.2167392339136812), 66: (2, 31, 0.215853878807637), 67: (2, 31, 0.21618801015879838), 68: (2, 31, 0.21698224950101105), 69: (2, 31, 0.21578281522998888), 70: (2, 31, 0.21508925333018264)}\n",
      "{'predict_runtime': 512.4338, 'predict_samples_per_second': 0.275, 'predict_steps_per_second': 0.139}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:32.43\n",
      "  predict_samples_per_second =      0.275\n",
      "  predict_steps_per_second   =      0.139\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.9322757823392749), 2: (4, 0.9139065332710743), 3: (4, 0.9137561051174998), 4: (4, 0.9142720429226756), 5: (4, 0.914141483604908), 6: (4, 0.9157079486176372), 7: (4, 0.9144849022850394), 8: (4, 0.9152960106730461), 9: (4, 0.9145599119365215), 10: (4, 0.9154308196157217), 11: (4, 0.915177091024816), 12: (4, 0.9162296568974853), 13: (4, 0.9148113019764423), 14: (4, 0.9143608519807458), 15: (4, 0.91475760191679), 16: (4, 0.9148390013724566), 17: (4, 0.913574805483222), 18: (4, 0.9134844252839684), 19: (4, 0.9140521436929703), 20: (4, 0.9138909447938204), 21: (4, 0.9134382652118802), 22: (4, 0.9136846037581563), 23: (4, 0.9139295034110546), 24: (4, 0.9140440244227648), 25: (4, 0.9143215520307422), 26: (4, 0.913389845751226), 27: (4, 0.9137882841750979), 28: (4, 0.9137172140181065), 29: (4, 0.9141770331189036), 30: (4, 0.9137864531949162), 31: (4, 0.9134506145492196), 32: (4, 0.9136394951492548), 33: (4, 0.9142881128937006), 34: (4, 0.9138515535742044), 35: (4, 0.9136384343728423), 36: (4, 0.9144661230966449), 37: (4, 0.9137737937271595), 38: (4, 0.9133310858160257), 39: (4, 0.9142078226432204), 40: (4, 0.9131310759112239), 41: (4, 0.9134799651801586), 42: (4, 0.9146132720634341), 43: (4, 0.9147087018936872), 44: (4, 0.9137782258912921), 45: (4, 0.9145161621272564), 46: (4, 0.9141747932881117), 47: (4, 0.914426151663065), 48: (4, 0.9145349822938442), 49: (4, 0.9141494426876307), 50: (4, 0.913470714353025), 51: (4, 0.9140938427299261), 52: (4, 0.9139654533937573), 53: (4, 0.9137359941378236), 54: (4, 0.9150848593562841), 55: (4, 0.9137012250721455), 56: (4, 0.914079163223505), 57: (4, 0.9139257743954659), 58: (4, 0.9138095937669277), 59: (4, 0.9135902244597673), 60: (4, 0.9137759236618876), 61: (4, 0.9139575641602278), 62: (4, 0.9140095934271812), 63: (4, 0.9142585331574082), 64: (4, 0.914351693354547), 65: (4, 0.9141235332936049), 66: (4, 0.9143460728228092), 67: (4, 0.9140240484848619), 68: (4, 0.9137069405987859), 69: (4, 0.9149680268019438), 70: (4, 0.9132083207368851), 71: (1, 0.3450527470558882)}\n",
      "{1: (4, 31, 0.22811738951432128), 2: (4, 31, 0.22636423019632215), 3: (4, 31, 0.22654478077686602), 4: (4, 31, 0.22532665789608033), 5: (4, 31, 0.2274315547378313), 6: (4, 31, 0.2232374401102143), 7: (4, 31, 0.22492408689351812), 8: (4, 31, 0.2257271643968359), 9: (4, 31, 0.22594466493014367), 10: (4, 31, 0.2261088561687258), 11: (4, 31, 0.22706098500038346), 12: (4, 31, 0.22403443066944037), 13: (4, 31, 0.2244094344036233), 14: (4, 31, 0.22725942090994888), 15: (4, 31, 0.22795394050978846), 16: (4, 31, 0.22357154051743208), 17: (4, 31, 0.22162951036326348), 18: (4, 31, 0.22172927694214928), 19: (4, 31, 0.22193649711628113), 20: (4, 31, 0.22251008685317733), 21: (4, 31, 0.22285469053613563), 22: (4, 31, 0.2214501540386869), 23: (4, 31, 0.2213676678797891), 24: (4, 31, 0.2226498302132372), 25: (4, 31, 0.22178928845471912), 26: (4, 31, 0.22232138816147082), 27: (4, 31, 0.22195113330118119), 28: (4, 31, 0.222228528210713), 29: (4, 31, 0.22198015126970508), 30: (4, 31, 0.22189093423226186), 31: (4, 31, 0.2218947249254392), 32: (4, 31, 0.22148024669337657), 33: (4, 31, 0.22180461898566253), 34: (4, 31, 0.22202857484620425), 35: (4, 31, 0.22133993916213512), 36: (4, 31, 0.2216631097478732), 37: (4, 31, 0.2214267307351674), 38: (4, 31, 0.2216952692176546), 39: (4, 31, 0.2212987810132965), 40: (4, 31, 0.2217668709795802), 41: (4, 31, 0.22389265453262674), 42: (4, 31, 0.22416873065935028), 43: (4, 31, 0.2245576703440278), 44: (4, 31, 0.2247161082322559), 45: (4, 31, 0.22379804730054834), 46: (4, 31, 0.22407951905962922), 47: (4, 31, 0.22125940496522573), 48: (4, 31, 0.2237579396535312), 49: (4, 31, 0.22184007608842465), 50: (4, 31, 0.22296121157705784), 51: (4, 31, 0.22157423017967132), 52: (4, 31, 0.22154555331555106), 53: (4, 31, 0.22186893257763116), 54: (4, 31, 0.22190747995890917), 55: (4, 31, 0.22114591234393657), 56: (4, 31, 0.22200968528106327), 57: (4, 31, 0.22162410373529118), 58: (4, 31, 0.22267260922179108), 59: (4, 31, 0.22177832369362155), 60: (4, 31, 0.22162732668220997), 61: (4, 31, 0.2215709503920328), 62: (4, 31, 0.22206889928108262), 63: (4, 31, 0.22378299421360415), 64: (4, 31, 0.22144523605463967), 65: (4, 31, 0.2234369026076409), 66: (4, 31, 0.22140568801231922), 67: (4, 31, 0.22210521554394114), 68: (4, 31, 0.2218624747568561), 69: (4, 31, 0.224664875937085), 70: (4, 31, 0.22448010757685669)}\n",
      "{'predict_runtime': 552.7752, 'predict_samples_per_second': 0.508, 'predict_steps_per_second': 0.128}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:09:12.77\n",
      "  predict_samples_per_second =      0.508\n",
      "  predict_steps_per_second   =      0.128\n",
      "Evaluating with num_layers: 30\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.3761810529977083), 2: (1, 0.3580032764002681), 3: (1, 0.35732113663107157), 4: (1, 0.3572096973657608), 5: (1, 0.35693409759551287), 6: (1, 0.35711502842605114), 7: (1, 0.3577246069908142), 8: (1, 0.35715362057089806), 9: (1, 0.3571856701746583), 10: (1, 0.35713827051222324), 11: (1, 0.35858651623129845), 12: (1, 0.3576126992702484), 13: (1, 0.35735648963600397), 14: (1, 0.3572705900296569), 15: (1, 0.35754801891744137), 16: (1, 0.357419959269464), 17: (1, 0.3589447448030114), 18: (1, 0.35819113813340664), 19: (1, 0.35837813653051853), 20: (1, 0.3572627706453204), 21: (1, 0.3569829408079386), 22: (1, 0.3582662269473076), 23: (1, 0.35743148904293776), 24: (1, 0.357485699467361), 25: (1, 0.35715613048523664), 26: (1, 0.3579665580764413), 27: (1, 0.3573096003383398), 28: (1, 0.3575855288654566), 29: (1, 0.357689437456429), 30: (1, 0.3572900090366602), 31: (1, 0.3572566704824567), 32: (1, 0.3569569205865264), 33: (1, 0.35692234989255667), 34: (1, 0.35741973854601383), 35: (1, 0.35742050874978304), 36: (1, 0.35723234061151743), 37: (1, 0.3575545707717538), 38: (1, 0.35730820056051016), 39: (1, 0.35749558079987764), 40: (1, 0.35707039199769497), 41: (1, 0.35699486173689365), 42: (1, 0.3575456701219082), 43: (1, 0.3571772510185838), 44: (1, 0.3581143692135811), 45: (1, 0.3572317520156503), 46: (1, 0.35747755132615566), 47: (1, 0.3572265114635229), 48: (1, 0.3576148096472025), 49: (1, 0.3572387620806694), 50: (1, 0.35759520158171654), 51: (1, 0.3572804732248187), 52: (1, 0.35886583756655455), 53: (1, 0.35693346429616213), 54: (1, 0.3573942016810179), 55: (1, 0.35745364241302013), 56: (1, 0.3569760425016284), 57: (1, 0.35711732413619757), 58: (1, 0.3573323432356119), 59: (1, 0.3573188427835703), 60: (1, 0.35723546240478754), 61: (1, 0.35712303407490253), 62: (1, 0.3577179806306958), 63: (1, 0.3571480829268694), 64: (1, 0.35718881990760565), 65: (1, 0.3576742187142372), 66: (1, 0.35780408792197704), 67: (1, 0.3570287600159645), 68: (1, 0.3575068786740303), 69: (1, 0.35701945051550865), 70: (1, 0.35719501972198486), 71: (1, 0.35637647192925215)}\n",
      "{1: (1, 31, 0.1367644756551712), 2: (1, 31, 0.13559689045312903), 3: (1, 31, 0.1351273495764021), 4: (1, 31, 0.1350074911550168), 5: (1, 31, 0.13471435223736108), 6: (1, 31, 0.13485637944071524), 7: (1, 31, 0.1344998659445874), 8: (1, 31, 0.1344916396924565), 9: (1, 31, 0.13433901178500346), 10: (1, 31, 0.13510274298248753), 11: (1, 31, 0.13437505751367537), 12: (1, 31, 0.13442341917224468), 13: (1, 31, 0.13439856836151692), 14: (1, 31, 0.13431188944847353), 15: (1, 31, 0.13487997251532732), 16: (1, 31, 0.13441963004128588), 17: (1, 31, 0.1343308798968792), 18: (1, 31, 0.13440174657490947), 19: (1, 31, 0.13529018763332598), 20: (1, 31, 0.13866735168642574), 21: (1, 31, 0.1362231310997759), 22: (1, 31, 0.13597619593624147), 23: (1, 31, 0.13533081453774246), 24: (1, 31, 0.13473166366137804), 25: (1, 31, 0.13661094397426612), 26: (1, 31, 0.13456347662835352), 27: (1, 31, 0.13733894765497215), 28: (1, 31, 0.1356096939153729), 29: (1, 31, 0.13503045489590976), 30: (1, 31, 0.1347591639045746), 31: (1, 31, 0.13709333584073088), 32: (1, 31, 0.13565341223992647), 33: (1, 31, 0.1354087206925596), 34: (1, 31, 0.13542581505833134), 35: (1, 31, 0.13804965898875268), 36: (1, 31, 0.1383565629441892), 37: (1, 31, 0.1363943459526185), 38: (1, 31, 0.138077974409586), 39: (1, 31, 0.13752402827864693), 40: (1, 31, 0.13718183290573857), 41: (1, 31, 0.13618364434448943), 42: (1, 31, 0.137255271175696), 43: (1, 31, 0.13519808914392226), 44: (1, 31, 0.13811156342947675), 45: (1, 31, 0.13688689067719445), 46: (1, 31, 0.13533028338344827), 47: (1, 31, 0.14109165987540637), 48: (1, 31, 0.135373781134765), 49: (1, 31, 0.13879295330374472), 50: (1, 31, 0.13485172414971935), 51: (1, 31, 0.1372456306952142), 52: (1, 31, 0.13720270219228922), 53: (1, 31, 0.13657820480124605), 54: (1, 31, 0.1370334904640913), 55: (1, 31, 0.136265151262764), 56: (1, 31, 0.13609662015111215), 57: (1, 31, 0.1363770633695587), 58: (1, 31, 0.1362584609418146), 59: (1, 31, 0.1382137971119054), 60: (1, 31, 0.137226379176061), 61: (1, 31, 0.13620961535601847), 62: (1, 31, 0.13561294209812919), 63: (1, 31, 0.13522607250319374), 64: (1, 31, 0.1349803654236659), 65: (1, 31, 0.13429266821232536), 66: (1, 31, 0.13456853827641857), 67: (1, 31, 0.13470971295910497), 68: (1, 31, 0.1351431344425486), 69: (1, 31, 0.1344418082566511), 70: (1, 31, 0.13532885118958451)}\n",
      "{'predict_runtime': 324.6579, 'predict_samples_per_second': 0.219, 'predict_steps_per_second': 0.219}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:24.65\n",
      "  predict_samples_per_second =      0.219\n",
      "  predict_steps_per_second   =      0.219\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5833920761942863), 2: (2, 0.5618823477998376), 3: (2, 0.5632840637117624), 4: (2, 0.5623933877795935), 5: (2, 0.5630620177835226), 6: (2, 0.5621558595448732), 7: (2, 0.5614711223170161), 8: (2, 0.562461749650538), 9: (2, 0.5625798488035798), 10: (2, 0.562807678245008), 11: (2, 0.5622166506946087), 12: (2, 0.5627216594293714), 13: (2, 0.5626952461898327), 14: (2, 0.5623251274228096), 15: (2, 0.5632488746196032), 16: (2, 0.5636795526370406), 17: (2, 0.563325765542686), 18: (2, 0.5626806560903788), 19: (2, 0.5620069680735469), 20: (2, 0.5623840671032667), 21: (2, 0.5627286862581968), 22: (2, 0.56430918071419), 23: (2, 0.5629001250490546), 24: (2, 0.5638147434219718), 25: (2, 0.5625410564243793), 26: (2, 0.5629497151821852), 27: (2, 0.5622680466622114), 28: (2, 0.5634344425052404), 29: (2, 0.5641627022996545), 30: (2, 0.5629144348204136), 31: (2, 0.5622763046994805), 32: (2, 0.5638424614444375), 33: (2, 0.5639331806451082), 34: (2, 0.5637105712667108), 35: (2, 0.5636646412312984), 36: (2, 0.5630037738010287), 37: (2, 0.5634781010448933), 38: (2, 0.562749033793807), 39: (2, 0.5638938592746854), 40: (2, 0.5633325800299644), 41: (2, 0.5632755309343338), 42: (2, 0.5638581188395619), 43: (2, 0.5627305814996362), 44: (2, 0.5630975607782602), 45: (2, 0.5636164098978043), 46: (2, 0.563561568967998), 47: (2, 0.5630011213943362), 48: (2, 0.5627512959763408), 49: (2, 0.5636019827798009), 50: (2, 0.5630902256816626), 51: (2, 0.5635163327679038), 52: (2, 0.5641762502491474), 53: (2, 0.5640416406095028), 54: (2, 0.5642139511182904), 55: (2, 0.5640685204416513), 56: (2, 0.5629930151626468), 57: (2, 0.562901996076107), 58: (2, 0.563692694529891), 59: (2, 0.5618016989901662), 60: (2, 0.5624482473358512), 61: (2, 0.562226178124547), 62: (2, 0.5632621441036463), 63: (2, 0.5630371058359742), 64: (2, 0.5619924888014793), 65: (2, 0.5621003853157163), 66: (2, 0.5626802230253816), 67: (2, 0.5622862949967384), 68: (2, 0.5621262947097421), 69: (2, 0.5637415004894137), 70: (2, 0.5623695943504572), 71: (1, 0.35570941120386124)}\n",
      "{1: (2, 31, 0.22338803244694586), 2: (2, 31, 0.22283703539400332), 3: (2, 31, 0.22629320185871854), 4: (2, 31, 0.22477067514292656), 5: (2, 31, 0.22448311794188716), 6: (2, 31, 0.2228652790128704), 7: (2, 31, 0.2234460830748562), 8: (2, 31, 0.22289578159970622), 9: (2, 31, 0.2234028264459583), 10: (2, 31, 0.22416942308266316), 11: (2, 31, 0.22309530880903045), 12: (2, 31, 0.2229353009813255), 13: (2, 31, 0.22435879575148707), 14: (2, 31, 0.2242074859058184), 15: (2, 31, 0.2230082744011475), 16: (2, 31, 0.2228991073225775), 17: (2, 31, 0.22281588037167827), 18: (2, 31, 0.22426831842430175), 19: (2, 31, 0.22420416072371505), 20: (2, 31, 0.22428456486593332), 21: (2, 31, 0.22482568106704182), 22: (2, 31, 0.2264648967332417), 23: (2, 31, 0.22437710996957555), 24: (2, 31, 0.22294774942941242), 25: (2, 31, 0.22557215629926614), 26: (2, 31, 0.2231824425680022), 27: (2, 31, 0.22343016157467518), 28: (2, 31, 0.2228500019578684), 29: (2, 31, 0.22341329892796855), 30: (2, 31, 0.2233951443866376), 31: (2, 31, 0.22284010058689502), 32: (2, 31, 0.22328668871834392), 33: (2, 31, 0.22346523136741692), 34: (2, 31, 0.2228487426294915), 35: (2, 31, 0.22458564979775297), 36: (2, 31, 0.22363592248650327), 37: (2, 31, 0.22754235661798908), 38: (2, 31, 0.22573626882606937), 39: (2, 31, 0.22806248858931563), 40: (2, 31, 0.22321255946712149), 41: (2, 31, 0.22393942849650497), 42: (2, 31, 0.22712008426747016), 43: (2, 31, 0.2242903260273799), 44: (2, 31, 0.22568160809216), 45: (2, 31, 0.22359248409949004), 46: (2, 31, 0.22317475906663364), 47: (2, 31, 0.2263974468073537), 48: (2, 31, 0.22511764252257924), 49: (2, 31, 0.2263278017541574), 50: (2, 31, 0.22276165952245075), 51: (2, 31, 0.22611016930351335), 52: (2, 31, 0.22421092452901986), 53: (2, 31, 0.22711106903490522), 54: (2, 31, 0.2253820415766489), 55: (2, 31, 0.2247432932377823), 56: (2, 31, 0.22278702598545821), 57: (2, 31, 0.22148062183611816), 58: (2, 31, 0.22144993746112432), 59: (2, 31, 0.22151530050342122), 60: (2, 31, 0.22143094376811095), 61: (2, 31, 0.22139241558409506), 62: (2, 31, 0.2214629918997807), 63: (2, 31, 0.22144708593165682), 64: (2, 31, 0.22134685008636407), 65: (2, 31, 0.22137578937315172), 66: (2, 31, 0.2213296667642651), 67: (2, 31, 0.22153141713070293), 68: (2, 31, 0.22135112041066732), 69: (2, 31, 0.2215695569532052), 70: (2, 31, 0.22132238439254223)}\n",
      "{'predict_runtime': 529.504, 'predict_samples_per_second': 0.266, 'predict_steps_per_second': 0.134}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:08:49.50\n",
      "  predict_samples_per_second =      0.266\n",
      "  predict_steps_per_second   =      0.134\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.9656265089288354), 2: (4, 0.9444569703191519), 3: (4, 0.9440895104780793), 4: (4, 0.9464285541325808), 5: (4, 0.9463573340326548), 6: (4, 0.9463931946083903), 7: (4, 0.9466146426275373), 8: (4, 0.9462277749553323), 9: (4, 0.9465646035969257), 10: (4, 0.9468612214550376), 11: (4, 0.946382649242878), 12: (4, 0.9470004877075553), 13: (4, 0.9462637389078736), 14: (4, 0.9468049174174666), 15: (4, 0.9462094195187092), 16: (4, 0.9454711303114891), 17: (4, 0.9468073975294828), 18: (4, 0.9459640998393297), 19: (4, 0.9456149218603969), 20: (4, 0.9453553725033998), 21: (4, 0.9463178785517812), 22: (4, 0.9461715798825026), 23: (4, 0.9461023798212409), 24: (4, 0.9455237407237291), 25: (4, 0.945538361556828), 26: (4, 0.9460667306557298), 27: (4, 0.9461546977981925), 28: (4, 0.9454461513087153), 29: (4, 0.9458868093788624), 30: (4, 0.945531539618969), 31: (4, 0.9467041771858931), 32: (4, 0.945951109752059), 33: (4, 0.9471473069861531), 34: (4, 0.9464956680312753), 35: (4, 0.9457422606647015), 36: (4, 0.9452665904536843), 37: (4, 0.9458850203081965), 38: (4, 0.9459472289308906), 39: (4, 0.9470705464482307), 40: (4, 0.9462179988622665), 41: (4, 0.9464426077902317), 42: (4, 0.9457653202116489), 43: (4, 0.9455490875989199), 44: (4, 0.9460391271859407), 45: (4, 0.9461350571364164), 46: (4, 0.9462978355586529), 47: (4, 0.9463355168700218), 48: (4, 0.9458372676745057), 49: (4, 0.9460708377882838), 50: (4, 0.9462597370147705), 51: (4, 0.9459459967911243), 52: (4, 0.9467523656785488), 53: (4, 0.946728466078639), 54: (4, 0.946993874385953), 55: (4, 0.94635343644768), 56: (4, 0.946367216296494), 57: (4, 0.9467156250029802), 58: (4, 0.9465228961780667), 59: (4, 0.947694112546742), 60: (4, 0.9463410163298249), 61: (4, 0.9469155035912991), 62: (4, 0.9461075868457556), 63: (4, 0.9463932272046804), 64: (4, 0.9463474964722991), 65: (4, 0.9462788458913565), 66: (4, 0.9463061457499862), 67: (4, 0.9470016146078706), 68: (4, 0.9466489953920245), 69: (4, 0.9461408769711852), 70: (4, 0.9446816705167294), 71: (1, 0.3569314619526267)}\n",
      "{1: (4, 31, 0.23117735125725308), 2: (4, 31, 0.23118599966889428), 3: (4, 31, 0.23039950253141503), 4: (4, 31, 0.23071448162438407), 5: (4, 31, 0.23040103903340717), 6: (4, 31, 0.23068794761333736), 7: (4, 31, 0.23058097082520684), 8: (4, 31, 0.23151545430864057), 9: (4, 31, 0.2305638338288953), 10: (4, 31, 0.23077423011343326), 11: (4, 31, 0.23035262519073102), 12: (4, 31, 0.23025337471476487), 13: (4, 31, 0.2304733670166423), 14: (4, 31, 0.23161096726694413), 15: (4, 31, 0.22995074874451082), 16: (4, 31, 0.22936464581758745), 17: (4, 31, 0.22913704848577898), 18: (4, 31, 0.2293381517933261), 19: (4, 31, 0.22899823734957364), 20: (4, 31, 0.2294826571559233), 21: (4, 31, 0.22911529270030798), 22: (4, 31, 0.22892927847081615), 23: (4, 31, 0.2288881972912819), 24: (4, 31, 0.22891729021625173), 25: (4, 31, 0.22988058049832621), 26: (4, 31, 0.2293087431500035), 27: (4, 31, 0.22890080772941152), 28: (4, 31, 0.22872905901843502), 29: (4, 31, 0.2289806145934328), 30: (4, 31, 0.2312751969082221), 31: (4, 31, 0.23026185431667873), 32: (4, 31, 0.2304736929194581), 33: (4, 31, 0.23020639946503985), 34: (4, 31, 0.23024322702399186), 35: (4, 31, 0.22903433814644814), 36: (4, 31, 0.22930690706256898), 37: (4, 31, 0.2299697621154689), 38: (4, 31, 0.2289529838749478), 39: (4, 31, 0.2310752348613835), 40: (4, 31, 0.23011127186398353), 41: (4, 31, 0.2302494425206415), 42: (4, 31, 0.23361312129324482), 43: (4, 31, 0.22978047131290358), 44: (4, 31, 0.23009247813493974), 45: (4, 31, 0.23445622824252613), 46: (4, 31, 0.23021875697398378), 47: (4, 31, 0.23147628429315745), 48: (4, 31, 0.23048758572868763), 49: (4, 31, 0.23041489035371812), 50: (4, 31, 0.23027095880599752), 51: (4, 31, 0.23042023764742958), 52: (4, 31, 0.2301490512045641), 53: (4, 31, 0.2302311831904996), 54: (4, 31, 0.23023491533052537), 55: (4, 31, 0.23008461864364724), 56: (4, 31, 0.23035271468782617), 57: (4, 31, 0.23029658964444552), 58: (4, 31, 0.23008894758118736), 59: (4, 31, 0.23024723717882747), 60: (4, 31, 0.23032345881144847), 61: (4, 31, 0.23066997251683666), 62: (4, 31, 0.23042686860407552), 63: (4, 31, 0.23142027671659185), 64: (4, 31, 0.23051049121685566), 65: (4, 31, 0.2312476863603919), 66: (4, 31, 0.2311771678467912), 67: (4, 31, 0.2305821139786032), 68: (4, 31, 0.23488513242092826), 69: (4, 31, 0.23113450314849615), 70: (4, 31, 0.2302888167361098)}\n",
      "{'predict_runtime': 570.8214, 'predict_samples_per_second': 0.492, 'predict_steps_per_second': 0.124}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:09:30.82\n",
      "  predict_samples_per_second =      0.492\n",
      "  predict_steps_per_second   =      0.124\n",
      "Evaluating with num_layers: 31\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.388383811339736), 2: (1, 0.36779946088790894), 3: (1, 0.3686096491292119), 4: (1, 0.3674753913655877), 5: (1, 0.36811850033700466), 6: (1, 0.3680278901010752), 7: (1, 0.3682353887706995), 8: (1, 0.36834810953587294), 9: (1, 0.3683173293247819), 10: (1, 0.3680629404261708), 11: (1, 0.3686789385974407), 12: (1, 0.36914384737610817), 13: (1, 0.36812769901007414), 14: (1, 0.36809698957949877), 15: (1, 0.3683355990797281), 16: (1, 0.3679883386939764), 17: (1, 0.367777849547565), 18: (1, 0.3685601782053709), 19: (1, 0.36849122773855925), 20: (1, 0.36886204686015844), 21: (1, 0.36799096036702394), 22: (1, 0.36803963873535395), 23: (1, 0.3689069068059325), 24: (1, 0.36804815009236336), 25: (1, 0.36811854131519794), 26: (1, 0.36838187742978334), 27: (1, 0.3682820191606879), 28: (1, 0.3682577293366194), 29: (1, 0.36846301797777414), 30: (1, 0.3681669197976589), 31: (1, 0.3687742678448558), 32: (1, 0.36826434917747974), 33: (1, 0.3679485386237502), 34: (1, 0.3684234665706754), 35: (1, 0.36827467754483223), 36: (1, 0.36793321929872036), 37: (1, 0.36810921784490347), 38: (1, 0.3683598982170224), 39: (1, 0.36809426732361317), 40: (1, 0.368565377779305), 41: (1, 0.3682611882686615), 42: (1, 0.3682518983259797), 43: (1, 0.36842360720038414), 44: (1, 0.36862447671592236), 45: (1, 0.3684172770008445), 46: (1, 0.3681054785847664), 47: (1, 0.3677869886159897), 48: (1, 0.36844646744430065), 49: (1, 0.3680051490664482), 50: (1, 0.3686508070677519), 51: (1, 0.3682898283004761), 52: (1, 0.36847587767988443), 53: (1, 0.36809801775962114), 54: (1, 0.3678825590759516), 55: (1, 0.3684261180460453), 56: (1, 0.36836649756878614), 57: (1, 0.3679573191329837), 58: (1, 0.36808909848332405), 59: (1, 0.36797582916915417), 60: (1, 0.3681007884442806), 61: (1, 0.36839927174150944), 62: (1, 0.36880586948245764), 63: (1, 0.36981901712715626), 64: (1, 0.3675835132598877), 65: (1, 0.368073851801455), 66: (1, 0.36786681320518255), 67: (1, 0.36788441240787506), 68: (1, 0.3680567014962435), 69: (1, 0.3674170542508364), 70: (1, 0.36824759282171726), 71: (1, 0.36720689479261637)}\n",
      "{1: (1, 31, 0.13778316328722623), 2: (1, 31, 0.13766786329928907), 3: (1, 31, 0.1376944482026081), 4: (1, 31, 0.13766097385556467), 5: (1, 31, 0.13748547122363122), 6: (1, 31, 0.1374103908216761), 7: (1, 31, 0.13758745116572227), 8: (1, 31, 0.13776481935694332), 9: (1, 31, 0.13758633138551826), 10: (1, 31, 0.1377656369980785), 11: (1, 31, 0.13792825105690187), 12: (1, 31, 0.13769260905082187), 13: (1, 31, 0.1376566965012781), 14: (1, 31, 0.1375417248496125), 15: (1, 31, 0.13761956476035617), 16: (1, 31, 0.13739113975316286), 17: (1, 31, 0.13769812942031892), 18: (1, 31, 0.13771868283830344), 19: (1, 31, 0.13744803596167796), 20: (1, 31, 0.13747336249798536), 21: (1, 31, 0.13725985550592024), 22: (1, 31, 0.1375424136077204), 23: (1, 31, 0.13722258196362563), 24: (1, 31, 0.1374762321131364), 25: (1, 31, 0.13765690851235582), 26: (1, 31, 0.1372169824016671), 27: (1, 31, 0.1375069449986181), 28: (1, 31, 0.1377067736860725), 29: (1, 31, 0.1380150128576544), 30: (1, 31, 0.13759509921674767), 31: (1, 31, 0.13765563575490827), 32: (1, 31, 0.13757410765655578), 33: (1, 31, 0.13763706593383704), 34: (1, 31, 0.13762285986975317), 35: (1, 31, 0.13955123959890298), 36: (1, 31, 0.14041083447274663), 37: (1, 31, 0.14122829598284536), 38: (1, 31, 0.13756773608826822), 39: (1, 31, 0.13746367692346534), 40: (1, 31, 0.13749168170315604), 41: (1, 31, 0.1375064019474291), 42: (1, 31, 0.1375589348495968), 43: (1, 31, 0.1375936001479145), 44: (1, 31, 0.13761960033087), 45: (1, 31, 0.13752815623076692), 46: (1, 31, 0.1371874212317409), 47: (1, 31, 0.13757636917815094), 48: (1, 31, 0.13770012662655884), 49: (1, 31, 0.13739736074762), 50: (1, 31, 0.13759222070896818), 51: (1, 31, 0.13757738477039722), 52: (1, 31, 0.13755481290600954), 53: (1, 31, 0.13758094293335754), 54: (1, 31, 0.13773896581222933), 55: (1, 31, 0.13761091538734974), 56: (1, 31, 0.13770522711978805), 57: (1, 31, 0.13764114587778045), 58: (1, 31, 0.13740207221839698), 59: (1, 31, 0.1381299153511082), 60: (1, 31, 0.14402491557261637), 61: (1, 31, 0.14148593633886306), 62: (1, 31, 0.1406656646980874), 63: (1, 31, 0.14456548932338914), 64: (1, 31, 0.13753402689772268), 65: (1, 31, 0.13739625094158034), 66: (1, 31, 0.13758289868072157), 67: (1, 31, 0.1399370618464966), 68: (1, 31, 0.1395422929837819), 69: (1, 31, 0.14523537643253803), 70: (1, 31, 0.14342440571635962)}\n",
      "{'predict_runtime': 330.7903, 'predict_samples_per_second': 0.215, 'predict_steps_per_second': 0.215}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:30.79\n",
      "  predict_samples_per_second =      0.215\n",
      "  predict_steps_per_second   =      0.215\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.5996599039062858), 2: (2, 0.5811790572479367), 3: (2, 0.5811515785753727), 4: (2, 0.5794722633436322), 5: (2, 0.5788492048159242), 6: (2, 0.5789784947410226), 7: (2, 0.5799163114279509), 8: (2, 0.5801028115674853), 9: (2, 0.5818259362131357), 10: (2, 0.5799478013068438), 11: (2, 0.5806315038353205), 12: (2, 0.5808225441724062), 13: (2, 0.581814200617373), 14: (2, 0.5806799931451678), 15: (2, 0.5800679046660662), 16: (2, 0.5803181743249297), 17: (2, 0.5807069623842835), 18: (2, 0.5815231408923864), 19: (2, 0.581597151234746), 20: (2, 0.5806483738124371), 21: (2, 0.580376984551549), 22: (2, 0.5793551579117775), 23: (2, 0.5804408146068454), 24: (2, 0.581183422356844), 25: (2, 0.5803900454193354), 26: (2, 0.5803867839276791), 27: (2, 0.5813779318705201), 28: (2, 0.5801320727914572), 29: (2, 0.5811942284926772), 30: (2, 0.5802686717361212), 31: (2, 0.5802784003317356), 32: (2, 0.5808845702558756), 33: (2, 0.5809160182252526), 34: (2, 0.5816778978332877), 35: (2, 0.5804875306785107), 36: (2, 0.5805931314826012), 37: (2, 0.5813058987259865), 38: (2, 0.5799184227362275), 39: (2, 0.5800564819946885), 40: (2, 0.5804268913343549), 41: (2, 0.5808505099266768), 42: (2, 0.5818152073770761), 43: (2, 0.5797669626772404), 44: (2, 0.5802610320970416), 45: (2, 0.5802580555900931), 46: (2, 0.5811569429934025), 47: (2, 0.5800816165283322), 48: (2, 0.5804121550172567), 49: (2, 0.5798906860873103), 50: (2, 0.5798900369554758), 51: (2, 0.5796042867004871), 52: (2, 0.5812412928789854), 53: (2, 0.5798291368409991), 54: (2, 0.5800654562190175), 55: (2, 0.5808701338246465), 56: (2, 0.5808758037164807), 57: (2, 0.5802485756576061), 58: (2, 0.5805107653141022), 59: (2, 0.5803614649921656), 60: (2, 0.5805598143488169), 61: (2, 0.5804137345403433), 62: (2, 0.5802139872685075), 63: (2, 0.5805028257891536), 64: (2, 0.5800461675971746), 65: (2, 0.5793138081207871), 66: (2, 0.5796983074396849), 67: (2, 0.5819014105945826), 68: (2, 0.5800932664424181), 69: (2, 0.5816525723785162), 70: (2, 0.579223888926208), 71: (1, 0.36715370137244463)}\n",
      "{1: (2, 31, 0.23651395449715276), 2: (2, 31, 0.23608408829257374), 3: (2, 31, 0.22887833374402217), 4: (2, 31, 0.22897709221128495), 5: (2, 31, 0.22937413503325754), 6: (2, 31, 0.22918542777939188), 7: (2, 31, 0.229804391492038), 8: (2, 31, 0.22904278893744753), 9: (2, 31, 0.22880561682846276), 10: (2, 31, 0.2291185413337042), 11: (2, 31, 0.22869395921307226), 12: (2, 31, 0.22896602668709332), 13: (2, 31, 0.23038003812994687), 14: (2, 31, 0.228912265971303), 15: (2, 31, 0.22932841502610715), 16: (2, 31, 0.23136690207907268), 17: (2, 31, 0.22954595049903279), 18: (2, 31, 0.22897393538826896), 19: (2, 31, 0.2289434620629876), 20: (2, 31, 0.2289321839869503), 21: (2, 31, 0.22883181814705172), 22: (2, 31, 0.22877791169429978), 23: (2, 31, 0.2289154496524603), 24: (2, 31, 0.228832557076408), 25: (2, 31, 0.22958713340302628), 26: (2, 31, 0.23088912542669043), 27: (2, 31, 0.235483484012225), 28: (2, 31, 0.23299287376745093), 29: (2, 31, 0.2344048684462905), 30: (2, 31, 0.2304597265357452), 31: (2, 31, 0.2356078252196312), 32: (2, 31, 0.23378202721716895), 33: (2, 31, 0.233410888712012), 34: (2, 31, 0.2346987467739851), 35: (2, 31, 0.23368774336432258), 36: (2, 31, 0.23459880354423676), 37: (2, 31, 0.2343787048913298), 38: (2, 31, 0.22939556275284098), 39: (2, 31, 0.23054572323998135), 40: (2, 31, 0.22870230921093496), 41: (2, 31, 0.22871518093011073), 42: (2, 31, 0.2286370741503854), 43: (2, 31, 0.22928893280726287), 44: (2, 31, 0.22944024322374212), 45: (2, 31, 0.22886944823567906), 46: (2, 31, 0.22879637351199503), 47: (2, 31, 0.22999306756161875), 48: (2, 31, 0.22956550544908932), 49: (2, 31, 0.22898142018745984), 50: (2, 31, 0.2290805814367148), 51: (2, 31, 0.22865578529214667), 52: (2, 31, 0.2291369610916703), 53: (2, 31, 0.22861623271338402), 54: (2, 31, 0.2290388834812949), 55: (2, 31, 0.22886289548008673), 56: (2, 31, 0.22934542578314582), 57: (2, 31, 0.2292303066520441), 58: (2, 31, 0.22930655490246513), 59: (2, 31, 0.23087286627701215), 60: (2, 31, 0.2304944170098151), 61: (2, 31, 0.230301690828656), 62: (2, 31, 0.23009267070841405), 63: (2, 31, 0.2291331915485282), 64: (2, 31, 0.22953621418245376), 65: (2, 31, 0.2294936774358634), 66: (2, 31, 0.2289593324906403), 67: (2, 31, 0.22994372498003707), 68: (2, 31, 0.2339621775993897), 69: (2, 31, 0.22995981438866547), 70: (2, 31, 0.22952001304515907)}\n",
      "{'predict_runtime': 545.3775, 'predict_samples_per_second': 0.259, 'predict_steps_per_second': 0.13}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:09:05.37\n",
      "  predict_samples_per_second =      0.259\n",
      "  predict_steps_per_second   =       0.13\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 0.99675886426121), 2: (4, 0.9752134261652827), 3: (4, 0.973984070122242), 4: (4, 0.9766279524192214), 5: (4, 0.9746818281710148), 6: (4, 0.9749543378129601), 7: (4, 0.9750739466398954), 8: (4, 0.9744156897068024), 9: (4, 0.9748884281143546), 10: (4, 0.9755342258140445), 11: (4, 0.9765941528603435), 12: (4, 0.9767459826543927), 13: (4, 0.976832932792604), 14: (4, 0.9768917923793197), 15: (4, 0.9767590221017599), 16: (4, 0.9769957214593887), 17: (4, 0.9767021620646119), 18: (4, 0.9764538230374455), 19: (4, 0.9770257119089365), 20: (4, 0.9764167340472341), 21: (4, 0.9765824330970645), 22: (4, 0.9772541960701346), 23: (4, 0.9766531884670258), 24: (4, 0.977681215852499), 25: (4, 0.9770033974200487), 26: (4, 0.9770102081820369), 27: (4, 0.9771186681464314), 28: (4, 0.9775892067700624), 29: (4, 0.9772836267948151), 30: (4, 0.9767999080941081), 31: (4, 0.9771846868097782), 32: (4, 0.9773846762254834), 33: (4, 0.9763461090624332), 34: (4, 0.9770416971296072), 35: (4, 0.9767049383372068), 36: (4, 0.9764890391379595), 37: (4, 0.9770787209272385), 38: (4, 0.9768107021227479), 39: (4, 0.9766722917556763), 40: (4, 0.9762542434036732), 41: (4, 0.9766111727803946), 42: (4, 0.9767706021666527), 43: (4, 0.9769386705011129), 44: (4, 0.9767177533358335), 45: (4, 0.9768743319436908), 46: (4, 0.9767149435356259), 47: (4, 0.9766474319621921), 48: (4, 0.976696303114295), 49: (4, 0.9769301125779748), 50: (4, 0.9762366637587547), 51: (4, 0.9765239330008626), 52: (4, 0.9769355114549398), 53: (4, 0.9763119202107191), 54: (4, 0.9767286498099566), 55: (4, 0.9769323784857988), 56: (4, 0.977302928455174), 57: (4, 0.9767261501401663), 58: (4, 0.976872400380671), 59: (4, 0.9771308787167072), 60: (4, 0.9770784182474017), 61: (4, 0.9770553791895509), 62: (4, 0.9764419002458453), 63: (4, 0.976574051193893), 64: (4, 0.9767917301505804), 65: (4, 0.9768546195700765), 66: (4, 0.9770638989284635), 67: (4, 0.9772655293345451), 68: (4, 0.9768740497529507), 69: (4, 0.977426097728312), 70: (4, 0.9754432132467628), 71: (1, 0.367831957526505)}\n",
      "{1: (4, 31, 0.2381438664611309), 2: (4, 31, 0.23896805085842648), 3: (4, 31, 0.2376557772738799), 4: (4, 31, 0.24386963767990952), 5: (4, 31, 0.24409967096101853), 6: (4, 31, 0.23919001290754927), 7: (4, 31, 0.23833657230340666), 8: (4, 31, 0.23750760670631163), 9: (4, 31, 0.2374337816370591), 10: (4, 31, 0.23718994318117056), 11: (4, 31, 0.23914613739977922), 12: (4, 31, 0.23762308118203956), 13: (4, 31, 0.2380993072424204), 14: (4, 31, 0.23783011419037658), 15: (4, 31, 0.237566176171024), 16: (4, 31, 0.23930069089176192), 17: (4, 31, 0.23800061949558796), 18: (4, 31, 0.2392077711561034), 19: (4, 31, 0.23844190738013676), 20: (4, 31, 0.2370876942070261), 21: (4, 31, 0.23811282689172414), 22: (4, 31, 0.2379244365579178), 23: (4, 31, 0.239606031216681), 24: (4, 31, 0.23741847483982), 25: (4, 31, 0.23950557092264776), 26: (4, 31, 0.24325481585917935), 27: (4, 31, 0.24185814062554029), 28: (4, 31, 0.23816762993773144), 29: (4, 31, 0.23732752839644108), 30: (4, 31, 0.23902243682213367), 31: (4, 31, 0.24116253864861303), 32: (4, 31, 0.241313831940774), 33: (4, 31, 0.23710985628948097), 34: (4, 31, 0.23826081437929983), 35: (4, 31, 0.2372478704839464), 36: (4, 31, 0.23836610610446624), 37: (4, 31, 0.23788958421397594), 38: (4, 31, 0.23861545273253032), 39: (4, 31, 0.2379845068639805), 40: (4, 31, 0.2371655911387455), 41: (4, 31, 0.2373314015266876), 42: (4, 31, 0.2375015535301739), 43: (4, 31, 0.2384891579107892), 44: (4, 31, 0.23728591627291135), 45: (4, 31, 0.23798137918234832), 46: (4, 31, 0.237015227576898), 47: (4, 31, 0.23901363414141438), 48: (4, 31, 0.23795711234091751), 49: (4, 31, 0.23747265978806442), 50: (4, 31, 0.2395061846942671), 51: (4, 31, 0.23746780762749334), 52: (4, 31, 0.23754377735237922), 53: (4, 31, 0.24244806783333903), 54: (4, 31, 0.2406669620785021), 55: (4, 31, 0.24356687270225055), 56: (4, 31, 0.23922843990787382), 57: (4, 31, 0.24015500366447434), 58: (4, 31, 0.23995629493747989), 59: (4, 31, 0.24029865524461191), 60: (4, 31, 0.23794152353319428), 61: (4, 31, 0.23786945803271187), 62: (4, 31, 0.2389097162372162), 63: (4, 31, 0.24022200322079082), 64: (4, 31, 0.24022635216674498), 65: (4, 31, 0.2394843629351066), 66: (4, 31, 0.24077004455630818), 67: (4, 31, 0.24078299952370505), 68: (4, 31, 0.23863428551703691), 69: (4, 31, 0.240693018771708), 70: (4, 31, 0.24116602185512742)}\n",
      "{'predict_runtime': 591.8811, 'predict_samples_per_second': 0.475, 'predict_steps_per_second': 0.12}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:09:51.88\n",
      "  predict_samples_per_second =      0.475\n",
      "  predict_steps_per_second   =       0.12\n",
      "Evaluating with num_layers: 32\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 0.40125147346407175), 2: (1, 0.3812619736418128), 3: (1, 0.38040116522461176), 4: (1, 0.3803508058190346), 5: (1, 0.3798735374584794), 6: (1, 0.38022057618945837), 7: (1, 0.380195795558393), 8: (1, 0.3801930360496044), 9: (1, 0.37962453812360764), 10: (1, 0.38126498460769653), 11: (1, 0.38023470621556044), 12: (1, 0.3801853861659765), 13: (1, 0.38014693558216095), 14: (1, 0.38082268461585045), 15: (1, 0.3804576760157943), 16: (1, 0.3803910156711936), 17: (1, 0.38012788631021976), 18: (1, 0.3800801169127226), 19: (1, 0.38005672581493855), 20: (1, 0.3807776318863034), 21: (1, 0.3796946741640568), 22: (1, 0.379853623919189), 23: (1, 0.3800199432298541), 24: (1, 0.38092026114463806), 25: (1, 0.3796419743448496), 26: (1, 0.38048364222049713), 27: (1, 0.37978786416351795), 28: (1, 0.3801573533564806), 29: (1, 0.3799483338370919), 30: (1, 0.38007729314267635), 31: (1, 0.3807773608714342), 32: (1, 0.38014907389879227), 33: (1, 0.37987974379211664), 34: (1, 0.3801329731941223), 35: (1, 0.380113142542541), 36: (1, 0.3798726024106145), 37: (1, 0.38008417282253504), 38: (1, 0.3802645830437541), 39: (1, 0.3800786128267646), 40: (1, 0.3801724826917052), 41: (1, 0.38185046799480915), 42: (1, 0.37985623348504305), 43: (1, 0.3801788426935673), 44: (1, 0.37986028380692005), 45: (1, 0.3798757139593363), 46: (1, 0.3800456514582038), 47: (1, 0.38102114014327526), 48: (1, 0.38001035153865814), 49: (1, 0.37975496239960194), 50: (1, 0.3805577903985977), 51: (1, 0.37993863224983215), 52: (1, 0.3799391919746995), 53: (1, 0.3803029106929898), 54: (1, 0.3801684007048607), 55: (1, 0.37909467332065105), 56: (1, 0.3790365541353822), 57: (1, 0.378884295001626), 58: (1, 0.37899628560990095), 59: (1, 0.37912729382514954), 60: (1, 0.3794120140373707), 61: (1, 0.3786055352538824), 62: (1, 0.3793375240638852), 63: (1, 0.3788998145610094), 64: (1, 0.3793982146307826), 65: (1, 0.37926646415144205), 66: (1, 0.3791686538606882), 67: (1, 0.37890963442623615), 68: (1, 0.37912862468510866), 69: (1, 0.3789626145735383), 70: (1, 0.3789542047306895), 71: (1, 0.3782072365283966)}\n",
      "{1: (1, 31, 0.14825517422850093), 2: (1, 31, 0.14508977286036936), 3: (1, 31, 0.1443728397209798), 4: (1, 31, 0.14337182729955641), 5: (1, 31, 0.14549313650857057), 6: (1, 31, 0.14380812572856103), 7: (1, 31, 0.1484480071812868), 8: (1, 31, 0.14815106792675872), 9: (1, 31, 0.14459253784509435), 10: (1, 31, 0.14452456400519417), 11: (1, 31, 0.14558004723080703), 12: (1, 31, 0.1469314151533669), 13: (1, 31, 0.14458047820916098), 14: (1, 31, 0.14359807036817074), 15: (1, 31, 0.14431442569700942), 16: (1, 31, 0.14301247438115458), 17: (1, 31, 0.14722069557155332), 18: (1, 31, 0.14427878990048362), 19: (1, 31, 0.1440893527901461), 20: (1, 31, 0.14518766150239013), 21: (1, 31, 0.14652535295294178), 22: (1, 31, 0.14382199636630474), 23: (1, 31, 0.1444510844866595), 24: (1, 31, 0.14563052869972684), 25: (1, 31, 0.14475490333091828), 26: (1, 31, 0.14672444760799408), 27: (1, 31, 0.1451096694255548), 28: (1, 31, 0.1479128034665219), 29: (1, 31, 0.14338668141393893), 30: (1, 31, 0.14944050980791931), 31: (1, 31, 0.1462145385542704), 32: (1, 31, 0.14716667588800192), 33: (1, 31, 0.14814100687902781), 34: (1, 31, 0.1470222702670482), 35: (1, 31, 0.14977953564976493), 36: (1, 31, 0.14622580836857518), 37: (1, 31, 0.14832932246668684), 38: (1, 31, 0.14536143632064905), 39: (1, 31, 0.14823098027057224), 40: (1, 31, 0.1482158296651417), 41: (1, 31, 0.14629765927431085), 42: (1, 31, 0.14977989435916947), 43: (1, 31, 0.14594527093633528), 44: (1, 31, 0.1462469042669381), 45: (1, 31, 0.14455031843916064), 46: (1, 31, 0.14549773922490497), 47: (1, 31, 0.1481059460089572), 48: (1, 31, 0.14525251279795362), 49: (1, 31, 0.14266258997902756), 50: (1, 31, 0.14308101404458284), 51: (1, 31, 0.14739192048868827), 52: (1, 31, 0.1483640048592802), 53: (1, 31, 0.14618798985236114), 54: (1, 31, 0.14303224224356875), 55: (1, 31, 0.1413541591515945), 56: (1, 31, 0.14146770771232345), 57: (1, 31, 0.14132804931291648), 58: (1, 31, 0.14122943048395456), 59: (1, 31, 0.14101236253496138), 60: (1, 31, 0.14131050130292291), 61: (1, 31, 0.1411307938096504), 62: (1, 31, 0.14103294689688953), 63: (1, 31, 0.14108023528129823), 64: (1, 31, 0.1413273125165893), 65: (1, 31, 0.1412045090729671), 66: (1, 31, 0.14141092867019675), 67: (1, 31, 0.14131251344036672), 68: (1, 31, 0.1412219140798815), 69: (1, 31, 0.14143220034818496), 70: (1, 31, 0.14131433937338092)}\n",
      "{'predict_runtime': 345.8673, 'predict_samples_per_second': 0.205, 'predict_steps_per_second': 0.205}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:05:45.86\n",
      "  predict_samples_per_second =      0.205\n",
      "  predict_steps_per_second   =      0.205\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (2, 0.6188558172434568), 2: (2, 0.5974686425179243), 3: (2, 0.5966535061597824), 4: (2, 0.5950609501451254), 5: (2, 0.5968484356999397), 6: (2, 0.59613027703017), 7: (2, 0.5960262268781662), 8: (2, 0.5955394888296723), 9: (2, 0.5955837778747082), 10: (2, 0.5964759457856417), 11: (2, 0.5964269461110234), 12: (2, 0.5961735565215349), 13: (2, 0.596158217638731), 14: (2, 0.5965920751914382), 15: (2, 0.5960332565009594), 16: (2, 0.5968562746420503), 17: (2, 0.596421635709703), 18: (2, 0.5961192697286606), 19: (2, 0.5959740309044719), 20: (2, 0.5962624093517661), 21: (2, 0.5963249392807484), 22: (2, 0.5967129375785589), 23: (2, 0.5960973193868995), 24: (2, 0.596634947694838), 25: (2, 0.5965418079867959), 26: (2, 0.5970078380778432), 27: (2, 0.5959938308224082), 28: (2, 0.596183049492538), 29: (2, 0.5967862578108907), 30: (2, 0.5961213689297438), 31: (2, 0.5957877216860652), 32: (2, 0.5965799074620008), 33: (2, 0.597029966302216), 34: (2, 0.5957999508827925), 35: (2, 0.5956223113462329), 36: (2, 0.5967338979244232), 37: (2, 0.5964960381388664), 38: (2, 0.5962274186313152), 39: (2, 0.5956826694309711), 40: (2, 0.5955534912645817), 41: (2, 0.596178749576211), 42: (2, 0.5958501799032092), 43: (2, 0.596053859218955), 44: (2, 0.5965735586360097), 45: (2, 0.5960141001269221), 46: (2, 0.5963537888601422), 47: (2, 0.5962846195325255), 48: (2, 0.596000149846077), 49: (2, 0.59670015797019), 50: (2, 0.5958436420187354), 51: (2, 0.5967967510223389), 52: (2, 0.5956867728382349), 53: (2, 0.5961461924016476), 54: (2, 0.595958792604506), 55: (2, 0.5962309623137116), 56: (2, 0.5966487508267164), 57: (2, 0.5957377040758729), 58: (2, 0.5955647537484765), 59: (2, 0.5960071124136448), 60: (2, 0.5964300511404872), 61: (2, 0.5967366704717278), 62: (2, 0.59704305883497), 63: (2, 0.5966747412458062), 64: (2, 0.5963628618046641), 65: (2, 0.596599631011486), 66: (2, 0.5959498323500156), 67: (2, 0.5967151643708348), 68: (2, 0.5961833456531167), 69: (2, 0.5976647706702352), 70: (2, 0.5951362876221538), 71: (1, 0.3788917129859328)}\n",
      "{1: (2, 31, 0.2391231473114702), 2: (2, 31, 0.23765007205187313), 3: (2, 31, 0.2372717118311313), 4: (2, 31, 0.2377861466919703), 5: (2, 31, 0.23894565852899705), 6: (2, 31, 0.23855700403932603), 7: (2, 31, 0.23726282827556133), 8: (2, 31, 0.2370763762643741), 9: (2, 31, 0.23769803363228997), 10: (2, 31, 0.23854251764714718), 11: (2, 31, 0.2389581012389352), 12: (2, 31, 0.23788499291385373), 13: (2, 31, 0.23934656189334008), 14: (2, 31, 0.23778558813876682), 15: (2, 31, 0.23910197849956252), 16: (2, 31, 0.23753360334423282), 17: (2, 31, 0.23824329244633835), 18: (2, 31, 0.23765601256802196), 19: (2, 31, 0.23942937467607758), 20: (2, 31, 0.23905000291884906), 21: (2, 31, 0.2370669450610876), 22: (2, 31, 0.23676593983245472), 23: (2, 31, 0.2366997076258544), 24: (2, 31, 0.2367290259008446), 25: (2, 31, 0.23686870647173736), 26: (2, 31, 0.23669833167185705), 27: (2, 31, 0.23682279602414177), 28: (2, 31, 0.23663132814990898), 29: (2, 31, 0.23671359583855636), 30: (2, 31, 0.23691748812674515), 31: (2, 31, 0.23736508785476607), 32: (2, 31, 0.2367082533516711), 33: (2, 31, 0.23684667543538154), 34: (2, 31, 0.23646330668200408), 35: (2, 31, 0.23713798373336753), 36: (2, 31, 0.23683671121515573), 37: (2, 31, 0.23662355599263984), 38: (2, 31, 0.23659199992975882), 39: (2, 31, 0.23664698833900114), 40: (2, 31, 0.23662652880434068), 41: (2, 31, 0.2369088003592145), 42: (2, 31, 0.23805237399233925), 43: (2, 31, 0.23748721825259347), 44: (2, 31, 0.23667179808140762), 45: (2, 31, 0.23683959038387384), 46: (2, 31, 0.23684412886899325), 47: (2, 31, 0.23694205323174114), 48: (2, 31, 0.23692804049219815), 49: (2, 31, 0.23672599748017326), 50: (2, 31, 0.23668966706722014), 51: (2, 31, 0.23682050587188813), 52: (2, 31, 0.23745300620794296), 53: (2, 31, 0.23683738780598487), 54: (2, 31, 0.2369299004635503), 55: (2, 31, 0.2367196974134253), 56: (2, 31, 0.23680649917092053), 57: (2, 31, 0.2364564759116019), 58: (2, 31, 0.23661264038134006), 59: (2, 31, 0.23621317026235403), 60: (2, 31, 0.23668736288504255), 61: (2, 31, 0.23671014069188986), 62: (2, 31, 0.2365939655611592), 63: (2, 31, 0.2401324858768813), 64: (2, 31, 0.23717746261747613), 65: (2, 31, 0.23723015823071042), 66: (2, 31, 0.23720413909083413), 67: (2, 31, 0.23661437675717376), 68: (2, 31, 0.23641811566607607), 69: (2, 31, 0.24361954878775344), 70: (2, 31, 0.23985620239569294)}\n",
      "{'predict_runtime': 562.0268, 'predict_samples_per_second': 0.251, 'predict_steps_per_second': 0.126}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:09:22.02\n",
      "  predict_samples_per_second =      0.251\n",
      "  predict_steps_per_second   =      0.126\n",
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (4, 1.0256664454936981), 2: (4, 1.0047647841274738), 3: (4, 1.006563389673829), 4: (4, 1.0057952012866735), 5: (4, 1.0060192300006747), 6: (4, 1.0059685604646802), 7: (4, 1.0066113788634539), 8: (4, 1.0075784660875797), 9: (4, 1.0063643101602793), 10: (4, 1.0065463203936815), 11: (4, 1.0087432879954576), 12: (4, 1.0081871999427676), 13: (4, 1.009379635564983), 14: (4, 1.0111064007505774), 15: (4, 1.0091453567147255), 16: (4, 1.0090582873672247), 17: (4, 1.0095064053311944), 18: (4, 1.0082912994548678), 19: (4, 1.0094763459637761), 20: (4, 1.008516508154571), 21: (4, 1.008849618025124), 22: (4, 1.0082094594836235), 23: (4, 1.0084519693627954), 24: (4, 1.0081815514713526), 25: (4, 1.0085828676819801), 26: (4, 1.0084751984104514), 27: (4, 1.0076411599293351), 28: (4, 1.008320857770741), 29: (4, 1.009606333449483), 30: (4, 1.0088317655026913), 31: (4, 1.0090158265084028), 32: (4, 1.0078699104487896), 33: (4, 1.0093762846663594), 34: (4, 1.00908147636801), 35: (4, 1.0082770185545087), 36: (4, 1.0078332386910915), 37: (4, 1.0080501288175583), 38: (4, 1.0081020686775446), 39: (4, 1.008035629056394), 40: (4, 1.0074143009260297), 41: (4, 1.0079117976129055), 42: (4, 1.0077823381870985), 43: (4, 1.0086306147277355), 44: (4, 1.0081595461815596), 45: (4, 1.008453975431621), 46: (4, 1.008385056629777), 47: (4, 1.0084145665168762), 48: (4, 1.0078279273584485), 49: (4, 1.0079870074987411), 50: (4, 1.0075867483392358), 51: (4, 1.0080518871545792), 52: (4, 1.008619044907391), 53: (4, 1.0085846856236458), 54: (4, 1.0084459660574794), 55: (4, 1.0083118556067348), 56: (4, 1.0083595709875226), 57: (4, 1.0080334013327956), 58: (4, 1.0082261208444834), 59: (4, 1.0082136504352093), 60: (4, 1.0083593698218465), 61: (4, 1.0082196611911058), 62: (4, 1.0079103615134954), 63: (4, 1.008491249755025), 64: (4, 1.008111692033708), 65: (4, 1.008783639408648), 66: (4, 1.0086872400715947), 67: (4, 1.0089474394917488), 68: (4, 1.0077859833836555), 69: (4, 1.0084950597956777), 70: (4, 1.0062050875276327), 71: (1, 0.3798986133188009)}\n",
      "{1: (4, 31, 0.24933016828952298), 2: (4, 31, 0.24682246716392617), 3: (4, 31, 0.2444284130188246), 4: (4, 31, 0.2455596827992028), 5: (4, 31, 0.24837532627486414), 6: (4, 31, 0.24635401103765733), 7: (4, 31, 0.24560725394516222), 8: (4, 31, 0.24536705410648738), 9: (4, 31, 0.2495594551306098), 10: (4, 31, 0.24549608115827845), 11: (4, 31, 0.2454730193581312), 12: (4, 31, 0.24543819765770628), 13: (4, 31, 0.24945681169629097), 14: (4, 31, 0.24547126844164827), 15: (4, 31, 0.25121394779172634), 16: (4, 31, 0.25239118759430224), 17: (4, 31, 0.24549749033946183), 18: (4, 31, 0.24536844036511837), 19: (4, 31, 0.2486002399856525), 20: (4, 31, 0.2497232280250999), 21: (4, 31, 0.2460138850635098), 22: (4, 31, 0.250391335707278), 23: (4, 31, 0.24529492314304074), 24: (4, 31, 0.2457321739845699), 25: (4, 31, 0.25180863964581685), 26: (4, 31, 0.24877642786070223), 27: (4, 31, 0.2454275486149615), 28: (4, 31, 0.24527103673186032), 29: (4, 31, 0.24541800814650713), 30: (4, 31, 0.24523785355831346), 31: (4, 31, 0.2483199771433588), 32: (4, 31, 0.2483964673874359), 33: (4, 31, 0.2519672978068552), 34: (4, 31, 0.24536265126399456), 35: (4, 31, 0.24974938791485563), 36: (4, 31, 0.24526577502969774), 37: (4, 31, 0.24533271059514053), 38: (4, 31, 0.248286145859428), 39: (4, 31, 0.24574839978689147), 40: (4, 31, 0.24589865375310183), 41: (4, 31, 0.24603125284756383), 42: (4, 31, 0.24597138067286822), 43: (4, 31, 0.24584797962057975), 44: (4, 31, 0.24542084642715992), 45: (4, 31, 0.24563830613248772), 46: (4, 31, 0.24538902896306208), 47: (4, 31, 0.2513836995668469), 48: (4, 31, 0.24966939565755666), 49: (4, 31, 0.25000336354658487), 50: (4, 31, 0.24963563272068579), 51: (4, 31, 0.2454848136572588), 52: (4, 31, 0.2457466143814306), 53: (4, 31, 0.24584904201929608), 54: (4, 31, 0.24812395783561852), 55: (4, 31, 0.24645022786552867), 56: (4, 31, 0.25035492775420987), 57: (4, 31, 0.24811266221466563), 58: (4, 31, 0.24518228670762432), 59: (4, 31, 0.24622237228698307), 60: (4, 31, 0.24854943543792732), 61: (4, 31, 0.2470114105230858), 62: (4, 31, 0.24613144894641253), 63: (4, 31, 0.24698293329246582), 64: (4, 31, 0.25263992826183956), 65: (4, 31, 0.25272990627995423), 66: (4, 31, 0.2525032418930242), 67: (4, 31, 0.25290782653516336), 68: (4, 31, 0.25196808846967833), 69: (4, 31, 0.250704514673881), 70: (4, 31, 0.2526608881871066)}\n",
      "{'predict_runtime': 613.3831, 'predict_samples_per_second': 0.458, 'predict_steps_per_second': 0.116}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:10:13.38\n",
      "  predict_samples_per_second =      0.458\n",
      "  predict_steps_per_second   =      0.116\n"
     ]
    }
   ],
   "source": [
    "eval_num_layers = range(16, 33)\n",
    "for num_layers in eval_num_layers:\n",
    "    print(f\"Evaluating with num_layers: {num_layers}\")\n",
    "\n",
    "    args.eval_num_layer = num_layers\n",
    "    key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt32'\n",
    "\n",
    "    results[key] = []\n",
    "    ttfts = []\n",
    "    tbts = []\n",
    "    for bs in [1, 2, 4]:\n",
    "        training_args.per_device_eval_batch_size = bs\n",
    "        args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "        data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,\n",
    "            **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "        )\n",
    "        ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "        ttfts.append(ttft)\n",
    "        tbts.append(tbt)\n",
    "        results[key].append(get_latency_stats(ttft, tbt, bs))\n",
    "    \n",
    "    with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "        json.dump(results, fout)\n",
    "    with open(f'latencies_{key}.json', 'w') as fout:\n",
    "        json.dump({'ttft': ttfts, 'tbt': tbts}, fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedf325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoeballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
