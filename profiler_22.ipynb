{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables before using the transformers library\n",
    "os.environ[\"HF_HOME\"] = \"/serenity/scratch/hkolisetty6/.cache/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"./transformers/src\")\n",
    "sys.path.insert(0, \"./peft/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiler import (\n",
    "    parse_args,\n",
    "    get_last_checkpoint,\n",
    "    load_model,\n",
    "    set_width_mask_and_bias,\n",
    "    make_data_module,\n",
    "    Seq2SeqTrainer,\n",
    "    profile_latencies,\n",
    "    get_latency_stats,\n",
    "    logging,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 64\n",
    "- Depths: 22, 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"64\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.3624214846640825), 2: (1, 0.19314152281731367), 3: (1, 0.19825988914817572), 4: (1, 0.19835578836500645), 5: (1, 0.18905852362513542), 6: (1, 0.19363172724843025), 7: (1, 0.18832881934940815), 8: (1, 0.19448340591043234), 9: (1, 0.18916048761457205), 10: (1, 0.1977219171822071), 11: (1, 0.19581038784235716), 12: (1, 0.1935673337429762), 13: (1, 0.19293517153710127), 14: (1, 0.19026360474526882), 15: (1, 0.188787710852921), 16: (1, 0.19024965353310108), 17: (1, 0.188099498860538), 18: (1, 0.18687761295586824), 19: (1, 0.19000643584877253), 20: (1, 0.1895083412528038), 21: (1, 0.18843580223619938), 22: (1, 0.18915826547890902), 23: (1, 0.18710357788950205), 24: (1, 0.19873379077762365), 25: (1, 0.19130859803408384), 26: (1, 0.19178853183984756), 27: (1, 0.1886417092755437), 28: (1, 0.18887985590845346), 29: (1, 0.19039790891110897), 30: (1, 0.1871211752295494), 31: (1, 0.18728038482367992), 32: (1, 0.18686925899237394), 33: (1, 0.18830127269029617), 34: (1, 0.18852869886904955), 35: (1, 0.18862152937799692), 36: (1, 0.18767837900668383), 37: (1, 0.1883470518514514), 38: (1, 0.1902389982715249), 39: (1, 0.18946830742061138), 40: (1, 0.18706186581403017), 41: (1, 0.18919072020798922), 42: (1, 0.18979491293430328), 43: (1, 0.18844451941549778), 44: (1, 0.19376754481345415), 45: (1, 0.18872030545026064), 46: (1, 0.18667861819267273), 47: (1, 0.1883208891376853), 48: (1, 0.18708808440715075), 49: (1, 0.18950525484979153), 50: (1, 0.1869224952533841), 51: (1, 0.19027719553560019), 52: (1, 0.1904788026586175), 53: (1, 0.18681949563324451), 54: (1, 0.1888883514329791), 55: (1, 0.18804560136049986), 56: (1, 0.18931376561522484), 57: (1, 0.1890737395733595), 58: (1, 0.1870241928845644), 59: (1, 0.18716832995414734), 60: (1, 0.18953304272145033), 61: (1, 0.18845088500529528), 62: (1, 0.18888472020626068), 63: (1, 0.18662405665963888), 64: (1, 0.18760359473526478), 65: (1, 0.19221662916243076), 66: (1, 0.18861158192157745), 67: (1, 0.18697390239685774), 68: (1, 0.18852878268808126), 69: (1, 0.18846309464424849), 70: (1, 0.18920169584453106), 71: (1, 0.18717176839709282)}\n",
      "{1: (1, 127, 0.11645206206250848), 2: (1, 127, 0.11794937723206253), 3: (1, 127, 0.11716135896331682), 4: (1, 127, 0.11592242917353947), 5: (1, 127, 0.11518075418343225), 6: (1, 127, 0.11548174478436314), 7: (1, 127, 0.11557856646520416), 8: (1, 127, 0.11567574768055847), 9: (1, 127, 0.11547010286351828), 10: (1, 127, 0.12281379634587783), 11: (1, 127, 0.1174975539828966), 12: (1, 127, 0.11582633141633564), 13: (1, 127, 0.11672752116638141), 14: (1, 127, 0.11542864807507419), 15: (1, 127, 0.11536174927522817), 16: (1, 127, 0.11517802609028074), 17: (1, 127, 0.11509019305093551), 18: (1, 127, 0.11506459689662447), 19: (1, 127, 0.11498578651038212), 20: (1, 127, 0.11495566602033658), 21: (1, 127, 0.11504979956689781), 22: (1, 127, 0.11485975237900582), 23: (1, 127, 0.11712100094286945), 24: (1, 127, 0.11762375934562815), 25: (1, 127, 0.11601231912312311), 26: (1, 127, 0.11533624066523915), 27: (1, 127, 0.11516635223313815), 28: (1, 127, 0.11512624121850401), 29: (1, 127, 0.11498199539684405), 30: (1, 127, 0.11514869990839263), 31: (1, 127, 0.11471184509564337), 32: (1, 127, 0.11503745331685608), 33: (1, 127, 0.11527242528377321), 34: (1, 127, 0.11476895425791346), 35: (1, 127, 0.11461468768401409), 36: (1, 127, 0.11471466653371655), 37: (1, 127, 0.1147439757538006), 38: (1, 127, 0.11473169875895883), 39: (1, 127, 0.1147208316764963), 40: (1, 127, 0.11466374261466068), 41: (1, 127, 0.1150548514932042), 42: (1, 127, 0.11472937907642267), 43: (1, 127, 0.11467338670925127), 44: (1, 127, 0.11482830396963387), 45: (1, 127, 0.1148317049836784), 46: (1, 127, 0.11470275554131334), 47: (1, 127, 0.11478758999329852), 48: (1, 127, 0.11480559297199325), 49: (1, 127, 0.11465147822567327), 50: (1, 127, 0.11467890431884471), 51: (1, 127, 0.11468100276460329), 52: (1, 127, 0.11492597030138406), 53: (1, 127, 0.11484712057226286), 54: (1, 127, 0.11484592645539074), 55: (1, 127, 0.11475855698735696), 56: (1, 127, 0.11497477738289383), 57: (1, 127, 0.11503737148513475), 58: (1, 127, 0.11490925518047856), 59: (1, 127, 0.11485773341099578), 60: (1, 127, 0.11510624074355119), 61: (1, 127, 0.11483514613259262), 62: (1, 127, 0.11501956100421627), 63: (1, 127, 0.11472001327128392), 64: (1, 127, 0.11490644025433017), 65: (1, 127, 0.11482523859837862), 66: (1, 127, 0.11488476746136278), 67: (1, 127, 0.1147380881598146), 68: (1, 127, 0.1148644997774968), 69: (1, 127, 0.11487521758435044), 70: (1, 127, 0.11493389434584482)}\n",
      "{'predict_runtime': 1053.561, 'predict_samples_per_second': 0.067, 'predict_steps_per_second': 0.067}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:17:33.56\n",
      "  predict_samples_per_second =      0.067\n",
      "  predict_steps_per_second   =      0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.2324928604066372), 2: (2, 0.20100251492112875), 3: (2, 0.2014517579227686), 4: (2, 0.21333300787955523), 5: (2, 0.21439869422465563), 6: (2, 0.19867962133139372), 7: (2, 0.1997447581961751), 8: (2, 0.20122103858739138), 9: (2, 0.20782819110900164), 10: (2, 0.2039972571656108), 11: (2, 0.21098528243601322), 12: (2, 0.20823752600699663), 13: (2, 0.19796434696763754), 14: (2, 0.2102847108617425), 15: (2, 0.19794861692935228), 16: (2, 0.21070208493620157), 17: (2, 0.20039326790720224), 18: (2, 0.21724196802824736), 19: (2, 0.19925560988485813), 20: (2, 0.19570013228803873), 21: (2, 0.20701279770582914), 22: (2, 0.2063162960112095), 23: (2, 0.20679588988423347), 24: (2, 0.20345055032521486), 25: (2, 0.19722038321197033), 26: (2, 0.20884801540523767), 27: (2, 0.19939186796545982), 28: (2, 0.1971929231658578), 29: (2, 0.20019763987511396), 30: (2, 0.19569356925785542), 31: (2, 0.2152425143867731), 32: (2, 0.21330412570387125), 33: (2, 0.19725055806338787), 34: (2, 0.19791106972843409), 35: (2, 0.19848203100264072), 36: (2, 0.214877063408494), 37: (2, 0.20907296799123287), 38: (2, 0.2070723194628954), 39: (2, 0.21369275264441967), 40: (2, 0.20855663996189833), 41: (2, 0.2107502045109868), 42: (2, 0.20313012972474098), 43: (2, 0.19368145801126957), 44: (2, 0.19953125901520252), 45: (2, 0.19875564705580473), 46: (2, 0.1956600621342659), 47: (2, 0.1986609362065792), 48: (2, 0.19896385166794062), 49: (2, 0.19701103307306767), 50: (2, 0.19839090574532747), 51: (2, 0.19759514462202787), 52: (2, 0.20039054192602634), 53: (2, 0.19942867197096348), 54: (2, 0.1994131812825799), 55: (2, 0.21332092955708504), 56: (2, 0.20208503864705563), 57: (2, 0.20625834818929434), 58: (2, 0.21549713145941496), 59: (2, 0.2003169059753418), 60: (2, 0.19786492455750704), 61: (2, 0.20079775899648666), 62: (2, 0.2146435882896185), 63: (2, 0.20021644327789545), 64: (2, 0.19919799454510212), 65: (2, 0.19660583324730396), 66: (2, 0.19664420187473297), 67: (2, 0.21854572836309671), 68: (2, 0.19680040888488293), 69: (2, 0.20101909898221493), 70: (2, 0.1925288662314415), 71: (1, 0.20640295557677746)}\n",
      "{1: (2, 127, 0.17904279875297716), 2: (2, 127, 0.17787051432597356), 3: (2, 127, 0.17732158494658593), 4: (2, 127, 0.17721773296095958), 5: (2, 127, 0.17723484496461359), 6: (2, 127, 0.1770368046603921), 7: (2, 127, 0.17708530678875803), 8: (2, 127, 0.17707674895361888), 9: (2, 127, 0.17700320811516893), 10: (2, 127, 0.1770618262620071), 11: (2, 127, 0.17707470142260545), 12: (2, 127, 0.17718313148934542), 13: (2, 127, 0.17714646361093586), 14: (2, 127, 0.17726475483642554), 15: (2, 127, 0.17713446839617228), 16: (2, 127, 0.17760996010858476), 17: (2, 127, 0.17749123548076848), 18: (2, 127, 0.17761666813175978), 19: (2, 127, 0.17768534335241778), 20: (2, 127, 0.1846984433024887), 21: (2, 127, 0.1812694037157133), 22: (2, 127, 0.18049367527499444), 23: (2, 127, 0.1779690778660258), 24: (2, 127, 0.1777358977124095), 25: (2, 127, 0.17798083602619452), 26: (2, 127, 0.17772312576728544), 27: (2, 127, 0.1777058564287823), 28: (2, 127, 0.17787049138757188), 29: (2, 127, 0.1775574006110899), 30: (2, 127, 0.177488590920652), 31: (2, 127, 0.17741601868701262), 32: (2, 127, 0.17739680758494092), 33: (2, 127, 0.17751019294043696), 34: (2, 127, 0.1774615332205582), 35: (2, 127, 0.1773323814465305), 36: (2, 127, 0.17735919026349942), 37: (2, 127, 0.17715996948224821), 38: (2, 127, 0.17722951625217134), 39: (2, 127, 0.17723124752217156), 40: (2, 127, 0.17714160787102978), 41: (2, 127, 0.17756912120302595), 42: (2, 127, 0.1776288469564023), 43: (2, 127, 0.17744440763572775), 44: (2, 127, 0.17773555035842217), 45: (2, 127, 0.17777863955198545), 46: (2, 127, 0.17765001671784741), 47: (2, 127, 0.1773956758080153), 48: (2, 127, 0.17730428989037988), 49: (2, 127, 0.17729564414425628), 50: (2, 127, 0.17737190245731374), 51: (2, 127, 0.17773543667840205), 52: (2, 127, 0.17768578889860412), 53: (2, 127, 0.17758710666258973), 54: (2, 127, 0.1772747692600714), 55: (2, 127, 0.17733835705416642), 56: (2, 127, 0.17759496122451984), 57: (2, 127, 0.17748108006808466), 58: (2, 127, 0.17736302935114995), 59: (2, 127, 0.17767752278742827), 60: (2, 127, 0.17765189142619062), 61: (2, 127, 0.1774799193981595), 62: (2, 127, 0.17743880051650165), 63: (2, 127, 0.17746884925804268), 64: (2, 127, 0.17768253979280474), 65: (2, 127, 0.1773299823449118), 66: (2, 127, 0.17720398133048626), 67: (2, 127, 0.17755061956342516), 68: (2, 127, 0.1772745148843433), 69: (2, 127, 0.1774012642714569), 70: (2, 127, 0.17741639047538435)}\n",
      "{'predict_runtime': 1608.5933, 'predict_samples_per_second': 0.088, 'predict_steps_per_second': 0.044}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:26:48.59\n",
      "  predict_samples_per_second =      0.088\n",
      "  predict_steps_per_second   =      0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.2449884358793497), 2: (4, 0.2148794550448656), 3: (4, 0.22972646169364452), 4: (4, 0.21640328504145145), 5: (4, 0.214554768987), 6: (4, 0.20815714728087187), 7: (4, 0.20828136522322893), 8: (4, 0.21002365369349718), 9: (4, 0.213896868750453), 10: (4, 0.21406079549342394), 11: (4, 0.22973379865288734), 12: (4, 0.20820379815995693), 13: (4, 0.21274828631430864), 14: (4, 0.21508123632520437), 15: (4, 0.21473828051239252), 16: (4, 0.23093048576265574), 17: (4, 0.21020441688597202), 18: (4, 0.21398725267499685), 19: (4, 0.22338657639920712), 20: (4, 0.21084802597761154), 21: (4, 0.2219360088929534), 22: (4, 0.22458542697131634), 23: (4, 0.2137383297085762), 24: (4, 0.2253625961020589), 25: (4, 0.21121873520314693), 26: (4, 0.20999357663094997), 27: (4, 0.21006478369235992), 28: (4, 0.21572390012443066), 29: (4, 0.20956162828952074), 30: (4, 0.2119635995477438), 31: (4, 0.21345203090459108), 32: (4, 0.21091141924262047), 33: (4, 0.2158368406817317), 34: (4, 0.21270487643778324), 35: (4, 0.21694508660584688), 36: (4, 0.21392782870680094), 37: (4, 0.2248474732041359), 38: (4, 0.21314419619739056), 39: (4, 0.2120213471353054), 40: (4, 0.21098598651587963), 41: (4, 0.2144795572385192), 42: (4, 0.21293089259415865), 43: (4, 0.2116117374971509), 44: (4, 0.21317609772086143), 45: (4, 0.21634451113641262), 46: (4, 0.21698008198291063), 47: (4, 0.21698612067848444), 48: (4, 0.21292605716735125), 49: (4, 0.2132942220196128), 50: (4, 0.2138897441327572), 51: (4, 0.21677439846098423), 52: (4, 0.2208376107737422), 53: (4, 0.209854937158525), 54: (4, 0.22577802278101444), 55: (4, 0.21006801165640354), 56: (4, 0.21566371712833643), 57: (4, 0.2192635340616107), 58: (4, 0.21252312045544386), 59: (4, 0.2088658520951867), 60: (4, 0.22672713547945023), 61: (4, 0.21338941808789968), 62: (4, 0.21264780592173338), 63: (4, 0.2194484369829297), 64: (4, 0.21332983579486609), 65: (4, 0.21783986315131187), 66: (4, 0.2206481797620654), 67: (4, 0.21660369634628296), 68: (4, 0.21514559164643288), 69: (4, 0.22032249998301268), 70: (4, 0.22156428452581167), 71: (1, 0.1893130373209715)}\n",
      "{1: (4, 127, 0.17921858214897904), 2: (4, 127, 0.177776200491495), 3: (4, 127, 0.1776098511805098), 4: (4, 127, 0.17756093165829895), 5: (4, 127, 0.17765923875464698), 6: (4, 127, 0.17756986420777604), 7: (4, 127, 0.17768431006102112), 8: (4, 127, 0.17790176676894268), 9: (4, 127, 0.17789237482077258), 10: (4, 127, 0.17773031957418195), 11: (4, 127, 0.17769447151630177), 12: (4, 127, 0.17747131606021266), 13: (4, 127, 0.17773146462428757), 14: (4, 127, 0.17797863428429592), 15: (4, 127, 0.1781582060585341), 16: (4, 127, 0.1776553986183419), 17: (4, 127, 0.17772142430694085), 18: (4, 127, 0.17755073527475512), 19: (4, 127, 0.17742088840409057), 20: (4, 127, 0.17756177965316952), 21: (4, 127, 0.1773840476956776), 22: (4, 127, 0.17740849894654798), 23: (4, 127, 0.17751400875968962), 24: (4, 127, 0.17740781341980058), 25: (4, 127, 0.17742552197589648), 26: (4, 127, 0.177362964048571), 27: (4, 127, 0.1773396364713865), 28: (4, 127, 0.17746306345688076), 29: (4, 127, 0.17734840726406556), 30: (4, 127, 0.17735124699126079), 31: (4, 127, 0.1774624827369226), 32: (4, 127, 0.1772945335604192), 33: (4, 127, 0.17733593777144754), 34: (4, 127, 0.17739148284711942), 35: (4, 127, 0.17743659702928985), 36: (4, 127, 0.17722000775668095), 37: (4, 127, 0.17723208934244677), 38: (4, 127, 0.17737074518268267), 39: (4, 127, 0.17737613908037192), 40: (4, 127, 0.17727916179532846), 41: (4, 127, 0.17718936144337644), 42: (4, 127, 0.1774120885570805), 43: (4, 127, 0.17732408017976078), 44: (4, 127, 0.17736727637275468), 45: (4, 127, 0.17708377364113576), 46: (4, 127, 0.17723117149838313), 47: (4, 127, 0.17731013353620692), 48: (4, 127, 0.1773002530543471), 49: (4, 127, 0.17717888811236526), 50: (4, 127, 0.1770610326065088), 51: (4, 127, 0.1771540899548357), 52: (4, 127, 0.17728988114216432), 53: (4, 127, 0.17710723656075678), 54: (4, 127, 0.177162779876449), 55: (4, 127, 0.17714765134054844), 56: (4, 127, 0.17710395550399316), 57: (4, 127, 0.1770193611645675), 58: (4, 127, 0.17718647055943884), 59: (4, 127, 0.17716866461046804), 60: (4, 127, 0.17709268516618906), 61: (4, 127, 0.1772072240783591), 62: (4, 127, 0.17746728635943076), 63: (4, 127, 0.17713964623435746), 64: (4, 127, 0.17830562617219103), 65: (4, 127, 0.17837986061862837), 66: (4, 127, 0.17798284012237636), 67: (4, 127, 0.17729369459277766), 68: (4, 127, 0.1775135051928402), 69: (4, 127, 0.17734479761176455), 70: (4, 127, 0.1773806488449414)}\n",
      "{'predict_runtime': 1607.6315, 'predict_samples_per_second': 0.175, 'predict_steps_per_second': 0.044}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:26:47.63\n",
      "  predict_samples_per_second =      0.175\n",
      "  predict_steps_per_second   =      0.044\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 22\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (1, 0.22584474366158247), 2: (1, 0.19900790508836508), 3: (1, 0.20049078669399023), 4: (1, 0.19620271679013968), 5: (1, 0.1977990372106433), 6: (1, 0.19798066560178995), 7: (1, 0.19687456730753183), 8: (1, 0.1969820847734809), 9: (1, 0.19507269747555256), 10: (1, 0.1965956473723054), 11: (1, 0.19848316628485918), 12: (1, 0.19437717366963625), 13: (1, 0.1976372255012393), 14: (1, 0.19718055985867977), 15: (1, 0.19710595905780792), 16: (1, 0.19722846802324057), 17: (1, 0.19722414761781693), 18: (1, 0.19785434007644653), 19: (1, 0.19578170403838158), 20: (1, 0.19544363766908646), 21: (1, 0.19683284033089876), 22: (1, 0.19524269923567772), 23: (1, 0.1971428170800209), 24: (1, 0.19743911270052195), 25: (1, 0.19701785501092672), 26: (1, 0.19534211326390505), 27: (1, 0.19645927008241415), 28: (1, 0.197914132848382), 29: (1, 0.19838307704776525), 30: (1, 0.19582571648061275), 31: (1, 0.19479369837790728), 32: (1, 0.19431764353066683), 33: (1, 0.194585588760674), 34: (1, 0.19458068069070578), 35: (1, 0.19610884133726358), 36: (1, 0.1944796796888113), 37: (1, 0.19490017462521791), 38: (1, 0.19567817635834217), 39: (1, 0.19563702587038279), 40: (1, 0.1960203517228365), 41: (1, 0.19851438235491514), 42: (1, 0.19699722900986671), 43: (1, 0.1965355947613716), 44: (1, 0.1961709577590227), 45: (1, 0.19584213104099035), 46: (1, 0.19710057694464922), 47: (1, 0.19593811966478825), 48: (1, 0.1977584296837449), 49: (1, 0.19755673967301846), 50: (1, 0.1987428367137909), 51: (1, 0.19417024869471788), 52: (1, 0.19410177040845156), 53: (1, 0.1949506001546979), 54: (1, 0.19413996953517199), 55: (1, 0.19455613382160664), 56: (1, 0.1942165568470955), 57: (1, 0.19758694805204868), 58: (1, 0.19764747750014067), 59: (1, 0.1958548966795206), 60: (1, 0.19370444118976593), 61: (1, 0.19594672694802284), 62: (1, 0.19596170540899038), 63: (1, 0.19455065112560987), 64: (1, 0.19502025563269854), 65: (1, 0.19724148977547884), 66: (1, 0.19818132743239403), 67: (1, 0.19734127819538116), 68: (1, 0.19449375104159117), 69: (1, 0.19493788573890924), 70: (1, 0.19586108531802893), 71: (1, 0.193064846098423)}\n",
      "{1: (1, 127, 0.12113622748329649), 2: (1, 127, 0.12038400460503937), 3: (1, 127, 0.12026840791575552), 4: (1, 127, 0.12019369925012974), 5: (1, 127, 0.12017593914862927), 6: (1, 127, 0.12016843065003475), 7: (1, 127, 0.12026969847218023), 8: (1, 127, 0.12012270332761402), 9: (1, 127, 0.12026722576674514), 10: (1, 127, 0.11990996764782141), 11: (1, 127, 0.12000116179367219), 12: (1, 127, 0.120380143400311), 13: (1, 127, 0.12054024667545098), 14: (1, 127, 0.12035791165980063), 15: (1, 127, 0.11998725426566648), 16: (1, 127, 0.12018401404534738), 17: (1, 127, 0.12007211900396844), 18: (1, 127, 0.12022439851682251), 19: (1, 127, 0.12012090243575141), 20: (1, 127, 0.1201077879765841), 21: (1, 127, 0.12018620615869056), 22: (1, 127, 0.12015765400852745), 23: (1, 127, 0.12145779010524431), 24: (1, 127, 0.12112828000910639), 25: (1, 127, 0.12104012892676855), 26: (1, 127, 0.12049776103758202), 27: (1, 127, 0.12050490360707045), 28: (1, 127, 0.12101545005186101), 29: (1, 127, 0.1202118654962717), 30: (1, 127, 0.1200689358460739), 31: (1, 127, 0.12005994103731603), 32: (1, 127, 0.12005008900112758), 33: (1, 127, 0.11988123563506942), 34: (1, 127, 0.119816712573112), 35: (1, 127, 0.11987608399858156), 36: (1, 127, 0.11980519667414465), 37: (1, 127, 0.11989441860877857), 38: (1, 127, 0.11990025159206212), 39: (1, 127, 0.11990074849298854), 40: (1, 127, 0.11990812153181457), 41: (1, 127, 0.11999987439054438), 42: (1, 127, 0.12003419193343853), 43: (1, 127, 0.1197166072175376), 44: (1, 127, 0.119810239514556), 45: (1, 127, 0.11981112278968566), 46: (1, 127, 0.11985858907468441), 47: (1, 127, 0.11979509710414907), 48: (1, 127, 0.11972089637598889), 49: (1, 127, 0.11960313496304543), 50: (1, 127, 0.1197343079270575), 51: (1, 127, 0.11994788890308518), 52: (1, 127, 0.11969857247120987), 53: (1, 127, 0.12020212278415368), 54: (1, 127, 0.11962118239589328), 55: (1, 127, 0.11979481077745674), 56: (1, 127, 0.11971861928496069), 57: (1, 127, 0.11973967878367957), 58: (1, 127, 0.11966648112659849), 59: (1, 127, 0.11976830891560851), 60: (1, 127, 0.11993681041773145), 61: (1, 127, 0.11968548119244143), 62: (1, 127, 0.11974527191106729), 63: (1, 127, 0.11979771160527947), 64: (1, 127, 0.11966686091554446), 65: (1, 127, 0.11974399135719369), 66: (1, 127, 0.11969448412643878), 67: (1, 127, 0.11988492436179025), 68: (1, 127, 0.11987055459712434), 69: (1, 127, 0.11989182733204656), 70: (1, 127, 0.11987888646554055)}\n",
      "{'predict_runtime': 1096.546, 'predict_samples_per_second': 0.065, 'predict_steps_per_second': 0.065}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:18:16.54\n",
      "  predict_samples_per_second =      0.065\n",
      "  predict_steps_per_second   =      0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([2, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (2, 0.2396997269243002), 2: (2, 0.20870848465710878), 3: (2, 0.22656673844903708), 4: (2, 0.20642163511365652), 5: (2, 0.20837686210870743), 6: (2, 0.2226713877171278), 7: (2, 0.2043374963104725), 8: (2, 0.22128443233668804), 9: (2, 0.20802297443151474), 10: (2, 0.22096605505794287), 11: (2, 0.20621398463845253), 12: (2, 0.22304400149732828), 13: (2, 0.22110294178128242), 14: (2, 0.22621510177850723), 15: (2, 0.2091153496876359), 16: (2, 0.22064359579235315), 17: (2, 0.22237659618258476), 18: (2, 0.21437388751655817), 19: (2, 0.20799638889729977), 20: (2, 0.22237745393067598), 21: (2, 0.22131777461618185), 22: (2, 0.2054856587201357), 23: (2, 0.20457290671765804), 24: (2, 0.20440854877233505), 25: (2, 0.22195439599454403), 26: (2, 0.2036610273644328), 27: (2, 0.22097501624375582), 28: (2, 0.21860314346849918), 29: (2, 0.22172559704631567), 30: (2, 0.217258607968688), 31: (2, 0.20768048893660307), 32: (2, 0.20395514089614153), 33: (2, 0.20676421839743853), 34: (2, 0.20481984037905931), 35: (2, 0.22150827664881945), 36: (2, 0.21485567279160023), 37: (2, 0.2153842356055975), 38: (2, 0.21369737666100264), 39: (2, 0.20821494981646538), 40: (2, 0.218321630731225), 41: (2, 0.21072091907262802), 42: (2, 0.21498463954776525), 43: (2, 0.2213801136240363), 44: (2, 0.21093875635415316), 45: (2, 0.21239665802568197), 46: (2, 0.20392487663775682), 47: (2, 0.20425742212682962), 48: (2, 0.2077315403148532), 49: (2, 0.2054496267810464), 50: (2, 0.20485691353678703), 51: (2, 0.20669960137456656), 52: (2, 0.2210394348949194), 53: (2, 0.20619003660976887), 54: (2, 0.22001444548368454), 55: (2, 0.22203921247273684), 56: (2, 0.20746825076639652), 57: (2, 0.20341356750577688), 58: (2, 0.20817579049617052), 59: (2, 0.2033916972577572), 60: (2, 0.21086659096181393), 61: (2, 0.22491575684398413), 62: (2, 0.20172461587935686), 63: (2, 0.2056512888520956), 64: (2, 0.20592676475644112), 65: (2, 0.2045277412980795), 66: (2, 0.220943721011281), 67: (2, 0.22233916353434324), 68: (2, 0.2036327812820673), 69: (2, 0.2230511950328946), 70: (2, 0.20075830444693565), 71: (1, 0.20195418037474155)}\n",
      "{1: (2, 127, 0.18615721584862377), 2: (2, 127, 0.18561260129405757), 3: (2, 127, 0.185097389803158), 4: (2, 127, 0.18494029313061885), 5: (2, 127, 0.18478071082412728), 6: (2, 127, 0.18493537200013482), 7: (2, 127, 0.1846946295292124), 8: (2, 127, 0.1848581122513127), 9: (2, 127, 0.1848046324384494), 10: (2, 127, 0.18487192886170206), 11: (2, 127, 0.18486978208250182), 12: (2, 127, 0.18487679126019788), 13: (2, 127, 0.18456047221167585), 14: (2, 127, 0.18470653278503832), 15: (2, 127, 0.18469980236612202), 16: (2, 127, 0.18461232036205494), 17: (2, 127, 0.18479269590434128), 18: (2, 127, 0.18489561644272776), 19: (2, 127, 0.1847144965463736), 20: (2, 127, 0.1849668878020616), 21: (2, 127, 0.1847832502181253), 22: (2, 127, 0.185008558716009), 23: (2, 127, 0.18493885904785215), 24: (2, 127, 0.18491584002443656), 25: (2, 127, 0.18528759375390574), 26: (2, 127, 0.18509547329529769), 27: (2, 127, 0.18475793926851955), 28: (2, 127, 0.18484807884921944), 29: (2, 127, 0.18464501112640844), 30: (2, 127, 0.1847978399215838), 31: (2, 127, 0.18485347598087132), 32: (2, 127, 0.18468701604049742), 33: (2, 127, 0.18474597655471384), 34: (2, 127, 0.1849164485447402), 35: (2, 127, 0.18469876951472028), 36: (2, 127, 0.18471717563142456), 37: (2, 127, 0.18487056473812719), 38: (2, 127, 0.18484535891064038), 39: (2, 127, 0.1849477729635445), 40: (2, 127, 0.185088375935287), 41: (2, 127, 0.18507373133512933), 42: (2, 127, 0.1847616912078435), 43: (2, 127, 0.18468255106007725), 44: (2, 127, 0.18477722063777954), 45: (2, 127, 0.18478067803717269), 46: (2, 127, 0.18475534900377585), 47: (2, 127, 0.18472385179163434), 48: (2, 127, 0.18470731093071577), 49: (2, 127, 0.18467570135120567), 50: (2, 127, 0.18463647477035447), 51: (2, 127, 0.18462991647744978), 52: (2, 127, 0.18473963124868203), 53: (2, 127, 0.18469292083095143), 54: (2, 127, 0.1847351026816631), 55: (2, 127, 0.1853642442564326), 56: (2, 127, 0.185203645165687), 57: (2, 127, 0.1849098288945443), 58: (2, 127, 0.18480384002227013), 59: (2, 127, 0.18472494510567095), 60: (2, 127, 0.18468214653608367), 61: (2, 127, 0.1848049569200343), 62: (2, 127, 0.18475089754586613), 63: (2, 127, 0.18471998689094865), 64: (2, 127, 0.18477888802051778), 65: (2, 127, 0.18465009793697848), 66: (2, 127, 0.18472830199555854), 67: (2, 127, 0.18486513270021188), 68: (2, 127, 0.18461998610016633), 69: (2, 127, 0.18473516651025906), 70: (2, 127, 0.18872808406906805)}\n",
      "{'predict_runtime': 1674.2158, 'predict_samples_per_second': 0.084, 'predict_steps_per_second': 0.042}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:27:54.21\n",
      "  predict_samples_per_second =      0.084\n",
      "  predict_steps_per_second   =      0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 65])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([4, 65])\n",
      "input_ids shape: torch.Size([1, 65])\n",
      "{1: (4, 0.2483546705916524), 2: (4, 0.23225792776793242), 3: (4, 0.23726431746035814), 4: (4, 0.23271912056952715), 5: (4, 0.21896167006343603), 6: (4, 0.23051047511398792), 7: (4, 0.23134327493607998), 8: (4, 0.23578408267349005), 9: (4, 0.22752890828996897), 10: (4, 0.2355501353740692), 11: (4, 0.2347338441759348), 12: (4, 0.22583670634776354), 13: (4, 0.23004816845059395), 14: (4, 0.2206153068691492), 15: (4, 0.21862445026636124), 16: (4, 0.22275738324970007), 17: (4, 0.21698657982051373), 18: (4, 0.2211410803720355), 19: (4, 0.2206379659473896), 20: (4, 0.23954272456467152), 21: (4, 0.23024349380284548), 22: (4, 0.22623144183307886), 23: (4, 0.22761269565671682), 24: (4, 0.2237422876060009), 25: (4, 0.23730363510549068), 26: (4, 0.22177932877093554), 27: (4, 0.2238212153315544), 28: (4, 0.21875515300780535), 29: (4, 0.21874135173857212), 30: (4, 0.22394684329628944), 31: (4, 0.22234116028994322), 32: (4, 0.22055746987462044), 33: (4, 0.2400190094485879), 34: (4, 0.2214662879705429), 35: (4, 0.2224847162142396), 36: (4, 0.2281208522617817), 37: (4, 0.2367333136498928), 38: (4, 0.2186315692961216), 39: (4, 0.23474209569394588), 40: (4, 0.22706125304102898), 41: (4, 0.2208373723551631), 42: (4, 0.22200791910290718), 43: (4, 0.21765493787825108), 44: (4, 0.23875442799180746), 45: (4, 0.23528288584202528), 46: (4, 0.2364797629415989), 47: (4, 0.23803599551320076), 48: (4, 0.22261095978319645), 49: (4, 0.22099278587847948), 50: (4, 0.22163138911128044), 51: (4, 0.22188399638980627), 52: (4, 0.2217443874105811), 53: (4, 0.2215961990877986), 54: (4, 0.22562854271382093), 55: (4, 0.2220176225528121), 56: (4, 0.2259544562548399), 57: (4, 0.22092849388718605), 58: (4, 0.2177981985732913), 59: (4, 0.21949571929872036), 60: (4, 0.22162652388215065), 61: (4, 0.21926403045654297), 62: (4, 0.22064839489758015), 63: (4, 0.22031972836703062), 64: (4, 0.22148058377206326), 65: (4, 0.21806476172059774), 66: (4, 0.22044590394943953), 67: (4, 0.22440426982939243), 68: (4, 0.22349258977919817), 69: (4, 0.22279503755271435), 70: (4, 0.22549195773899555), 71: (1, 0.19560961611568928)}\n",
      "{1: (4, 127, 0.1865433551679094), 2: (4, 127, 0.18564633689234106), 3: (4, 127, 0.18571956393374936), 4: (4, 127, 0.1859982548002887), 5: (4, 127, 0.18553083758126562), 6: (4, 127, 0.18546106030533868), 7: (4, 127, 0.1852698614674173), 8: (4, 127, 0.1853003767209025), 9: (4, 127, 0.18564221763792704), 10: (4, 127, 0.18559150015715303), 11: (4, 127, 0.18569868350562851), 12: (4, 127, 0.185415748169455), 13: (4, 127, 0.18566871628047912), 14: (4, 127, 0.1855382342918182), 15: (4, 127, 0.18573616012402877), 16: (4, 127, 0.18562158984022112), 17: (4, 127, 0.18560926254662707), 18: (4, 127, 0.18566502941640342), 19: (4, 127, 0.18539899146902983), 20: (4, 127, 0.18552308061020814), 21: (4, 127, 0.18541092974845114), 22: (4, 127, 0.1854234811021235), 23: (4, 127, 0.18541604522469007), 24: (4, 127, 0.18520829694594923), 25: (4, 127, 0.18524821651146167), 26: (4, 127, 0.18551843994715084), 27: (4, 127, 0.18591524469922846), 28: (4, 127, 0.18568453850503278), 29: (4, 127, 0.18522368341420345), 30: (4, 127, 0.18535952128499278), 31: (4, 127, 0.1852130337552292), 32: (4, 127, 0.18502389639616013), 33: (4, 127, 0.18497604367829215), 34: (4, 127, 0.18518137069433693), 35: (4, 127, 0.1849529685115251), 36: (4, 127, 0.18507872162548106), 37: (4, 127, 0.18547498861577097), 38: (4, 127, 0.1854118497631564), 39: (4, 127, 0.18514994482737124), 40: (4, 127, 0.18512538854238086), 41: (4, 127, 0.1850107341535448), 42: (4, 127, 0.18498658385186448), 43: (4, 127, 0.18488581451462713), 44: (4, 127, 0.1849806977538612), 45: (4, 127, 0.1849385458668034), 46: (4, 127, 0.18537321092751552), 47: (4, 127, 0.18528501498036262), 48: (4, 127, 0.18544305926262158), 49: (4, 127, 0.1851355602202101), 50: (4, 127, 0.18546948785798287), 51: (4, 127, 0.18533337089108434), 52: (4, 127, 0.18533918405993013), 53: (4, 127, 0.18522779493204017), 54: (4, 127, 0.1850556157910683), 55: (4, 127, 0.18500888705488264), 56: (4, 127, 0.1850691612619232), 57: (4, 127, 0.1850814436613692), 58: (4, 127, 0.18532465540576637), 59: (4, 127, 0.1850969969023635), 60: (4, 127, 0.18503704793223247), 61: (4, 127, 0.18498013931231236), 62: (4, 127, 0.18527931270490247), 63: (4, 127, 0.18528741997058), 64: (4, 127, 0.18547455606410118), 65: (4, 127, 0.18523269885138968), 66: (4, 127, 0.18509316235399387), 67: (4, 127, 0.18543384615771882), 68: (4, 127, 0.1852273227148286), 69: (4, 127, 0.18499148897386677), 70: (4, 127, 0.1851815708700245)}\n",
      "{'predict_runtime': 1678.9323, 'predict_samples_per_second': 0.167, 'predict_steps_per_second': 0.042}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:27:58.93\n",
      "  predict_samples_per_second =      0.167\n",
      "  predict_steps_per_second   =      0.042\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 23\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with source_max_length of 128\n",
    "- Depths: 22, 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"128\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.3577101705595851), 2: (1, 0.19878964684903622), 3: (1, 0.19745663180947304), 4: (1, 0.19568663369864225), 5: (1, 0.20586980413645506), 6: (1, 0.2004829877987504), 7: (1, 0.19759755209088326), 8: (1, 0.1960954898968339), 9: (1, 0.19730158522725105), 10: (1, 0.19554688595235348), 11: (1, 0.20351569261401892), 12: (1, 0.19800104666501284), 13: (1, 0.19540128763765097), 14: (1, 0.1972136553376913), 15: (1, 0.19438183028250933), 16: (1, 0.19264856074005365), 17: (1, 0.19484271574765444), 18: (1, 0.1966735739260912), 19: (1, 0.1936874482780695), 20: (1, 0.20005735382437706), 21: (1, 0.19748683366924524), 22: (1, 0.19797738920897245), 23: (1, 0.1963111674413085), 24: (1, 0.19466630835086107), 25: (1, 0.19787497073411942), 26: (1, 0.19398862589150667), 27: (1, 0.19525282084941864), 28: (1, 0.19350027199834585), 29: (1, 0.19894771836698055), 30: (1, 0.20779505372047424), 31: (1, 0.1986122028902173), 32: (1, 0.19802003912627697), 33: (1, 0.19886403996497393), 34: (1, 0.1937101911753416), 35: (1, 0.19717963878065348), 36: (1, 0.19523179344832897), 37: (1, 0.1944084418937564), 38: (1, 0.1927403910085559), 39: (1, 0.19673578534275293), 40: (1, 0.1958120157942176), 41: (1, 0.19558733887970448), 42: (1, 0.1940046101808548), 43: (1, 0.19686955772340298), 44: (1, 0.19347080774605274), 45: (1, 0.19463817309588194), 46: (1, 0.19400442019104958), 47: (1, 0.19575144164264202), 48: (1, 0.19355447590351105), 49: (1, 0.19716170337051153), 50: (1, 0.19516199734061956), 51: (1, 0.19572867266833782), 52: (1, 0.1968533182516694), 53: (1, 0.1933995671570301), 54: (1, 0.1931449919939041), 55: (1, 0.1946484548971057), 56: (1, 0.19645416364073753), 57: (1, 0.19468463398516178), 58: (1, 0.1929708644747734), 59: (1, 0.1963865952566266), 60: (1, 0.1943186977878213), 61: (1, 0.19481495115906), 62: (1, 0.1969852764159441), 63: (1, 0.19555058423429728), 64: (1, 0.19548786524683237), 65: (1, 0.19382476527243853), 66: (1, 0.1935826577246189), 67: (1, 0.19391684420406818), 68: (1, 0.19525237753987312), 69: (1, 0.19380447454750538), 70: (1, 0.19572779349982738), 71: (1, 0.19445562828332186)}\n",
      "{1: (1, 127, 0.11733893862390142), 2: (1, 127, 0.11585584656870741), 3: (1, 127, 0.11568078962631348), 4: (1, 127, 0.11830256562533341), 5: (1, 127, 0.11723555222622992), 6: (1, 127, 0.11646253159489688), 7: (1, 127, 0.1163981695050799), 8: (1, 127, 0.11590844870170974), 9: (1, 127, 0.11620348057614302), 10: (1, 127, 0.11651074051065004), 11: (1, 127, 0.12219811976689288), 12: (1, 127, 0.1164693322296687), 13: (1, 127, 0.11539149549093068), 14: (1, 127, 0.11561680046885502), 15: (1, 127, 0.11546169462665094), 16: (1, 127, 0.11556244893806188), 17: (1, 127, 0.11584170368008727), 18: (1, 127, 0.11595711664216021), 19: (1, 127, 0.121102612670951), 20: (1, 127, 0.12072382954601932), 21: (1, 127, 0.1166739211102405), 22: (1, 127, 0.11587331922152849), 23: (1, 127, 0.11562556430961438), 24: (1, 127, 0.11635002107396135), 25: (1, 127, 0.12348378466544893), 26: (1, 127, 0.11546981482817902), 27: (1, 127, 0.1157717496142026), 28: (1, 127, 0.11581057244838458), 29: (1, 127, 0.11714316161686746), 30: (1, 127, 0.11888071303585852), 31: (1, 127, 0.11784006467485052), 32: (1, 127, 0.11644625814822246), 33: (1, 127, 0.11565497535185551), 34: (1, 127, 0.11536725532028853), 35: (1, 127, 0.11529137957547828), 36: (1, 127, 0.11538136630194394), 37: (1, 127, 0.11522601581523269), 38: (1, 127, 0.11528377441000047), 39: (1, 127, 0.11561882352881779), 40: (1, 127, 0.11525656531498892), 41: (1, 127, 0.1152174523041591), 42: (1, 127, 0.1153005065953755), 43: (1, 127, 0.11527737378194107), 44: (1, 127, 0.11544915270353631), 45: (1, 127, 0.11529534010172594), 46: (1, 127, 0.11546530455028213), 47: (1, 127, 0.1153876494586937), 48: (1, 127, 0.11538876662045483), 49: (1, 127, 0.11536300241741843), 50: (1, 127, 0.11534328586385241), 51: (1, 127, 0.11540770934029358), 52: (1, 127, 0.11550975366546883), 53: (1, 127, 0.11539960809521319), 54: (1, 127, 0.1154622354537366), 55: (1, 127, 0.11543086336148302), 56: (1, 127, 0.11538098275837466), 57: (1, 127, 0.11527080325717766), 58: (1, 127, 0.11535652601490105), 59: (1, 127, 0.11535157913004788), 60: (1, 127, 0.1153942372972571), 61: (1, 127, 0.11536793633708804), 62: (1, 127, 0.11537375348788781), 63: (1, 127, 0.11538697575314308), 64: (1, 127, 0.11541461479652115), 65: (1, 127, 0.11528709816093755), 66: (1, 127, 0.11525635889870679), 67: (1, 127, 0.11519836926260801), 68: (1, 127, 0.11533907594115246), 69: (1, 127, 0.11518123439388482), 70: (1, 127, 0.11521855952203508)}\n",
      "{'predict_runtime': 1061.1299, 'predict_samples_per_second': 0.067, 'predict_steps_per_second': 0.067}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:17:41.12\n",
      "  predict_samples_per_second =      0.067\n",
      "  predict_steps_per_second   =      0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.24802475981414318), 2: (2, 0.21677323523908854), 3: (2, 0.21358795370906591), 4: (2, 0.23003648966550827), 5: (2, 0.21463143173605204), 6: (2, 0.22513023857027292), 7: (2, 0.21177986543625593), 8: (2, 0.2120429426431656), 9: (2, 0.22706967685371637), 10: (2, 0.22407109197229147), 11: (2, 0.21268784627318382), 12: (2, 0.22823814395815134), 13: (2, 0.210063386708498), 14: (2, 0.22962397802621126), 15: (2, 0.2251416016370058), 16: (2, 0.2291360618546605), 17: (2, 0.2093768734484911), 18: (2, 0.21273921336978674), 19: (2, 0.21704487409442663), 20: (2, 0.2195805348455906), 21: (2, 0.22747517097741365), 22: (2, 0.21803639270365238), 23: (2, 0.22713927552103996), 24: (2, 0.2116794679313898), 25: (2, 0.21414540894329548), 26: (2, 0.20904156938195229), 27: (2, 0.21413429826498032), 28: (2, 0.2254547169432044), 29: (2, 0.2271128986030817), 30: (2, 0.2188280252739787), 31: (2, 0.22641832567751408), 32: (2, 0.22758618276566267), 33: (2, 0.22481825482100248), 34: (2, 0.2177268099039793), 35: (2, 0.22711024899035692), 36: (2, 0.22866415977478027), 37: (2, 0.22577090468257666), 38: (2, 0.2188617056235671), 39: (2, 0.2270661611109972), 40: (2, 0.21276466827839613), 41: (2, 0.22056854702532291), 42: (2, 0.21533998847007751), 43: (2, 0.21442105900496244), 44: (2, 0.23030587285757065), 45: (2, 0.22107220068573952), 46: (2, 0.2276932941749692), 47: (2, 0.22692281287163496), 48: (2, 0.213044885545969), 49: (2, 0.2147099757567048), 50: (2, 0.21759306266903877), 51: (2, 0.21804987825453281), 52: (2, 0.2168666822835803), 53: (2, 0.23079743888229132), 54: (2, 0.21562211774289608), 55: (2, 0.22787857335060835), 56: (2, 0.21429438143968582), 57: (2, 0.22607840411365032), 58: (2, 0.21513833291828632), 59: (2, 0.2270196145400405), 60: (2, 0.21661701519042253), 61: (2, 0.22869027499109507), 62: (2, 0.21148673631250858), 63: (2, 0.22906013019382954), 64: (2, 0.21639504935592413), 65: (2, 0.22101248521357775), 66: (2, 0.22836980037391186), 67: (2, 0.224233478307724), 68: (2, 0.22622164338827133), 69: (2, 0.2167126154527068), 70: (2, 0.22680667787790298), 71: (1, 0.20540617778897285)}\n",
      "{1: (2, 127, 0.1793882314365093), 2: (2, 127, 0.1779492740614677), 3: (2, 127, 0.17781520870286882), 4: (2, 127, 0.17793225597472875), 5: (2, 127, 0.17766008806216904), 6: (2, 127, 0.1778041238375888), 7: (2, 127, 0.17763421061910747), 8: (2, 127, 0.17763427273172328), 9: (2, 127, 0.1777457943274163), 10: (2, 127, 0.17764734837600565), 11: (2, 127, 0.17761134184662283), 12: (2, 127, 0.17775239239586152), 13: (2, 127, 0.17802455414115914), 14: (2, 127, 0.1777304543446251), 15: (2, 127, 0.17770844982482317), 16: (2, 127, 0.17760745862014884), 17: (2, 127, 0.1778082105837117), 18: (2, 127, 0.17775658463809904), 19: (2, 127, 0.17772266439594855), 20: (2, 127, 0.17777183648257508), 21: (2, 127, 0.177843815155738), 22: (2, 127, 0.1777844388243251), 23: (2, 127, 0.17775311076089623), 24: (2, 127, 0.17773418898481552), 25: (2, 127, 0.17772766502618087), 26: (2, 127, 0.17778157209610845), 27: (2, 127, 0.1777936079224029), 28: (2, 127, 0.1777376369756507), 29: (2, 127, 0.1778138599204501), 30: (2, 127, 0.17768489660357867), 31: (2, 127, 0.17761000274409225), 32: (2, 127, 0.17768040748210404), 33: (2, 127, 0.1778607662092513), 34: (2, 127, 0.17752556467619468), 35: (2, 127, 0.17755807214599895), 36: (2, 127, 0.17747591317110645), 37: (2, 127, 0.17752932141146321), 38: (2, 127, 0.17759134836025595), 39: (2, 127, 0.17758049090634884), 40: (2, 127, 0.17756145401293133), 41: (2, 127, 0.17766513181923646), 42: (2, 127, 0.17762204151835262), 43: (2, 127, 0.1776098662650022), 44: (2, 127, 0.17756622549381076), 45: (2, 127, 0.1775473542658128), 46: (2, 127, 0.17755504846426212), 47: (2, 127, 0.1776885474980699), 48: (2, 127, 0.17757927292708572), 49: (2, 127, 0.17763501261984269), 50: (2, 127, 0.17751798987036616), 51: (2, 127, 0.17769185526252496), 52: (2, 127, 0.17767790869963684), 53: (2, 127, 0.17759532561364372), 54: (2, 127, 0.17757512195637143), 55: (2, 127, 0.1777145017789105), 56: (2, 127, 0.17764619302268572), 57: (2, 127, 0.17769728166850532), 58: (2, 127, 0.17760436168659155), 59: (2, 127, 0.17762631020237377), 60: (2, 127, 0.17763816058547713), 61: (2, 127, 0.1776434505490337), 62: (2, 127, 0.1778487879489585), 63: (2, 127, 0.17780097381864476), 64: (2, 127, 0.17784162376838641), 65: (2, 127, 0.17772546538892459), 66: (2, 127, 0.17757975579217428), 67: (2, 127, 0.1776360600497427), 68: (2, 127, 0.17780249452174413), 69: (2, 127, 0.17823330895960565), 70: (2, 127, 0.177666666242844)}\n",
      "{'predict_runtime': 1610.3163, 'predict_samples_per_second': 0.088, 'predict_steps_per_second': 0.044}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:26:50.31\n",
      "  predict_samples_per_second =      0.088\n",
      "  predict_steps_per_second   =      0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3040310852229595), 2: (4, 0.2876327456906438), 3: (4, 0.27625962160527706), 4: (4, 0.28292727284133434), 5: (4, 0.28097338415682316), 6: (4, 0.287228612229228), 7: (4, 0.28780290484428406), 8: (4, 0.2819434143602848), 9: (4, 0.29112077690660954), 10: (4, 0.27732781041413546), 11: (4, 0.2821287726983428), 12: (4, 0.2717357138171792), 13: (4, 0.2729638097807765), 14: (4, 0.29448268935084343), 15: (4, 0.2749889073893428), 16: (4, 0.29217997658997774), 17: (4, 0.27204268239438534), 18: (4, 0.27012327406555414), 19: (4, 0.2718755351379514), 20: (4, 0.2758561475202441), 21: (4, 0.2751770652830601), 22: (4, 0.273382936604321), 23: (4, 0.2726630251854658), 24: (4, 0.27257990650832653), 25: (4, 0.2884856313467026), 26: (4, 0.27613124530762434), 27: (4, 0.27673045732080936), 28: (4, 0.2732776291668415), 29: (4, 0.27176211681216955), 30: (4, 0.28647236432880163), 31: (4, 0.2727374043315649), 32: (4, 0.2787317456677556), 33: (4, 0.2748273303732276), 34: (4, 0.27634147461503744), 35: (4, 0.272578408010304), 36: (4, 0.274796892888844), 37: (4, 0.2727788155898452), 38: (4, 0.2918758736923337), 39: (4, 0.28266082145273685), 40: (4, 0.27064829785376787), 41: (4, 0.27970695216208696), 42: (4, 0.2778302142396569), 43: (4, 0.2729700105264783), 44: (4, 0.2765141297131777), 45: (4, 0.2768857041373849), 46: (4, 0.27794512175023556), 47: (4, 0.2718021450564265), 48: (4, 0.2731296606361866), 49: (4, 0.277515659108758), 50: (4, 0.274778769351542), 51: (4, 0.2763683423399925), 52: (4, 0.28024416603147984), 53: (4, 0.2783780796453357), 54: (4, 0.2923570331186056), 55: (4, 0.2795622358098626), 56: (4, 0.2769980765879154), 57: (4, 0.2727393265813589), 58: (4, 0.2719194069504738), 59: (4, 0.2788983639329672), 60: (4, 0.2751186089590192), 61: (4, 0.27867943700402975), 62: (4, 0.27945719845592976), 63: (4, 0.2775968015193939), 64: (4, 0.27575434278696775), 65: (4, 0.27437660936266184), 66: (4, 0.273254263214767), 67: (4, 0.27588077168911695), 68: (4, 0.2761714980006218), 69: (4, 0.2791665829718113), 70: (4, 0.2859075842425227), 71: (1, 0.19267252925783396)}\n",
      "{1: (4, 127, 0.1796499932346147), 2: (4, 127, 0.17878065697526133), 3: (4, 127, 0.1785810947652877), 4: (4, 127, 0.17843700341117663), 5: (4, 127, 0.17820591945201159), 6: (4, 127, 0.17818351423617187), 7: (4, 127, 0.17825606199142735), 8: (4, 127, 0.17818216877571474), 9: (4, 127, 0.17820194266795172), 10: (4, 127, 0.178072586721616), 11: (4, 127, 0.17824484623499273), 12: (4, 127, 0.17819459235486318), 13: (4, 127, 0.17813717478548918), 14: (4, 127, 0.17871599126695178), 15: (4, 127, 0.17811103575078285), 16: (4, 127, 0.17820119158196168), 17: (4, 127, 0.1781800930190274), 18: (4, 127, 0.17833056396210756), 19: (4, 127, 0.1781546909171413), 20: (4, 127, 0.1782167000608064), 21: (4, 127, 0.17822728412387173), 22: (4, 127, 0.1781135087055484), 23: (4, 127, 0.17817695624393037), 24: (4, 127, 0.17811122757390024), 25: (4, 127, 0.1780138815731162), 26: (4, 127, 0.17811975357540716), 27: (4, 127, 0.17807516647781443), 28: (4, 127, 0.17813081669760503), 29: (4, 127, 0.1780731665322513), 30: (4, 127, 0.17799149183043111), 31: (4, 127, 0.1780544579557077), 32: (4, 127, 0.17812550895092055), 33: (4, 127, 0.17812638399081202), 34: (4, 127, 0.17812919758230916), 35: (4, 127, 0.17806609368729076), 36: (4, 127, 0.1779931536838999), 37: (4, 127, 0.17806416947951936), 38: (4, 127, 0.17795777142663874), 39: (4, 127, 0.17804554983328177), 40: (4, 127, 0.17796149955490442), 41: (4, 127, 0.17791421083718773), 42: (4, 127, 0.1779676024530699), 43: (4, 127, 0.17797636473918055), 44: (4, 127, 0.17795802063242658), 45: (4, 127, 0.17790672432367258), 46: (4, 127, 0.17820772769912255), 47: (4, 127, 0.17802416471632446), 48: (4, 127, 0.1779813608227987), 49: (4, 127, 0.17804389728570547), 50: (4, 127, 0.17778850616667213), 51: (4, 127, 0.17821688134604552), 52: (4, 127, 0.17807895016277164), 53: (4, 127, 0.17802086330979594), 54: (4, 127, 0.17809875776595252), 55: (4, 127, 0.17839170391048034), 56: (4, 127, 0.17856651100176058), 57: (4, 127, 0.17821654909855034), 58: (4, 127, 0.1781297871534984), 59: (4, 127, 0.17825029133342382), 60: (4, 127, 0.17814599140363885), 61: (4, 127, 0.1781785331563804), 62: (4, 127, 0.17799018940881012), 63: (4, 127, 0.17815141467832205), 64: (4, 127, 0.1781844377635032), 65: (4, 127, 0.1781685929965433), 66: (4, 127, 0.1780052252524481), 67: (4, 127, 0.1782168462271179), 68: (4, 127, 0.1780902912004257), 69: (4, 127, 0.17822690973952998), 70: (4, 127, 0.17872443179944603)}\n",
      "{'predict_runtime': 1618.326, 'predict_samples_per_second': 0.174, 'predict_steps_per_second': 0.044}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:26:58.32\n",
      "  predict_samples_per_second =      0.174\n",
      "  predict_steps_per_second   =      0.044\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 22\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.23058190941810608), 2: (1, 0.2124234950169921), 3: (1, 0.20578346401453018), 4: (1, 0.20447565894573927), 5: (1, 0.205516766756773), 6: (1, 0.20218499656766653), 7: (1, 0.20630350802093744), 8: (1, 0.20658898446708918), 9: (1, 0.2033920418471098), 10: (1, 0.2021800372749567), 11: (1, 0.20313501730561256), 12: (1, 0.20473702810704708), 13: (1, 0.20437373220920563), 14: (1, 0.20555885881185532), 15: (1, 0.20367714203894138), 16: (1, 0.2044023647904396), 17: (1, 0.2040087804198265), 18: (1, 0.20180990546941757), 19: (1, 0.2023479202762246), 20: (1, 0.20385337248444557), 21: (1, 0.20332300011068583), 22: (1, 0.20347306970506907), 23: (1, 0.20573656260967255), 24: (1, 0.2055009650066495), 25: (1, 0.20329518243670464), 26: (1, 0.2018482591956854), 27: (1, 0.20304466504603624), 28: (1, 0.20330072287470102), 29: (1, 0.20316326431930065), 30: (1, 0.2016401430591941), 31: (1, 0.20211056899279356), 32: (1, 0.2020919593051076), 33: (1, 0.2023070165887475), 34: (1, 0.20156303700059652), 35: (1, 0.2042268654331565), 36: (1, 0.20426316652446985), 37: (1, 0.20481016859412193), 38: (1, 0.2031946089118719), 39: (1, 0.20213131234049797), 40: (1, 0.2047039121389389), 41: (1, 0.20442611631006002), 42: (1, 0.20458493568003178), 43: (1, 0.20387961342930794), 44: (1, 0.203909813426435), 45: (1, 0.20443349797278643), 46: (1, 0.20291072502732277), 47: (1, 0.20510939043015242), 48: (1, 0.20210168696939945), 49: (1, 0.203459270298481), 50: (1, 0.20521864015609026), 51: (1, 0.20253755245357752), 52: (1, 0.20302835758775473), 53: (1, 0.20355537999421358), 54: (1, 0.20268384087830782), 55: (1, 0.20205079019069672), 56: (1, 0.2030823277309537), 57: (1, 0.20313753746449947), 58: (1, 0.2014602478593588), 59: (1, 0.20389114879071712), 60: (1, 0.20311839878559113), 61: (1, 0.20431501511484385), 62: (1, 0.2020517522469163), 63: (1, 0.20215585082769394), 64: (1, 0.20176005735993385), 65: (1, 0.2033183667808771), 66: (1, 0.2014867402613163), 67: (1, 0.20560456067323685), 68: (1, 0.20216002315282822), 69: (1, 0.20537870470434427), 70: (1, 0.20468955300748348), 71: (1, 0.20155637152493)}\n",
      "{1: (1, 127, 0.12132831958423215), 2: (1, 127, 0.1212428809825595), 3: (1, 127, 0.12110757116433674), 4: (1, 127, 0.12093015200656465), 5: (1, 127, 0.12088526150314358), 6: (1, 127, 0.1208539061233636), 7: (1, 127, 0.12083298063242999), 8: (1, 127, 0.12119920049449355), 9: (1, 127, 0.12093197018289426), 10: (1, 127, 0.12073293382551258), 11: (1, 127, 0.12090249642671093), 12: (1, 127, 0.12087993457268073), 13: (1, 127, 0.12097889951276262), 14: (1, 127, 0.12094945750954583), 15: (1, 127, 0.12085027741194945), 16: (1, 127, 0.12086117687070463), 17: (1, 127, 0.12085297585677678), 18: (1, 127, 0.12086039401708155), 19: (1, 127, 0.12101065022797566), 20: (1, 127, 0.12084960000310827), 21: (1, 127, 0.12077844579242111), 22: (1, 127, 0.12085833873482436), 23: (1, 127, 0.12069184685081948), 24: (1, 127, 0.12079506574242603), 25: (1, 127, 0.12061988182483226), 26: (1, 127, 0.1206853273874662), 27: (1, 127, 0.12054783284781485), 28: (1, 127, 0.12099439714573265), 29: (1, 127, 0.12063351804463882), 30: (1, 127, 0.12063916257076611), 31: (1, 127, 0.12048478972342774), 32: (1, 127, 0.1204271373800992), 33: (1, 127, 0.12029962490246755), 34: (1, 127, 0.12063210914424789), 35: (1, 127, 0.12057833019350692), 36: (1, 127, 0.12051987202148738), 37: (1, 127, 0.12045688256181365), 38: (1, 127, 0.12076699595135731), 39: (1, 127, 0.12053929648442765), 40: (1, 127, 0.12055988617124051), 41: (1, 127, 0.12047918965878683), 42: (1, 127, 0.12062348558853461), 43: (1, 127, 0.12056032178087497), 44: (1, 127, 0.1204688628827493), 45: (1, 127, 0.12044554041683908), 46: (1, 127, 0.12082850710144193), 47: (1, 127, 0.12099211710673852), 48: (1, 127, 0.12071068661184761), 49: (1, 127, 0.1203923863248797), 50: (1, 127, 0.12062466015496592), 51: (1, 127, 0.12050046469634912), 52: (1, 127, 0.12079018430681679), 53: (1, 127, 0.12082337398140684), 54: (1, 127, 0.12080121723069685), 55: (1, 127, 0.12078285152752569), 56: (1, 127, 0.12072157862002221), 57: (1, 127, 0.12073117273852346), 58: (1, 127, 0.12069562007856416), 59: (1, 127, 0.1207279495924242), 60: (1, 127, 0.12069204811182782), 61: (1, 127, 0.1207665990832753), 62: (1, 127, 0.12065283553748149), 63: (1, 127, 0.12082379465321387), 64: (1, 127, 0.12075324303023224), 65: (1, 127, 0.12058525507551009), 66: (1, 127, 0.12058245611384394), 67: (1, 127, 0.12058356369104911), 68: (1, 127, 0.12055985268762731), 69: (1, 127, 0.12058112168259273), 70: (1, 127, 0.12064644851259829)}\n",
      "{'predict_runtime': 1103.1435, 'predict_samples_per_second': 0.064, 'predict_steps_per_second': 0.064}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:18:23.14\n",
      "  predict_samples_per_second =      0.064\n",
      "  predict_steps_per_second   =      0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.27096632588654757), 2: (2, 0.23643480613827705), 3: (2, 0.24151712656021118), 4: (2, 0.22504500299692154), 5: (2, 0.21872262936085463), 6: (2, 0.22290520928800106), 7: (2, 0.2299985559657216), 8: (2, 0.23544658161699772), 9: (2, 0.2352762147784233), 10: (2, 0.23727462999522686), 11: (2, 0.2366967387497425), 12: (2, 0.23764947708696127), 13: (2, 0.22035594377666712), 14: (2, 0.22118229512125254), 15: (2, 0.22926067933440208), 16: (2, 0.236040779389441), 17: (2, 0.23646583408117294), 18: (2, 0.23742364346981049), 19: (2, 0.23597257025539875), 20: (2, 0.22371016535907984), 21: (2, 0.22131143603473902), 22: (2, 0.22653777431696653), 23: (2, 0.2319389395415783), 24: (2, 0.2382074249908328), 25: (2, 0.23050898872315884), 26: (2, 0.21981997601687908), 27: (2, 0.23712123092263937), 28: (2, 0.2377906832844019), 29: (2, 0.23653039894998074), 30: (2, 0.2296411208808422), 31: (2, 0.21950132120400667), 32: (2, 0.222110690549016), 33: (2, 0.2215733090415597), 34: (2, 0.23739094007760286), 35: (2, 0.2361550247296691), 36: (2, 0.23781724739819765), 37: (2, 0.23639678489416838), 38: (2, 0.23672911152243614), 39: (2, 0.2341215731576085), 40: (2, 0.2373171653598547), 41: (2, 0.21967557352036238), 42: (2, 0.23559351544827223), 43: (2, 0.2382810339331627), 44: (2, 0.23630855791270733), 45: (2, 0.23714492842555046), 46: (2, 0.23752089496701956), 47: (2, 0.23606235347688198), 48: (2, 0.2369859702885151), 49: (2, 0.2306016944348812), 50: (2, 0.23568164557218552), 51: (2, 0.2380463583394885), 52: (2, 0.22981587518006563), 53: (2, 0.23687274288386106), 54: (2, 0.24116967245936394), 55: (2, 0.2368089547380805), 56: (2, 0.2366423960775137), 57: (2, 0.23654963728040457), 58: (2, 0.2365398472175002), 59: (2, 0.23600839544087648), 60: (2, 0.23332594614475965), 61: (2, 0.2368529550731182), 62: (2, 0.23658998776227236), 63: (2, 0.23943014442920685), 64: (2, 0.2359250672161579), 65: (2, 0.237827954813838), 66: (2, 0.2378789046779275), 67: (2, 0.23639059346169233), 68: (2, 0.2378827352076769), 69: (2, 0.22377262078225613), 70: (2, 0.23467277362942696), 71: (1, 0.22030892316251993)}\n",
      "{1: (2, 127, 0.18840339273859666), 2: (2, 127, 0.18635966358926354), 3: (2, 127, 0.18609570380388282), 4: (2, 127, 0.18618037756972425), 5: (2, 127, 0.18603660774923217), 6: (2, 127, 0.185981004293568), 7: (2, 127, 0.18587473645718314), 8: (2, 127, 0.1858433643429298), 9: (2, 127, 0.18602755785311068), 10: (2, 127, 0.18608343453095186), 11: (2, 127, 0.1859456096577832), 12: (2, 127, 0.1860181937639521), 13: (2, 127, 0.1859842629179241), 14: (2, 127, 0.18612859065197115), 15: (2, 127, 0.18594241333670739), 16: (2, 127, 0.1860467784004066), 17: (2, 127, 0.1858931034436728), 18: (2, 127, 0.1859043255140345), 19: (2, 127, 0.18610364500814536), 20: (2, 127, 0.1861029635000182), 21: (2, 127, 0.18607138833544384), 22: (2, 127, 0.1858863020095769), 23: (2, 127, 0.1858738137878419), 24: (2, 127, 0.1860143716821051), 25: (2, 127, 0.18589465447708847), 26: (2, 127, 0.1858803379811405), 27: (2, 127, 0.18594215317504612), 28: (2, 127, 0.18588810526274555), 29: (2, 127, 0.1858500201460414), 30: (2, 127, 0.18606064506021774), 31: (2, 127, 0.18586602958109905), 32: (2, 127, 0.1859964385746032), 33: (2, 127, 0.18596964929340862), 34: (2, 127, 0.18593161477611994), 35: (2, 127, 0.18591087391438682), 36: (2, 127, 0.18585813435630535), 37: (2, 127, 0.18592149885297996), 38: (2, 127, 0.1858798646859414), 39: (2, 127, 0.18594216776821088), 40: (2, 127, 0.18612280969075332), 41: (2, 127, 0.18616191313902694), 42: (2, 127, 0.18603801976625375), 43: (2, 127, 0.1860404794478393), 44: (2, 127, 0.18589252746099327), 45: (2, 127, 0.18596390183047046), 46: (2, 127, 0.18603840616245673), 47: (2, 127, 0.18593801802948234), 48: (2, 127, 0.18598625684289014), 49: (2, 127, 0.1859045976728905), 50: (2, 127, 0.18597339356948775), 51: (2, 127, 0.18612663931851312), 52: (2, 127, 0.18606804380941344), 53: (2, 127, 0.1859797795750494), 54: (2, 127, 0.18597581860147358), 55: (2, 127, 0.18589883761876447), 56: (2, 127, 0.1858489279759916), 57: (2, 127, 0.1858681952214147), 58: (2, 127, 0.18590655452828472), 59: (2, 127, 0.18580439523977088), 60: (2, 127, 0.18584835093732424), 61: (2, 127, 0.18594556048835123), 62: (2, 127, 0.1858058854218895), 63: (2, 127, 0.1858300275616641), 64: (2, 127, 0.18577956598926718), 65: (2, 127, 0.18587726710261557), 66: (2, 127, 0.18580335171849238), 67: (2, 127, 0.1858562037466079), 68: (2, 127, 0.18599299572437533), 69: (2, 127, 0.18567183813974847), 70: (2, 127, 0.1857384895157861)}\n",
      "{'predict_runtime': 1685.3679, 'predict_samples_per_second': 0.084, 'predict_steps_per_second': 0.042}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:28:05.36\n",
      "  predict_samples_per_second =      0.084\n",
      "  predict_steps_per_second   =      0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.315040466375649), 2: (4, 0.28905504290014505), 3: (4, 0.28551165480166674), 4: (4, 0.2933922428637743), 5: (4, 0.283999334089458), 6: (4, 0.2845861567184329), 7: (4, 0.282516710460186), 8: (4, 0.29148106649518013), 9: (4, 0.28900254610925913), 10: (4, 0.28500302229076624), 11: (4, 0.2822942342609167), 12: (4, 0.2860790193080902), 13: (4, 0.2865338455885649), 14: (4, 0.2871843380853534), 15: (4, 0.2814633660018444), 16: (4, 0.28544635977596045), 17: (4, 0.28965985029935837), 18: (4, 0.28201747965067625), 19: (4, 0.2854574201628566), 20: (4, 0.2885346245020628), 21: (4, 0.28436058294028044), 22: (4, 0.28531094919890165), 23: (4, 0.28630873654037714), 24: (4, 0.2888235282152891), 25: (4, 0.28485917299985886), 26: (4, 0.283610618673265), 27: (4, 0.28583260253071785), 28: (4, 0.28725516609847546), 29: (4, 0.2833958016708493), 30: (4, 0.2838915856555104), 31: (4, 0.2873598039150238), 32: (4, 0.2855989448726177), 33: (4, 0.2857243428006768), 34: (4, 0.28432342037558556), 35: (4, 0.285879660397768), 36: (4, 0.2861016085371375), 37: (4, 0.2870738375931978), 38: (4, 0.2943072831258178), 39: (4, 0.28914590273052454), 40: (4, 0.28914222214370966), 41: (4, 0.2862195074558258), 42: (4, 0.2954506492242217), 43: (4, 0.29788623098284006), 44: (4, 0.2879699766635895), 45: (4, 0.29238538537174463), 46: (4, 0.2849370511248708), 47: (4, 0.28412190079689026), 48: (4, 0.2852127179503441), 49: (4, 0.2862665858119726), 50: (4, 0.2834256598725915), 51: (4, 0.28611338790506124), 52: (4, 0.28545448556542397), 53: (4, 0.28709216602146626), 54: (4, 0.2846089843660593), 55: (4, 0.2853006571531296), 56: (4, 0.28413689136505127), 57: (4, 0.28601772896945477), 58: (4, 0.2859356692060828), 59: (4, 0.2846979945898056), 60: (4, 0.28635711409151554), 61: (4, 0.28688815981149673), 62: (4, 0.28783306758850813), 63: (4, 0.2843883680179715), 64: (4, 0.2845054352656007), 65: (4, 0.2830797331407666), 66: (4, 0.2833769991993904), 67: (4, 0.2840407704934478), 68: (4, 0.2846291046589613), 69: (4, 0.2835666071623564), 70: (4, 0.2813892215490341), 71: (1, 0.2012009397149086)}\n",
      "{1: (4, 127, 0.18777568607525094), 2: (4, 127, 0.18700302207446473), 3: (4, 127, 0.1864398420443685), 4: (4, 127, 0.1861445480062971), 5: (4, 127, 0.18623225409244223), 6: (4, 127, 0.18603416645210089), 7: (4, 127, 0.18604443823610703), 8: (4, 127, 0.18582119081374698), 9: (4, 127, 0.1859052342575366), 10: (4, 127, 0.18583184521733306), 11: (4, 127, 0.18581990002999155), 12: (4, 127, 0.18578998975485095), 13: (4, 127, 0.1858613797148147), 14: (4, 127, 0.1858999262761882), 15: (4, 127, 0.18595150850830586), 16: (4, 127, 0.18579844920712663), 17: (4, 127, 0.18603269457377083), 18: (4, 127, 0.1859238666489603), 19: (4, 127, 0.1858998893679479), 20: (4, 127, 0.1859531929041809), 21: (4, 127, 0.18595592678326556), 22: (4, 127, 0.18581670956084811), 23: (4, 127, 0.1857923295598213), 24: (4, 127, 0.1858027168718262), 25: (4, 127, 0.18577795986848789), 26: (4, 127, 0.18590210388436562), 27: (4, 127, 0.18577077930543837), 28: (4, 127, 0.18582256131724814), 29: (4, 127, 0.18578339134174304), 30: (4, 127, 0.1861584293619385), 31: (4, 127, 0.18610295626943504), 32: (4, 127, 0.1859446468095728), 33: (4, 127, 0.18567145467684495), 34: (4, 127, 0.18573357414190225), 35: (4, 127, 0.1857660946722223), 36: (4, 127, 0.18622428588715828), 37: (4, 127, 0.18674947025885028), 38: (4, 127, 0.18634537738696563), 39: (4, 127, 0.1861534494261338), 40: (4, 127, 0.18647795339210296), 41: (4, 127, 0.18606674602240558), 42: (4, 127, 0.1863390302842879), 43: (4, 127, 0.18825648555634764), 44: (4, 127, 0.1868397861675132), 45: (4, 127, 0.18648439043707501), 46: (4, 127, 0.18606469577809018), 47: (4, 127, 0.18594187685823815), 48: (4, 127, 0.18587734104376138), 49: (4, 127, 0.18583926584894264), 50: (4, 127, 0.1858810016328073), 51: (4, 127, 0.18575909963302958), 52: (4, 127, 0.18618360259313518), 53: (4, 127, 0.18590635453592838), 54: (4, 127, 0.18588244312948835), 55: (4, 127, 0.185717959492284), 56: (4, 127, 0.18565483051755532), 57: (4, 127, 0.18567354294405444), 58: (4, 127, 0.18564509875397747), 59: (4, 127, 0.18566072310548365), 60: (4, 127, 0.18570615695129464), 61: (4, 127, 0.18564155601757013), 62: (4, 127, 0.18568330998789137), 63: (4, 127, 0.18565228638627868), 64: (4, 127, 0.18561104063208647), 65: (4, 127, 0.18562916021676748), 66: (4, 127, 0.18573119820601594), 67: (4, 127, 0.18553819413494876), 68: (4, 127, 0.1855761066563134), 69: (4, 127, 0.18553973515848005), 70: (4, 127, 0.18551694925903806)}\n",
      "{'predict_runtime': 1689.0008, 'predict_samples_per_second': 0.166, 'predict_steps_per_second': 0.042}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:28:09.00\n",
      "  predict_samples_per_second =      0.166\n",
      "  predict_steps_per_second   =      0.042\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 23\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt128'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with source_max_len of 128 and max_new_tokens of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/serenity/scratch/dgarg/anaconda3/envs/amoaballm/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding correct special tokens to the llama tokenizer\n",
      "Loading adapters from checkpoint\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--model_name_or_path\", \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"--output_dir\", \"amoeba_llama2\",\n",
    "    \"--do_predict\", \"True\",\n",
    "    \"--do_eval\", \"False\",\n",
    "    \"--do_train\", \"False\",\n",
    "    \"--do_mmlu_eval\", \"False\",\n",
    "    \"--enable_shrinking\",\n",
    "    \"--min_num_layer\", \"20\",\n",
    "    \"--shrinking_method\", \"calib_dp\",\n",
    "    \"--shrinking_file\", \"dp_selection_strategy.npy\",\n",
    "    \"--shrinkable_width\",\n",
    "    \"--width_choice\", \"[1,7/8,3/4,5/8,1/2]\",\n",
    "    \"--prune_width_method\", \"flap\",\n",
    "    \"--use_moe_lora\",\n",
    "    \"--moe_num_expert\", \"5\",\n",
    "    \"--moe_topk\", \"2\",\n",
    "    \"--eval_num_layer\", \"32\",\n",
    "    \"--eval_num_width\", \"1\",\n",
    "    \"--predict_with_generate\", \"True\",\n",
    "    \"--source_max_len\", \"128\",\n",
    "    \"--max_new_tokens\", \"256\",\n",
    "]\n",
    "args, training_args = parse_args(args_list=args)\n",
    "checkpoint_dir = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = load_model(args, checkpoint_dir)\n",
    "set_width_mask_and_bias(model, args)\n",
    "logger = logging.getLogger(__name__)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.34790936298668385), 2: (1, 0.20104585029184818), 3: (1, 0.1970225479453802), 4: (1, 0.19712073728442192), 5: (1, 0.197751360014081), 6: (1, 0.1994593907147646), 7: (1, 0.19534688908606768), 8: (1, 0.19365215953439474), 9: (1, 0.1968407928943634), 10: (1, 0.19723371788859367), 11: (1, 0.19630474969744682), 12: (1, 0.1961213406175375), 13: (1, 0.19473782740533352), 14: (1, 0.19670767523348331), 15: (1, 0.19542279094457626), 16: (1, 0.19742529839277267), 17: (1, 0.19560358952730894), 18: (1, 0.19600767362862825), 19: (1, 0.20720089226961136), 20: (1, 0.19792598206549883), 21: (1, 0.19646984990686178), 22: (1, 0.19760177750140429), 23: (1, 0.1980040930211544), 24: (1, 0.2027039472013712), 25: (1, 0.2043750872835517), 26: (1, 0.20443985238671303), 27: (1, 0.19699755124747753), 28: (1, 0.19960106071084738), 29: (1, 0.19448283221572638), 30: (1, 0.19649929832667112), 31: (1, 0.19780036341398954), 32: (1, 0.19594605546444654), 33: (1, 0.19664057623595), 34: (1, 0.19682777393609285), 35: (1, 0.19420797564089298), 36: (1, 0.1971122920513153), 37: (1, 0.19548913184553385), 38: (1, 0.1972573008388281), 39: (1, 0.1946374224498868), 40: (1, 0.19663152936846018), 41: (1, 0.1958509273827076), 42: (1, 0.19688651617616415), 43: (1, 0.19394944235682487), 44: (1, 0.19494677893817425), 45: (1, 0.1960574658587575), 46: (1, 0.1966115701943636), 47: (1, 0.19651376083493233), 48: (1, 0.19635080266743898), 49: (1, 0.1950238598510623), 50: (1, 0.1963075753301382), 51: (1, 0.19397567305713892), 52: (1, 0.19657262228429317), 53: (1, 0.19353831838816404), 54: (1, 0.1948660220950842), 55: (1, 0.19328980147838593), 56: (1, 0.19483415316790342), 57: (1, 0.1933737201616168), 58: (1, 0.19671225175261497), 59: (1, 0.1946957539767027), 60: (1, 0.1954195974394679), 61: (1, 0.19448835868388414), 62: (1, 0.19517692178487778), 63: (1, 0.19712193030864), 64: (1, 0.19496992602944374), 65: (1, 0.19572020694613457), 66: (1, 0.1942376047372818), 67: (1, 0.1973616275936365), 68: (1, 0.19639576971530914), 69: (1, 0.19642163906246424), 70: (1, 0.19578212592750788), 71: (1, 0.19330225605517626)}\n",
      "{1: (1, 255, 0.11638455096559197), 2: (1, 255, 0.1174401893408275), 3: (1, 255, 0.11649234784657464), 4: (1, 255, 0.11713644213170982), 5: (1, 255, 0.11928964476740243), 6: (1, 255, 0.11636213011601391), 7: (1, 255, 0.11536939051367488), 8: (1, 255, 0.11520605744684444), 9: (1, 255, 0.11721756097805851), 10: (1, 255, 0.11618311598020441), 11: (1, 255, 0.11591312798726208), 12: (1, 255, 0.11586474260570956), 13: (1, 255, 0.11581476092995967), 14: (1, 255, 0.11702393219605381), 15: (1, 255, 0.11570774699177812), 16: (1, 255, 0.11548975232769461), 17: (1, 255, 0.11574733876349295), 18: (1, 255, 0.11719354742078804), 19: (1, 255, 0.11862939626855008), 20: (1, 255, 0.11577029203009956), 21: (1, 255, 0.11555500143737185), 22: (1, 255, 0.11659988606092976), 23: (1, 255, 0.11647778958739603), 24: (1, 255, 0.117361559536235), 25: (1, 255, 0.11701569706566778), 26: (1, 255, 0.11658561569729857), 27: (1, 255, 0.11617029854918227), 28: (1, 255, 0.1163689793726685), 29: (1, 255, 0.11583790975969796), 30: (1, 255, 0.11542858508433781), 31: (1, 255, 0.11541657629696762), 32: (1, 255, 0.11567323074548268), 33: (1, 255, 0.11640653704092199), 34: (1, 255, 0.11560736531939576), 35: (1, 255, 0.11558167190820563), 36: (1, 255, 0.11558224563212956), 37: (1, 255, 0.11531866482075523), 38: (1, 255, 0.11541764372411896), 39: (1, 255, 0.11525296498747432), 40: (1, 255, 0.1152355149607448), 41: (1, 255, 0.11525921076536179), 42: (1, 255, 0.11543974908543568), 43: (1, 255, 0.11549043993593432), 44: (1, 255, 0.1153380543030068), 45: (1, 255, 0.11547924309384588), 46: (1, 255, 0.11539986238760107), 47: (1, 255, 0.11524140270901662), 48: (1, 255, 0.1151544616977666), 49: (1, 255, 0.11504215710595542), 50: (1, 255, 0.11510284861513212), 51: (1, 255, 0.11541324840749011), 52: (1, 255, 0.11548633309921214), 53: (1, 255, 0.11544838704022707), 54: (1, 255, 0.11543952956722647), 55: (1, 255, 0.11545258379888301), 56: (1, 255, 0.1155666248215472), 57: (1, 255, 0.11573559700274), 58: (1, 255, 0.1161680372249262), 59: (1, 255, 0.11573989724776909), 60: (1, 255, 0.11983165651486785), 61: (1, 255, 0.11550280825034076), 62: (1, 255, 0.11537420514459704), 63: (1, 255, 0.11574397535227678), 64: (1, 255, 0.11591588830684914), 65: (1, 255, 0.11583180316157785), 66: (1, 255, 0.11599386697087218), 67: (1, 255, 0.11579293787990715), 68: (1, 255, 0.11569859700679194), 69: (1, 255, 0.11582062352886971), 70: (1, 255, 0.11572468918839506)}\n",
      "{'predict_runtime': 2114.2889, 'predict_samples_per_second': 0.034, 'predict_steps_per_second': 0.034}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:35:14.28\n",
      "  predict_samples_per_second =      0.034\n",
      "  predict_steps_per_second   =      0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2477486003190279), 2: (2, 0.21650035120546818), 3: (2, 0.2203006660565734), 4: (2, 0.22397681418806314), 5: (2, 0.24294089898467064), 6: (2, 0.21997705195099115), 7: (2, 0.20801933389157057), 8: (2, 0.23413717281073332), 9: (2, 0.20964808482676744), 10: (2, 0.25135823991149664), 11: (2, 0.22017094027251005), 12: (2, 0.21665204223245382), 13: (2, 0.245282213203609), 14: (2, 0.21022063959389925), 15: (2, 0.23207884933799505), 16: (2, 0.21259327046573162), 17: (2, 0.21633359603583813), 18: (2, 0.21417392883449793), 19: (2, 0.2081836275756359), 20: (2, 0.21209425199776888), 21: (2, 0.22633974719792604), 22: (2, 0.21347762551158667), 23: (2, 0.208954319357872), 24: (2, 0.22274947818368673), 25: (2, 0.31611573323607445), 26: (2, 0.25684608798474073), 27: (2, 0.25306921172887087), 28: (2, 0.20768140442669392), 29: (2, 0.25931847747415304), 30: (2, 0.2186458557844162), 31: (2, 0.25187805481255054), 32: (2, 0.22827996220439672), 33: (2, 0.21663651894778013), 34: (2, 0.25128154642879963), 35: (2, 0.2159822592511773), 36: (2, 0.2374782580882311), 37: (2, 0.25137703493237495), 38: (2, 0.21653423178941011), 39: (2, 0.23661363683640957), 40: (2, 0.20860507246106863), 41: (2, 0.21592347789555788), 42: (2, 0.2552085490897298), 43: (2, 0.23336597345769405), 44: (2, 0.21298056188970804), 45: (2, 0.21790685411542654), 46: (2, 0.24720708187669516), 47: (2, 0.2181207025423646), 48: (2, 0.21332180686295033), 49: (2, 0.21369922254234552), 50: (2, 0.24137137830257416), 51: (2, 0.21661857888102531), 52: (2, 0.2160801338031888), 53: (2, 0.21765990648418665), 54: (2, 0.21197194140404463), 55: (2, 0.2267282996326685), 56: (2, 0.25944532733410597), 57: (2, 0.24098845198750496), 58: (2, 0.21541483141481876), 59: (2, 0.21460399962961674), 60: (2, 0.25277782417833805), 61: (2, 0.2404018985107541), 62: (2, 0.21188600175082684), 63: (2, 0.2474991250783205), 64: (2, 0.24575124494731426), 65: (2, 0.23831920139491558), 66: (2, 0.24682299327105284), 67: (2, 0.24664552323520184), 68: (2, 0.24655091483145952), 69: (2, 0.25036212150007486), 70: (2, 0.2076209494844079), 71: (1, 0.22498701699078083)}\n",
      "{1: (2, 255, 0.17879463452845812), 2: (2, 255, 0.1779700794531142), 3: (2, 255, 0.17941305186672538), 4: (2, 255, 0.18197391667202406), 5: (2, 255, 0.17839223115029287), 6: (2, 255, 0.1783425239736543), 7: (2, 255, 0.17820134082188208), 8: (2, 255, 0.17810977613370793), 9: (2, 255, 0.17816964839311206), 10: (2, 255, 0.17811340920115803), 11: (2, 255, 0.17830451715591492), 12: (2, 255, 0.1783184234892913), 13: (2, 255, 0.17823942322649208), 14: (2, 255, 0.17800991796322313), 15: (2, 255, 0.17836850651850303), 16: (2, 255, 0.1785422631411576), 17: (2, 255, 0.17851655128247598), 18: (2, 255, 0.17813973995108232), 19: (2, 255, 0.17807816946331192), 20: (2, 255, 0.17810034567453698), 21: (2, 255, 0.17813232852255598), 22: (2, 255, 0.1782334176604362), 23: (2, 255, 0.17825137725939938), 24: (2, 255, 0.17801785412080148), 25: (2, 255, 0.1801366090847581), 26: (2, 255, 0.17813410552620304), 27: (2, 255, 0.1781041907950067), 28: (2, 255, 0.17809823754006157), 29: (2, 255, 0.17795534146328768), 30: (2, 255, 0.17790660585331566), 31: (2, 255, 0.17792212459094384), 32: (2, 255, 0.1777564368922921), 33: (2, 255, 0.17742025174346623), 34: (2, 255, 0.17749486326002606), 35: (2, 255, 0.17745205275714399), 36: (2, 255, 0.17752093292188412), 37: (2, 255, 0.17755991845008204), 38: (2, 255, 0.1774826043230646), 39: (2, 255, 0.1776995802115576), 40: (2, 255, 0.1774979457405268), 41: (2, 255, 0.1777783259785935), 42: (2, 255, 0.1776538237819777), 43: (2, 255, 0.17762571524317358), 44: (2, 255, 0.17745265240470567), 45: (2, 255, 0.17746439493243016), 46: (2, 255, 0.1775147346195345), 47: (2, 255, 0.17760633402230108), 48: (2, 255, 0.17761095848811023), 49: (2, 255, 0.1774839089197271), 50: (2, 255, 0.17786615470095593), 51: (2, 255, 0.17795325423791714), 52: (2, 255, 0.17760715115742357), 53: (2, 255, 0.17752939498088524), 54: (2, 255, 0.17869278614354484), 55: (2, 255, 0.1779701526806343), 56: (2, 255, 0.17769662123173474), 57: (2, 255, 0.17770073473380477), 58: (2, 255, 0.1775922715992612), 59: (2, 255, 0.17744271818767576), 60: (2, 255, 0.17734739944411843), 61: (2, 255, 0.17750704677812024), 62: (2, 255, 0.17744869184406364), 63: (2, 255, 0.17733993565334993), 64: (2, 255, 0.17748025079056912), 65: (2, 255, 0.1773978655500447), 66: (2, 255, 0.17741304262376884), 67: (2, 255, 0.17753139652457892), 68: (2, 255, 0.17736986201694782), 69: (2, 255, 0.17755125593394042), 70: (2, 255, 0.17746470259392963)}\n",
      "{'predict_runtime': 3222.198, 'predict_samples_per_second': 0.044, 'predict_steps_per_second': 0.022}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:53:42.19\n",
      "  predict_samples_per_second =      0.044\n",
      "  predict_steps_per_second   =      0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.3056099722161889), 2: (4, 0.27414780110120773), 3: (4, 0.275086909532547), 4: (4, 0.2732336921617389), 5: (4, 0.27944599930197), 6: (4, 0.28082688339054585), 7: (4, 0.2763137258589268), 8: (4, 0.28197122644633055), 9: (4, 0.28057837300002575), 10: (4, 0.27740500774234533), 11: (4, 0.27201374992728233), 12: (4, 0.28028547391295433), 13: (4, 0.2758364053443074), 14: (4, 0.27162178233265877), 15: (4, 0.2736434303224087), 16: (4, 0.27928326465189457), 17: (4, 0.27494540344923735), 18: (4, 0.2804017495363951), 19: (4, 0.2754809055477381), 20: (4, 0.273194563575089), 21: (4, 0.2754454854875803), 22: (4, 0.27435801830142736), 23: (4, 0.27169510815292597), 24: (4, 0.27432225830852985), 25: (4, 0.2786642974242568), 26: (4, 0.27654221188277006), 27: (4, 0.27655739057809114), 28: (4, 0.27390466164797544), 29: (4, 0.2742847567424178), 30: (4, 0.2761422451585531), 31: (4, 0.273387735709548), 32: (4, 0.27508126478642225), 33: (4, 0.2764577688649297), 34: (4, 0.2753394516184926), 35: (4, 0.27750853542238474), 36: (4, 0.2755093974992633), 37: (4, 0.27777392975986004), 38: (4, 0.28391335997730494), 39: (4, 0.27767648082226515), 40: (4, 0.27387333288788795), 41: (4, 0.27559866290539503), 42: (4, 0.27308949921280146), 43: (4, 0.27576220873743296), 44: (4, 0.2741802269592881), 45: (4, 0.27513033617287874), 46: (4, 0.2716928943991661), 47: (4, 0.27257923409342766), 48: (4, 0.27482882607728243), 49: (4, 0.27729548793286085), 50: (4, 0.27613715920597315), 51: (4, 0.27726572658866644), 52: (4, 0.27740511391311884), 53: (4, 0.27398508321493864), 54: (4, 0.2765951054170728), 55: (4, 0.2757556950673461), 56: (4, 0.2730054650455713), 57: (4, 0.2757787723094225), 58: (4, 0.274907642044127), 59: (4, 0.27760664001107216), 60: (4, 0.27755390945822), 61: (4, 0.27440324518829584), 62: (4, 0.2724943570792675), 63: (4, 0.2845937963575125), 64: (4, 0.2740852069109678), 65: (4, 0.274251745082438), 66: (4, 0.2865159325301647), 67: (4, 0.27442467119544744), 68: (4, 0.2731345659121871), 69: (4, 0.27758846431970596), 70: (4, 0.27119268756359816), 71: (1, 0.19767787028104067)}\n",
      "{1: (4, 255, 0.18003000429667093), 2: (4, 255, 0.1792999884077147), 3: (4, 255, 0.1788407335496124), 4: (4, 255, 0.17882879835498683), 5: (4, 255, 0.17897251385318882), 6: (4, 255, 0.17876998885881668), 7: (4, 255, 0.178873683395339), 8: (4, 255, 0.1786735893647168), 9: (4, 255, 0.17885281006422113), 10: (4, 255, 0.17891992018284167), 11: (4, 255, 0.17870666350365855), 12: (4, 255, 0.17877983178797305), 13: (4, 255, 0.17882021724739494), 14: (4, 255, 0.17874607452940122), 15: (4, 255, 0.17862318156323598), 16: (4, 255, 0.17857418864892394), 17: (4, 255, 0.17856259177639788), 18: (4, 255, 0.1786381134288568), 19: (4, 255, 0.17891052496053425), 20: (4, 255, 0.17868679447063043), 21: (4, 255, 0.17863783850973727), 22: (4, 255, 0.17870354887609388), 23: (4, 255, 0.17866256353536658), 24: (4, 255, 0.1786741384067664), 25: (4, 255, 0.17864094843686212), 26: (4, 255, 0.17875287843247253), 27: (4, 255, 0.17877335901938232), 28: (4, 255, 0.17864734663390647), 29: (4, 255, 0.17854809806335206), 30: (4, 255, 0.1786257700300684), 31: (4, 255, 0.17864126298284413), 32: (4, 255, 0.1785282901689118), 33: (4, 255, 0.17858136703132416), 34: (4, 255, 0.17856981287180793), 35: (4, 255, 0.17862976445798195), 36: (4, 255, 0.17865222309734308), 37: (4, 255, 0.1785984170093548), 38: (4, 255, 0.1785405908912128), 39: (4, 255, 0.1785508033362966), 40: (4, 255, 0.17858027066378032), 41: (4, 255, 0.17854369722452818), 42: (4, 255, 0.17852063050091851), 43: (4, 255, 0.1785973934128004), 44: (4, 255, 0.17865911885438596), 45: (4, 255, 0.17851914509254344), 46: (4, 255, 0.17846664993421119), 47: (4, 255, 0.17844094189577828), 48: (4, 255, 0.17842646642935042), 49: (4, 255, 0.17848377164234133), 50: (4, 255, 0.1784704714684802), 51: (4, 255, 0.17851814455991866), 52: (4, 255, 0.1785345065973553), 53: (4, 255, 0.17849092345830855), 54: (4, 255, 0.1785074819427203), 55: (4, 255, 0.1783922061360642), 56: (4, 255, 0.17847090677230382), 57: (4, 255, 0.17894335314631463), 58: (4, 255, 0.1785400017438566), 59: (4, 255, 0.17841413847225554), 60: (4, 255, 0.17837708567214364), 61: (4, 255, 0.1783663638703087), 62: (4, 255, 0.17841107618136734), 63: (4, 255, 0.1784204882003513), 64: (4, 255, 0.17843330425812917), 65: (4, 255, 0.17842113053535713), 66: (4, 255, 0.17847522511055655), 67: (4, 255, 0.17854652816027988), 68: (4, 255, 0.1784640714489654), 69: (4, 255, 0.1783798888398736), 70: (4, 255, 0.17847554009480804)}\n",
      "{'predict_runtime': 3237.4728, 'predict_samples_per_second': 0.087, 'predict_steps_per_second': 0.022}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:53:57.47\n",
      "  predict_samples_per_second =      0.087\n",
      "  predict_steps_per_second   =      0.022\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 22\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/71 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (1, 0.23761594109237194), 2: (1, 0.20645896904170513), 3: (1, 0.20588213484734297), 4: (1, 0.20378837920725346), 5: (1, 0.2022082069888711), 6: (1, 0.20709967985749245), 7: (1, 0.20317804533988237), 8: (1, 0.20120059698820114), 9: (1, 0.2013887157663703), 10: (1, 0.20576505456119776), 11: (1, 0.20277945790439844), 12: (1, 0.20489723421633244), 13: (1, 0.2029101951047778), 14: (1, 0.20207740552723408), 15: (1, 0.20301047526299953), 16: (1, 0.2026186492294073), 17: (1, 0.20142544247210026), 18: (1, 0.2020335365086794), 19: (1, 0.20498228073120117), 20: (1, 0.20389654394239187), 21: (1, 0.2026436971500516), 22: (1, 0.20287368446588516), 23: (1, 0.20201637502759695), 24: (1, 0.20319531951099634), 25: (1, 0.20371212344616652), 26: (1, 0.20211293175816536), 27: (1, 0.20250563696026802), 28: (1, 0.20062061864882708), 29: (1, 0.2047399114817381), 30: (1, 0.2021156521514058), 31: (1, 0.20338740572333336), 32: (1, 0.2044137753546238), 33: (1, 0.20417419634759426), 34: (1, 0.20308756921440363), 35: (1, 0.2031604591757059), 36: (1, 0.20326031558215618), 37: (1, 0.2033458249643445), 38: (1, 0.20175158511847258), 39: (1, 0.20424290373921394), 40: (1, 0.20107337180525064), 41: (1, 0.20337596535682678), 42: (1, 0.2007226636633277), 43: (1, 0.20450806710869074), 44: (1, 0.20237889047712088), 45: (1, 0.20453697443008423), 46: (1, 0.20430693868547678), 47: (1, 0.20246647763997316), 48: (1, 0.20375935267657042), 49: (1, 0.20119381230324507), 50: (1, 0.20471030194312334), 51: (1, 0.2016268763691187), 52: (1, 0.20330073684453964), 53: (1, 0.2073801001533866), 54: (1, 0.20238514710217714), 55: (1, 0.20154279563575983), 56: (1, 0.2012407574802637), 57: (1, 0.2055713189765811), 58: (1, 0.20294147916138172), 59: (1, 0.20178486220538616), 60: (1, 0.20445742085576057), 61: (1, 0.20333997439593077), 62: (1, 0.2042949115857482), 63: (1, 0.20514199323952198), 64: (1, 0.20109573658555746), 65: (1, 0.20311798341572285), 66: (1, 0.20643136650323868), 67: (1, 0.2031409740447998), 68: (1, 0.20341333094984293), 69: (1, 0.2022604225203395), 70: (1, 0.20387937501072884), 71: (1, 0.2037534862756729)}\n",
      "{1: (1, 255, 0.12082173651559096), 2: (1, 255, 0.12017420566111219), 3: (1, 255, 0.12029266663845263), 4: (1, 255, 0.12028601579733339), 5: (1, 255, 0.1202853750839245), 6: (1, 255, 0.12011893836087456), 7: (1, 255, 0.12003106465380566), 8: (1, 255, 0.12016323296828013), 9: (1, 255, 0.12040703729452455), 10: (1, 255, 0.1202134916741474), 11: (1, 255, 0.1201753897482858), 12: (1, 255, 0.12029919962161312), 13: (1, 255, 0.12034189685010442), 14: (1, 255, 0.12020802932480971), 15: (1, 255, 0.12032116559133225), 16: (1, 255, 0.12018465422386047), 17: (1, 255, 0.12009470494573607), 18: (1, 255, 0.12007163803586189), 19: (1, 255, 0.12000704588112877), 20: (1, 255, 0.1198987673748942), 21: (1, 255, 0.11984760373027302), 22: (1, 255, 0.11989103618132717), 23: (1, 255, 0.12007947594438698), 24: (1, 255, 0.11999733038977081), 25: (1, 255, 0.12012185575623138), 26: (1, 255, 0.11992260041263174), 27: (1, 255, 0.11994312540354098), 28: (1, 255, 0.1199682692869329), 29: (1, 255, 0.12011704652698017), 30: (1, 255, 0.12012304392661534), 31: (1, 255, 0.12007677483134994), 32: (1, 255, 0.12004178509335307), 33: (1, 255, 0.12004597993092794), 34: (1, 255, 0.11999697349235124), 35: (1, 255, 0.1200582234006302), 36: (1, 255, 0.12005617607604055), 37: (1, 255, 0.12010124239924491), 38: (1, 255, 0.12011291911350745), 39: (1, 255, 0.12016182693050188), 40: (1, 255, 0.12015524456167923), 41: (1, 255, 0.12003563561421983), 42: (1, 255, 0.12011952814372147), 43: (1, 255, 0.12013547111886974), 44: (1, 255, 0.11995593627147814), 45: (1, 255, 0.11994005329541715), 46: (1, 255, 0.11987502832769178), 47: (1, 255, 0.11989941506409178), 48: (1, 255, 0.11992247929321785), 49: (1, 255, 0.12004212451477846), 50: (1, 255, 0.12029697361822221), 51: (1, 255, 0.12026931533918661), 52: (1, 255, 0.120964075851382), 53: (1, 255, 0.12042000996423703), 54: (1, 255, 0.1202783125507481), 55: (1, 255, 0.12031345046399271), 56: (1, 255, 0.12028888129063096), 57: (1, 255, 0.12029986473202121), 58: (1, 255, 0.12030999214552782), 59: (1, 255, 0.12028473608341872), 60: (1, 255, 0.12025449733231582), 61: (1, 255, 0.1202990465560088), 62: (1, 255, 0.12025314128282023), 63: (1, 255, 0.12036877343175457), 64: (1, 255, 0.12098471735987593), 65: (1, 255, 0.12081000373936167), 66: (1, 255, 0.12045781190196674), 67: (1, 255, 0.12041505055830759), 68: (1, 255, 0.12025105972938678), 69: (1, 255, 0.12021556246441369), 70: (1, 255, 0.12028094185333627)}\n",
      "{'predict_runtime': 2190.5653, 'predict_samples_per_second': 0.032, 'predict_steps_per_second': 0.032}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:36:30.56\n",
      "  predict_samples_per_second =      0.032\n",
      "  predict_steps_per_second   =      0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([2, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([2, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (2, 0.2526182206347585), 2: (2, 0.25320105254650116), 3: (2, 0.22186587937176228), 4: (2, 0.24668405577540398), 5: (2, 0.22369855549186468), 6: (2, 0.25538757629692554), 7: (2, 0.22274198848754168), 8: (2, 0.22449959721416235), 9: (2, 0.22142121102660894), 10: (2, 0.22755574062466621), 11: (2, 0.2447410449385643), 12: (2, 0.2586688557639718), 13: (2, 0.23774763382971287), 14: (2, 0.22115602251142263), 15: (2, 0.23354468122124672), 16: (2, 0.22077582497149706), 17: (2, 0.2564940582960844), 18: (2, 0.2476482391357422), 19: (2, 0.23767649289220572), 20: (2, 0.25919001549482346), 21: (2, 0.22136599756777287), 22: (2, 0.22521464340388775), 23: (2, 0.23988590482622385), 24: (2, 0.23571088165044785), 25: (2, 0.23093130625784397), 26: (2, 0.2448839070275426), 27: (2, 0.22678394336253405), 28: (2, 0.25962353870272636), 29: (2, 0.22107144817709923), 30: (2, 0.2517481567338109), 31: (2, 0.24809480924159288), 32: (2, 0.25733259320259094), 33: (2, 0.21955788414925337), 34: (2, 0.26595156360417604), 35: (2, 0.2299139341339469), 36: (2, 0.2223330857232213), 37: (2, 0.24735612887889147), 38: (2, 0.262687424197793), 39: (2, 0.2620752714574337), 40: (2, 0.26387389842420816), 41: (2, 0.23070870898663998), 42: (2, 0.22482835594564676), 43: (2, 0.2323453789576888), 44: (2, 0.258799416013062), 45: (2, 0.2250310517847538), 46: (2, 0.2197832828387618), 47: (2, 0.22381398640573025), 48: (2, 0.2256891643628478), 49: (2, 0.226062280125916), 50: (2, 0.25590268801897764), 51: (2, 0.2223205715417862), 52: (2, 0.24720600713044405), 53: (2, 0.22660433128476143), 54: (2, 0.2212883746251464), 55: (2, 0.2522874679416418), 56: (2, 0.26163967978209257), 57: (2, 0.2229713834822178), 58: (2, 0.2624234016984701), 59: (2, 0.22882539685815573), 60: (2, 0.22042315360158682), 61: (2, 0.2607049811631441), 62: (2, 0.2241150802001357), 63: (2, 0.2420902531594038), 64: (2, 0.25975655019283295), 65: (2, 0.2312787165865302), 66: (2, 0.21967092994600534), 67: (2, 0.2248035306110978), 68: (2, 0.25949167273938656), 69: (2, 0.22622220404446125), 70: (2, 0.24603432696312666), 71: (1, 0.21460258681327105)}\n",
      "{1: (2, 255, 0.1863273583535178), 2: (2, 255, 0.18597239667513207), 3: (2, 255, 0.18574350549675087), 4: (2, 255, 0.18573551934723762), 5: (2, 255, 0.18582211831475007), 6: (2, 255, 0.18570603768834296), 7: (2, 255, 0.18580454593779994), 8: (2, 255, 0.1857858279318202), 9: (2, 255, 0.18588803571959336), 10: (2, 255, 0.18589241890346303), 11: (2, 255, 0.18631885391020891), 12: (2, 255, 0.18609549934227093), 13: (2, 255, 0.18607718240396648), 14: (2, 255, 0.18605423524391418), 15: (2, 255, 0.1860320752194407), 16: (2, 255, 0.1860721132809333), 17: (2, 255, 0.18586375965718546), 18: (2, 255, 0.18604457642810018), 19: (2, 255, 0.18590264970838438), 20: (2, 255, 0.18591374736644473), 21: (2, 255, 0.18598389960825443), 22: (2, 255, 0.1857517167487565), 23: (2, 255, 0.18586264285167642), 24: (2, 255, 0.18581244400976335), 25: (2, 255, 0.18584422442477708), 26: (2, 255, 0.1858105134036319), 27: (2, 255, 0.18576974830060614), 28: (2, 255, 0.18588944063248003), 29: (2, 255, 0.18569941418428046), 30: (2, 255, 0.1855957507575844), 31: (2, 255, 0.18541826817627047), 32: (2, 255, 0.18559757685836623), 33: (2, 255, 0.18547446586045566), 34: (2, 255, 0.18545801071632725), 35: (2, 255, 0.18566889271286188), 36: (2, 255, 0.18551549568918405), 37: (2, 255, 0.18539318215175002), 38: (2, 255, 0.18551067627382045), 39: (2, 255, 0.18549145482772705), 40: (2, 255, 0.18546074406042987), 41: (2, 255, 0.1856374355434787), 42: (2, 255, 0.1855416372601016), 43: (2, 255, 0.1854173001997611), 44: (2, 255, 0.18542820857655185), 45: (2, 255, 0.18563857670581224), 46: (2, 255, 0.18551379961929484), 47: (2, 255, 0.18554450310766696), 48: (2, 255, 0.18548843877061325), 49: (2, 255, 0.18556563949175908), 50: (2, 255, 0.18552621736684266), 51: (2, 255, 0.18555096319931394), 52: (2, 255, 0.18551416265248669), 53: (2, 255, 0.1855108129773654), 54: (2, 255, 0.1854353782410423), 55: (2, 255, 0.18540778520571835), 56: (2, 255, 0.18552892331910484), 57: (2, 255, 0.18531921542815719), 58: (2, 255, 0.18548405049916575), 59: (2, 255, 0.1856242663245283), 60: (2, 255, 0.18520898542494751), 61: (2, 255, 0.18558900556435773), 62: (2, 255, 0.1854793623856762), 63: (2, 255, 0.18525776323296275), 64: (2, 255, 0.18544467445097718), 65: (2, 255, 0.18551442988728192), 66: (2, 255, 0.18538813164421156), 67: (2, 255, 0.1853511641057683), 68: (2, 255, 0.18548826696533782), 69: (2, 255, 0.18529530216154513), 70: (2, 255, 0.1855083128620012)}\n",
      "{'predict_runtime': 3361.6251, 'predict_samples_per_second': 0.042, 'predict_steps_per_second': 0.021}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:56:01.62\n",
      "  predict_samples_per_second =      0.042\n",
      "  predict_steps_per_second   =      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train dataset in train and validation according to `eval_dataset_size`\n",
      "input_ids shape: torch.Size([4, 129])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([4, 129])\n",
      "input_ids shape: torch.Size([1, 129])\n",
      "{1: (4, 0.31191268004477024), 2: (4, 0.2875409107655287), 3: (4, 0.29039986710995436), 4: (4, 0.28841551672667265), 5: (4, 0.28652435820549726), 6: (4, 0.2883747471496463), 7: (4, 0.2844147626310587), 8: (4, 0.2906106011942029), 9: (4, 0.2867667945101857), 10: (4, 0.28622631076723337), 11: (4, 0.3281750688329339), 12: (4, 0.2865253761410713), 13: (4, 0.284729796461761), 14: (4, 0.2855484476312995), 15: (4, 0.285398880019784), 16: (4, 0.28971191961318254), 17: (4, 0.28955492191016674), 18: (4, 0.28533503878861666), 19: (4, 0.28650268632918596), 20: (4, 0.28724671714007854), 21: (4, 0.28649126552045345), 22: (4, 0.2842169823125005), 23: (4, 0.2895255656912923), 24: (4, 0.2886268263682723), 25: (4, 0.28745310939848423), 26: (4, 0.2883826084434986), 27: (4, 0.285062987357378), 28: (4, 0.2861672844737768), 29: (4, 0.28829908929765224), 30: (4, 0.2862667525187135), 31: (4, 0.2861227737739682), 32: (4, 0.2864564601331949), 33: (4, 0.2902287757024169), 34: (4, 0.2915592510253191), 35: (4, 0.2888153837993741), 36: (4, 0.2888330528512597), 37: (4, 0.2866964880377054), 38: (4, 0.29775951988995075), 39: (4, 0.2883675182238221), 40: (4, 0.2876089261844754), 41: (4, 0.28518934454768896), 42: (4, 0.2859988948330283), 43: (4, 0.2895196136087179), 44: (4, 0.2926143677905202), 45: (4, 0.2874511880800128), 46: (4, 0.29223844315856695), 47: (4, 0.28560836985707283), 48: (4, 0.28597223572432995), 49: (4, 0.2892068764194846), 50: (4, 0.2880762815475464), 51: (4, 0.28701209276914597), 52: (4, 0.2860820731148124), 53: (4, 0.2878693025559187), 54: (4, 0.2847493477165699), 55: (4, 0.2870591916143894), 56: (4, 0.2826484329998493), 57: (4, 0.28439702186733484), 58: (4, 0.2847708985209465), 59: (4, 0.2873450983315706), 60: (4, 0.2859735041856766), 61: (4, 0.2897055307403207), 62: (4, 0.28674579598009586), 63: (4, 0.2866076370701194), 64: (4, 0.2859845543280244), 65: (4, 0.289227357134223), 66: (4, 0.2830780567601323), 67: (4, 0.29048393201082945), 68: (4, 0.28738303761929274), 69: (4, 0.2926747063174844), 70: (4, 0.28180095460265875), 71: (1, 0.20742431934922934)}\n",
      "{1: (4, 255, 0.18753866742127667), 2: (4, 255, 0.18708386005578087), 3: (4, 255, 0.18695161030353868), 4: (4, 255, 0.18691634053693099), 5: (4, 255, 0.1866331493920263), 6: (4, 255, 0.18672838017490564), 7: (4, 255, 0.18663683341925635), 8: (4, 255, 0.1866876012262176), 9: (4, 255, 0.18674425198970473), 10: (4, 255, 0.1865185384693391), 11: (4, 255, 0.18682080813336607), 12: (4, 255, 0.18680270810921987), 13: (4, 255, 0.18682202593441688), 14: (4, 255, 0.1868290131546411), 15: (4, 255, 0.18675948831015357), 16: (4, 255, 0.18671022872714435), 17: (4, 255, 0.18673144473383824), 18: (4, 255, 0.18677169934061227), 19: (4, 255, 0.1867642502610882), 20: (4, 255, 0.18657794348238146), 21: (4, 255, 0.18661747884151397), 22: (4, 255, 0.18668485712990457), 23: (4, 255, 0.1866387632036326), 24: (4, 255, 0.18662613924665777), 25: (4, 255, 0.18662638404570958), 26: (4, 255, 0.18668094390236278), 27: (4, 255, 0.1865956999982397), 28: (4, 255, 0.18662717051657976), 29: (4, 255, 0.1867826622782969), 30: (4, 255, 0.1866607628762722), 31: (4, 255, 0.18674736636526446), 32: (4, 255, 0.18668784770530228), 33: (4, 255, 0.18670551646135602), 34: (4, 255, 0.1866603081023284), 35: (4, 255, 0.18668527253994754), 36: (4, 255, 0.18668086736225614), 37: (4, 255, 0.18689184761880076), 38: (4, 255, 0.18681510562698048), 39: (4, 255, 0.18691750811595542), 40: (4, 255, 0.18727006510849678), 41: (4, 255, 0.1869846234353734), 42: (4, 255, 0.18665977376056653), 43: (4, 255, 0.18906268488396616), 44: (4, 255, 0.18752513851093897), 45: (4, 255, 0.18700211726713414), 46: (4, 255, 0.1865604911693463), 47: (4, 255, 0.186507362200349), 48: (4, 255, 0.1863152122161552), 49: (4, 255, 0.18652484026171412), 50: (4, 255, 0.18636650874407268), 51: (4, 255, 0.18636339540575064), 52: (4, 255, 0.18641412747549077), 53: (4, 255, 0.18633628488317425), 54: (4, 255, 0.18635164095344497), 55: (4, 255, 0.18636577650174208), 56: (4, 255, 0.18633870402095365), 57: (4, 255, 0.18633545742315405), 58: (4, 255, 0.18629845364347977), 59: (4, 255, 0.18637009818545158), 60: (4, 255, 0.18634586006622103), 61: (4, 255, 0.1863448948909839), 62: (4, 255, 0.18639954614142576), 63: (4, 255, 0.18627977770771467), 64: (4, 255, 0.18640951162532848), 65: (4, 255, 0.18628324856433798), 66: (4, 255, 0.18630520591841024), 67: (4, 255, 0.1862864250317216), 68: (4, 255, 0.1863190251639953), 69: (4, 255, 0.18631312670734), 70: (4, 255, 0.18622580430306057)}\n",
      "{'predict_runtime': 3383.0734, 'predict_samples_per_second': 0.083, 'predict_steps_per_second': 0.021}\n",
      "***** predict metrics *****\n",
      "  predict_runtime            = 0:56:23.07\n",
      "  predict_samples_per_second =      0.083\n",
      "  predict_steps_per_second   =      0.021\n"
     ]
    }
   ],
   "source": [
    "args.eval_num_width = 1.0\n",
    "args.eval_num_layer = 23\n",
    "key = f'l{args.eval_num_layer}w{args.eval_num_width}sml{args.source_max_len}mnt256'\n",
    "results = {}\n",
    "results[key] = []\n",
    "ttfts = []\n",
    "tbts = []\n",
    "\n",
    "for bs in [1, 2, 4]:\n",
    "    training_args.per_device_eval_batch_size = bs\n",
    "    args.eval_dataset_size = training_args.per_device_eval_batch_size * 70 + 1\n",
    "    data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        **{k: v for k, v in data_module.items() if k != \"predict_dataset\"},\n",
    "    )\n",
    "    ttft, tbt = profile_latencies(model, tokenizer, args, logger, trainer, data_module)\n",
    "    ttfts.append(ttft)\n",
    "    tbts.append(tbt)\n",
    "    results[key].append(get_latency_stats(ttft, tbt, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'latency_results_{key}.json', 'w') as fout:\n",
    "    json.dump(results, fout)\n",
    "with open(f'latencies_{key}.json', 'w') as fout:\n",
    "    json.dump({'ttft': ttfts, 'tbt': tbts}, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amoaballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
